# FinAI: AI-Native Financial Intelligence System
## Technical Deep-Dive Specification (TDD)
### Complete 6-Module Architecture Documentation

---

## üìã METADATA (Document Header)

| Field | Value |
|-------|-------|
| **Title** | FinAI: 6-Module AI-Native Architecture ‚Äî Technical Deep-Dive |
| **Product** | FinAI (Financial AI Intelligence Platform) |
| **Version** | 1.0.0 (MVP Enterprise) |
| **Status** | Approved for International Submission |
| **Author** | FinAI Architecture Team |
| **Reviewers** | CTO, Product Lead, Security Officer |
| **Created** | December 2025 |
| **Last Updated** | December 10, 2025 |
| **Classification** | Technical Architecture (Public) |
| **Related Docs** | API Spec, Security Whitepaper, Operations Runbook, Deployment Guide |

---

## EXECUTIVE SUMMARY (TL;DR)

**Problem Statement:**  
Modern financial intelligence systems require real-time synthesis of multi-source data (market feeds, corporate filings, research reports) with AI-powered reasoning. Existing solutions suffer from high latency (>30s), poor citation accuracy, limited actionable insights, and weak structured output for downstream applications.

**Proposed Solution:**  
FinAI implements a **6-stage agentic pipeline** with single orchestrator pattern, processing raw user queries ‚Üí normalized input ‚Üí intent classification ‚Üí plan generation ‚Üí evidence retrieval + computation ‚Üí structured reasoning ‚Üí final synthesis. Each stage is independently deployable and horizontally scalable, optimizing latency through aggressive parallelization, token budgeting, and deterministic routing.

**Impact & Business Value:**
- ‚úÖ **Response Latency:** p95 < 8‚Äì12 seconds (full pipeline with web browsing)
- ‚úÖ **Citation Accuracy:** 95%+ claims backed by evidence  
- ‚úÖ **Query Coverage:** Supports financial Q&A, comparative analysis, regulatory research, portfolio analysis
- ‚úÖ **Cost Efficiency:** 60% token reduction through evidence compression + smart model selection
- ‚úÖ **Enterprise Ready:** Multi-tenant, GDPR-compliant, 99.9% availability SLA

---

## 1. OVERVIEW & CONTEXT

### 1.1 Problem Statement & Motivation

Financial professionals face a critical challenge: synthesizing diverse information sources (APIs, web content, databases) into actionable intelligence within seconds. Existing solutions are either:

- **Too Slow:** Traditional RAG systems with serial pipeline = 30‚Äì60s latency
- **Hallucination-Prone:** LLMs generating answers without proper evidence grounding
- **Unstructured:** Plain text responses unsuitable for automated downstream processing
- **Expensive:** Every query triggers expensive LLM calls for all stages

**Why Now?**  
The explosion of financial APIs (stock prices, earnings data, regulatory filings) combined with advances in LLMs enables real-time synthesis. Competitors like Perplexity, GPT-4 Web Browsing show market demand. FinAI aims to dominate financial domain through specialized architecture.

### 1.2 Current Landscape & Competitive Positioning

| Aspect | Perplexity | ChatGPT-4 Web | Traditional RAG | FinAI |
|--------|-----------|---------------|-----------------|-------|
| **Latency (p95)** | 15‚Äì20s | 20‚Äì30s | 5‚Äì15s | **<12s** |
| **Citation Accuracy** | 85% | 70% | 80% | **95%+** |
| **Structured Output** | Limited | Limited | Good | **Excellent** |
| **Financial Domain** | General | General | Medium | **Specialized** |
| **Cost per Query** | $0.05‚Äì0.15 | $0.03‚Äì0.10 | $0.02‚Äì0.08 | **$0.02‚Äì0.05** |

### 1.3 Success Criteria & Definition of Done

| Metric | Target | Status |
|--------|--------|--------|
| **Stage 1‚Äì2 Latency** | <1.5s (p95) | ‚úÖ Achievable |
| **Full Pipeline Latency** | <12s (p95, with browse) | ‚úÖ Achievable |
| **Citation Success Rate** | >95% claims backed | ‚úÖ Achievable |
| **Availability** | 99.9% uptime | ‚úÖ Target |
| **Cost per Query** | <$0.05 avg | ‚úÖ Target |
| **Evidence Extraction Accuracy** | >90% on financial docs | ‚úÖ Achievable |

---

## 2. GOALS, SCOPE, ASSUMPTIONS

### 2.1 Goals (Business & Technical)

**Business Goals:**
- Launch MVP with 6 modules integrated (Stages 1‚Äì6) covering financial Q&A use cases
- Support 1000 requests/second sustained throughput
- Reduce per-query cost by 60% vs. competitors through multi-stage optimization
- Achieve 95% positive user satisfaction (evidence quality, latency, accuracy)

**Technical Goals:**
- Stage 1‚Äì2 deterministic & fast: <200ms per stage (rule-based path)
- Stage 3‚Äì6 async pipeline: <10s end-to-end for full pipeline
- 99.9% availability across all services
- Support horizontal auto-scaling to 10x peak load
- Enable per-tenant budget & policy enforcement

**User Experience Goals:**
- First response in <500ms (TaskSpec ready)
- Streaming evidence + final answer >progressively
- Clear citation trails for all claims (URL + offset + confidence)
- Graceful degradation under overload (use faster models, reduce depth)

### 2.2 In-Scope (MVP Must-Have)

‚úÖ **Module 1 (UnifiedInputCore):** Normalize input, extract URLs, language detect  
‚úÖ **Module 2 (QueryUnderstanding):** Intent + slots, rule-based routing, optional SLM fallback  
‚úÖ **Module 3 (RouterPlanner):** Mode selection (A/B/C/D), ActionPlan generation, budget enforcement  
‚úÖ **Module 4 (UnifiedExecutor):** Hybrid search, fetch, extract, no interactive actions yet  
‚úÖ **Module 5 (Reasoning):** Evidence compression, claim extraction, citation mapping  
‚úÖ **Module 6 (AnswerSynthesis):** Final text generation, markdown formatting, PII redaction  

‚úÖ **Supporting Services:** Model Gateway, Retrieval Service, Web Worker  
‚úÖ **Observability:** JSON logging, Prometheus metrics, OpenTelemetry traces  
‚úÖ **Testing:** Unit (80%+ coverage), Integration, E2E, Golden tests  
‚úÖ **Deployment:** Docker Compose (local), Kubernetes (prod), Terraform IaC  

### 2.3 Out-of-Scope (Phase 2+)

‚ùå **Interactive Actions:** Form filling, clicks, submissions (Phase 2 ‚Äì requires human approval)  
‚ùå **Voice Input:** Audio transcription & spoken query handling (Phase 2)  
‚ùå **PDF/OCR Pipeline:** Advanced document processing (Phase 2 ‚Äì VLM hooks ready)  
‚ùå **Real-time Stock Pricing:** Direct broker API integration (can add as custom plugin)  
‚ùå **Mobile App:** Web-first, responsive; native apps Phase 2+  
‚ùå **Multi-Modal (Video):** YouTube transcription, video understanding Phase 2+  

### 2.4 Assumptions

- **Infrastructure:** Assume available: API Gateway, Kubernetes, Redis, PostgreSQL, LLM API access
- **Data Access:** Assume public web accessible; no private databases initially
- **Authentication:** Assume JWT-based identity (OAuth2 via API Gateway)
- **Models:** Assume access to GPT-4 (reasoning), Llama-2 (SLM), embedding service
- **Throughput:** MVP assumes 1K req/s; scale to 10K via auto-scaling

### 2.5 Constraints

**Technical:**
- Must use Python 3.11+ (async/await patterns)
- Deploy on Kubernetes (GKE, EKS, or AKS compatible)
- TLS 1.3 mandatory for all communication
- Max request size: 20KB input, 1MB response

**Business:**
- Budget: $50K/month infrastructure + LLM API costs
- Timeline: MVP launch in 12 weeks
- Team: 8 engineers (4 backend, 2 ML, 2 DevOps)

**Compliance:**
- GDPR: No PII in logs, right-to-delete, data residency
- SOC 2: Audit logging, access controls, encryption
- PCI-DSS: If handling financial account numbers (Phase 2)

### 2.6 Dependencies

**External APIs:**
- LLM Provider (OpenAI, Anthropic, local Llama)
- Embedding API (OpenAI, Cohere, local)
- Web Search API (optional: Google Custom Search, Bing)
- State Management: Redis cluster (idempotency, sessions)
- Database: PostgreSQL (artifact storage, audit logs)

**Team Dependencies:**
- ML Team: Model selection, fine-tuning decision
- Security Team: Threat modeling, penetration testing
- DevOps Team: Infrastructure provisioning, monitoring setup
- Product Team: Feature prioritization, user feedback loops

---

## 3. USER STORIES & USE CASES

### 3.1 Primary Actors

1. **Financial Analyst** ‚Äì Research portfolio holdings, compare fund performance
2. **Investor** ‚Äì Ask about market conditions, company fundamentals, risk analysis
3. **Compliance Officer** ‚Äì Research regulatory requirements, filing deadlines
4. **Trader** ‚Äì Quick market news, sector analysis, technical signals
5. **Internal Service** ‚Äì API client retrieving structured financial intelligence

### 3.2 User Stories (Primary Flows)

**Story 1: "I want to compare two stocks"**  
```
As a Retail Investor
I want to compare valuation metrics of Tesla vs. Ford
So that I can make informed investment decisions

Acceptance Criteria:
‚úì System fetches current P/E, EV/EBITDA, debt ratios for both stocks
‚úì Cites sources (financial APIs, latest filings)
‚úì Returns comparison table + narrative analysis
‚úì Completes in <10 seconds
‚úì Includes forward guidance + analyst ratings (if available)
```

**Story 2: "I need regulatory compliance research"**  
```
As a Compliance Officer
I want to understand SEC disclosure requirements for 10-K filings
So that I can audit our company's compliance status

Acceptance Criteria:
‚úì System searches SEC regulations, company filings, legal interpretations
‚úì Returns structured compliance checklist
‚úì Cites regulatory sources (CFR sections)
‚úì Includes timestamps of latest updates
‚úì Supports follow-up questions without re-researching
```

**Story 3: "Analyze my portfolio sector exposure"**  
```
As a Portfolio Manager
I want sector-level breakdown of my $10M portfolio
So that I can rebalance toward strategic allocations

Acceptance Criteria:
‚úì System reads portfolio data (via API or upload)
‚úì Fetches current sector classifications, weights
‚úì Calculates diversification ratios
‚úì Returns allocation table + rebalancing recommendations
‚úì Outputs in JSON/CSV for downstream tools
```

### 3.3 User Flows (Critical Paths)

```
[Query] ‚Üí [Stage 1: Parse]
  ‚Üì (NormalizedInput)
[Stage 2: Understand]
  ‚Üì (TaskSpecV1)
[Stage 3: Plan]
  ‚Üì (ActionPlan)
[Stage 4: Execute] ‚Üê Research/Fetch/Compute (4‚Äì5s typical)
  ‚Üì (EvidencePack)
[Stage 5: Reason]
  ‚Üì (AnswerSkeleton + CitationMap)
[Stage 6: Synthesize] ‚Üê Compose final answer (2‚Äì3s)
  ‚Üì (FinalAnswer)
[Response] with streaming progress
```

### 3.4 Edge Cases & Error Scenarios

| Scenario | Handling | Example |
|----------|----------|---------|
| **Ambiguous query** | Route to slow path (use SLM) | "Banks performance 2025" ‚Üí requires entity disambiguation |
| **No evidence found** | Return partial answer + "no data available" | "XYZ Corp insider trades" ‚Üí may be restricted |
| **Fetch timeout** | Graceful degradation: use cached data or skip | NYSE API down ‚Üí use previous closing prices |
| **Conflicting sources** | Flag contradiction, show both views | "Stock price $100 vs $102 different sources" |
| **Large result set** | Paginate, return top-K + link to full results | "All S&P 500 stocks sorted by P/E" |

---

## 4. API CONTRACT & INTERFACES

### 4.1 API Design Principles

- **Protocol:** REST over HTTP/2 + optional gRPC for internal services
- **Versioning:** `/v1/` in path; major breaking changes ‚Üí `/v2/`
- **Authentication:** JWT Bearer token (OAuth2 compliant)
- **Rate Limiting:** Per-user (60 req/min default) + per-IP (300 req/min)
- **Idempotency:** Required for `/tasks:execute` via `Idempotency-Key` header
- **Response Format:** JSON (default) + optional CSV/Markdown for certain endpoints

### 4.2 Primary Endpoints

#### `POST /v1/tasks:execute` ‚Äì Execute Financial Query

**Purpose:** Submit query, retrieve structured financial intelligence

**Request:**
```json
{
  "request_id": "req_abc123",
  "idempotency_key": "idem_xyz789",
  "input": {
    "type": "text",
    "text": "Compare Tesla vs. Ford valuation. Include P/E, debt ratio, FCF."
  },
  "context": {
    "current_url": "https://investor.tesla.com",
    "locale": "en-US",
    "timezone": "America/New_York"
  },
  "options": {
    "mode": "auto",
    "allow_browse": true,
    "max_latency_ms": 12000,
    "response_format": "markdown"
  }
}
```

**Response (202 Async):**
```json
{
  "task_id": "task_f9e2d1a",
  "status": "RUNNING",
  "correlation_id": "corr_abcd1234",
  "estimate_seconds": 8,
  "progress": {
    "stage": 3,
    "message": "Planning evidence collection..."
  }
}
```

**Response (200 Sync ‚Äì Fallback):**
```json
{
  "task_id": "task_f9e2d1a",
  "status": "SUCCEEDED",
  "answer": {
    "content": "# Tesla vs. Ford Valuation Comparison\n\n## P/E Ratio\n- **Tesla:** 35.2x [Source: Yahoo Finance, Dec 10, 2025]\n- **Ford:** 5.1x [Source: Morningstar]\n\n## Key Insight\nTesla trades at 6.9x Ford's multiple, reflecting growth premium...",
    "format": "markdown"
  },
  "citations": [
    {
      "id": 1,
      "url": "https://finance.yahoo.com/quote/TSLA",
      "title": "Tesla Inc. (TSLA) - Financial Data",
      "accessed_at": "2025-12-10T15:23:45Z"
    }
  ],
  "metadata": {
    "latency_ms": 9847,
    "stages": {
      "stage1": 45,
      "stage2": 120,
      "stage3": 850,
      "stage4": 5200,
      "stage5": 2100,
      "stage6": 1532
    },
    "model_calls": 4,
    "tokens_used": 2847,
    "cost_estimate_usd": 0.042
  }
}
```

#### `GET /v1/tasks/{task_id}` ‚Äì Poll Task Status

**Purpose:** Retrieve task progress and results

**Response:**
```json
{
  "task_id": "task_f9e2d1a",
  "status": "RUNNING|SUCCEEDED|FAILED",
  "progress": {
    "stage": 4,
    "stage_name": "UnifiedExecutor",
    "percentage": 45,
    "message": "Fetching financial data..."
  },
  "artifacts": {
    "task_spec": { "intent": "compare", "entities": ["TSLA", "F"] },
    "evidence_pack": null,
    "answer_skeleton": null,
    "final_answer": null
  },
  "error": null
}
```

### 4.3 Error Model (Standardized)

```json
{
  "error_code": "INVALID_INPUT|AUTH_FAILED|RATE_LIMITED|TIMEOUT|INTERNAL",
  "message": "Human-readable error description",
  "details": {
    "stage": "stage_4",
    "module": "web_fetch",
    "retry_after_seconds": 30
  },
  "trace_id": "trace_12345abcde",
  "timestamp": "2025-12-10T15:23:45Z"
}
```

### 4.4 Data Models (Core Schemas)

**RawRequest (Input):**
```typescript
interface RawRequest {
  request_id: string;
  idempotency_key: string;
  user: { user_id: string; session_id: string };
  input: {
    type: "text" | "url" | "html_snapshot";
    text?: string;
    url?: string;
    html?: string;
  };
  context?: {
    current_url?: string;
    locale?: string;
    timezone?: string;
  };
  options: {
    mode: "auto" | "quick" | "deep";
    allow_browse: boolean;
    max_latency_ms: number;
  };
}
```

**TaskSpecV1 (Output of Stage 2):**
```typescript
interface TaskSpecV1 {
  task_id: string;
  intent: "qa" | "compare" | "summarize" | "research" | "analyze";
  entities: string[];
  routing: {
    quick_path: boolean;
    needs_browse: boolean;
    needs_citations: boolean;
  };
  budget: {
    max_model_calls: number;
    max_tokens: number;
    max_latency_ms: number;
  };
}
```

**FinalAnswer (Output of Stage 6):**
```typescript
interface FinalAnswer {
  task_id: string;
  content: string;
  format: "markdown" | "json" | "csv";
  citations: Citation[];
  metadata: {
    latency_ms: number;
    stages: Record<string, number>;
    model_calls: number;
    tokens_used: number;
    cost_usd: number;
    confidence: number;
  };
}
```

---

## 5. DATA MODEL & STORAGE DESIGN

### 5.1 Entity Relationship Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ tasks       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)     ‚îÇ
‚îÇ user_id (FK)‚îÇ
‚îÇ status      ‚îÇ
‚îÇ created_at  ‚îÇ
‚îÇ completed_at‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚Üí ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ    ‚îÇ task_specs       ‚îÇ
       ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
       ‚îÇ    ‚îÇ task_id (FK)     ‚îÇ
       ‚îÇ    ‚îÇ intent           ‚îÇ
       ‚îÇ    ‚îÇ entities (JSON)  ‚îÇ
       ‚îÇ    ‚îÇ routing (JSON)   ‚îÇ
       ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚Üí ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ    ‚îÇ evidence_packs   ‚îÇ
       ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
       ‚îÇ    ‚îÇ task_id (FK)     ‚îÇ
       ‚îÇ    ‚îÇ items (JSONB)    ‚îÇ
       ‚îÇ    ‚îÇ traces (JSONB)   ‚îÇ
       ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îî‚îÄ‚îÄ‚Üí ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ final_answers    ‚îÇ
            ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
            ‚îÇ task_id (FK)     ‚îÇ
            ‚îÇ content          ‚îÇ
            ‚îÇ citations (JSON) ‚îÇ
            ‚îÇ metadata (JSON)  ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ sessions     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)      ‚îÇ
‚îÇ user_id (FK) ‚îÇ
‚îÇ cached_queries
‚îÇ created_at   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ audit_logs   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)      ‚îÇ
‚îÇ user_id      ‚îÇ
‚îÇ action       ‚îÇ
‚îÇ resource_id  ‚îÇ
‚îÇ timestamp    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 5.2 Schema Definition (PostgreSQL)

```sql
-- Core tasks table
CREATE TABLE tasks (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES users(id),
  request_id VARCHAR(255) UNIQUE NOT NULL,
  status VARCHAR(50) NOT NULL CHECK (status IN ('PENDING', 'RUNNING', 'SUCCEEDED', 'FAILED')),
  created_at TIMESTAMP NOT NULL DEFAULT NOW(),
  completed_at TIMESTAMP,
  latency_ms INTEGER,
  cost_usd DECIMAL(10, 4),
  INDEX idx_user_id (user_id),
  INDEX idx_created_at (created_at),
  INDEX idx_status (status)
);

-- Task specifications
CREATE TABLE task_specs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  task_id UUID NOT NULL REFERENCES tasks(id) ON DELETE CASCADE,
  intent VARCHAR(50) NOT NULL,
  entities JSONB,
  routing JSONB,
  budget JSONB,
  created_at TIMESTAMP DEFAULT NOW(),
  INDEX idx_task_id (task_id)
);

-- Evidence storage
CREATE TABLE evidence_items (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  task_id UUID NOT NULL REFERENCES tasks(id) ON DELETE CASCADE,
  source_url TEXT NOT NULL,
  title TEXT,
  content TEXT NOT NULL,
  content_hash VARCHAR(64),
  score DECIMAL(4, 3),
  retrieved_at TIMESTAMP DEFAULT NOW(),
  INDEX idx_task_id (task_id),
  INDEX idx_content_hash (content_hash)
);

-- Final answers
CREATE TABLE final_answers (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  task_id UUID NOT NULL REFERENCES tasks(id) ON DELETE CASCADE UNIQUE,
  content TEXT NOT NULL,
  format VARCHAR(20),
  citations JSONB,
  metadata JSONB,
  created_at TIMESTAMP DEFAULT NOW(),
  INDEX idx_task_id (task_id)
);

-- Sessions & caching
CREATE TABLE sessions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES users(id),
  cached_data JSONB,
  created_at TIMESTAMP DEFAULT NOW(),
  expires_at TIMESTAMP,
  INDEX idx_user_id (user_id),
  INDEX idx_expires_at (expires_at)
);

-- Audit logging
CREATE TABLE audit_logs (
  id BIGSERIAL PRIMARY KEY,
  user_id UUID NOT NULL,
  action VARCHAR(50) NOT NULL,
  resource_type VARCHAR(50),
  resource_id VARCHAR(255),
  details JSONB,
  timestamp TIMESTAMP DEFAULT NOW(),
  INDEX idx_user_id (user_id),
  INDEX idx_timestamp (timestamp),
  INDEX idx_action (action)
);
```

### 5.3 Caching Strategy

**Redis Keys & TTLs:**
- `task:{task_id}:progress` ‚Äì Real-time task progress (TTL: 5 min)
- `session:{session_id}:history` ‚Äì Recent queries (TTL: 1 hour)
- `evidence:{query_hash}` ‚Äì Cached evidence for similar queries (TTL: 24 hours)
- `user:{user_id}:budget` ‚Äì Token budget tracking (TTL: 1 day)
- `embeddings:{text_hash}` ‚Äì Cached query embeddings (TTL: 7 days)

**Cache Invalidation:**
- Evict `evidence:*` on market open/close (financial data freshness)
- Evict `user:*:budget` daily (reset token allowance)
- LRU eviction if memory >80%

---

## 6. SYSTEM ARCHITECTURE & FLOW

### 6.1 High-Level Architecture (C4 Level 1 & 2)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          CLIENT LAYER                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ Web Browser  ‚îÇ  ‚îÇ Mobile App   ‚îÇ  ‚îÇ API Client   ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì HTTPS
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              API GATEWAY (WAF, Auth, Rate Limit)                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ TLS Termination ‚îÇ JWT Validation ‚îÇ Rate Limit (60 req/min)  ‚îÇ‚îÇ
‚îÇ  ‚îÇ CORS & Headers  ‚îÇ Request Logging‚îÇ Size Limit (20KB input)  ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            ORCHESTRATOR SERVICE (Main Router)                   ‚îÇ
‚îÇ  Dispatches across 6 stage services, manages state machine      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì Route to Stages
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       STAGE SERVICES                              ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îÇ Stage 1: Input  ‚îÇ‚Üí ‚îÇ Stage 2: Query  ‚îÇ‚Üí ‚îÇ Stage 3: Plan   ‚îÇ  ‚îÇ
‚îÇ ‚îÇ Normalization   ‚îÇ  ‚îÇ Understanding   ‚îÇ  ‚îÇ & Routing       ‚îÇ  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚Üì NormalizedInput    ‚Üì TaskSpecV1      ‚Üì ActionPlan    ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îÇ Stage 4:        ‚îÇ  ‚îÇ Stage 5:        ‚îÇ  ‚îÇ Stage 6:        ‚îÇ  ‚îÇ
‚îÇ ‚îÇ Unified Exec.   ‚îÇ‚Üí ‚îÇ Reasoning       ‚îÇ‚Üí ‚îÇ Answer Synth.   ‚îÇ  ‚îÇ
‚îÇ ‚îÇ(Search/Fetch)   ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ    ‚Üì EvidencePack    ‚Üì AnswerSkeleton       ‚Üì FinalAnswer      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì Supporting Services
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MODEL-GATEWAY    ‚îÇ  RETRIEVAL-SERVICE    ‚îÇ  WEB-WORKER           ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ     ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ         ‚îÇ
‚îÇ ‚Ä¢ LLM adapter    ‚îÇ ‚Ä¢ Hybrid search      ‚îÇ ‚Ä¢ HTTP fetch          ‚îÇ
‚îÇ ‚Ä¢ SLM adapter    ‚îÇ ‚Ä¢ BM25 + Vector      ‚îÇ ‚Ä¢ HTML parse          ‚îÇ
‚îÇ ‚Ä¢ Embeddings     ‚îÇ ‚Ä¢ Reranking          ‚îÇ ‚Ä¢ Table extract       ‚îÇ
‚îÇ ‚Ä¢ Token budget   ‚îÇ ‚Ä¢ Dedup & scoring    ‚îÇ ‚Ä¢ SSRF guard          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì Storage & Infrastructure
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  REDIS (State)   ‚îÇ  POSTGRES (Artifacts) ‚îÇ  OBSERVABILITY         ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ       ‚îÇ
‚îÇ ‚Ä¢ Idempotency   ‚îÇ ‚Ä¢ Tasks              ‚îÇ ‚Ä¢ Prometheus (metrics) ‚îÇ
‚îÇ ‚Ä¢ Sessions      ‚îÇ ‚Ä¢ Evidence           ‚îÇ ‚Ä¢ Jaeger (traces)     ‚îÇ
‚îÇ ‚Ä¢ Cache         ‚îÇ ‚Ä¢ Answers            ‚îÇ ‚Ä¢ ELK (logs)          ‚îÇ
‚îÇ ‚Ä¢ Locks         ‚îÇ ‚Ä¢ Audit logs         ‚îÇ ‚Ä¢ Alerts (PagerDuty)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 6.2 Component Diagram (C4 Level 3)

**Stage 1: UnifiedInputCore Components**
```
InputAdapter
  ‚îú‚îÄ schema_validator
  ‚îú‚îÄ idempotency_checker
  ‚îî‚îÄ trace_context_builder
       ‚Üì
ContextCollector
  ‚îú‚îÄ url_extractor
  ‚îú‚îÄ locale_detector
  ‚îî‚îÄ timezone_resolver
       ‚Üì
Normalizer
  ‚îú‚îÄ text_whitespace_normalizer
  ‚îú‚îÄ language_detector
  ‚îî‚îÄ url_validator
       ‚Üì
SafetyPrecheck
  ‚îú‚îÄ prompt_injection_scanner
  ‚îî‚îÄ ssrf_url_blocker
```

**Stage 2: QueryUnderstanding Components**
```
PolicyClassifiers
  ‚îú‚îÄ toxicity_detector
  ‚îú‚îÄ pii_detector
  ‚îî‚îÄ injection_risk_scorer
       ‚Üì
RuleEngine (A/B/C/D routing)
  ‚îú‚îÄ intent_rules
  ‚îú‚îÄ entity_rules
  ‚îî‚îÄ routing_rules
       ‚Üì
SLMModule (fallback for slow path)
  ‚îî‚îÄ semantic_classifier
       ‚Üì
EmbeddingPrep
  ‚îî‚îÄ query_embedding_generator
```

**Stage 3: RouterPlanner Components**
```
SignalExtractor
  ‚îú‚îÄ needs_research_detector
  ‚îú‚îÄ needs_action_detector
  ‚îî‚îÄ risk_level_assessor
       ‚Üì
ModeSelector (A/B/C/D)
  ‚îî‚îÄ routing_decision_maker
       ‚Üì
PlanBuilder (LLM)
  ‚îú‚îÄ query_decomposer
  ‚îú‚îÄ step_generator
  ‚îî‚îÄ success_criteria_definer
       ‚Üì
PlanValidator
  ‚îú‚îÄ policy_enforcer
  ‚îú‚îÄ budget_checker
  ‚îî‚îÄ capability_matcher
       ‚Üì
StateManager
  ‚îî‚îÄ task_fsm_tracker
```

**Stage 4: UnifiedExecutor Components**
```
4.1 Retrieve
  ‚îú‚îÄ RetrievalEngine (hybrid: BM25+vector)
  ‚îú‚îÄ Deduplicator
  ‚îî‚îÄ DomainScorer
       ‚Üì
4.2 FetchData
  ‚îú‚îÄ WebFetch (HTTP client)
  ‚îú‚îÄ SSRFGuard
  ‚îî‚îÄ ContentTypeValidator
       ‚Üì
4.3 Extract
  ‚îú‚îÄ DOMParser
  ‚îú‚îÄ MainContentExtractor
  ‚îî‚îÄ TableExtractor
       ‚Üì
4.4 EvidenceBuilder
  ‚îú‚îÄ Chunker
  ‚îú‚îÄ CitationAnchorCreator
  ‚îî‚îÄ SafetySanitizer (PII redactor)
```

### 6.3 Data Flow Diagram (Critical Happy Path)

```
User Query (e.g., "Compare TSLA vs F P/E ratios")
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Stage 1: Input ‚îÇ
    ‚îÇ Normalize      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ Input: "Compare TSLA vs F..."
           ‚îÇ Output: NormalizedInput {text, entities: [TSLA, F], locale}
           ‚îÇ Time: ~50ms
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Stage 2: Query ‚îÇ
    ‚îÇ Understand     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ Intent: "compare"
           ‚îÇ Slots: {entity1: TSLA, entity2: F, metric: P/E}
           ‚îÇ Routing: quick_path=true (simple comparison query)
           ‚îÇ Time: ~100ms (rule-only fast path)
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Stage 3: Plan  ‚îÇ
    ‚îÇ & Route        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ Mode: A (Research-only, no interactive actions)
           ‚îÇ ActionPlan: [
           ‚îÇ   {step: Retrieve, query: "TSLA P/E ratio"},
           ‚îÇ   {step: Retrieve, query: "Ford P/E ratio"},
           ‚îÇ   {step: Extract, from_urls: [finance.yahoo.com, morningstar.com]},
           ‚îÇ   {step: Compute, operation: compare_metrics}
           ‚îÇ ]
           ‚îÇ Time: ~150ms (LLM planning)
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Stage 4: Executor      ‚îÇ
    ‚îÇ (Search ‚Üí Fetch ‚Üí Ext) ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ [4.1] Retrieve: Search "TSLA P/E", get 50 candidates
           ‚îÇ [4.1] Rerank: Top 5 financial sources
           ‚îÇ [4.2] Fetch: 5 URLs (2-3 sec)
           ‚îÇ [4.3] Extract: P/E from each page
           ‚îÇ [4.4] EvidencePack: {TSLA: 35.2, Ford: 5.1, sources: [...]}
           ‚îÇ Time: ~5200ms (fetch bottleneck)
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Stage 5:       ‚îÇ
    ‚îÇ Reasoning      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ Compress evidence: "TSLA P/E 35.2x vs Ford 5.1x"
           ‚îÇ Extract claim: "TSLA trades 6.9x Ford's multiple"
           ‚îÇ Citation map: claim_1 ‚Üí [source_1, source_2]
           ‚îÇ AnswerSkeleton:
           ‚îÇ   - Headline: "TSLA P/E Premium"
           ‚îÇ   - Claim: "TSLA 6.9x Ford multiple"
           ‚îÇ   - Insight: "Reflects growth premium..."
           ‚îÇ Time: ~2100ms (LLM reasoning)
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Stage 6:       ‚îÇ
    ‚îÇ Synthesize     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ Compose: # Tesla vs. Ford Valuation
           ‚îÇ           TSLA P/E: 35.2x [1]
           ‚îÇ           Ford P/E: 5.1x [2]
           ‚îÇ           Multiple gap: 6.9x [1][2]
           ‚îÇ           Insight: Growth premium reflects...
           ‚îÇ Citations: [{id:1, url, title, accessed_at}]
           ‚îÇ Metadata: {latency: 9847ms, stages: {...}}
           ‚îÇ Time: ~1532ms (LLM composition)
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ FINAL RESPONSE   ‚îÇ
    ‚îÇ (p95: ~10 sec)   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
     User sees structured answer with citations
     Response sent via streaming
```

### 6.4 Sequence Diagram (Key Components)

```
User                API Gateway              Orchestrator            Stage 1-6
  ‚îÇ                     ‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îú‚îÄ POST /tasks:execute‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ                     ‚îÇ Validate & Auth         ‚îÇ                      ‚îÇ
  ‚îÇ                     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                      ‚îÇ
  ‚îÇ                     ‚îÇ                         ‚îÇ Dispatch Stage 1     ‚îÇ
  ‚îÇ                     ‚îÇ                         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
  ‚îÇ                     ‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ                     ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
  ‚îÇ                     ‚îÇ (NormalizedInput)       ‚îÇ                      ‚îÇ
  ‚îÇ                     ‚îÇ                         ‚îÇ Dispatch Stage 2     ‚îÇ
  ‚îÇ                     ‚îÇ                         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
  ‚îÇ                     ‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ (202 ACCEPTED)          ‚îÇ                      ‚îÇ
  ‚îÇ task_id: task_abc   ‚îÇ                         ‚îÇ Dispatch Stage 3-6   ‚îÇ
  ‚îÇ                     ‚îÇ                         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
  ‚îÇ                     ‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ [Client polls]      ‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ‚îÄ GET /tasks/task_abc‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ                     ‚îÇ Check status            ‚îÇ                      ‚îÇ
  ‚îÇ                     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                      ‚îÇ
  ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ {progress: Stage 4, 45%}‚îÇ                      ‚îÇ
  ‚îÇ                     ‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ [Poll again...]     ‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ‚îÄ GET /tasks/task_abc‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ                     ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
  ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ {status: SUCCEEDED, answer: {...}}             ‚îÇ
  ‚îÇ Final Answer        ‚îÇ                         ‚îÇ                      ‚îÇ
  ‚îÇ                     ‚îÇ                         ‚îÇ                      ‚îÇ
```

---

## 7. IMPLEMENTATION DETAILS (Deep-Dive per Module)

### 7.1 Stage 1: UnifiedInputCore ‚Äî Input Normalization

**Responsibility:**  
Validate, normalize, and enrich user input before processing

**Inputs:**
- RawRequest: text query + optional URL/context
- Headers: Auth, Idempotency-Key, X-Request-ID

**Outputs:**
- NormalizedInput: validated, normalized query
- TraceContext: correlation IDs for tracing

**Key Algorithm:**

```python
async def stage1_pipeline(raw_request: RawRequest, headers: Dict) -> NormalizedInput:
    # 1. Idempotency check
    cached = await redis.get(f"idem:{user_id}:{idempotency_key}")
    if cached and cached.payload_hash == hash(raw_request):
        return cached.response  # 409 if different payload
    
    # 2. Validate input
    validator.validate_schema(raw_request)  # 400 if invalid
    if len(raw_request.text) > MAX_INPUT_LENGTH:
        raise PayloadTooLarge(413)
    
    # 3. Extract URLs
    urls = URL_REGEX.findall(raw_request.text)
    if len(urls) > MAX_URLS:
        urls = urls[:MAX_URLS]
        warnings.append("TRUNCATED_URLS")
    
    # 4. Normalize text
    normalized_text = text.strip().replace('\n\n+', '\n\n')
    detected_lang = detect_language(normalized_text)  # heuristic: check Vietnamese diacritics
    
    # 5. Attach context (page title, selected text, timezone)
    if context.active_url:
        if is_valid_url(context.active_url):
            urls.append(context.active_url)
        else:
            warnings.append("INVALID_ACTIVE_URL")
    
    # 6. Safety precheck
    if contains_prompt_injection(normalized_text):
        flags.injection_risk = True
    if contains_ssrf_urls(urls):
        flags.ssrf_risk = True
    
    # 7. Build output
    normalized_input = NormalizedInput(
        request_id=str(uuid4()),
        text=normalized_text,
        urls=urls,
        language=detected_lang,
        context=context,
        flags=flags,
        telemetry={
            "stage1_latency_ms": elapsed_ms,
            "input_length": len(normalized_text),
            "url_count": len(urls)
        }
    )
    
    # 8. Cache for idempotency
    await redis.setex(
        f"idem:{user_id}:{idempotency_key}",
        TTL_24H,
        pickle(normalized_input)
    )
    
    return normalized_input
```

**Failure Modes & Mitigation:**

| Scenario                | Handling                         |
| ----------------------- | -------------------------------- |
| Payload too large       | Return 413, log attempt          |
| Invalid JSON            | Return 400, suggest format       |
| Missing idempotency key | Warn but continue (non-critical) |
| URL extraction fails    | Return partial results + warning |

---

### 7.2 Stage 2: QueryUnderstanding ‚Äî Intent Classification

**Responsibility:**  
Classify intent, extract entities, determine routing (fast path vs. slow path)

**Inputs:**
- NormalizedInput

**Outputs:**
- TaskSpecV1: intent, slots, routing decision

**Fast Path (Rule-Only, >85% confidence):**

```python
def rule_engine_abcd(text: str) -> RuleResult:
    # A: Intent Classification
    intent = Intent.QA  # default
    
    if any(word in text.lower() for word in ["summarize", "tldr", "overview"]):
        intent = Intent.SUMMARIZE
        intent_score = 0.95
    elif any(word in text.lower() for word in ["compare", "vs", "difference"]):
        intent = Intent.COMPARE
        intent_score = 0.90
    elif any(word in text.lower() for word in ["explain", "how does", "what is"]):
        intent = Intent.EXPLAIN
        intent_score = 0.85
    else:
        intent_score = 0.6
    
    # B: Entity Extraction (financial focus)
    entities = []
    stock_tickers = extract_tickers(text)  # Regex: [A-Z]{1,5}
    entities.extend(stock_tickers)
    
    # C: Slot Extraction (financial metrics)
    slots = {}
    if "P/E" in text or "price-earnings" in text:
        slots["metric"] = "valuation"
    if extract_number(text) and "time" in text:
        slots["timeframe"] = extract_timeframe(text)
    
    # D: Policy Check
    pii_risk = detect_pii_keywords(text)  # email, phone, SSN
    injection_risk = contains_injection_patterns(text)
    
    # Confidence calculation
    confidence = 0.4 * intent_score + 0.2 * (len(entities) > 0) + 0.2 * (len(slots) > 0) + 0.2
    
    return RuleResult(intent, entities, slots, confidence)

rule_result = rule_engine_abcd(normalized_input.text)

if rule_result.confidence > 0.85:
    # Fast path: Use rule result directly
    task_spec = build_task_spec_from_rule(rule_result)
else:
    # Slow path: Call SLM for semantic understanding
    prompt = f"Intent: {rule_result.intent}, Entities: {rule_result.entities}. Refine understanding."
    slm_result = await model_gateway.call_slm(prompt, max_tokens=200)
    task_spec = build_task_spec_from_slm(slm_result)
```

**Slow Path (SLM Call, <85% confidence):**

```python
async def slm_module(normalized_input: NormalizedInput) -> TaskSpecV1:
    prompt = f"""
    Analyze this financial query:
    Query: {normalized_input.text}
    Language: {normalized_input.language}
    
    Extract:
    1. intent: qa | compare | summarize | research | analyze
    2. entities: List of financial entities (tickers, companies, metrics)
    3. slots: {{metric, timeframe, filter, aggregation, ...}}
    4. confidence: 0.0-1.0
    
    Respond in JSON.
    """
    
    response = await model_gateway.call_slm(
        prompt,
        model="llama-2-7b",
        max_tokens=200,
        temperature=0.1
    )
    
    result = parse_json(response)
    return TaskSpecV1(**result)
```

**Latency Targets:**
- Rule-only: ~50‚Äì100ms
- SLM fallback: ~400‚Äì500ms
- Target p95: <500ms

---

### 7.3 Stage 3: RouterPlanner ‚Äî Plan Generation

**Responsibility:**  
Select execution mode (A/B/C/D), generate step-by-step ActionPlan, enforce budgets & policies

**Inputs:**
- TaskSpecV1

**Outputs:**
- ActionPlan: ordered steps with tool/goal/constraints

**Mode Selection Logic:**

```python
def select_mode(task_spec: TaskSpecV1) -> Mode:
    needs_research = task_spec.intent in [Intent.COMPARE, Intent.RESEARCH]
    needs_action = task_spec.intent == Intent.ACT
    needs_state_first = "current" in task_spec.text or "my account" in task_spec.text
    risk_level = task_spec.risk
    
    if needs_research and needs_action:
        return Mode.C  # Research ‚Üí Action
    elif needs_action and needs_state_first:
        return Mode.D  # Action ‚Üí Research (check current state first)
    elif needs_action:
        return Mode.B  # Action only (known workflow)
    else:
        return Mode.A  # Research only (Perplexity-like)
```

**Plan Generation (LLM):**

```python
async def plan_builder(task_spec: TaskSpecV1, mode: Mode) -> ActionPlan:
    prompt = f"""
    Generate ActionPlan for Mode {mode.name}:
    Intent: {task_spec.intent}
    Entities: {task_spec.entities}
    
    Return JSON steps like:
    [
      {{
        "step_id": "s1",
        "goal": "Find P/E ratios",
        "tool": "retrieval.search",
        "input": {{"query": "TSLA P/E ratio 2025"}},
        "constraints": {{"max_candidates": 80}},
        "expected_output": "CandidateList"
      }},
      ...
    ]
    
    Constraints:
    - Max 6 steps
    - No submit/payment in MVP
    - Early stop if confidence > 0.85
    """
    
    response = await model_gateway.call_llm(
        prompt,
        model="gpt-4",
        max_tokens=800
    )
    
    plan = parse_json(response)
    return ActionPlan(steps=plan, mode=mode, global_budget=task_spec.budget)

# Validate plan
def validate_plan(plan: ActionPlan, policies: Policies) -> ActionPlan:
    # Remove forbidden tools (e.g., "submit_form")
    plan.steps = [s for s in plan.steps if s.tool not in FORBIDDEN_TOOLS]
    
    # Enforce budget
    if len(plan.steps) > policies.max_steps:
        plan.steps = plan.steps[:policies.max_steps]
    
    # Check SSRF policy
    for step in plan.steps:
        if step.tool == "web.fetch":
            for url in step.input.get("urls", []):
                if is_ssrf_blocked(url):
                    step.input["urls"].remove(url)
    
    return plan
```

---

### 7.4 Stage 4: UnifiedExecutor ‚Äî Evidence Retrieval & Extraction

**Responsibility:**  
Execute ActionPlan steps: search, fetch, extract, deduplicate evidence

**Inputs:**
- ActionPlan

**Outputs:**
- EvidencePack: filtered evidence with citations

**Substep 4.1: Retrieve (Hybrid Search)**

```python
async def retrieve_engine(query: str) -> CandidateList:
    # Hybrid search: BM25 (keyword) + Vector (semantic)
    
    # Vector search
    query_embedding = await embeddings_service.embed(query)
    vector_results = await vector_db.search(query_embedding, top_k=50)
    
    # BM25 search
    bm25_results = await bm25_engine.search(query, top_k=50)
    
    # Merge & deduplicate
    candidates = merge_results(vector_results, bm25_results)
    candidates = deduplicate_by_url(candidates)
    
    # Domain scoring (trust bias)
    for candidate in candidates:
        domain = urlparse(candidate.url).netloc
        if domain in TRUSTED_DOMAINS:  # bloomberg.com, reuters.com, etc.
            candidate.score *= 1.2
    
    # Rerank using cross-encoder
    candidates = await reranker.rerank(candidates, query, top_k=10)
    
    return candidates
```

**Substep 4.2: Fetch & Parse**

```python
async def web_fetch(urls: List[str]) -> List[FetchResult]:
    results = []
    
    for url in urls:
        try:
            # SSRF check
            if is_ssrf_blocked(url):
                results.append(FetchResult(url, status=403, blocked=True))
                continue
            
            # Fetch with timeout
            response = await http_client.get(url, timeout=2.5)
            
            if response.status_code == 200:
                html = response.text
                
                # Extract main content
                main_content = extract_main_content(html)  # Readability algorithm
                
                # Extract tables (optional, financial focus)
                tables = extract_tables(html)
                
                results.append(FetchResult(
                    url=url,
                    status=200,
                    content=main_content,
                    tables=tables,
                    title=extract_title(html)
                ))
            else:
                results.append(FetchResult(url, status=response.status_code))
                
        except TimeoutError:
            results.append(FetchResult(url, status=504, error="timeout"))
        except Exception as e:
            logger.error(f"Fetch error {url}: {e}")
            results.append(FetchResult(url, status=500, error=str(e)))
    
    return results
```

**Substep 4.3: Extract Evidence**

```python
def evidence_builder(fetch_results: List[FetchResult]) -> EvidencePack:
    evidence_items = []
    
    for fetch_result in fetch_results:
        if fetch_result.status == 200:
            # Chunk content
            chunks = chunk_text(fetch_result.content, chunk_size=300, overlap=50)
            
            for chunk in chunks:
                evidence_item = EvidenceItem(
                    source_url=fetch_result.url,
                    title=fetch_result.title,
                    content=chunk,
                    type="snippet",
                    score=fetch_result.score,
                    anchors={
                        "hash": sha256(chunk.encode()).hexdigest(),
                        "offset": fetch_result.content.find(chunk)
                    }
                )
                evidence_items.append(evidence_item)
            
            # Extract tables if present
            if fetch_result.tables:
                for table in fetch_result.tables:
                    evidence_items.append(EvidenceItem(
                        source_url=fetch_result.url,
                        title=f"{fetch_result.title} (Table)",
                        content=table_to_markdown(table),
                        type="table",
                        score=fetch_result.score * 0.9
                    ))
    
    # Safety sanitize (remove PII, redact)
    for item in evidence_items:
        item.content = redact_pii(item.content)
        item.content = sanitize_prompt_injection(item.content)
    
    return EvidencePack(items=evidence_items)
```

---

### 7.5 Stage 5: Reasoning ‚Äî Multi-Step Inference

**Responsibility:**  
Compress evidence, extract atomic claims, map citations

**Inputs:**
- EvidencePack

**Outputs:**
- AnswerSkeleton + CitationMap

**Evidence Compression:**

```python
async def evidence_summarizer(evidence_pack: EvidencePack) -> EvidenceDigest:
    # Compress to reduce token usage
    digest_prompt = f"""
    Summarize this financial evidence concisely:
    
    {evidence_pack.to_summary()}
    
    Format as:
    FACTS: [fact1, fact2, ...]
    TABLES: [table1_json, table2_json, ...]
    KEY_QUOTES: ["quote1", "quote2", ...]
    
    Keep factual, no interpretation.
    """
    
    summary = await model_gateway.call_slm(
        digest_prompt,
        model="llama-2-7b",
        max_tokens=500
    )
    
    return parse_digest(summary)

async def reasoning_core(
    task_spec: TaskSpecV1,
    evidence_digest: EvidenceDigest
) -> (AnswerSkeleton, List[Claim]):
    reasoning_prompt = f"""
    Task: {task_spec.intent}
    Entities: {task_spec.entities}
    
    Evidence Summary:
    {evidence_digest}
    
    Generate answer structure with atomic claims:
    {{
      "outline": [
        {{"section": "...", "bullets": ["...", "..."]}},
        ...
      ],
      "claims": [
        {{"claim_id": "c1", "text": "...", "confidence": 0.95}},
        ...
      ]
    }}
    
    Rules:
    - Each claim must be traceable to evidence
    - Confidence: 0.0-1.0 (lower if uncertain)
    - No speculation; only evidence-based claims
    """
    
    response = await model_gateway.call_llm(
        reasoning_prompt,
        model="gpt-4",
        max_tokens=1000
    )
    
    result = parse_json(response)
    return AnswerSkeleton(result["outline"]), result["claims"]
```

**Citation Mapping:**

```python
def citation_mapper(claims: List[Claim], evidence_pack: EvidencePack) -> CitationMap:
    citation_map = {}
    
    for claim in claims:
        matching_evidence = []
        
        for item in evidence_pack.items:
            similarity = semantic_similarity(claim.text, item.content)
            
            if similarity > 0.7:  # threshold
                matching_evidence.append({
                    "evidence_id": item.id,
                    "score": similarity,
                    "url": item.source_url
                })
        
        if matching_evidence:
            citation_map[claim.claim_id] = sorted(
                matching_evidence,
                key=lambda x: x["score"],
                reverse=True
            )[:3]  # Top 3 sources per claim
        else:
            claim.confidence *= 0.5  # Downgrade if no evidence
    
    return citation_map
```

---

### 7.6 Stage 6: Answer Synthesis ‚Äî Final Formatting

**Responsibility:**  
Compose final answer from skeleton, insert citations, personalize

**Inputs:**
- AnswerSkeleton + CitationMap

**Outputs:**
- FinalAnswer (markdown + citations)

**Synthesis (LLM):**

```python
async def synthesis_composer(
    skeleton: AnswerSkeleton,
    citation_map: CitationMap,
    user_preferences: Dict
) -> FinalAnswer:
    compose_prompt = f"""
    Write a financial intelligence response:
    
    Structure:
    {skeleton.to_markdown()}
    
    Citations (insert inline as [1], [2], etc.):
    {citation_map.to_citation_refs()}
    
    Style preferences:
    - Depth: {user_preferences.get('depth', 'medium')}
    - Tone: {user_preferences.get('tone', 'professional')}
    - Length: {user_preferences.get('max_words', 500)} words max
    
    Requirements:
    - Cite every factual claim
    - Bold key metrics
    - Add actionable insights
    - No speculation
    
    Respond in Markdown.
    """
    
    response = await model_gateway.call_llm(
        compose_prompt,
        model="gpt-4",
        max_tokens=800
    )
    
    final_answer = FinalAnswer(
        content=response,
        format="markdown",
        citations=citation_map.to_citation_list(),
        metadata={...}
    )
    
    # Post-process
    final_answer.content = redact_pii(final_answer.content)
    final_answer.content = enforce_max_length(final_answer.content, 2000)
    
    return final_answer
```

---

## 8. SECURITY & COMPLIANCE

### 8.1 Authentication & Authorization

- **Method:** JWT Bearer tokens (OAuth2)
- **RBAC Roles:** `user` (default), `analyst` (enhanced features), `admin` (full access)
- **Token Expiry:** 1 hour access + 7-day refresh
- **Scopes:** `read`, `write`, `execute_tasks`

### 8.2 Data Security

**Encryption at Rest:**
- PostgreSQL: AES-256 for sensitive columns (user_id, email)
- Redis: TLS for all connections

**Encryption in Transit:**
- TLS 1.3 mandatory (except internal Docker network)
- HSTS headers (strict-transport-security)

**Secret Management:**
- AWS Secrets Manager or Vault for API keys, LLM credentials
- Rotate quarterly
- Never log secrets

### 8.3 API Security

| Control | Implementation |
|---------|-----------------|
| **Input Validation** | JSON Schema validation + Pydantic models |
| **SQL Injection** | Parameterized queries (ORM: SQLAlchemy) |
| **XSS Prevention** | HTML entity escaping in responses, CSP headers |
| **CSRF** | CSRF tokens for POST requests (optional for API) |
| **Rate Limiting** | 60 req/min per user, 300 req/min per IP (WAF enforced) |
| **CORS** | Allowlist trusted origins only |

### 8.4 SSRF & URL Protection

```python
def is_ssrf_blocked(url: str) -> bool:
    parsed = urlparse(url)
    
    # Block private IP ranges
    BLOCKED_RANGES = [
        "127.0.0.1", "localhost",
        "169.254.169.254",  # AWS metadata
        "10.0.0.0/8",  # RFC1918
        "172.16.0.0/12",
        "192.168.0.0/16",
        "0.0.0.0/8"
    ]
    
    ip = socket.gethostbyname(parsed.netloc)
    for blocked_range in BLOCKED_RANGES:
        if ipaddress.ip_address(ip) in ipaddress.ip_network(blocked_range):
            return True
    
    return False
```

### 8.5 Threat Model (STRIDE)

| Threat | Mitigation |
|--------|-----------|
| **Spoofing** | JWT validation, IP whitelist for internal services |
| **Tampering** | HTTPS + signed requests, DB integrity checks |
| **Repudiation** | Audit logging (who did what when) |
| **Information Disclosure** | PII redaction, encrypted storage, access logs |
| **Denial of Service** | Rate limiting, auto-scaling, circuit breakers |
| **Elevation of Privilege** | RBAC, principle of least privilege, secrets rotation |

### 8.6 Compliance

- **GDPR:** Data subject rights (access, deletion, portability)
- **SOC 2:** Audit logs, encryption, access controls
- **Financial Data Privacy:** No disclosure of account numbers (future: tokenization)

---

## 9. NON-FUNCTIONAL REQUIREMENTS (NFR)

### 9.1 Performance Targets

| Metric | Target | Rationale |
|--------|--------|-----------|
| **Stage 1 Latency** | <200ms (p95) | Minimal input parsing |
| **Stage 2 Latency** | <500ms (p95) | Rule-based fast path |
| **Stage 3 Latency** | <1s (p95) | LLM planning |
| **Stage 4 Latency** | <5s (p95) | Web fetch bottleneck |
| **Stage 5 Latency** | <2s (p95) | Compressed reasoning |
| **Stage 6 Latency** | <2s (p95) | LLM composition |
| **Full Pipeline** | <12s (p95, with browse) | User expectation |
| **Throughput** | 1000 req/s sustained | Enterprise SLA |

### 9.2 Scalability

**Horizontal Scaling:**
- Kubernetes HPA: Auto-scale stages based on CPU (>60%) / Queue length
- Load balancing: Round-robin via Kubernetes Service
- Database: Connection pooling (PgBouncer)

**Estimated Capacity:**
- 1 Stage instance: 100‚Äì200 req/s (depends on latency)
- 10 Stage instances: 1000‚Äì2000 req/s
- Peak load (10x): 10,000 req/s (requires pre-scaling)

### 9.3 Reliability & Availability

| SLA | Target | Mechanism |
|-----|--------|-----------|
| **Uptime** | 99.9% (8.76 h downtime/year) | Multi-AZ, auto-failover, health checks |
| **RTO** | <1 hour | Blue-green deployment, rollback capability |
| **RPO** | <15 minutes | Daily incremental backups + 5-min snapshots |
| **MTTR** | <30 min | Automated alerts, runbooks, on-call rotation |

**High Availability Design:**
- Services deployed across 3 availability zones (minimum)
- Database multi-master replication
- Redis cluster with replication
- Circuit breakers for external dependencies (LLM API, web fetch)

### 9.4 Data Durability

- **PostgreSQL:** Daily backups (S3 + GCS), continuous replication
- **Redis:** RDB snapshots + AOF logging
- **Artifact Retention:** 30 days (user can extend)
- **Audit Logs:** 1-year retention (compliance)

---

## 10. OBSERVABILITY (Logs/Metrics/Traces)

### 10.1 Structured Logging

**JSON Log Format:**
```json
{
  "timestamp": "2025-12-10T15:23:45.123Z",
  "level": "INFO",
  "service": "stage_4_executor",
  "request_id": "req_abc123",
  "correlation_id": "corr_xyz",
  "user_id_hash": "sha256(user_id)",
  "stage": 4,
  "step_id": "s2",
  "action": "web.fetch",
  "url": "https://finance.yahoo.com/...",
  "status": "SUCCESS",
  "latency_ms": 2547,
  "bytes_fetched": 45230,
  "retry_count": 1,
  "error": null
}
```

**Log Levels:**
- **DEBUG:** Token usage, LLM calls, cache hits
- **INFO:** Request start/end, stage transitions, cache misses
- **WARN:** Timeouts, degraded operations, policy warnings
- **ERROR:** Failures, exceptions, retryable errors
- **CRITICAL:** Data corruption, auth failures, cascading failures

**PII Masking:**
- Never log: passwords, credit cards, SSNs, full emails
- Always hash: user_id, session_id
- Redact: Financial account numbers (if included in future)

### 10.2 Golden Metrics (Prometheus)

**Request Metrics:**
```
finai_requests_total{stage, status}
finai_request_latency_seconds{stage, quantile=[0.5, 0.95, 0.99]}
finai_request_size_bytes{stage, quantile=[0.5, 0.99]}
```

**Resource Metrics:**
```
finai_cpu_usage_percent{service}
finai_memory_usage_bytes{service}
finai_disk_usage_bytes{service}
```

**Model Metrics:**
```
finai_llm_calls_total{model, stage}
finai_llm_tokens_total{model, type=[input, output]}
finai_llm_latency_seconds{model, quantile=[0.5, 0.95, 0.99]}
finai_llm_cost_usd_total{model}
```

**Data Metrics:**
```
finai_evidence_items_total{source_type=[web, cache, api]}
finai_citation_accuracy_percent
finai_cache_hit_rate{cache_type=[redis, db]}
```

### 10.3 Distributed Tracing (OpenTelemetry)

**Trace Structure:**
```
Root Span: POST /v1/tasks:execute
‚îú‚îÄ‚îÄ Span: Stage 1 - UnifiedInputCore
‚îÇ   ‚îú‚îÄ‚îÄ validate_input (45ms)
‚îÇ   ‚îú‚îÄ‚îÄ normalize_text (20ms)
‚îÇ   ‚îî‚îÄ‚îÄ safety_precheck (15ms)
‚îú‚îÄ‚îÄ Span: Stage 2 - QueryUnderstanding
‚îÇ   ‚îú‚îÄ‚îÄ rule_engine (80ms)
‚îÇ   ‚îî‚îÄ‚îÄ embedding_prep (40ms)
‚îú‚îÄ‚îÄ Span: Stage 3 - RouterPlanner
‚îÇ   ‚îú‚îÄ‚îÄ signal_extraction (60ms)
‚îÇ   ‚îú‚îÄ‚îÄ plan_builder (450ms)
‚îÇ   ‚îî‚îÄ‚îÄ plan_validation (40ms)
‚îú‚îÄ‚îÄ Span: Stage 4 - UnifiedExecutor
‚îÇ   ‚îú‚îÄ‚îÄ retrieve (200ms)
‚îÇ   ‚îú‚îÄ‚îÄ rerank (150ms)
‚îÇ   ‚îú‚îÄ‚îÄ web_fetch (5200ms)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fetch URL 1 (2100ms)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fetch URL 2 (1800ms)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fetch URL 3 (1300ms)
‚îÇ   ‚îî‚îÄ‚îÄ extract_evidence (550ms)
‚îú‚îÄ‚îÄ Span: Stage 5 - Reasoning
‚îÇ   ‚îú‚îÄ‚îÄ compress_evidence (300ms)
‚îÇ   ‚îú‚îÄ‚îÄ reasoning_core (1800ms)
‚îÇ   ‚îî‚îÄ‚îÄ citation_mapper (200ms)
‚îî‚îÄ‚îÄ Span: Stage 6 - AnswerSynthesis
    ‚îú‚îÄ‚îÄ compose (1200ms)
    ‚îú‚îÄ‚îÄ personalize (100ms)
    ‚îî‚îÄ‚îÄ post_process (232ms)
```

### 10.4 Alerting Rules (PagerDuty)

| Alert | Threshold | Severity |
|-------|-----------|----------|
| **High Error Rate** | >5% 4xx+5xx | CRITICAL |
| **High Latency** | p95 > 15s | HIGH |
| **Low Availability** | <99.5% | CRITICAL |
| **Cache Miss Rate** | >50% | MEDIUM |
| **Model API Down** | 0 successful calls for 5min | CRITICAL |
| **Database Down** | Cannot connect | CRITICAL |
| **Memory Leak** | Continuous growth >1GB/hour | HIGH |

---

## 11. FAILURE MODES & RESILIENCE

### 11.1 Failure Mode Analysis (FMEA)

| Component | Failure Mode | Impact | Probability | Mitigation |
|-----------|--------------|--------|-------------|-----------|
| **Database** | Connection lost | Critical | Low (1/month) | Connection pool retry, circuit breaker, fallback to read cache |
| **LLM API** | Timeout (>30s) | High | Medium (5/month) | Retry with exponential backoff (3x), fallback to SLM, queue-based retry |
| **Web Fetch** | URL unreachable | Medium | High (50/month) | Skip failed URL, return partial evidence, use cache |
| **Embedding API** | Rate limited | Medium | Medium | Queue requests, use cached embeddings, fallback to BM25 |
| **Redis** | Out of memory | Medium | Low (1/year) | LRU eviction, alert when >80%, separate session cache |
| **Disk Full** | Write failures | Critical | Very low | Auto-scale storage, archive old logs, alert at 70% |

### 11.2 Retry Strategy

```python
# Exponential backoff with jitter
RETRY_CONFIG = {
    "max_retries": 3,
    "initial_delay_ms": 100,
    "max_delay_ms": 10000,
    "backoff_multiplier": 2.0,
    "jitter_factor": 0.1  # ¬±10%
}

# Example: Retry sequence
# Attempt 1: Delay 0ms
# Attempt 2: Delay 100ms + jitter
# Attempt 3: Delay 200ms + jitter
# Attempt 4: Delay 400ms + jitter
# Timeout after 4 attempts or 30s
```

### 11.3 Circuit Breaker Pattern

```python
class CircuitBreaker:
    CLOSED = "closed"  # Normal
    OPEN = "open"      # Blocked (failing fast)
    HALF_OPEN = "half_open"  # Testing recovery
    
    def __init__(self, failure_threshold=5, timeout_sec=30):
        self.state = CLOSED
        self.failure_count = 0
        self.failure_threshold = failure_threshold
        self.timeout_sec = timeout_sec
        self.last_failure_time = None
    
    async def call(self, func, *args, **kwargs):
        if self.state == OPEN:
            if time.time() - self.last_failure_time > self.timeout_sec:
                self.state = HALF_OPEN
            else:
                raise CircuitBreakerOpen()
        
        try:
            result = await func(*args, **kwargs)
            if self.state == HALF_OPEN:
                self.state = CLOSED
                self.failure_count = 0
            return result
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()
            
            if self.failure_count >= self.failure_threshold:
                self.state = OPEN
            
            raise
```

### 11.4 Graceful Degradation

| Scenario | Degraded Behavior | User Impact |
|----------|------------------|------------|
| **Reranker down** | Use similarity scores only | 10% fewer citations |
| **Web fetch timeout** | Use cache + historical data | May miss recent changes |
| **LLM rate limited** | Use faster SLM instead | Slightly lower quality |
| **Embedding API down** | Use BM25 only (keyword search) | Miss semantic results |
| **Memory pressure** | Reduce evidence pool size | Faster but fewer sources |

### 11.5 Timeout Configuration

```python
TIMEOUTS = {
    "http_connect": 5,  # 5s to establish connection
    "http_read": 10,    # 10s to read response
    "http_fetch_total": 2.5,  # Total per URL
    "model_request": 30,  # 30s for LLM call
    "redis_operation": 1,  # 1s for Redis get/set
    "database_query": 5,  # 5s for DB query
    "stage_total": 15,  # 15s per stage (soft limit)
    "pipeline_total": 60,  # 60s for full pipeline
}
```

---

## 12. TESTING STRATEGY

### 12.1 Test Pyramid

```
       /\
      /  \      E2E Tests (10%)
     /____\     - Full pipeline (Stage 1-6)
     /    \     - Realistic queries + assertions
    /      \    - Slow but comprehensive
   /________\

   /      \
  /        \    Integration Tests (20%)
 /          \   - Stage-to-stage interaction
/____________\  - Mock external APIs
- Database testing
- Cache validation

/            \
/              \  Unit Tests (70%)
/                \ - Single module/function
/__________________\ - Fast, deterministic
- Validators, extractors, formatters
- Edge case coverage
```

### 12.2 Unit Testing

**Coverage Target: 80%+**

```python
# Example: Test Stage 1 Normalizer
def test_normalize_whitespace():
    text = "Hello  \n\n  world"
    result = normalizer.normalize_text(text)
    assert result == "Hello\nworld"

def test_detect_language_vietnamese():
    text = "Xin ch√†o, ƒë√¢y l√† c√¢u ti·∫øng Vi·ªát"
    lang = normalizer.detect_language(text)
    assert lang == "vi"

def test_extract_urls():
    text = "Visit https://example.com and http://test.org"
    urls = classifier.extract_urls(text)
    assert len(urls) == 2
    assert "https://example.com" in urls

# Edge case
def test_extract_urls_with_parentheses():
    text = "Check (https://example.com) for details"
    urls = classifier.extract_urls(text)
    assert "https://example.com" in urls
```

### 12.3 Integration Testing

```python
# Example: Test Stage 1 ‚Üí Stage 2 interaction
async def test_stage1_to_stage2_flow():
    raw_request = RawRequest(
        input={"type": "text", "text": "Compare TSLA vs F"},
        context={...}
    )
    
    # Execute Stage 1
    normalized = await stage1_pipeline(raw_request, headers)
    assert normalized.language == "en"
    
    # Execute Stage 2
    task_spec = await stage2_query_understanding(normalized)
    assert task_spec.intent == Intent.COMPARE
    assert set(task_spec.entities) == {"TSLA", "F"}
    
    # Validate output format
    assert isinstance(task_spec, TaskSpecV1)

# Test with database
async def test_idempotency_with_redis():
    await redis.flushdb()
    
    raw_request = RawRequest(...)
    idem_key = "idem_test_123"
    headers = {"Idempotency-Key": idem_key, "X-User-Id": "user_1"}
    
    # First request
    result1 = await stage1_pipeline(raw_request, headers)
    
    # Second request (same key, same payload)
    result2 = await stage1_pipeline(raw_request, headers)
    
    assert result1.request_id == result2.request_id  # Same response
    
    # Different payload with same key ‚Üí 409 Conflict
    raw_request.input.text = "Different query"
    with pytest.raises(IdempotencyKeyReused):
        await stage1_pipeline(raw_request, headers)
```

### 12.4 End-to-End Testing

```python
async def test_e2e_simple_comparison():
    """Full pipeline: Query ‚Üí Answer with citations"""
    
    query = "Compare Tesla P/E vs Ford"
    request = RawRequest(input={"type": "text", "text": query})
    
    # Execute full pipeline
    final_answer = await full_pipeline_async(request)
    
    # Assertions
    assert final_answer.status == "SUCCEEDED"
    assert len(final_answer.citations) >= 2
    assert "Tesla" in final_answer.content
    assert "Ford" in final_answer.content
    assert final_answer.metadata.latency_ms < 12000
    
    # Citation accuracy
    for citation in final_answer.citations:
        assert citation.url.startswith("http")
        assert citation.title is not None

async def test_e2e_financial_analysis():
    """Complex query: Portfolio analysis with JSON output"""
    
    query = """Analyze my portfolio sector exposure:
    AAPL: 500 shares @ $120
    MSFT: 300 shares @ $380
    XLE: 100 shares @ $80"""
    
    request = RawRequest(
        input={"type": "text", "text": query},
        options={"response_format": "json"}
    )
    
    final_answer = await full_pipeline_async(request)
    
    # Verify JSON output
    result = json.loads(final_answer.content)
    assert "sectors" in result
    assert "allocations" in result
    assert sum(result["allocations"].values()) == pytest.approx(100, 0.01)
```

### 12.5 Performance Testing

```bash
# Load test with k6
k6 run load_test.js --vus 100 --duration 5m

# Stress test
k6 run stress_test.js --vus 500 --ramp-up 2m --ramp-down 1m

# Spike test
k6 run spike_test.js --vus 1000 --duration 30s
```

### 12.6 Golden Tests (Regression Prevention)

```python
# Deterministic outputs for critical paths
def test_rule_engine_deterministic():
    """Rule engine should give consistent output for same input"""
    
    text = "Compare TSLA vs Ford valuation metrics"
    
    results = [
        rule_engine_abcd(text)
        for _ in range(10)
    ]
    
    # All results should be identical
    for i in range(1, len(results)):
        assert results[i].intent == results[0].intent
        assert results[i].entities == results[0].entities
        assert results[i].confidence == results[0].confidence
```

---

## 13. DEPLOYMENT & OPERATIONS

### 13.1 Deployment Strategy

**Canary Deployment (Recommended):**
```
1. Deploy v2.0 to 5% canary pool
2. Monitor metrics for 30min (error rate, latency)
3. If healthy, expand to 25% (10% more)
4. Monitor another 30min
5. If still healthy, rollout to 100%
6. Keep v1.9 in place for 1 hour (quick rollback)
```

**Blue-Green Deployment (Alternative):**
```
Blue (v1.9) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                Load Balancer (switch)
Green (v2.0) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

1. Deploy v2.0 to Green environment
2. Run smoke tests
3. Switch traffic Blue ‚Üí Green
4. Keep Blue alive for 24h (rollback capability)
5. Decommission Blue
```

### 13.2 CI/CD Pipeline

```yaml
stages:
  - build:
      # Compile, lint, format check
      - docker build -t finai:${CI_COMMIT_SHA}
      - docker push registry.example.com/finai:${CI_COMMIT_SHA}
  
  - test:
      # Unit tests (must pass)
      - pytest tests/unit --cov=src --cov-fail-under=80
      # Integration tests
      - pytest tests/integration -m integration
  
  - security:
      # SAST, dependency scanning
      - trivy image finai:${CI_COMMIT_SHA}
      - snyk test --file=pyproject.toml
  
  - deploy-dev:
      # Auto-deploy to Dev
      - kubectl set image deployment/stage1-dev stage1-dev=finai:${CI_COMMIT_SHA}
      - kubectl rollout status deployment/stage1-dev
  
  - deploy-staging:
      # Auto-deploy to Staging
      - kubectl set image deployment/stage1-staging stage1-staging=finai:${CI_COMMIT_SHA}
      - helm test finai-staging --debug
  
  - deploy-prod:
      # Manual approval required
      - when: manual
      - kubectl set image deployment/stage1-prod stage1-prod=finai:${CI_COMMIT_SHA}
      - helm test finai-prod --debug
      - terraform apply -auto-approve  # IaC updates
```

### 13.3 Infrastructure as Code (Terraform)

```hcl
# kubernetes.tf
resource "kubernetes_deployment" "stage1" {
  metadata {
    name = "stage1-unified-input-core"
    namespace = var.namespace
  }
  
  spec {
    replicas = var.stage1_replicas
    
    template {
      spec {
        container {
          image = "${var.registry}/finai:${var.image_tag}"
          port { container_port = 8001 }
          
          resources {
            requests = { cpu = "500m", memory = "512Mi" }
            limits = { cpu = "1000m", memory = "1Gi" }
          }
          
          env {
            name = "STAGE"
            value = "1"
          }
          env {
            name = "LOG_LEVEL"
            value = var.log_level
          }
          
          liveness_probe {
            http_get {
              path = "/healthz"
              port = 8001
            }
            initial_delay_seconds = 10
            period_seconds = 10
          }
          
          readiness_probe {
            http_get {
              path = "/readyz"
              port = 8001
            }
            initial_delay_seconds = 5
            period_seconds = 5
          }
        }
      }
    }
  }
}

# Auto-scaling
resource "kubernetes_horizontal_pod_autoscaler" "stage1" {
  metadata {
    name = "stage1-hpa"
  }
  
  spec {
    scale_target_ref {
      api_version = "apps/v1"
      kind = "Deployment"
      name = kubernetes_deployment.stage1.metadata[0].name
    }
    
    min_replicas = 3
    max_replicas = 20
    
    target_cpu_utilization_percentage = 70
    target_memory_utilization_percentage = 80
  }
}
```

### 13.4 Operations Runbooks

**Runbook: Scale Stage 4 (High Load)**

```
# Problem: Stage 4 latency degrading (p95 > 8s)

# 1. Check current metrics
kubectl top pods -n finai | grep stage4
kubectl get hpa stage4-hpa -n finai

# 2. Check queue length
redis-cli LLEN finai:stage4:queue

# 3. If queue building up, manually scale
kubectl scale deployment stage4-unified-executor -n finai --replicas=15

# 4. Monitor recovery
watch kubectl get hpa stage4-hpa -n finai
watch 'kubectl top pods -n finai | grep stage4'

# 5. If still degrading, check logs
kubectl logs -n finai -l app=stage4 --tail=100 --follow

# 6. If external API down (web.fetch timeouts):
kubectl set env deployment/stage4 FETCH_TIMEOUT=1s -n finai
# Reduces fetch timeout from 2.5s to 1s, faster degradation

# 7. Rollback if needed
kubectl rollout undo deployment/stage4-unified-executor -n finai
```

### 13.5 Disaster Recovery

**Backup Strategy:**
- PostgreSQL: Daily full + hourly incremental (S3)
- Redis: RDB snapshot every 6 hours (S3)
- Artifacts: Daily export to cold storage (GCS) after 30 days

**Recovery Procedure:**
```bash
# 1. Identify backup point (e.g., 2h ago)
aws s3 ls s3://finai-backups/postgres/ | grep "2025-12-10T13"

# 2. Restore to new RDS instance
rds_restore_from_db_snapshot --db-instance-identifier finai-recovery

# 3. Verify data integrity (spot check)
SELECT COUNT(*) FROM tasks WHERE created_at > NOW() - INTERVAL '24 HOUR';

# 4. Update services to point to recovery instance (DNS CNAME update)
nslookup postgres.finai.internal  # Should resolve to recovery instance

# 5. Monitor for 1 hour before switching production traffic
```

---

## 14. TRADE-OFFS & ALTERNATIVES

### 14.1 Architecture Decisions (ADR)

**Decision 1: Single Orchestrator vs. Multi-Agent Swarm**

| Aspect | Single Orchestrator | Multi-Agent Swarm |
|--------|-------------------|-------------------|
| **Latency** | Deterministic (~8s) | Variable (unpredictable) |
| **Control** | Tight budget/policy enforcement | Loose (agents decide) |
| **Complexity** | Lower | Much higher |
| **Cost** | $0.02‚Äì0.05/query | $0.05‚Äì0.15/query |
| **Chosen** | ‚úÖ YES | ‚ùå NO |

**Rationale:** Enterprise customers require predictable latency + strict cost/policy controls.

---

**Decision 2: Sync vs. Async Pipeline**

| Aspect | Sync (1 request ‚Üí 1 response) | Async (task_id polling) |
|--------|-------------------------------|------------------------|
| **Latency Guarantee** | Fixed (all stages in request) | p95, not guaranteed |
| **Gateway Timeout Risk** | High (>60s timeout likely) | Low (202 response <500ms) |
| **Complexity** | Lower | Higher (task state machine) |
| **Chosen** | ‚ùå NO (MVP) | ‚úÖ YES (P0) |

**Rationale:** Async avoids gateway timeouts, enables graceful degradation.

---

**Decision 3: PostgreSQL vs. MongoDB**

| Aspect | PostgreSQL | MongoDB |
|--------|-----------|---------|
| **Schema Flexibility** | Fixed (need migrations) | Dynamic (documents) |
| **Transaction Support** | Strong ACID | Eventual consistency |
| **Cost** | Lower | Higher (at scale) |
| **Chosen** | ‚úÖ YES | ‚ùå NO |

**Rationale:** Structured data (tasks, evidence) benefits from schema definition + ACID.

---

### 14.2 Identified Risks & Mitigation

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|-----------|
| **LLM API pricing surge** | Cost/query 10x | Medium | Implement SLM fallback, on-device models (Phase 2) |
| **Web fetch latency (site slowness)** | p95 > 12s | High | Implement timeout + degradation, cache, ISP peering |
| **Citation accuracy <90%** | User dissatisfaction | Medium | Improve prompt, add evidence validation, human review (Phase 2) |
| **Competitor launches similar product** | Market pressure | High | Focus on financial domain specialization, beat on latency/accuracy |

---

## 15. GLOSSARY & REFERENCES

### 15.1 Key Terms

| Term | Definition |
|------|-----------|
| **Stage** | Sequential processing phase (1‚Äì6) in the pipeline |
| **Module** | Reusable component within a stage |
| **Orchestrator** | Central service coordinating all stages |
| **TaskSpecV1** | Canonical object representing query intent + constraints |
| **ActionPlan** | Ordered steps with tools/goals/budgets |
| **EvidencePack** | Filtered sources + citations for reasoning |
| **AnswerSkeleton** | Structured outline + atomic claims (pre-synthesis) |
| **FinalAnswer** | User-facing markdown response with citations |
| **SLM** | Small Language Model (lightweight, <7B params) |
| **LLM** | Large Language Model (e.g., GPT-4) |
| **Hybrid Search** | Combination of BM25 (keyword) + Vector (semantic) |
| **SSRF** | Server-Side Request Forgery (attack vector) |
| **Idempotency** | Operation produces same result regardless of retries |
| **Circuit Breaker** | Pattern to fail fast when dependency is degraded |

### 15.2 External References

- [Google Design Docs Culture](https://www.industrialempathy.com/posts/design-docs-at-google/)
- [AWS Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/)
- [OpenTelemetry Specification](https://opentelemetry.io/)
- [OWASP Top 10](https://owasp.org/www-project-top-ten/)
- [Kubernetes Best Practices](https://kubernetes.io/docs/concepts/configuration/overview/)

---

## 16. APPENDICES

### 16.1 Configuration Defaults (.env template)

```bash
# Service Configuration
STAGE=1
LOG_LEVEL=INFO
PORT=8001
WORKERS=4

# Database
DATABASE_URL=postgresql://user:pass@postgres:5432/finai
DATABASE_POOL_SIZE=20
DATABASE_TIMEOUT_SEC=5

# Redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_TIMEOUT_SEC=1

# Model Gateway
LLM_PROVIDER=openai
LLM_MODEL=gpt-4
SLM_MODEL=llama-2-7b
EMBEDDING_MODEL=text-embedding-ada-002
API_KEY_OPENAI=sk-...

# Observability
OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317
PROMETHEUS_PORT=9090

# Feature Flags
ENABLE_ASYNC=true
ENABLE_HEADLESS_BROWSING=false
ENABLE_VLM=false

# Limits
MAX_INPUT_LENGTH=20000
MAX_URLS=10
MAX_FETCH_SIZE_MB=2
FETCH_TIMEOUT_SEC=2.5
STAGE_TIMEOUT_SEC=15
PIPELINE_TIMEOUT_SEC=60
```

### 16.2 Kubernetes Manifests (Example)

```yaml
# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: finai

---
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: finai-config
  namespace: finai
data:
  log_level: INFO
  max_input_length: "20000"

---
# secret.yaml (created separately)
apiVersion: v1
kind: Secret
metadata:
  name: finai-secrets
  namespace: finai
type: Opaque
data:
  # Base64 encoded values
  openai_api_key: c2stLi4u  # echo -n "sk-..." | base64

---
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: stage1-service
  namespace: finai
spec:
  selector:
    app: stage1
  ports:
    - port: 8001
      targetPort: 8001
  type: LoadBalancer

---
# deployment.yaml (simplified)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: stage1-unified-input-core
  namespace: finai
spec:
  replicas: 3
  selector:
    matchLabels:
      app: stage1
  template:
    metadata:
      labels:
        app: stage1
    spec:
      containers:
      - name: stage1
        image: registry.example.com/finai:v1.0.0
        ports:
        - containerPort: 8001
        env:
        - name: STAGE
          value: "1"
        - name: LOG_LEVEL
          valueFrom:
            configMapKeyRef:
              name: finai-config
              key: log_level
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: finai-secrets
              key: openai_api_key
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8001
          initialDelaySeconds: 10
          periodSeconds: 10
```

### 16.3 Docker Compose (Local Development)

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: finai
      POSTGRES_PASSWORD: dev123
      POSTGRES_DB: finai
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7
    ports:
      - "6379:6379"

  stage1:
    build:
      context: ./services/stage1
      dockerfile: Dockerfile
    environment:
      DATABASE_URL: postgresql://finai:dev123@postgres:5432/finai
      REDIS_HOST: redis
      REDIS_PORT: 6379
    ports:
      - "8001:8001"
    depends_on:
      - postgres
      - redis

  stage2:
    build:
      context: ./services/stage2
      dockerfile: Dockerfile
    environment:
      DATABASE_URL: postgresql://finai:dev123@postgres:5432/finai
      REDIS_HOST: redis
    ports:
      - "8002:8002"
    depends_on:
      - postgres
      - redis

  # ... Stage 3-6, Model Gateway, Retrieval, Web Worker ...

  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  jaeger:
    image: jaegertracing/all-in-one
    ports:
      - "16686:16686"
      - "4317:4317"

volumes:
  postgres_data:
```

### 16.4 API Documentation (OpenAPI Spec)

```yaml
openapi: 3.0.0
info:
  title: FinAI API
  version: 1.0.0
  description: AI-Powered Financial Intelligence Platform
  contact:
    name: FinAI Team
    url: https://finai.io

servers:
  - url: https://api.finai.io/v1
    description: Production

paths:
  /tasks:execute:
    post:
      summary: Execute financial query
      tags:
        - Tasks
      security:
        - bearerAuth: []
      parameters:
        - name: Idempotency-Key
          in: header
          required: true
          schema:
            type: string
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RawRequest'
      responses:
        '202':
          description: Task accepted (async)
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TaskResponse'
        '400':
          description: Invalid input
        '401':
          description: Unauthorized
        '429':
          description: Rate limited

  /tasks/{taskId}:
    get:
      summary: Poll task status
      tags:
        - Tasks
      parameters:
        - name: taskId
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Task status
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TaskStatusResponse'

components:
  schemas:
    RawRequest:
      type: object
      required:
        - input
        - options
      properties:
        request_id:
          type: string
        idempotency_key:
          type: string
        input:
          type: object
          properties:
            type:
              enum: [text, url, html_snapshot]
            text:
              type: string
        options:
          type: object
          properties:
            mode:
              enum: [auto, quick, deep]
            allow_browse:
              type: boolean
            max_latency_ms:
              type: integer

    TaskResponse:
      type: object
      properties:
        task_id:
          type: string
        status:
          enum: [PENDING, RUNNING, SUCCEEDED, FAILED]
        estimate_seconds:
          type: integer

  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT
```

---

## 17. CHANGE LOG

| Version | Date | Changes |
|---------|------|---------|
| **1.0.0** | 2025-12-10 | Initial MVP specification (6 modules complete) |
| **0.9.0** | 2025-12-05 | Draft for internal review |
| **0.8.0** | 2025-11-20 | Architecture finalization |

---

## üéØ DOCUMENT COMPLETENESS CHECKLIST

‚úÖ **Metadata:** Title, Author, Status, Version  
‚úÖ **1. Overview:** Problem, Solution, Impact (<1 page TL;DR)  
‚úÖ **2. Goals/Scope:** In-scope, Out-of-scope, Assumptions, Constraints, Dependencies  
‚úÖ **3. User Stories:** 3+ primary flows with Acceptance Criteria  
‚úÖ **4. API Contract:** Full endpoint specs (Request/Response) + Error model  
‚úÖ **5. Data Model:** ERD + SQL Schema + Indexing + Caching strategy  
‚úÖ **6. Architecture:** C4 diagrams + Component diagrams + Data flows + Sequence diagrams  
‚úÖ **7. Implementation:** Per-module pseudocode + algorithms + code examples  
‚úÖ **8. Security:** AuthN/AuthZ + Encryption + SSRF protection + Threat model  
‚úÖ **9. NFR:** Latency/Throughput targets + SLA + Scalability + Data durability  
‚úÖ **10. Observability:** Logging strategy + Metrics + Distributed tracing + Alerting  
‚úÖ **11. Failure Modes:** FMEA + Retry logic + Circuit breaker + Graceful degradation  
‚úÖ **12. Testing:** Unit/Integration/E2E/Load/Golden tests  
‚úÖ **13. Deployment:** Strategy + CI/CD + IaC + Runbooks + Disaster recovery  
‚úÖ **14. Trade-offs:** Alternatives considered + Design decisions (ADR)  
‚úÖ **15. Glossary:** Terms + References  
‚úÖ **16. Appendices:** Config templates + K8s manifests + Docker Compose + OpenAPI spec  
‚úÖ **17. Change Log:** Version history  

---

## üìä EXECUTIVE METRICS SUMMARY

| Metric | Target | Status |
|--------|--------|--------|
| **MVP Stages Implemented** | 6/6 | ‚úÖ Complete |
| **Response Latency (p95)** | <12 seconds | ‚úÖ Achievable |
| **Citation Accuracy** | >95% | ‚úÖ Target |
| **Cost per Query** | <$0.05 | ‚úÖ Achievable |
| **System Availability** | 99.9% | ‚úÖ Target |
| **Evidence Quality** | >90% relevant | ‚úÖ Target |

---

**FinAI: Production-Ready Specification**  
**Status: Approved for Implementation ‚úÖ**  
**Date: December 10, 2025**  
**Version: 1.0.0 (Enterprise MVP)**

---

*This document is proprietary and confidential. For international submission: Include with English executive summary, architecture diagrams (PDF), and API documentation.*
