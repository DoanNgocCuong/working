# finAI Browser Agent - SDD Update Document (Complete)

**Mục tiêu thiết kế:**

1. ✅ Sử dụng codebase hiện tại (travel_agent pattern)
2. ✅ Implement finAI browser agent cụ thể
3. ✅ Thiết kế sẵn để mở rộng thành generic web browser agent sau này

**Phiên bản:** 1.0  
**Ngày:** December 17, 2025  
**Codebase reference:** SpecialProd_Agent_FinAIWebBrowser_T12_2025-.zip

---

# SECTION 5: HIGH-LEVEL DESIGN

## 5.1 System Architecture Overview

### 5.1.1 Multi-Agent Platform Architecture

**Actual Implementation (từ codebase):**

Hệ thống được thiết kế theo **Multi-Agent Platform Architecture**, không phải standalone agent như SDD ban đầu mô tả.

```
┌─────────────────────────────────────────────────────────────┐
│           Multi-Agent Platform Infrastructure               │
└─────────────────────────────────────────────────────────────┘
                            │
        ┌───────────────────┼───────────────────┐
        │                   │                   │
        ▼                   ▼                   ▼
┌──────────────┐    ┌──────────────┐    ┌──────────────┐
│   Common     │    │ Agent        │    │    API       │
│Infrastructure│    │ Registry     │    │   Layer      │
│              │    │              │    │              │
│ • Logging    │    │ • Factory    │    │ • Routes     │
│ • Database   │    │ • Discovery  │    │ • Services   │
│ • LLM Client │    │ • Lifecycle  │    │ • Models     │
│ • HTTP       │    │              │    │              │
└──────────────┘    └──────────────┘    └──────────────┘
                            │
        ┌───────────────────┼───────────────────┐
        │                   │                   │
        ▼                   ▼                   ▼
┌──────────────┐    ┌──────────────┐    ┌──────────────┐
│   Travel     │    │    finAI     │    │   Future     │
│   Agent      │    │   Browser    │    │   Agents     │
│  (Reference) │    │    Agent     │    │  (Generic)   │
└──────────────┘    └──────────────┘    └──────────────┘
```

**Lợi ích của kiến trúc này:**

- ✅ Shared infrastructure → không duplicate code
- ✅ Consistent patterns → dễ onboard developers
- ✅ Easy to add new agents → scale horizontally
- ✅ Centralized monitoring & logging

### 5.1.2 Agent Registration Pattern

**Cách hoạt động:**

```python
# app/common/agent/registry.py (existing)
class AgentRegistry:
    """Central registry for all agents."""
    _agents: Dict[str, Type[BaseAgent]] = {}
    
    @classmethod
    def register(cls, name: str, agent_class: Type[BaseAgent]):
        cls._agents[name] = agent_class
    
    @classmethod
    def get_agent(cls, name: str) -> Type[BaseAgent]:
        return cls._agents.get(name)


# app/common/agent/base.py (existing)
class BaseAgent(ABC):
    """Base interface for all agents."""
    
    @abstractmethod
    async def execute(self, *args, **kwargs):
        """Main execution method."""
        pass
```

**finAI Agent sẽ implement:**

```python
# app/module/finai_agent/__init__.py (NEW)
from app.common.agent.registry import AgentRegistry
from app.common.agent.base import BaseAgent

@AgentRegistry.register("finai_browser_agent")
class FinAIBrowserAgent(BaseAgent):
    """
    finAI Browser Agent implementation.
    
    Follows travel_agent pattern but for financial data extraction.
    """
    
    async def execute(self, query: str, user_id: str = None):
        """Execute financial analysis."""
        # Implementation follows Section 6
        pass
```

### 5.1.3 finAI Browser Agent Architecture (4-Layer Q3 Autonomy)

**Dựa trên travel_agent reference implementation:**

```
┌─────────────────────────────────────────────────────────────┐
│                  finAI Browser Agent                         │
│              (Q3 Autonomy - 4 Layers)                        │
└─────────────────────────────────────────────────────────────┘
                            │
        ┌───────────────────┼───────────────────┐
        │                   │                   │
        ▼                   ▼                   ▼
┌──────────────┐    ┌──────────────┐    ┌──────────────┐
│   LAYER 0    │    │   LAYER 1    │    │   LAYER 2    │
│  Governance  │───▶│  Perception  │───▶│  Cognition   │
│              │    │              │    │              │
│ Phase 1:     │    │ • Query      │    │ • LangGraph  │
│ Input Gate   │    │   Processor  │    │   StateGraph │
│              │    │              │    │              │
│ Phase 2:     │    │ • Financial  │    │ • 7 Nodes:   │
│ In-Flight    │    │   Entity     │    │   - Perceive │
│ Guards       │    │   Extractor  │    │   - Plan     │
│              │    │              │    │   - Navigate │
│ Phase 3:     │    │ • Context    │    │   - Extract  │
│ Output Gate  │    │   Builder    │    │   - Verify   │
│              │    │              │    │   - Renavigate│
└──────────────┘    └──────────────┘    │   - Synthesize│
                                        └──────┬────────┘
                                               │
                                               ▼
                                    ┌──────────────────┐
                                    │    LAYER 3       │
                                    │    Action        │
                                    │                  │
                                    │ • Playwright     │
                                    │   Controller     │
                                    │                  │
                                    │ • Browser Pool   │
                                    │                  │
                                    │ • Browser Tools: │
                                    │   - Navigate     │
                                    │   - Click        │
                                    │   - Scroll       │
                                    │   - Search       │
                                    │                  │
                                    │ • Financial      │
                                    │   Tools:         │
                                    │   - Extract Data │
                                    │   - Extract Table│
                                    │   - OCR          │
                                    │                  │
                                    │ • Tool Registry  │
                                    └──────────────────┘
```

### 5.1.4 Shared Infrastructure Integration

**finAI Agent sẽ sử dụng:**

1. **Common Logging** (`app.common.log`)
    
    ```python
    from app.common.log import setup_logger
    logger = setup_logger(__name__)
    ```
    
2. **Database Managers** (`app.common.mysql`, `app.common.postgres`)
    
    ```python
    from app.common.mysql.async_database_manager import AsyncDatabaseManager
    db = AsyncDatabaseManager()
    ```
    
3. **LLM Providers** (`app.common.langchain`)
    
    ```python
    from langchain_openai import ChatOpenAI
    llm = ChatOpenAI(model="gpt-4")
    ```
    
4. **HTTP Client** (`app.common.http`)
    
    ```python
    from app.common.http import get_http_client
    client = get_http_client()
    ```
    
5. **Redis** (`app.common.redis`)
    
    ```python
    from app.common.redis.redis import RedisClient
    redis = RedisClient()
    ```
    

## 5.2 Design for Future Generalization

**Thiết kế chiến lược để dễ mở rộng sau này:**

### 5.2.1 Abstraction Layer (Chuẩn bị sẵn)

```python
# app/module/finai_agent/core/base_extractor.py (NEW)
class BaseDataExtractor(ABC):
    """
    Base class for data extraction.
    
    Thiết kế này cho phép:
    - finAI: FinancialDataExtractor (current)
    - E-commerce: ProductDataExtractor (future)
    - Research: PaperDataExtractor (future)
    """
    
    @abstractmethod
    async def extract_from_page(
        self,
        a11y_tree: Dict,
        url: str
    ) -> Dict[str, Any]:
        """Extract data from current page."""
        pass
    
    @abstractmethod
    def validate_extracted_data(
        self,
        data: Dict[str, Any]
    ) -> bool:
        """Validate extracted data quality."""
        pass
```

```python
# app/module/finai_agent/extractors/financial_extractor.py (NEW)
class FinancialDataExtractor(BaseDataExtractor):
    """
    Financial-specific implementation.
    
    Trong tương lai có thể tách thành plugin.
    """
    
    async def extract_from_page(self, a11y_tree: Dict, url: str):
        # Financial-specific logic
        pass
```

### 5.2.2 Configuration-Driven Design

```python
# app/module/finai_agent/config/agent_config.py (NEW)
@dataclass
class AgentConfig:
    """
    Configuration for agent behavior.
    
    Thiết kế để dễ override cho các domains khác.
    """
    
    # Domain info
    domain: str = "financial"
    agent_name: str = "finai_browser_agent"
    
    # URL whitelist (có thể override)
    allowed_domains: List[str] = field(default_factory=lambda: [
        "finance.yahoo.com",
        "bloomberg.com",
        "sec.gov",
        "marketwatch.com"
    ])
    
    # LangGraph settings
    max_steps: int = 15
    timeout_seconds: int = 60
    
    # Extraction settings
    max_screenshots: int = 50
    screenshot_quality: int = 80
    
    # Prompts (có thể override)
    planning_prompt_template: str = """
    Create a navigation plan for financial analysis...
    """
    
    extraction_prompt_template: str = """
    Extract financial metrics from the page...
    """


# Usage
config = AgentConfig(domain="financial")
# Future: config = AgentConfig(domain="ecommerce", allowed_domains=[...])
```

### 5.2.3 Interface Segregation

**Tách rõ Generic vs Specific:**

```python
# app/module/finai_agent/interfaces/ (NEW folder structure)

# generic_browser_interface.py - GENERIC (tái sử dụng sau này)
class IBrowserController(ABC):
    @abstractmethod
    async def navigate(self, url: str): pass
    
    @abstractmethod
    async def click(self, selector: str): pass
    
    @abstractmethod
    async def screenshot(self) -> str: pass


# financial_interface.py - SPECIFIC (chỉ cho finAI)
class IFinancialExtractor(ABC):
    @abstractmethod
    async def extract_metrics(self, page_content: str) -> Dict: pass
    
    @abstractmethod
    async def extract_financial_tables(self, html: str) -> List[Dict]: pass
```

## 5.3 Deployment Architecture

### 5.3.1 Component Deployment

```
┌─────────────────────────────────────────────────────────┐
│                    Load Balancer                         │
└────────────────────┬────────────────────────────────────┘
                     │
        ┌────────────┼────────────┐
        │            │            │
        ▼            ▼            ▼
┌──────────┐  ┌──────────┐  ┌──────────┐
│  API     │  │  API     │  │  API     │
│  Server  │  │  Server  │  │  Server  │
│  (FastAPI)│  │ (FastAPI)│  │ (FastAPI)│
└────┬─────┘  └────┬─────┘  └────┬─────┘
     │            │            │
     └────────────┼────────────┘
                  │
        ┌─────────┼─────────┐
        │         │         │
        ▼         ▼         ▼
┌──────────┐ ┌──────────┐ ┌──────────┐
│ Browser  │ │ Browser  │ │ Browser  │
│ Worker   │ │ Worker   │ │ Worker   │
│ Pool     │ │ Pool     │ │ Pool     │
└────┬─────┘ └────┬─────┘ └────┬─────┘
     │            │            │
     └────────────┼────────────┘
                  │
        ┌─────────┴─────────┐
        │                   │
        ▼                   ▼
┌──────────────┐    ┌──────────────┐
│   MySQL      │    │    Redis     │
│   (Queries,  │    │   (Cache,    │
│   Sessions)  │    │   Rate Limit)│
└──────────────┘    └──────────────┘
```

### 5.3.2 Browser Pool Strategy

**Để support cả finAI và future domains:**

```python
# app/module/finai_agent/layer_3_action/browser/browser_pool.py (NEW)
class BrowserPool:
    """
    Shared browser pool for all agents.
    
    Design: Domain-agnostic → có thể dùng cho mọi web agent.
    """
    
    def __init__(self):
        self.max_browsers = 10  # Config-driven
        self.active_sessions: Dict[str, BrowserSession] = {}
    
    async def get_browser(
        self, 
        session_id: str,
        domain: str = "financial"  # Future: support multiple domains
    ) -> PlaywrightController:
        """
        Get browser instance.
        
        Args:
            session_id: Unique session ID
            domain: Domain type (for future domain-specific configs)
        """
        # Check if session exists
        if session_id in self.active_sessions:
            return self.active_sessions[session_id].browser
        
        # Create new session
        browser = await self._create_browser(domain)
        self.active_sessions[session_id] = BrowserSession(
            id=session_id,
            browser=browser,
            domain=domain,
            created_at=datetime.now()
        )
        
        return browser
    
    async def _create_browser(self, domain: str):
        """
        Create browser with domain-specific config.
        
        Future: Different configs for different domains.
        """
        config = self._get_browser_config(domain)
        
        playwright = await async_playwright().start()
        browser = await playwright.chromium.launch(
            headless=config.headless,
            args=config.args
        )
        
        context = await browser.new_context(
            viewport=config.viewport,
            user_agent=config.user_agent
        )
        
        return PlaywrightController(context)
    
    def _get_browser_config(self, domain: str):
        """Get domain-specific browser config."""
        configs = {
            "financial": BrowserConfig(
                headless=True,
                viewport={"width": 1920, "height": 1080},
                user_agent="Mozilla/5.0..."
            ),
            # Future domains
            "ecommerce": BrowserConfig(...),
            "research": BrowserConfig(...)
        }
        
        return configs.get(domain, configs["financial"])
```

## 5.4 Migration Path to Generic Agent

**Khi cần mở rộng sang generic:**

### Phase 1: Extract Core (1 tuần)

```bash
# Move browser infrastructure
mv finai_agent/layer_3_action/browser/ → web_browser_agent/core/browser/

# Move base classes
mv finai_agent/core/base_*.py → web_browser_agent/core/
```

### Phase 2: Create Plugin Structure (3 ngày)

```python
# web_browser_agent/plugins/financial/ (NEW)
from finai_agent import *  # Wrap existing code

class FinancialPlugin:
    entity_extractor = FinancialEntityExtractor  # Existing
    data_extractor = FinancialDataExtractor      # Existing
    validators = FinancialValidators             # Existing
```

### Phase 3: Add New Domain (2 ngày)

```python
# web_browser_agent/plugins/ecommerce/ (NEW)
class EcommercePlugin:
    entity_extractor = ProductEntityExtractor   # New
    data_extractor = ProductDataExtractor       # New
    validators = ProductValidators              # New
```

**Estimated migration effort:** 2-3 tuần

---

# SECTION 6: LOW-LEVEL DESIGN

## 6.1 Layer 0: Governance

### 6.1.1 Phase 1 - Input Gate

**File:** `app/module/finai_agent/layer_0_governance/phase_1_input_gate/input_gate.py`

**Pattern từ travel_agent:**

```python
class InputGate:
    async def check(self, user_prompt: str, user_id: str = None):
        # Rate limiting
        # Content validation
        # Risk scoring
```

**finAI Implementation:**

```python
from dataclasses import dataclass
from typing import Optional
from datetime import datetime, timedelta

@dataclass
class GateResult:
    """Result from input gate."""
    allowed: bool
    reason: str = ""
    risk_score: float = 0.0


class FinancialInputGate:
    """
    Input validation gate cho financial queries.
    
    Design: Có thể tách thành BaseInputGate + FinancialInputGate
            để dễ reuse cho domains khác.
    """
    
    def __init__(self):
        self.rate_limiter = RateLimiter()
        self.content_validator = ContentValidator()
    
    async def check(
        self,
        query: str,
        user_id: Optional[str] = None
    ) -> GateResult:
        """
        Validate financial query input.
        
        Checks:
        1. Rate limiting (generic - có thể reuse)
        2. Content safety (generic - có thể reuse)
        3. Financial-specific validation (specific)
        4. Malicious pattern detection (generic - có thể reuse)
        """
        
        # 1. Rate limiting (GENERIC - reusable)
        if user_id and await self._is_rate_limited(user_id):
            return GateResult(
                allowed=False,
                reason="Rate limit exceeded: 10 requests/hour",
                risk_score=1.0
            )
        
        # 2. Content safety (GENERIC - reusable)
        if await self._contains_harmful_content(query):
            return GateResult(
                allowed=False,
                reason="Harmful content detected",
                risk_score=0.9
            )
        
        # 3. Financial-specific validation (SPECIFIC)
        financial_check = await self._validate_financial_query(query)
        if not financial_check["valid"]:
            return GateResult(
                allowed=False,
                reason=financial_check["reason"],
                risk_score=0.7
            )
        
        # 4. Malicious patterns (GENERIC - reusable)
        if await self._detect_malicious_patterns(query):
            return GateResult(
                allowed=False,
                reason="Suspicious patterns detected",
                risk_score=0.95
            )
        
        # All checks passed
        return GateResult(
            allowed=True,
            risk_score=0.1
        )
    
    async def _is_rate_limited(self, user_id: str) -> bool:
        """
        Check rate limit.
        
        GENERIC - có thể move ra BaseInputGate.
        """
        from app.common.redis.redis import RedisClient
        
        redis = RedisClient()
        key = f"rate_limit:finai:{user_id}"
        
        count = await redis.incr(key)
        if count == 1:
            await redis.expire(key, 3600)  # 1 hour
        
        return count > 10  # 10 requests/hour
    
    async def _contains_harmful_content(self, query: str) -> bool:
        """
        Check for harmful content.
        
        GENERIC - có thể move ra BaseInputGate.
        """
        harmful_patterns = [
            "hack", "exploit", "ddos", "sql injection",
            "insider trading", "market manipulation"
        ]
        
        query_lower = query.lower()
        return any(pattern in query_lower for pattern in harmful_patterns)
    
    async def _validate_financial_query(self, query: str) -> Dict[str, Any]:
        """
        Financial-specific validation.
        
        SPECIFIC - chỉ cho finAI.
        """
        # Check for prohibited insider trading requests
        insider_keywords = [
            "insider information",
            "non-public information",
            "material non-public"
        ]
        
        query_lower = query.lower()
        if any(keyword in query_lower for keyword in insider_keywords):
            return {
                "valid": False,
                "reason": "Prohibited: Potential insider trading request"
            }
        
        # Check if query contains financial entities
        # (Simple check - Layer 1 will do detailed extraction)
        has_company = any(
            len(word) > 2 and word[0].isupper()
            for word in query.split()
        )
        
        has_financial_terms = any(
            term in query_lower
            for term in ["stock", "revenue", "earnings", "price", "market cap"]
        )
        
        if not (has_company or has_financial_terms):
            return {
                "valid": False,
                "reason": "Query does not appear to be financial-related"
            }
        
        return {"valid": True}
    
    async def _detect_malicious_patterns(self, query: str) -> bool:
        """
        Detect malicious URL injection or XSS.
        
        GENERIC - có thể move ra BaseInputGate.
        """
        import re
        
        # Check for suspicious URLs
        url_pattern = r'https?://[^\s]+'
        urls = re.findall(url_pattern, query)
        
        # Only allow whitelisted domains
        whitelist = [
            "finance.yahoo.com",
            "bloomberg.com",
            "sec.gov",
            "marketwatch.com"
        ]
        
        for url in urls:
            if not any(domain in url for domain in whitelist):
                return True  # Suspicious URL
        
        # Check for script injection
        if "<script" in query.lower() or "javascript:" in query.lower():
            return True
        
        return False
```

### 6.1.2 Phase 2 - In-Flight Guards

**File:** `app/module/finai_agent/layer_0_governance/phase_2_in_flight_guards/browser_guards.py`

```python
@dataclass
class GuardResult:
    """Result from browser guard check."""
    should_block: bool
    reason: str = ""
    severity: str = "low"  # low, medium, high


class BrowserGuards:
    """
    Runtime monitoring for browser agent execution.
    
    Design: Mostly GENERIC - có thể reuse cho mọi browser agent.
    """
    
    def __init__(self, domain: str = "financial"):
        self.domain = domain
        self.url_whitelist = self._load_whitelist(domain)
    
    def _load_whitelist(self, domain: str) -> List[str]:
        """
        Load URL whitelist for domain.
        
        GENERIC pattern - domain-specific data.
        """
        whitelists = {
            "financial": [
                "finance.yahoo.com",
                "bloomberg.com",
                "sec.gov",
                "marketwatch.com",
                "google.com/finance"
            ],
            # Future domains
            "ecommerce": [
                "amazon.com",
                "ebay.com",
                "walmart.com"
            ],
            "research": [
                "scholar.google.com",
                "arxiv.org",
                "ieee.org"
            ]
        }
        
        return whitelists.get(domain, [])
    
    async def monitor_browser_action(
        self,
        action: str,
        url: str,
        state: Any  # Will be FinAIState or other domain states
    ) -> GuardResult:
        """
        Monitor browser actions in real-time.
        
        GENERIC - works for any browser agent.
        """
        
        # 1. Domain whitelist check (GENERIC pattern)
        if not self._is_whitelisted_domain(url):
            return GuardResult(
                should_block=True,
                reason=f"Domain not whitelisted: {url}",
                severity="high"
            )
        
        # 2. Navigation loop detection (GENERIC)
        if self._detect_navigation_loop(state.navigation_history):
            return GuardResult(
                should_block=True,
                reason="Navigation loop detected - same URL visited 3+ times",
                severity="high"
            )
        
        # 3. Resource limits (GENERIC)
        if len(state.screenshots) > 50:
            return GuardResult(
                should_block=True,
                reason="Screenshot limit exceeded (50)",
                severity="medium"
            )
        
        if state.current_step > state.max_steps:
            return GuardResult(
                should_block=True,
                reason=f"Max steps exceeded ({state.max_steps})",
                severity="medium"
            )
        
        # 4. Execution time limit (GENERIC)
        if hasattr(state, 'start_time'):
            elapsed = (datetime.now() - state.start_time).total_seconds()
            if elapsed > 300:  # 5 minutes
                return GuardResult(
                    should_block=True,
                    reason="Execution timeout (5 minutes)",
                    severity="high"
                )
        
        return GuardResult(should_block=False)
    
    def _is_whitelisted_domain(self, url: str) -> bool:
        """
        Check against allowed domains.
        
        GENERIC - works for any domain.
        """
        from urllib.parse import urlparse
        
        domain = urlparse(url).netloc
        return any(allowed in domain for allowed in self.url_whitelist)
    
    def _detect_navigation_loop(self, history: List[str]) -> bool:
        """
        Detect if stuck in navigation loop.
        
        GENERIC - works for any browser agent.
        """
        if len(history) < 3:
            return False
        
        # Check last 3 URLs
        recent = history[-3:]
        return len(set(recent)) == 1  # All same URL
```

### 6.1.3 Phase 3 - Output Gate

**File:** `app/module/finai_agent/layer_0_governance/phase_3_output_gate/result_validator.py`

```python
@dataclass
class ValidationResult:
    """Result from output validation."""
    is_valid: bool
    quality_score: float = 0.0
    issues: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)


class FinancialOutputValidator:
    """
    Validate financial data extraction quality.
    
    Design: Có BaseOutputValidator + FinancialOutputValidator
    """
    
    async def validate(
        self,
        extracted_data: Dict[str, Any],
        metadata: Dict[str, Any]
    ) -> ValidationResult:
        """
        Validate output quality.
        
        Mix of GENERIC and SPECIFIC checks.
        """
        
        issues = []
        recommendations = []
        
        # 1. Completeness check (GENERIC pattern)
        required_fields = self._get_required_fields()
        for field in required_fields:
            if field not in extracted_data:
                issues.append(f"Missing required field: {field}")
        
        # 2. Data format validation (SPECIFIC)
        if "metrics" in extracted_data:
            for metric_name, value in extracted_data["metrics"].items():
                if not self._is_valid_metric_value(value):
                    issues.append(
                        f"Invalid metric value: {metric_name}={value}"
                    )
        
        # 3. Temporal consistency (SPECIFIC)
        if not self._check_temporal_consistency(extracted_data):
            issues.append("Temporal inconsistency detected")
            recommendations.append(
                "Verify that all metrics are from the same time period"
            )
        
        # 4. Source attribution (GENERIC)
        if "source_url" not in metadata:
            issues.append("Missing source URL")
        
        # 5. Confidence threshold (GENERIC)
        if metadata.get("data_confidence", 0) < 0.5:
            issues.append("Low confidence score")
            recommendations.append("Consider additional verification")
        
        # Calculate quality score
        quality_score = self._calculate_quality_score(
            extracted_data,
            metadata,
            len(issues)
        )
        
        return ValidationResult(
            is_valid=len(issues) == 0,
            quality_score=quality_score,
            issues=issues,
            recommendations=recommendations
        )
    
    def _get_required_fields(self) -> List[str]:
        """
        Required fields for valid output.
        
        SPECIFIC - depends on domain.
        """
        return [
            "company_name",
            "metrics",
            "source_url",
            "timestamp"
        ]
    
    def _is_valid_metric_value(self, value: Any) -> bool:
        """
        Validate metric value format.
        
        SPECIFIC - financial metrics.
        """
        if value is None:
            return False
        
        # Accept numbers
        if isinstance(value, (int, float)):
            return True
        
        # Accept formatted strings like "$1.5B", "25.3%"
        if isinstance(value, str):
            import re
            # Check for number patterns
            pattern = r'^[\$\€\¥]?[0-9,.]+[BMK%]?$'
            return bool(re.match(pattern, value))
        
        return False
    
    def _check_temporal_consistency(
        self,
        data: Dict[str, Any]
    ) -> bool:
        """
        Check if all metrics are from same time period.
        
        SPECIFIC - financial data.
        """
        # Extract time periods from data
        time_periods = set()
        
        if "fiscal_period" in data:
            time_periods.add(data["fiscal_period"])
        
        if "metrics" in data:
            for metric in data["metrics"].values():
                if isinstance(metric, dict) and "period" in metric:
                    time_periods.add(metric["period"])
        
        # All should be from same period
        return len(time_periods) <= 1
    
    def _calculate_quality_score(
        self,
        data: Dict[str, Any],
        metadata: Dict[str, Any],
        num_issues: int
    ) -> float:
        """
        Calculate overall quality score.
        
        GENERIC - same formula for all domains.
        """
        score = 1.0
        
        # Deduct for issues
        score -= num_issues * 0.1
        
        # Boost for high confidence
        if metadata.get("data_confidence", 0) > 0.8:
            score += 0.1
        
        # Ensure 0-1 range
        return max(0.0, min(1.0, score))
```

## 6.2 Layer 1: Perception

### 6.2.1 Input Processor

**File:** `app/module/finai_agent/layer_1_perception/input_processor.py`

**Pattern từ travel_agent:**

```python
class InputProcessor:
    def process(self, user_prompt: str) -> Dict[str, Any]:
        # Language detection (generic)
        # Text cleaning (generic)
        # Intent classification (domain-specific)
        # Quality scoring (generic)
```

**finAI Implementation:**

```python
class FinancialQueryProcessor:
    """
    Process financial queries.
    
    Design: Có BaseQueryProcessor + domain-specific processors
    """
    
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0)
    
    def process(self, query: str) -> Dict[str, Any]:
        """
        Process raw financial query.
        
        Returns:
            {
                "is_valid": bool,
                "intent": str,
                "quality_score": float,
                "language": str,
                "cleaned_text": str,
                "entities": Dict  # Preview of entities
            }
        """
        
        # 1. Language detection (GENERIC)
        language = self._detect_language(query)
        
        # 2. Text cleaning (GENERIC)
        cleaned = self._clean_text(query)
        
        # 3. Intent classification (SPECIFIC)
        intent = self._classify_financial_intent(cleaned)
        
        # 4. Quality scoring (GENERIC)
        quality = self._calculate_quality(cleaned)
        
        # 5. Quick entity preview (SPECIFIC)
        entities = self._extract_quick_entities(cleaned)
        
        return {
            "is_valid": quality > 0.3 and intent != "unknown",
            "intent": intent,
            "quality_score": quality,
            "language": language,
            "cleaned_text": cleaned,
            "entities": entities
        }
    
    def _detect_language(self, text: str) -> str:
        """
        Detect language.
        
        GENERIC - same for all domains.
        """
        # Simple heuristic - can be replaced with langdetect
        if any(ord(char) > 127 for char in text):
            return "vi"  # Vietnamese or other
        return "en"
    
    def _clean_text(self, text: str) -> str:
        """
        Clean and normalize text.
        
        GENERIC - same for all domains.
        """
        # Remove extra whitespace
        text = " ".join(text.split())
        
        # Remove special characters but keep financial symbols
        # Keep: $, €, %, numbers, letters
        import re
        text = re.sub(r'[^\w\s$€%.,!?-]', '', text)
        
        return text.strip()
    
    def _classify_financial_intent(self, text: str) -> str:
        """
        Classify financial query intent.
        
        SPECIFIC - financial domain.
        """
        text_lower = text.lower()
        
        intents = {
            "stock_analysis": [
                "stock price", "share price", "current price"
            ],
            "financial_metrics": [
                "revenue", "earnings", "profit", "eps", "p/e ratio"
            ],
            "company_comparison": [
                "compare", "vs", "versus", "better than"
            ],
            "financial_statements": [
                "balance sheet", "income statement", "cash flow"
            ],
            "market_data": [
                "market cap", "trading volume", "52-week"
            ]
        }
        
        for intent, keywords in intents.items():
            if any(keyword in text_lower for keyword in keywords):
                return intent
        
        return "general_financial_query"
    
    def _calculate_quality(self, text: str) -> float:
        """
        Calculate query quality score.
        
        GENERIC - same scoring approach for all domains.
        """
        score = 0.0
        
        # Length check
        if 10 <= len(text) <= 500:
            score += 0.3
        
        # Has capital letters (proper nouns)
        if any(c.isupper() for c in text):
            score += 0.2
        
        # Has numbers (metrics, prices)
        if any(c.isdigit() for c in text):
            score += 0.2
        
        # Not too short or too long
        words = text.split()
        if 3 <= len(words) <= 50:
            score += 0.3
        
        return min(1.0, score)
    
    def _extract_quick_entities(self, text: str) -> Dict[str, Any]:
        """
        Quick entity extraction preview.
        
        SPECIFIC - financial entities.
        Full extraction happens in EntityExtractor.
        """
        import re
        
        entities = {}
        
        # Extract potential company names (capitalized words)
        companies = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', text)
        if companies:
            entities["potential_companies"] = companies[:3]  # Top 3
        
        # Extract ticker symbols (uppercase 1-5 chars)
        tickers = re.findall(r'\b[A-Z]{1,5}\b', text)
        if tickers:
            entities["potential_tickers"] = tickers[:3]
        
        # Extract numbers (potential metrics)
        numbers = re.findall(r'\d+(?:\.\d+)?', text)
        if numbers:
            entities["numbers_mentioned"] = len(numbers)
        
        return entities
```

### 6.2.2 Entity Extractor

**File:** `app/module/finai_agent/layer_1_perception/entity_extractor.py`

```python
@dataclass
class FinancialQuery:
    """
    Structured financial query.
    
    Design: Có BaseQuery + domain-specific query classes.
    """
    
    # Core entities
    company: str = ""
    ticker_symbol: Optional[str] = None
    
    # Requested metrics
    metrics: List[str] = field(default_factory=list)
    
    # Temporal
    time_period: Optional[str] = None
    fiscal_year: Optional[str] = None
    fiscal_quarter: Optional[str] = None
    
    # Comparison
    compare_with: List[str] = field(default_factory=list)
    
    # Sources (if user specifies)
    specific_urls: List[str] = field(default_factory=list)
    
    # User preferences
    preferred_sources: List[str] = field(default_factory=list)


class FinancialEntityExtractor:
    """
    Extract financial entities using LLM.
    
    SPECIFIC - financial domain.
    """
    
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0)
    
    async def extract(self, query: str) -> FinancialQuery:
        """
        Extract structured financial entities.
        
        Uses LLM for robust extraction.
        """
        
        prompt = f"""
Extract financial entities from this query: "{query}"

Return JSON with:
{{
    "company": str,                    // Main company name or ticker
    "ticker_symbol": str or null,      // Stock ticker if mentioned
    "metrics": [str],                  // Requested metrics
    "time_period": str or null,        // e.g., "Q3 2024", "FY 2023"
    "fiscal_year": str or null,        // Year
    "fiscal_quarter": str or null,     // Quarter
    "compare_with": [str],             // Competitor companies
    "specific_urls": [str],            // If user provides URLs
    "preferred_sources": [str]         // e.g., ["yahoo finance"]
}}

Financial metrics can be:
- Revenue, Net Income, Gross Profit
- EPS (Earnings Per Share)
- P/E Ratio, P/B Ratio
- Market Cap, Enterprise Value
- ROE, ROA, Operating Margin
- Debt-to-Equity, Current Ratio
- Free Cash Flow

Examples:

Query: "What is Apple's current revenue?"
{{
    "company": "Apple Inc.",
    "ticker_symbol": "AAPL",
    "metrics": ["revenue"],
    "time_period": "current"
}}

Query: "Compare Tesla vs GM revenue and EPS for Q3 2024"
{{
    "company": "Tesla",
    "ticker_symbol": "TSLA",
    "metrics": ["revenue", "EPS"],
    "time_period": "Q3 2024",
    "fiscal_quarter": "Q3",
    "fiscal_year": "2024",
    "compare_with": ["General Motors", "Ford"]
}}

Query: "Show me Microsoft's P/E ratio from Yahoo Finance"
{{
    "company": "Microsoft",
    "ticker_symbol": "MSFT",
    "metrics": ["P/E ratio"],
    "preferred_sources": ["yahoo finance"]
}}

Now extract from: "{query}"
"""
        
        result = await self.llm.ainvoke(prompt)
        
        # Parse JSON response
        import json
        import re
        
        # Extract JSON from response
        content = result.content
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            data = json.loads(json_match.group())
        else:
            data = json.loads(content)
        
        return FinancialQuery(
            company=data.get("company", ""),
            ticker_symbol=data.get("ticker_symbol"),
            metrics=data.get("metrics", []),
            time_period=data.get("time_period"),
            fiscal_year=data.get("fiscal_year"),
            fiscal_quarter=data.get("fiscal_quarter"),
            compare_with=data.get("compare_with", []),
            specific_urls=data.get("specific_urls", []),
            preferred_sources=data.get("preferred_sources", [])
        )
```

### 6.2.3 Context Builder

**File:** `app/module/finai_agent/layer_1_perception/context_builder.py`

```python
class FinancialContextBuilder:
    """
    Build rich context for financial analysis.
    
    SPECIFIC but có base pattern có thể reuse.
    """
    
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0)
    
    async def build_context(
        self,
        query: FinancialQuery,
        user_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Build comprehensive financial context.
        
        Context includes:
        - Industry/sector info
        - Competitor landscape
        - Recent news
        - User history
        - Market conditions
        """
        
        context = {
            "query": query,
            "timestamp": datetime.now().isoformat()
        }
        
        # 1. Industry context (SPECIFIC)
        if query.company:
            context["industry"] = await self._get_industry(query.company)
            context["sector"] = await self._get_sector(query.company)
        
        # 2. Competitor context (SPECIFIC)
        if query.compare_with:
            context["competitors"] = query.compare_with
        else:
            # Auto-detect top competitors
            context["competitors"] = await self._get_top_competitors(
                query.company
            )
        
        # 3. Recent news (SPECIFIC but pattern reusable)
        context["recent_news"] = await self._get_recent_news(
            query.company,
            days=30
        )
        
        # 4. User history (GENERIC pattern)
        if user_id:
            context["user_history"] = await self._get_user_history(user_id)
        
        # 5. Market conditions (SPECIFIC)
        context["market_indices"] = await self._get_market_indices()
        
        return context
    
    async def _get_industry(self, company: str) -> str:
        """Get company's industry."""
        # In production: query database or API
        # For MVP: use LLM
        
        prompt = f"What industry is {company} in? Answer in 1-2 words."
        result = await self.llm.ainvoke(prompt)
        return result.content.strip()
    
    async def _get_sector(self, company: str) -> str:
        """Get company's sector."""
        prompt = f"What sector is {company} in? (Technology/Healthcare/Finance/etc)"
        result = await self.llm.ainvoke(prompt)
        return result.content.strip()
    
    async def _get_top_competitors(
        self,
        company: str,
        limit: int = 3
    ) -> List[str]:
        """Get main competitors."""
        prompt = f"""
List the top {limit} main competitors of {company}.
Return only company names, one per line.
"""
        result = await self.llm.ainvoke(prompt)
        
        competitors = [
            line.strip()
            for line in result.content.split('\n')
            if line.strip()
        ]
        
        return competitors[:limit]
    
    async def _get_recent_news(
        self,
        company: str,
        days: int = 30
    ) -> List[Dict[str, str]]:
        """
        Get recent news headlines.
        
        Pattern: Could use web search or news API.
        """
        # Placeholder - would use actual news API
        return [
            {
                "headline": f"Recent news about {company}",
                "source": "Financial Times",
                "date": datetime.now().isoformat()
            }
        ]
    
    async def _get_user_history(self, user_id: str) -> List[Dict]:
        """
        Get user's previous financial queries.
        
        GENERIC pattern - works for any domain.
        """
        from app.common.mysql.async_database_manager import AsyncDatabaseManager
        
        db = AsyncDatabaseManager()
        
        history = await db.fetch_all(
            """
            SELECT company, metrics, created_at
            FROM finai_query_history
            WHERE user_id = %s
            ORDER BY created_at DESC
            LIMIT 10
            """,
            (user_id,)
        )
        
        return history or []
    
    async def _get_market_indices(self) -> Dict[str, float]:
        """Get current market indices."""
        # Placeholder - would use actual market data API
        return {
            "S&P 500": 4500.0,
            "NASDAQ": 14000.0,
            "Dow Jones": 35000.0
        }
```

## 6.3 Layer 2: Cognition (LangGraph)

### 6.3.1 State Management

**File:** `app/module/finai_agent/layer_2_cognition/state.py`

```python
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from datetime import datetime

@dataclass
class FinAIState:
    """
    State schema for finAI browser agent.
    
    Design: Inherits patterns from BaseWebAgentState (future)
    """
    
    # ========================================
    # INPUT (from Layer 1)
    # ========================================
    financial_query: FinancialQuery
    original_query: str = ""
    context: Dict[str, Any] = field(default_factory=dict)
    
    # ========================================
    # BROWSER STATE (GENERIC - reusable)
    # ========================================
    current_url: Optional[str] = None
    navigation_history: List[str] = field(default_factory=list)
    screenshots: List[str] = field(default_factory=list)  # Base64 or paths
    a11y_trees: List[Dict] = field(default_factory=list)
    page_html: Optional[str] = None  # Current page HTML
    
    # ========================================
    # PLANNING (GENERIC - reusable)
    # ========================================
    navigation_plan: List[Dict[str, Any]] = field(default_factory=list)
    current_step: int = 0
    max_steps: int = 15
    
    # ========================================
    # EXTRACTED DATA (SPECIFIC - financial)
    # ========================================
    extracted_metrics: Dict[str, Any] = field(default_factory=dict)
    extracted_tables: List[Dict] = field(default_factory=list)
    extracted_text: List[str] = field(default_factory=list)
    
    # Company context
    company_info: Dict[str, Any] = field(default_factory=dict)
    
    # ========================================
    # VERIFICATION (GENERIC - reusable)
    # ========================================
    needs_renavigation: bool = False
    data_confidence: float = 0.0
    
    # ========================================
    # REASONING (GENERIC - reusable)
    # ========================================
    reasoning_steps: List[str] = field(default_factory=list)
    actions_taken: List[Dict] = field(default_factory=list)
    decisions_made: List[Dict] = field(default_factory=list)
    
    # ========================================
    # OUTPUT
    # ========================================
    final_report: Optional[str] = None
    source_attribution: List[Dict] = field(default_factory=list)
    itinerary_metadata: Dict[str, Any] = field(default_factory=dict)
    
    # ========================================
    # ERROR HANDLING (GENERIC - reusable)
    # ========================================
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    
    # ========================================
    # METADATA
    # ========================================
    start_time: datetime = field(default_factory=datetime.now)
    session_id: Optional[str] = None
    
    # ========================================
    # HELPER METHODS (GENERIC patterns)
    # ========================================
    
    def add_reasoning_step(self, step: str):
        """Add reasoning step with timestamp."""
        timestamp = datetime.now().isoformat()
        self.reasoning_steps.append(f"[{timestamp}] {step}")
    
    def add_decision(self, decision_type: str, details: Dict[str, Any]):
        """Record decision made by agent."""
        self.decisions_made.append({
            "timestamp": datetime.now().isoformat(),
            "type": decision_type,
            "details": details
        })
    
    def add_action(self, action: str, details: Dict[str, Any]):
        """Record action taken."""
        self.actions_taken.append({
            "timestamp": datetime.now().isoformat(),
            "action": action,
            "details": details
        })
```

### 6.3.2 LangGraph Definition

**File:** `app/module/finai_agent/layer_2_cognition/graph.py`

```python
from langgraph.graph import StateGraph, END
from .state import FinAIState
from .nodes import (
    perceive_node,
    plan_navigation_node,
    navigate_browser_node,
    extract_data_node,
    verify_data_node,
    renavigate_node,
    synthesize_node
)

def build_finai_graph():
    """
    Build LangGraph for finAI browser agent.
    
    Design: Similar to travel_agent but 7 nodes instead of 6.
    
    Graph flow:
    1. Perceive (context building)
    2. Plan (navigation planning)
    3. Navigate (browser actions)
    4. Extract (data extraction)
    5. Verify (quality check)
    6. If needs_renavigation: Renavigate → back to Plan
    7. Else: Synthesize → END
    """
    
    # Create state graph
    graph = StateGraph(FinAIState)
    
    # Add nodes
    graph.add_node("perceive", perceive_node)
    graph.add_node("plan", plan_navigation_node)
    graph.add_node("navigate", navigate_browser_node)
    graph.add_node("extract", extract_data_node)
    graph.add_node("verify", verify_data_node)
    graph.add_node("renavigate", renavigate_node)
    graph.add_node("synthesize", synthesize_node)
    
    # Define edges
    graph.add_edge("perceive", "plan")
    graph.add_edge("plan", "navigate")
    graph.add_edge("navigate", "extract")
    graph.add_edge("extract", "verify")
    
    # Conditional edge: verify → renavigate or synthesize
    def should_renavigate(state: FinAIState) -> str:
        """
        Decide whether to renavigate or synthesize.
        """
        # Check if renavigation needed and haven't exceeded max steps
        if state.needs_renavigation and state.current_step < state.max_steps:
            return "renavigate"
        else:
            return "synthesize"
    
    graph.add_conditional_edges("verify", should_renavigate)
    
    # Renavigate loops back to planning
    graph.add_edge("renavigate", "plan")
    
    # Synthesize ends the workflow
    graph.add_edge("synthesize", END)
    
    # Set entry point
    graph.set_entry_point("perceive")
    
    # Compile graph
    compiled_graph = graph.compile()
    
    return compiled_graph
```

### 6.3.3 LangGraph Nodes

**File:** `app/module/finai_agent/layer_2_cognition/nodes/__init__.py`

```python
from .perceive_node import perceive_node
from .plan_navigation_node import plan_navigation_node
from .navigate_browser_node import navigate_browser_node
from .extract_data_node import extract_data_node
from .verify_data_node import verify_data_node
from .renavigate_node import renavigate_node
from .synthesize_node import synthesize_node

__all__ = [
    "perceive_node",
    "plan_navigation_node",
    "navigate_browser_node",
    "extract_data_node",
    "verify_data_node",
    "renavigate_node",
    "synthesize_node"
]
```

**File:** `app/module/finai_agent/layer_2_cognition/nodes/perceive_node.py`

```python
async def perceive_node(state: FinAIState) -> FinAIState:
    """
    Perceive Node: Build financial context.
    
    Pattern: SPECIFIC implementation but follows generic pattern.
    """
    from app.module.finai_agent.layer_1_perception.context_builder import (
        FinancialContextBuilder
    )
    
    logger.info("[Perceive] Building financial context...")
    
    context_builder = FinancialContextBuilder()
    
    try:
        # Build context using query from Layer 1
        context = await context_builder.build_context(
            state.financial_query,
            user_id=None  # Would come from request
        )
        
        state.context = context
        state.add_reasoning_step(
            f"Built context: Industry={context.get('industry')}, "
            f"Competitors={len(context.get('competitors', []))}"
        )
        
        logger.info(f"[Perceive] ✅ Context ready")
        
    except Exception as e:
        error_msg = f"Context building failed: {str(e)}"
        logger.error(f"[Perceive] ❌ {error_msg}")
        state.errors.append(error_msg)
    
    return state
```

**File:** `app/module/finai_agent/layer_2_cognition/nodes/plan_navigation_node.py`

```python
async def plan_navigation_node(state: FinAIState) -> FinAIState:
    """
    Plan Navigation Node: Create browser navigation strategy.
    
    Pattern: SPECIFIC (financial sites) but structure reusable.
    """
    from langchain_openai import ChatOpenAI
    import json
    
    logger.info("[Plan] Creating navigation plan...")
    
    llm = ChatOpenAI(model="gpt-4", temperature=0)
    
    try:
        query = state.financial_query
        
        # Build planning prompt (SPECIFIC)
        prompt = f"""
Create a browser navigation plan to extract financial data.

Company: {query.company}
Ticker: {query.ticker_symbol or 'Unknown'}
Metrics needed: {', '.join(query.metrics)}
Time period: {query.time_period or 'Current'}

Available sources (prioritize in this order):
1. Yahoo Finance - Real-time stock data, financials, ratios
   URL pattern: https://finance.yahoo.com/quote/{{TICKER}}
   
2. MarketWatch - Market data, earnings, analyst ratings
   URL pattern: https://www.marketwatch.com/investing/stock/{{TICKER}}
   
3. SEC EDGAR - Official filings (10-K, 10-Q)
   URL pattern: https://www.sec.gov/cgi-bin/browse-edgar?company={{COMPANY}}

Create a navigation plan with 2-4 steps.

Return JSON array:
[
    {{
        "step": 1,
        "action": "navigate" | "search" | "click",
        "url": "https://...",
        "extract": ["metric1", "metric2"],
        "reasoning": "Why this step"
    }},
    ...
]

Example for "Apple revenue":
[
    {{
        "step": 1,
        "action": "navigate",
        "url": "https://finance.yahoo.com/quote/AAPL/financials",
        "extract": ["revenue", "net_income"],
        "reasoning": "Yahoo Finance has comprehensive financial statements"
    }},
    {{
        "step": 2,
        "action": "navigate",
        "url": "https://finance.yahoo.com/quote/AAPL/key-statistics",
        "extract": ["P/E ratio", "market cap"],
        "reasoning": "Key statistics page has valuation metrics"
    }}
]
"""
        
        result = await llm.ainvoke(prompt)
        
        # Parse plan
        import re
        content = result.content
        json_match = re.search(r'\[.*\]', content, re.DOTALL)
        if json_match:
            plan = json.loads(json_match.group())
        else:
            plan = json.loads(content)
        
        state.navigation_plan = plan
        state.add_reasoning_step(f"Created navigation plan with {len(plan)} steps")
        state.add_decision("planning", {
            "steps_count": len(plan),
            "sources": list(set(
                step["url"].split("/")[2] for step in plan
            ))
        })
        
        logger.info(f"[Plan] ✅ Plan created: {len(plan)} steps")
        
    except Exception as e:
        error_msg = f"Planning failed: {str(e)}"
        logger.error(f"[Plan] ❌ {error_msg}")
        state.errors.append(error_msg)
    
    return state
```

**File:** `app/module/finai_agent/layer_2_cognition/nodes/navigate_browser_node.py`

```python
async def navigate_browser_node(state: FinAIState) -> FinAIState:
    """
    Navigate Browser Node: Execute browser navigation.
    
    Pattern: GENERIC - works for any browser automation.
    """
    from app.module.finai_agent.layer_3_action.browser.playwright_controller import (
        PlaywrightController
    )
    
    logger.info("[Navigate] Executing browser navigation...")
    
    # Check if plan is complete
    if state.current_step >= len(state.navigation_plan):
        state.add_reasoning_step("Navigation plan completed")
        return state
    
    # Get current step
    current_action = state.navigation_plan[state.current_step]
    
    # Initialize browser (GENERIC)
    browser = PlaywrightController()
    
    try:
        await browser.initialize()
        
        # Execute action based on type (GENERIC)
        if current_action["action"] == "navigate":
            url = current_action["url"]
            
            logger.info(f"[Navigate] Navigating to: {url}")
            await browser.navigate(url)
            
            state.current_url = url
            state.navigation_history.append(url)
            state.add_action("navigate", {"url": url})
            
        elif current_action["action"] == "search":
            query = current_action.get("query", "")
            
            logger.info(f"[Navigate] Searching for: {query}")
            await browser.search(query)
            
            state.current_url = await browser.get_current_url()
            state.navigation_history.append(state.current_url)
            state.add_action("search", {"query": query})
            
        elif current_action["action"] == "click":
            selector = current_action.get("selector", "")
            
            logger.info(f"[Navigate] Clicking: {selector}")
            await browser.click(selector)
            
            state.current_url = await browser.get_current_url()
            state.add_action("click", {"selector": selector})
        
        # Capture page state (GENERIC)
        screenshot = await browser.screenshot()
        a11y_tree = await browser.get_a11y_tree()
        page_html = await browser.extract_html()
        
        state.screenshots.append(screenshot)
        state.a11y_trees.append(a11y_tree)
        state.page_html = page_html
        
        state.add_reasoning_step(
            f"Step {state.current_step + 1}: Navigated to {current_action['url']}"
        )
        
        logger.info(f"[Navigate] ✅ Navigation successful")
        
    except Exception as e:
        error_msg = f"Navigation failed: {str(e)}"
        logger.error(f"[Navigate] ❌ {error_msg}")
        state.errors.append(error_msg)
    
    finally:
        await browser.close()
    
    return state
```

**File:** `app/module/finai_agent/layer_2_cognition/nodes/extract_data_node.py`

```python
async def extract_data_node(state: FinAIState) -> FinAIState:
    """
    Extract Data Node: Extract financial data from page.
    
    Pattern: SPECIFIC (financial extraction) but structure reusable.
    """
    from app.module.finai_agent.layer_3_action.tools.financial_data_extractor import (
        FinancialDataExtractor
    )
    
    logger.info("[Extract] Extracting financial data...")
    
    if not state.a11y_trees:
        state.warnings.append("No page content to extract from")
        return state
    
    # Get current page content
    a11y_tree = state.a11y_trees[-1]
    page_html = state.page_html
    current_url = state.current_url
    
    # Initialize extractor (SPECIFIC)
    extractor = FinancialDataExtractor()
    
    try:
        # Get metrics to extract from current plan step
        current_action = state.navigation_plan[state.current_step]
        metrics_to_extract = current_action.get("extract", [])
        
        # Extract data (SPECIFIC)
        extracted = await extractor.extract(
            a11y_tree=a11y_tree,
            html=page_html,
            url=current_url,
            metrics=metrics_to_extract
        )
        
        # Merge into state
        state.extracted_metrics.update(extracted.get("metrics", {}))
        state.extracted_tables.extend(extracted.get("tables", []))
        
        state.add_reasoning_step(
            f"Extracted {len(extracted.get('metrics', {}))} metrics, "
            f"{len(extracted.get('tables', []))} tables"
        )
        
        logger.info(
            f"[Extract] ✅ Extracted {len(extracted.get('metrics', {}))} metrics"
        )
        
        # Move to next step
        state.current_step += 1
        
    except Exception as e:
        error_msg = f"Extraction failed: {str(e)}"
        logger.error(f"[Extract] ❌ {error_msg}")
        state.errors.append(error_msg)
    
    return state
```

**File:** `app/module/finai_agent/layer_2_cognition/nodes/verify_data_node.py`

```python
async def verify_data_node(state: FinAIState) -> FinAIState:
    """
    Verify Data Node: Check data quality and completeness.
    
    Pattern: Mix of GENERIC validation + SPECIFIC checks.
    """
    logger.info("[Verify] Verifying extracted data...")
    
    try:
        # Get requested metrics
        requested_metrics = set(state.financial_query.metrics)
        extracted_metrics = set(state.extracted_metrics.keys())
        
        # Check completeness (GENERIC pattern)
        missing_metrics = requested_metrics - extracted_metrics
        
        if missing_metrics:
            state.warnings.append(
                f"Missing metrics: {', '.join(missing_metrics)}"
            )
            
            # Decide if need to renavigate
            if len(extracted_metrics) < len(requested_metrics) / 2:
                state.needs_renavigation = True
                state.add_reasoning_step(
                    f"Incomplete data: only {len(extracted_metrics)}/"
                    f"{len(requested_metrics)} metrics. Will renavigate."
                )
            else:
                state.needs_renavigation = False
                state.add_reasoning_step(
                    f"Partial data acceptable: {len(extracted_metrics)}/"
                    f"{len(requested_metrics)} metrics"
                )
        else:
            state.needs_renavigation = False
            state.add_reasoning_step("All metrics extracted successfully")
        
        # Calculate confidence (GENERIC pattern)
        completeness = len(extracted_metrics) / max(len(requested_metrics), 1)
        has_sources = len(state.navigation_history) > 0
        no_errors = len(state.errors) == 0
        
        confidence = 0.0
        confidence += completeness * 0.5
        confidence += 0.3 if has_sources else 0.0
        confidence += 0.2 if no_errors else 0.0
        
        state.data_confidence = min(1.0, confidence)
        
        state.add_reasoning_step(
            f"Data confidence: {state.data_confidence:.2f}"
        )
        
        logger.info(
            f"[Verify] ✅ Verification complete. "
            f"Confidence: {state.data_confidence:.2f}, "
            f"Renavigate: {state.needs_renavigation}"
        )
        
    except Exception as e:
        error_msg = f"Verification failed: {str(e)}"
        logger.error(f"[Verify] ❌ {error_msg}")
        state.errors.append(error_msg)
    
    return state
```

**File:** `app/module/finai_agent/layer_2_cognition/nodes/renavigate_node.py`

```python
async def renavigate_node(state: FinAIState) -> FinAIState:
    """
    Renavigate Node: Adjust plan and try different approach.
    
    Pattern: GENERIC - works for any domain.
    """
    logger.info("[Renavigate] Adjusting navigation strategy...")
    
    try:
        # Analyze what went wrong
        missing_metrics = (
            set(state.financial_query.metrics) - 
            set(state.extracted_metrics.keys())
        )
        
        state.add_reasoning_step(
            f"Renavigating to find: {', '.join(missing_metrics)}"
        )
        
        # Could use LLM to create alternative plan
        # For now, simple strategy: try alternative sources
        
        # Mark that we've attempted renavigation
        state.warnings.append(
            f"Attempted renavigation at step {state.current_step}"
        )
        
        logger.info("[Renavigate] ✅ Renavigation strategy set")
        
    except Exception as e:
        error_msg = f"Renavigation planning failed: {str(e)}"
        logger.error(f"[Renavigate] ❌ {error_msg}")
        state.errors.append(error_msg)
    
    return state
```

**File:** `app/module/finai_agent/layer_2_cognition/nodes/synthesize_node.py`

```python
async def synthesize_node(state: FinAIState) -> FinAIState:
    """
    Synthesize Node: Generate final financial report.
    
    Pattern: SPECIFIC (financial report) but structure reusable.
    """
    from langchain_openai import ChatOpenAI
    import json
    
    logger.info("[Synthesize] Generating financial report...")
    
    llm = ChatOpenAI(model="gpt-4", temperature=0.3)
    
    try:
        query = state.financial_query
        
        # Build synthesis prompt (SPECIFIC)
        prompt = f"""
Generate a comprehensive financial analysis report.

Company: {query.company}
Analysis Date: {datetime.now().strftime('%Y-%m-%d')}

Requested Metrics: {', '.join(query.metrics)}

Extracted Data:
{json.dumps(state.extracted_metrics, indent=2)}

Sources Consulted:
{chr(10).join(f"- {url}" for url in state.navigation_history)}

Data Confidence: {state.data_confidence:.0%}

Generate a professional report with:

1. EXECUTIVE SUMMARY
   - Key findings in 2-3 sentences
   - Overall financial health assessment

2. FINANCIAL METRICS
   - Display each extracted metric with value
   - Include context and interpretation
   - Note any missing metrics

3. ANALYSIS & INSIGHTS
   - Trends and patterns
   - Comparisons to industry benchmarks (if available)
   - Notable observations

4. DATA SOURCES
   - List all sources with timestamps
   - Confidence level: {state.data_confidence:.0%}

5. LIMITATIONS
   - Any missing data
   - Any warnings encountered

Format the report professionally.
"""
        
        result = await llm.ainvoke(prompt)
        
        state.final_report = result.content
        
        # Build source attribution
        state.source_attribution = [
            {
                "url": url,
                "timestamp": datetime.now().isoformat(),
                "domain": url.split("/")[2] if "/" in url else url
            }
            for url in state.navigation_history
        ]
        
        # Build metadata
        state.itinerary_metadata = {
            "company": query.company,
            "metrics_requested": len(query.metrics),
            "metrics_extracted": len(state.extracted_metrics),
            "sources_consulted": len(state.navigation_history),
            "data_confidence": state.data_confidence,
            "execution_steps": state.current_step
        }
        
        state.add_reasoning_step("Generated final financial report")
        
        logger.info("[Synthesize] ✅ Report generated successfully")
        
    except Exception as e:
        error_msg = f"Report synthesis failed: {str(e)}"
        logger.error(f"[Synthesize] ❌ {error_msg}")
        state.errors.append(error_msg)
    
    return state
```

## 6.4 Layer 3: Action (Browser & Tools)

### 6.4.1 Playwright Controller

**File:** `app/module/finai_agent/layer_3_action/browser/playwright_controller.py`

```python
from playwright.async_api import async_playwright, Browser, BrowserContext, Page
from typing import Dict, Any, Optional
import base64

class PlaywrightController:
    """
    Browser automation using Playwright.
    
    Design: 100% GENERIC - works for any browser automation.
    """
    
    def __init__(self):
        self.playwright = None
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
    
    async def initialize(
        self,
        headless: bool = True,
        viewport: Dict[str, int] = None
    ):
        """
        Initialize browser.
        
        GENERIC - same for all domains.
        """
        if viewport is None:
            viewport = {"width": 1920, "height": 1080}
        
        self.playwright = await async_playwright().start()
        
        self.browser = await self.playwright.chromium.launch(
            headless=headless,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--no-sandbox'
            ]
        )
        
        self.context = await self.browser.new_context(
            viewport=viewport,
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        )
        
        self.page = await self.context.new_page()
    
    async def navigate(self, url: str, wait_until: str = "networkidle"):
        """
        Navigate to URL.
        
        GENERIC - same for all domains.
        """
        await self.page.goto(url, wait_until=wait_until)
    
    async def click(self, selector: str):
        """
        Click element.
        
        GENERIC.
        """
        await self.page.click(selector)
    
    async def scroll(self, direction: str = "down", amount: int = 500):
        """
        Scroll page.
        
        GENERIC.
        """
        if direction == "down":
            await self.page.evaluate(f"window.scrollBy(0, {amount})")
        else:
            await self.page.evaluate(f"window.scrollBy(0, -{amount})")
    
    async def search(self, query: str):
        """
        Perform search on current page.
        
        GENERIC - finds search input and submits.
        """
        # Try common search input selectors
        selectors = [
            'input[type="search"]',
            'input[name="q"]',
            'input[placeholder*="search" i]',
            'input[aria-label*="search" i]'
        ]
        
        for selector in selectors:
            try:
                search_input = await self.page.query_selector(selector)
                if search_input:
                    await search_input.fill(query)
                    await search_input.press("Enter")
                    await self.page.wait_for_load_state("networkidle")
                    return
            except:
                continue
        
        raise Exception("Could not find search input")
    
    async def screenshot(self) -> str:
        """
        Capture screenshot as base64.
        
        GENERIC.
        """
        screenshot_bytes = await self.page.screenshot(full_page=False)
        return base64.b64encode(screenshot_bytes).decode()
    
    async def get_a11y_tree(self) -> Dict:
        """
        Get accessibility tree.
        
        GENERIC - critical for data extraction.
        """
        snapshot = await self.page.accessibility.snapshot()
        return snapshot or {}
    
    async def extract_html(self) -> str:
        """
        Extract page HTML.
        
        GENERIC.
        """
        return await self.page.content()
    
    async def extract_text(self) -> str:
        """
        Extract all visible text.
        
        GENERIC.
        """
        return await self.page.evaluate("() => document.body.innerText")
    
    async def get_current_url(self) -> str:
        """Get current page URL."""
        return self.page.url
    
    async def close(self):
        """
        Close browser.
        
        GENERIC.
        """
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
```

### 6.4.2 Browser Pool Management

**File:** `app/module/finai_agent/layer_3_action/browser/browser_pool.py`

```python
@dataclass
class BrowserSession:
    """Browser session info."""
    id: str
    browser: PlaywrightController
    domain: str
    created_at: datetime
    last_activity: datetime = field(default_factory=datetime.now)


class BrowserPool:
    """
    Manage browser instances.
    
    Design: GENERIC - domain-agnostic.
    Future: Can be shared across all web agents.
    """
    
    def __init__(self, max_browsers: int = 10):
        self.max_browsers = max_browsers
        self.active_sessions: Dict[str, BrowserSession] = {}
        self._lock = asyncio.Lock()
    
    async def create_session(
        self,
        user_id: str,
        domain: str = "financial",
        **browser_config
    ) -> BrowserSession:
        """
        Create new browser session.
        
        GENERIC - works for any domain.
        """
        async with self._lock:
            # Check capacity
            if len(self.active_sessions) >= self.max_browsers:
                # Close oldest idle session
                await self._close_oldest_session()
            
            # Generate session ID
            session_id = f"{domain}_{user_id}_{datetime.now().timestamp()}"
            
            # Create browser
            browser = PlaywrightController()
            await browser.initialize(**browser_config)
            
            # Create session
            session = BrowserSession(
                id=session_id,
                browser=browser,
                domain=domain,
                created_at=datetime.now()
            )
            
            self.active_sessions[session_id] = session
            
            logger.info(f"[BrowserPool] Created session: {session_id}")
            
            return session
    
    async def get_session(self, session_id: str) -> Optional[BrowserSession]:
        """Get existing session."""
        session = self.active_sessions.get(session_id)
        if session:
            session.last_activity = datetime.now()
        return session
    
    async def close_session(self, session_id: str):
        """Close and remove session."""
        async with self._lock:
            if session_id in self.active_sessions:
                session = self.active_sessions[session_id]
                await session.browser.close()
                del self.active_sessions[session_id]
                
                logger.info(f"[BrowserPool] Closed session: {session_id}")
    
    async def _close_oldest_session(self):
        """Close oldest idle session."""
        if not self.active_sessions:
            return
        
        # Find oldest by last activity
        oldest_id = min(
            self.active_sessions.keys(),
            key=lambda k: self.active_sessions[k].last_activity
        )
        
        await self.close_session(oldest_id)
    
    async def health_check(self) -> Dict[str, Any]:
        """Check pool health."""
        return {
            "status": "healthy",
            "active_sessions": len(self.active_sessions),
            "max_browsers": self.max_browsers,
            "utilization": len(self.active_sessions) / self.max_browsers
        }
```

### 6.4.3 Financial Data Extractor

**File:** `app/module/finai_agent/layer_3_action/tools/financial_data_extractor.py`

```python
class FinancialDataExtractor:
    """
    Extract financial data from web pages.
    
    SPECIFIC - financial domain.
    Pattern: Có BaseDataExtractor interface để sau này extend.
    """
    
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0)
    
    async def extract(
        self,
        a11y_tree: Dict,
        html: str,
        url: str,
        metrics: List[str]
    ) -> Dict[str, Any]:
        """
        Extract financial data from page.
        
        Returns:
            {
                "metrics": {metric_name: value},
                "tables": [table_data],
                "confidence": float
            }
        """
        
        result = {
            "metrics": {},
            "tables": [],
            "confidence": 0.0
        }
        
        # Determine extraction strategy based on URL
        if "yahoo.com" in url:
            result = await self._extract_from_yahoo(a11y_tree, html, metrics)
        elif "bloomberg.com" in url:
            result = await self._extract_from_bloomberg(a11y_tree, html, metrics)
        elif "sec.gov" in url:
            result = await self._extract_from_sec(a11y_tree, html, metrics)
        else:
            # Generic extraction
            result = await self._extract_generic(a11y_tree, html, metrics)
        
        return result
    
    async def _extract_from_yahoo(
        self,
        a11y_tree: Dict,
        html: str,
        metrics: List[str]
    ) -> Dict[str, Any]:
        """
        Extract from Yahoo Finance.
        
        SPECIFIC - Yahoo Finance structure.
        """
        from bs4 import BeautifulSoup
        
        soup = BeautifulSoup(html, 'html.parser')
        extracted_metrics = {}
        
        # Yahoo Finance has specific selectors
        # Example: Stock price
        if "current price" in [m.lower() for m in metrics]:
            price_elem = soup.find('fin-streamer', {'data-field': 'regularMarketPrice'})
            if price_elem:
                extracted_metrics["current_price"] = price_elem.get_text(strip=True)
        
        # P/E Ratio
        if "p/e ratio" in [m.lower() for m in metrics]:
            # Yahoo shows P/E in statistics table
            stats_table = soup.find('table', class_='W(100%)')
            if stats_table:
                # Parse table for P/E ratio
                pass
        
        return {
            "metrics": extracted_metrics,
            "tables": [],
            "confidence": 0.8
        }
    
    async def _extract_generic(
        self,
        a11y_tree: Dict,
        html: str,
        metrics: List[str]
    ) -> Dict[str, Any]:
        """
        Generic extraction using LLM.
        
        Fallback when specific extractors don't work.
        """
        
        # Use LLM to extract from text
        from bs4 import BeautifulSoup
        
        soup = BeautifulSoup(html, 'html.parser')
        page_text = soup.get_text(separator=' ', strip=True)
        
        # Truncate if too long
        if len(page_text) > 5000:
            page_text = page_text[:5000] + "..."
        
        prompt = f"""
Extract financial metrics from this page text.

Metrics to find: {', '.join(metrics)}

Page text:
{page_text}

Return JSON:
{{
    "metric_name": "value_found" or null
}}

Only include metrics that are clearly stated. If not found, use null.
"""
        
        result = await self.llm.ainvoke(prompt)
        
        import json
        import re
        
        content = result.content
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            extracted_metrics = json.loads(json_match.group())
        else:
            extracted_metrics = {}
        
        return {
            "metrics": extracted_metrics,
            "tables": [],
            "confidence": 0.6  # Lower confidence for generic
        }
```

### 6.4.4 Tool Registry

**File:** `app/module/finai_agent/layer_3_action/tool_registry.py`

```python
from typing import Dict, List, Optional
from app.module.finai_agent.layer_3_action.tools.base_tool import BaseTool

class ToolRegistry:
    """
    Central registry for all tools.
    
    Design: GENERIC pattern from travel_agent.
    """
    
    def __init__(self):
        self._tools: Dict[str, BaseTool] = {}
        self._initialize_tools()
    
    def _initialize_tools(self):
        """
        Initialize tools.
        
        Mix of GENERIC browser tools + SPECIFIC financial tools.
        """
        from app.module.finai_agent.layer_3_action.tools import (
            NavigateTool,
            ClickTool,
            ScrollTool,
            ScreenshotTool,
            ExtractFinancialDataTool,
            ExtractTableTool
        )
        
        tools = [
            # GENERIC browser tools (reusable)
            NavigateTool(),
            ClickTool(),
            ScrollTool(),
            ScreenshotTool(),
            
            # SPECIFIC financial tools
            ExtractFinancialDataTool(),
            ExtractTableTool()
        ]
        
        for tool in tools:
            self.register_tool(tool)
    
    def register_tool(self, tool: BaseTool):
        """Register a tool."""
        self._tools[tool.name] = tool
    
    def get_tool(self, name: str) -> Optional[BaseTool]:
        """Get tool by name."""
        return self._tools.get(name)
    
    def list_tools(self) -> List[str]:
        """List all tool names."""
        return list(self._tools.keys())
    
    def get_tool_schemas(self) -> List[Dict]:
        """Get OpenAI function schemas."""
        return [
            tool.get_schema()
            for tool in self._tools.values()
        ]
```

---

# SECTION 7: API DESIGN

## 7.1 API Routes

### 7.1.1 Main Analysis Endpoint

**File:** `app/api/routes/finai_routes.py`

```python
from fastapi import APIRouter, HTTPException, BackgroundTasks, Depends
from typing import Optional
from datetime import datetime

from app.module.finai_agent.agent_entrypoint import FinAIBrowserAgent
from app.api.models.finai_models import (
    FinancialQueryRequest,
    FinancialAnalysisResponse
)

router = APIRouter(prefix="/finai", tags=["finAI Browser Agent"])


@router.post("/analyze", response_model=FinancialAnalysisResponse)
async def analyze_company(
    request: FinancialQueryRequest,
    background_tasks: BackgroundTasks,
    user_id: Optional[str] = None
):
    """
    Analyze company's financial data using browser automation.
    
    This is the main entry point for finAI browser agent.
    
    Design: SPECIFIC endpoint but follows generic FastAPI pattern.
    Future: Can be wrapped by generic /browser-agent/execute endpoint.
    """
    
    logger.info(f"[API] Financial analysis request: {request.company}")
    
    # Initialize agent
    agent = FinAIBrowserAgent()
    
    try:
        # Execute analysis
        result = await agent.analyze(
            company=request.company,
            metrics=request.metrics,
            time_period=request.time_period,
            user_id=user_id
        )
        
        # Handle result
        if result["status"] == "success":
            # Schedule cleanup
            if "session_id" in result:
                background_tasks.add_task(
                    cleanup_browser_session,
                    result["session_id"]
                )
            
            return FinancialAnalysisResponse(
                status="success",
                report=result["final_report"],
                extracted_data=result["extracted_metrics"],
                sources=result["source_attribution"],
                metadata=result["metadata"]
            )
        
        elif result["status"] == "blocked":
            raise HTTPException(
                status_code=403,
                detail={
                    "reason": result["reason"],
                    "risk_score": result.get("risk_score", 0)
                }
            )
        
        else:
            raise HTTPException(
                status_code=500,
                detail={
                    "error": result.get("error"),
                    "errors": result.get("errors", [])
                }
            )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[API] Unexpected error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Internal server error: {str(e)}"
        )


# Health check
@router.get("/health")
async def health_check():
    """
    Check finAI agent health.
    
    GENERIC pattern - works for any agent.
    """
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "service": "finai_browser_agent"
    }
```

## 7.2 Pydantic Models

**File:** `app/api/models/finai_models.py`

```python
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any

class FinancialQueryRequest(BaseModel):
    """
    Request model for financial analysis.
    
    SPECIFIC - financial domain.
    """
    
    company: str = Field(
        ...,
        description="Company name or ticker symbol",
        example="Apple Inc."
    )
    
    metrics: List[str] = Field(
        default=[],
        description="List of financial metrics to extract",
        example=["revenue", "EPS", "P/E ratio"]
    )
    
    time_period: Optional[str] = Field(
        None,
        description="Time period for analysis",
        example="Q3 2024"
    )


class FinancialAnalysisResponse(BaseModel):
    """
    Response model for financial analysis.
    
    SPECIFIC but follows generic response pattern.
    """
    
    status: str = Field(..., description="success | blocked | error")
    report: Optional[str] = Field(None, description="Generated report")
    extracted_data: Dict[str, Any] = Field(default={})
    sources: List[Dict[str, str]] = Field(default=[])
    metadata: Dict[str, Any] = Field(default={})
```

---

# SECTION 8: DATA DESIGN

## 8.1 Database Schema

### 8.1.1 Query History Table

```sql
-- app/module/finai_agent/migrations/001_create_tables.sql

CREATE TABLE finai_query_history (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    
    -- Identification
    query_id VARCHAR(64) UNIQUE NOT NULL,
    user_id VARCHAR(255),
    
    -- Query details (SPECIFIC)
    company VARCHAR(255) NOT NULL,
    ticker_symbol VARCHAR(20),
    metrics JSON NOT NULL,
    time_period VARCHAR(100),
    
    -- Execution (GENERIC)
    status ENUM('success', 'blocked', 'error') NOT NULL,
    execution_time_ms INT,
    steps_taken INT,
    urls_visited INT,
    
    -- Results (SPECIFIC)
    extracted_data JSON,
    final_report TEXT,
    data_confidence DECIMAL(3,2),
    
    -- Timestamps (GENERIC)
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP,
    
    -- Indexes
    INDEX idx_user_id (user_id),
    INDEX idx_company (company),
    INDEX idx_status (status),
    INDEX idx_created_at (created_at)
    
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

### 8.1.2 Navigation History Table

```sql
CREATE TABLE finai_navigation_history (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    
    -- Association
    query_id VARCHAR(64) NOT NULL,
    
    -- Navigation (GENERIC - reusable)
    url VARCHAR(2048) NOT NULL,
    domain VARCHAR(255),
    navigation_type ENUM('direct', 'search', 'click') NOT NULL,
    
    -- Page state (GENERIC)
    page_load_time_ms INT,
    http_status INT,
    
    -- Data extraction (GENERIC)
    data_extracted BOOLEAN DEFAULT FALSE,
    metrics_extracted INT DEFAULT 0,
    
    visited_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (query_id) 
        REFERENCES finai_query_history(query_id) 
        ON DELETE CASCADE
        
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

### 8.1.3 Extracted Data Table

```sql
CREATE TABLE finai_extracted_data (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    
    -- Association
    query_id VARCHAR(64) NOT NULL,
    
    -- Company (SPECIFIC)
    company VARCHAR(255) NOT NULL,
    ticker_symbol VARCHAR(20),
    
    -- Metric (SPECIFIC)
    metric_name VARCHAR(100) NOT NULL,
    metric_value VARCHAR(255),
    fiscal_period VARCHAR(50),
    
    -- Source (GENERIC)
    source_url VARCHAR(2048) NOT NULL,
    source_domain VARCHAR(255),
    confidence_score DECIMAL(3,2),
    
    extracted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (query_id)
        REFERENCES finai_query_history(query_id)
        ON DELETE CASCADE
        
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

## 8.2 Repository Pattern

**File:** `app/module/finai_agent/repositories/query_repository.py`

```python
class QueryRepository:
    """
    Repository for finAI query history.
    
    Pattern: GENERIC repository pattern - reusable for other domains.
    """
    
    def __init__(self):
        from app.common.mysql.async_database_manager import AsyncDatabaseManager
        self.db = AsyncDatabaseManager()
    
    async def create_query(
        self,
        query_id: str,
        user_id: Optional[str],
        company: str,
        metrics: List[str],
        **kwargs
    ):
        """
        Create new query record.
        
        GENERIC pattern - works for any domain with different fields.
        """
        import json
        
        query = """
        INSERT INTO finai_query_history
        (query_id, user_id, company, metrics, status, created_at)
        VALUES (%s, %s, %s, %s, %s, %s)
        """
        
        await self.db.execute(
            query,
            (
                query_id,
                user_id,
                company,
                json.dumps(metrics),
                'processing',
                datetime.now()
            )
        )
    
    async def update_query_result(
        self,
        query_id: str,
        status: str,
        **kwargs
    ):
        """
        Update query with results.
        
        GENERIC pattern.
        """
        import json
        
        updates = ["status = %s"]
        params = [status]
        
        if 'extracted_data' in kwargs:
            updates.append("extracted_data = %s")
            params.append(json.dumps(kwargs['extracted_data']))
        
        if 'final_report' in kwargs:
            updates.append("final_report = %s")
            params.append(kwargs['final_report'])
        
        updates.append("completed_at = %s")
        params.append(datetime.now())
        
        params.append(query_id)
        
        query = f"""
        UPDATE finai_query_history
        SET {', '.join(updates)}
        WHERE query_id = %s
        """
        
        await self.db.execute(query, tuple(params))
```

---

# MIGRATION GUIDE: Specific → Generic

Khi cần mở rộng sang generic web browser agent sau này:

## Step 1: Extract Generic Components (1 tuần)

```bash
# Create generic structure
mkdir -p app/module/web_browser_agent/core/

# Move browser infrastructure (100% reusable)
mv app/module/finai_agent/layer_3_action/browser/ \
   app/module/web_browser_agent/core/browser/

# Move base classes
mv app/module/finai_agent/core/base_*.py \
   app/module/web_browser_agent/core/

# Move generic tools
mv app/module/finai_agent/layer_3_action/tools/navigate_tool.py \
   app/module/web_browser_agent/core/tools/
```

## Step 2: Create Plugin Structure (3 ngày)

```python
# app/module/web_browser_agent/plugins/financial/__init__.py

from app.module.finai_agent import (
    FinancialEntityExtractor,
    FinancialDataExtractor,
    FinancialOutputValidator
)

class FinancialPlugin:
    """
    Financial domain plugin.
    
    Wraps existing finAI implementation.
    """
    
    name = "financial"
    
    @staticmethod
    def get_entity_extractor():
        return FinancialEntityExtractor()
    
    @staticmethod
    def get_data_extractor():
        return FinancialDataExtractor()
    
    @staticmethod
    def get_validators():
        return FinancialOutputValidator()
    
    @staticmethod
    def get_url_whitelist():
        return [
            "finance.yahoo.com",
            "bloomberg.com",
            "sec.gov"
        ]
```

## Step 3: Add New Domain (2 ngày/domain)

```python
# app/module/web_browser_agent/plugins/ecommerce/__init__.py

class EcommercePlugin:
    """E-commerce plugin."""
    
    name = "ecommerce"
    
    # Implement same interface
    @staticmethod
    def get_entity_extractor():
        return ProductEntityExtractor()  # New
```

**Total migration effort:** 2-3 tuần

---

# SUMMARY

## Key Decisions

1. **Architecture:** Multi-agent platform (not standalone)
2. **Base pattern:** Reuse travel_agent 4-layer Q3 Autonomy
3. **Design strategy:** Specific finAI now, generic-ready
4. **Code organization:** Clear separation of GENERIC vs SPECIFIC

## Code Statistics

|Component|Lines|Reusability|
|---|---|---|
|Browser infrastructure|~1,500|100% GENERIC|
|Tool framework|~800|90% GENERIC|
|Layer 0 (Governance)|~600|70% GENERIC|
|Layer 1 (Perception)|~800|40% SPECIFIC|
|Layer 2 (Cognition)|~1,200|60% GENERIC|
|Layer 3 (Tools)|~1,500|50/50 mix|
|API Layer|~500|80% GENERIC|
|Data Layer|~800|90% GENERIC|
|**Total**|**~7,700**|**~70% reusable**|

## Timeline

- **Initial finAI Implementation:** 10-12 tuần
- **Future migration to generic:** 2-3 tuần
- **Add new domain (after generic):** 2 ngày

## Next Steps

1. Review this SDD update with team
2. Set up project structure
3. Start with Layer 3 (browser infrastructure)
4. Build up through layers
5. Test end-to-end
6. Deploy to staging
7. Production rollout

---

**Document prepared by:** AI Analysis System  
**Date:** December 17, 2025  
**Based on:** SpecialProd_Agent_FinAIWebBrowser_T12_2025-.zip