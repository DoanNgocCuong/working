
# Source code zip 
# FinAI Multi-Agent Architecture (Sá»­ dá»¥ng kiáº¿n trÃºc Q4 Ä‘á»ƒ vá» sau dá»… má»Ÿ rá»™ng. VÃ¬ Q4 khi báº­t tuyáº¿n tÃ­nh thÃ¬ sáº½ giá»‘ng Q3) - á»Ÿ Step 2 

1. ÄÃ¡nh giÃ¡ dá»± Ã¡n nÃ y Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c bao nhiÃªu % má»¥c tiÃªu ?
2. Tá»± cháº¡y thá»­ code cÃ¡c pháº§n quan trá»ng
3. reasoning xem cÃ²n cáº§n code cÃ¡c pháº§n nÃ o Ä‘á»ƒ hoÃ n thiá»‡n 100% dá»± Ã¡n
4. Viáº¿t thÃ nh cÃ¡c tÃ i liá»‡u .md low level code Ä‘á»ƒ Ä‘á»™i ngÅ© kÄ© thuáº­t bÃªn dÆ°á»›i cÃ³ thá»ƒ dá»±a vÃ o Ä‘Ã³ 100% Ä‘á»ƒ implement theo (Ä‘á»‹nh dáº¡ng markdown , siÃªu chi tiáº¿t)

---

# PHáº¦N 1: FinAI Browser Agent - Project Assessment & Gap Analysis

**Version:** 2.0  
**Date:** 2025-12-20  
**Author:** Claude AI  
**Status:** Comprehensive Assessment

---

## ğŸ“Š EXECUTIVE SUMMARY

|Metric|Value|Notes|
|---|---|---|
|**Overall Completion**|**78%**|Core architecture solid, MCP external server missing|
|**Core Architecture**|95%|4-Layer + Multi-Agent implemented|
|**Multi-Agent System**|95%|6 agents + MessageBus functional|
|**MCP External Server**|0%|**P0 CRITICAL** - Not implemented|
|**Financial Extractors**|60%|Yahoo basic only, critical bug|
|**Test Coverage**|40%|Missing unit tests for 4 agents|
|**Production Features**|50%|Missing rate limiting, caching, metrics|
|**Total Lines of Code**|~7,566|In finai_agent module|

---

## âœ… VERIFIED IMPLEMENTATION STATUS

### Layer 0: Governance (100% Complete)

|Component|File|LOC|Status|
|---|---|---|---|
|Input Gate|`phase_1_input_gate/input_gate.py`|~150|âœ… Complete|
|Browser Guards|`phase_2_in_flight_guards/browser_guards.py`|~180|âœ… Complete|
|Output Validator|`phase_3_output_gate/result_validator.py`|~140|âœ… Complete|

**Features:**

- URL whitelist validation
- PII detection
- Risk scoring
- Quality checks

### Layer 1: Perception (100% Complete)

|Component|File|LOC|Status|
|---|---|---|---|
|Query Processor|`query_processor.py`|72|âœ… Complete|
|Entity Extractor|`entity_extractor.py`|74|âœ… Complete|
|Context Builder|`context_builder.py`|156|âœ… Complete|
|Classifier|`phase_1_input_processing/classifier.py`|30|âœ… Complete|
|Normalizer|`phase_1_input_processing/normalizer.py`|208|âœ… Complete|
|Envelope|`phase_1_input_processing/envelope.py`|50|âœ… Complete|
|Page Context|`phase_1_input_processing/page_context.py`|15|âœ… Complete|
|Telemetry|`phase_1_input_processing/telemetry.py`|41|âœ… Complete|

**Total Layer 1:** ~700 LOC

### Layer 2: Cognition - Multi-Agent System (95% Complete)

|Component|File|LOC|Status|
|---|---|---|---|
|MessageBus|`message_bus.py`|442|âœ… Complete|
|Base Agent (P2PAgent)|`base_agent.py`|175|âœ… Complete|
|Chief Agent|`chief_agent/chief.py`|142|âœ… Complete|
|Planner Agent|`planner_agent/planner.py`|172|âœ… Complete|
|Navigator Agent|`navigator_agent/navigator.py`|289|âœ… Complete|
|Extractor Agent|`extractor_agent/extractor.py`|152|âœ… Complete|
|Verifier Agent|`verifier_agent/verifier.py`|154|âœ… Complete|
|Synthesizer Agent|`synthesizer_agent/synthesizer.py`|255|âœ… Complete|
|Multi-Agent Orchestrator|`multi_agent_orchestrator.py`|174|âœ… Complete|
|MCP Tool Adapter|`mcp_tool_adapter.py`|187|âœ… Complete|
|MCP Init|`mcp_init.py`|68|âœ… Complete|
|Agent Chat Run|`agent_chat_run.py`|133|âœ… Complete|
|Prompt Service|`agent_prompt_service.py`|175|âœ… Complete|

**Total Layer 2:** ~2,518 LOC

**Message Flow (Verified):**

```
task_available â†’ plan_ready â†’ page_ready â†’ data_extracted â†’ verification_done â†’ final_report
                                    â†‘
                              renavigate_request (optional retry)
```

### Layer 3: Action (85% Complete)

|Component|File|LOC|Status|
|---|---|---|---|
|PlaywrightController|`browser/playwright_controller.py`|~209|âœ… Complete|
|Browser Pool|`browser/browser_pool.py`|~120|âœ… Complete|
|Mock Browser|`browser/mock_browser_controller.py`|~80|âœ… Complete|
|Tool Registry|`tool_registry.py`|~150|âœ… Complete|
|Browser Tools|`tools/browser_tools.py`|~100|âœ… Complete|
|Base Tool|`tools/base_tool.py`|~50|âœ… Complete|
|Financial Extractor|`tools/financial_data_extractor.py`|305|âš ï¸ **CRITICAL BUG**|
|Browser MCP Server|`mcp_servers/browser_mcp.py`|190|âœ… Complete (Internal)|
|MCP Server Base|`mcp_servers/mcp_server.py`|86|âœ… Complete|

**Total Layer 3:** ~1,290 LOC

---

## ğŸš¨ CRITICAL BUGS IDENTIFIED

### Bug #1: FinancialDataExtractor Missing Return (P0 - CRITICAL)

**File:** `/app/module/finai_agent/layer_3_action/tools/financial_data_extractor.py`

**Problem:** Lines 37-58 - `extract()` method creates result dict but **NEVER returns it**

```python
# CURRENT (BROKEN):
async def extract(
    self,
    a11y_tree: Dict,
    html: str,
    url: str,
    metrics: List[str],
) -> Dict[str, Any]:
    result = {
        "metrics": {},
        "tables": [],
        "confidence": 0.0,
    }
    # âŒ NO RETURN STATEMENT - METHOD ENDS HERE

# Lines 60+ start a new method, making lines 142-160 dead code
```

**Impact:**

- All extraction calls return `None`
- ExtractorAgent receives no data
- Entire workflow fails silently

**Fix Required:**

```python
async def extract(...) -> Dict[str, Any]:
    result = {
        "metrics": {},
        "tables": [],
        "confidence": 0.0,
    }
    
    # Add URL-based extraction strategy
    if "yahoo.com" in url:
        result = await self._extract_from_yahoo(a11y_tree, html, metrics)
    elif "bloomberg.com" in url:
        result = await self._extract_from_bloomberg(a11y_tree, html, metrics)
    elif "sec.gov" in url:
        result = await self._extract_from_sec(a11y_tree, html, metrics)
    else:
        result = await self._extract_generic(a11y_tree, html, metrics)
    
    return result  # âœ… ADD THIS LINE
```

### Bug #2: Dead Code (Lines 142-160)

**Problem:** Code after line 141 is unreachable dead code

**Fix:** Remove or reorganize into proper method structure

---

## ğŸ”´ CRITICAL GAPS (22% Missing)

### Gap #1: MCP External Server (0% - P0 CRITICAL)

**Missing:** Standalone MCP server for external clients (Claude Desktop, CLI, etc.)

**Required Structure:**

```
app/module/finai_agent/mcp/
â”œâ”€â”€ __init__.py                      # Module init with exports
â”œâ”€â”€ server.py                        # Main MCP Server entry point (~150 LOC)
â”œâ”€â”€ config.py                        # MCP configuration (~80 LOC)
â”‚
â”œâ”€â”€ tools/                           # Tool implementations (~400 LOC total)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_tool.py                 # Base tool class
â”‚   â”œâ”€â”€ analyze_tool.py              # finai_analyze tool
â”‚   â”œâ”€â”€ price_tool.py                # finai_get_price tool
â”‚   â”œâ”€â”€ extract_tool.py              # finai_extract tool
â”‚   â””â”€â”€ compare_tool.py              # finai_compare tool
â”‚
â”œâ”€â”€ resources/                       # Resource implementations (~300 LOC total)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_resource.py
â”‚   â”œâ”€â”€ market_data_resource.py
â”‚   â””â”€â”€ company_info_resource.py
â”‚
â”œâ”€â”€ prompts/                         # Prompt templates (~150 LOC)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ analysis_prompts.py
â”‚
â”œâ”€â”€ handlers/                        # Request handlers (~250 LOC total)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tool_handler.py
â”‚   â”œâ”€â”€ resource_handler.py
â”‚   â””â”€â”€ prompt_handler.py
â”‚
â”œâ”€â”€ adapters/                        # Service adapters (~200 LOC)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ finai_adapter.py
â”‚
â””â”€â”€ transports/                      # Transport implementations
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ stdio_transport.py           # For Claude Desktop
    â””â”€â”€ http_transport.py            # For web integration
```

**Estimated Effort:** 1,500-2,000 LOC, 5-7 days

**Why Critical:**

- SDD Section explicitly requires MCP integration
- No external client can use FinAI without this
- Core value proposition broken

### Gap #2: Financial Extractors (35% Missing)

|Extractor|Status|Missing|
|---|---|---|
|Yahoo Finance|âš ï¸ Basic|P/E, Market Cap, Revenue, EPS parsing|
|Bloomberg|âŒ Placeholder|Full implementation|
|SEC EDGAR|âŒ Placeholder|10-K parsing|
|Generic LLM|âœ… Working|-|
|Table Parser|âŒ Missing|Enhanced table extraction|

### Gap #3: Production Features (60% Missing)

|Feature|Status|Priority|
|---|---|---|
|Rate Limiting|âŒ Stub only|P1|
|Redis Caching|âŒ Not implemented|P1|
|Circuit Breaker|âŒ Not implemented|P1|
|Prometheus Metrics|âŒ Not implemented|P2|
|Health Checks|âŒ Not implemented|P1|
|Graceful Shutdown|âŒ Not implemented|P1|
|External Config|âš ï¸ Partial|P2|

### Gap #4: Test Coverage (55% Missing)

**Current Tests:**

- `test_chief_agent.py` - 90 LOC
- `test_message_bus.py` - 72 LOC
- `test_finai_agent_entrypoint.py` - 154 LOC
- `test_multi_agent_flow.py` - 87 LOC (integration)

**Missing Tests:**

- Navigator Agent unit tests
- Extractor Agent unit tests
- Verifier Agent unit tests
- Synthesizer Agent unit tests
- Planner Agent unit tests
- MCP Server tests (when implemented)
- E2E FinAI workflow tests
- Performance benchmarks

**Target:** 80%+ coverage

---

## ğŸ“‹ IMPLEMENTATION ROADMAP

### Phase 1: Critical Bug Fixes (1-2 days) - P0

|Task|File|Effort|Priority|
|---|---|---|---|
|Fix extract() missing return|`financial_data_extractor.py`|1h|P0|
|Remove dead code (lines 142-160)|`financial_data_extractor.py`|30m|P0|
|Add MCPToolAdapter argument validation|`mcp_tool_adapter.py:125`|1h|P1|
|Fix MessageBus deduplication edge case|`message_bus.py`|2h|P1|

### Phase 2: MCP External Server (5-7 days) - P0

**Day 1-2:**

- Create `mcp/` module structure
- Implement `config.py`
- Implement `server.py` with stdio transport

**Day 3-4:**

- Implement 4 MCP tools:
    - `finai_analyze` - Full analysis
    - `finai_get_price` - Quick price lookup
    - `finai_extract` - Specific metrics
    - `finai_compare` - Company comparison

**Day 5:**

- Implement resources (market_data, company_info)
- Implement prompt templates

**Day 6-7:**

- HTTP/SSE transport
- Testing & documentation

### Phase 3: Production Features (5-7 days) - P1

|Task|Effort|Dependencies|
|---|---|---|
|Redis caching layer|2 days|Redis setup|
|Circuit breaker pattern|1 day|-|
|Rate limiting (token bucket)|1 day|Redis|
|Prometheus metrics export|1 day|-|
|Health check endpoints|0.5 day|-|
|Graceful shutdown|0.5 day|-|
|Configuration externalization|1 day|-|

### Phase 4: Testing (4-5 days) - P1

|Task|Files|Effort|
|---|---|---|
|Unit tests for all 6 agents|6 files|2 days|
|MCP integration tests|2 files|1 day|
|E2E FinAI workflow tests|1 file|1 day|
|Performance benchmarks|1 file|1 day|

### Phase 5: Enhanced Extractors (3-4 days) - P2

|Extractor|Task|Effort|
|---|---|---|
|Yahoo Finance|Full parser (P/E, Market Cap, Revenue, EPS)|1 day|
|Bloomberg|Parser implementation|1 day|
|SEC EDGAR|10-K parser|1.5 days|
|Table Parser|Enhanced extraction|0.5 day|

---

## ğŸ“Š TIMELINE SUMMARY

|Phase|Duration|Priority|Dependencies|
|---|---|---|---|
|Phase 1: Bug Fixes|1-2 days|P0|None|
|Phase 2: MCP External Server|5-7 days|P0|Phase 1|
|Phase 3: Production Features|5-7 days|P1|Phase 1|
|Phase 4: Testing|4-5 days|P1|Phase 2, 3|
|Phase 5: Enhanced Extractors|3-4 days|P2|Phase 1|

**Total Estimated Time:** 4-5 weeks with 2-3 developers

---

## ğŸ¯ SUCCESS CRITERIA

### MVP Ready (100% Complete):

- [ ] All critical bugs fixed
- [ ] MCP External Server functional
- [ ] Basic tests passing
- [ ] Claude Desktop integration working

### Production Ready:

- [ ] 80%+ test coverage
- [ ] All production features implemented
- [ ] Performance benchmarks met (P95 < 3s)
- [ ] Security audit passed
- [ ] Documentation complete

---

## ğŸ“ ARCHITECTURE STRENGTHS

1. **Clean Separation:** SOLID principles, 4-layer design
2. **Async Implementation:** Proper async/await throughout
3. **Observability:** Langfuse @observe decorators, comprehensive logging
4. **Type Safety:** Good type annotation coverage
5. **Dual-Mode Support:** Navigator gracefully handles MCP/legacy mode
6. **Error Handling:** Try-except blocks in critical paths
7. **Message-Driven:** Asynchronous P2P communication via MessageBus

---

## âš ï¸ RISK MITIGATION

|Risk|Probability|Impact|Mitigation|
|---|---|---|---|
|MCP server not implemented|HIGH|CRITICAL|Prioritize Phase 2|
|Financial extraction incomplete|MEDIUM|HIGH|Fix bug first, then enhance|
|Low test coverage|MEDIUM|MEDIUM|Parallel testing during Phase 2-3|
|Missing error recovery|LOW|HIGH|Add circuit breaker|

---

**Document End**

_Next Steps: See `02_CRITICAL_BUG_FIXES.md` for detailed fix instructions_


---
# PHáº¦N 2: FinAI Browser Agent - Critical Bug Fixes

**Version:** 1.0  
**Date:** 2025-12-20  
**Priority:** P0 - CRITICAL  
**Estimated Time:** 1-2 days

---

## ğŸš¨ BUG #1: FinancialDataExtractor Missing Return Statement

### Summary

|Aspect|Details|
|---|---|
|**File**|`app/module/finai_agent/layer_3_action/tools/financial_data_extractor.py`|
|**Lines**|37-58|
|**Severity**|CRITICAL|
|**Impact**|All extraction returns `None`, breaking entire workflow|
|**Root Cause**|`extract()` method creates result dict but never returns it|

### Problem Code (Current)

```python
# Lines 37-58 - THE BUG
async def extract(
    self,
    a11y_tree: Dict,
    html: str,
    url: str,
    metrics: List[str],
) -> Dict[str, Any]:
    """
    Extract financial data from page.

    Returns:
        {
            "metrics": {metric_name: value},
            "tables": [table_data],
            "confidence": float
        }
    """
    result = {
        "metrics": {},
        "tables": [],
        "confidence": 0.0,
    }
    # âŒ NO RETURN STATEMENT - METHOD ENDS HERE
    # âŒ Lines 60+ start next method, making lines 142-160 dead code

async def extract_from_page(  # Line 60 - next method starts
    self,
    ...
```

### Dead Code Identified (Lines 142-160)

```python
# Lines 142-160 - DEAD CODE (unreachable after missing return)
        logger.info(f"[FinancialDataExtractor] Extracting from: {url}")

        # Determine extraction strategy based on URL
        if "yahoo.com" in url:
            result = await self._extract_from_yahoo(a11y_tree, html, metrics)
        elif "bloomberg.com" in url:
            result = await self._extract_from_bloomberg(a11y_tree, html, metrics)
        elif "sec.gov" in url:
            result = await self._extract_from_sec(a11y_tree, html, metrics)
        else:
            # Generic extraction
            result = await self._extract_generic(a11y_tree, html, metrics)

        logger.info(
            f"[FinancialDataExtractor] âœ… Extracted {len(result.get('metrics', {}))} metrics, "
            f"confidence: {result.get('confidence', 0.0):.2f}"
        )

        return result
```

### Fix Instructions

#### Step 1: Replace extract() method (Lines 37-58)

**Replace the ENTIRE method with:**

```python
async def extract(
    self,
    a11y_tree: Dict,
    html: str,
    url: str,
    metrics: List[str],
) -> Dict[str, Any]:
    """
    Extract financial data from page.
    
    This is the main entry point for extraction. It routes to
    specialized extractors based on URL domain.

    Args:
        a11y_tree: Accessibility tree from browser
        html: Page HTML content
        url: Current page URL
        metrics: List of metrics to extract (e.g., ["current_price", "market_cap"])

    Returns:
        {
            "metrics": {metric_name: value, ...},
            "tables": [table_data, ...],
            "confidence": float  # 0.0 - 1.0
        }
    """
    logger.info(f"[FinancialDataExtractor] Extracting from: {url}")
    
    # Initialize default result
    result = {
        "metrics": {},
        "tables": [],
        "confidence": 0.0,
    }

    try:
        # Determine extraction strategy based on URL
        if "yahoo.com" in url.lower():
            result = await self._extract_from_yahoo(a11y_tree, html, metrics)
        elif "bloomberg.com" in url.lower():
            result = await self._extract_from_bloomberg(a11y_tree, html, metrics)
        elif "sec.gov" in url.lower():
            result = await self._extract_from_sec(a11y_tree, html, metrics)
        else:
            # Generic extraction using LLM
            result = await self._extract_generic(a11y_tree, html, metrics)

        logger.info(
            f"[FinancialDataExtractor] âœ… Extracted {len(result.get('metrics', {}))} metrics, "
            f"confidence: {result.get('confidence', 0.0):.2f}"
        )

    except Exception as e:
        logger.error(f"[FinancialDataExtractor] Extraction failed: {e}")
        # Return empty result with zero confidence on error
        result = {
            "metrics": {},
            "tables": [],
            "confidence": 0.0,
        }

    return result  # âœ… CRITICAL: Always return result
```

#### Step 2: Remove Dead Code (Lines 142-160)

**DELETE these lines entirely** - they are now integrated into the fixed `extract()` method.

### Verification Script

```python
# test_financial_extractor_fix.py
import asyncio
import sys
sys.path.insert(0, '.')

from app.module.finai_agent.layer_3_action.tools.financial_data_extractor import (
    FinancialDataExtractor,
)

async def test_extract_returns_value():
    """Verify extract() returns a proper dict, not None."""
    extractor = FinancialDataExtractor()
    
    # Test with mock data
    result = await extractor.extract(
        a11y_tree={},
        html="<html><body>Test content with $150.00</body></html>",
        url="https://finance.yahoo.com/quote/AAPL",
        metrics=["current_price"],
    )
    
    # Assertions
    assert result is not None, "âŒ extract() returned None!"
    assert isinstance(result, dict), f"âŒ extract() returned {type(result)}, expected dict"
    assert "metrics" in result, "âŒ 'metrics' key missing from result"
    assert "tables" in result, "âŒ 'tables' key missing from result"
    assert "confidence" in result, "âŒ 'confidence' key missing from result"
    
    print("âœ… All assertions passed!")
    print(f"Result: {result}")
    
    return result

if __name__ == "__main__":
    result = asyncio.run(test_extract_returns_value())
```

---

## ğŸš¨ BUG #2: MCPToolAdapter Argument Validation (TODO at Line 125)

### Summary

|Aspect|Details|
|---|---|
|**File**|`app/module/finai_agent/layer_2_cognition/mcp_tool_adapter.py`|
|**Line**|~125|
|**Severity**|Medium|
|**Impact**|Invalid arguments can cause runtime errors|

### Current Code

```python
# Line ~125
async def execute(self, request: MCPToolRequest) -> MCPToolResult:
    # TODO: Add argument validation here
    ...
```

### Fix

```python
async def execute(self, request: MCPToolRequest) -> MCPToolResult:
    """
    Execute an MCP tool request.
    
    Args:
        request: MCPToolRequest with server, tool name, and arguments
        
    Returns:
        MCPToolResult with success status and result/error
    """
    # Validate request
    if not request.tool_server:
        return MCPToolResult(
            success=False,
            error="tool_server is required",
            result={},
        )
    
    if not request.tool_name:
        return MCPToolResult(
            success=False,
            error="tool_name is required",
            result={},
        )
    
    if request.arguments is None:
        request.arguments = {}
    
    # Validate arguments is a dict
    if not isinstance(request.arguments, dict):
        return MCPToolResult(
            success=False,
            error=f"arguments must be dict, got {type(request.arguments).__name__}",
            result={},
        )
    
    # Continue with execution...
    server = self._servers.get(request.tool_server)
    if not server:
        return MCPToolResult(
            success=False,
            error=f"Unknown MCP server: {request.tool_server}",
            result={},
        )
    
    # ... rest of implementation
```

---

## ğŸš¨ BUG #3: MessageBus Deduplication Edge Case

### Summary

|Aspect|Details|
|---|---|
|**File**|`app/module/finai_agent/layer_2_cognition/message_bus.py`|
|**Lines**|181-183, 273-276, 291-294|
|**Severity**|Low|
|**Impact**|Potential duplicate message processing in edge cases|

### Problem

The deduplication check uses list comprehension to check message IDs, which:

1. Has O(n) complexity for each check
2. Can miss duplicates during concurrent access

### Current Code

```python
# Line 181
if msg.message_id not in [m.message_id for m in self.message_history]:
    self.message_history.append(msg)
```

### Fix

```python
# Add set for O(1) lookups
class MessageBus:
    def __init__(self, redis_client=None):
        self.subscribers: Dict[str, List[Callable]] = {}
        self.message_history: List[Message] = []
        self._message_ids: Set[str] = set()  # âœ… Add this
        self.action_logs: List[Dict[str, Any]] = []
        self._lock = asyncio.Lock()
        # ... rest of init

    async def publish(self, msg: Message):
        # ... 
        async with self._lock:
            if msg.message_id not in self._message_ids:  # âœ… Use set
                self._message_ids.add(msg.message_id)
                self.message_history.append(msg)
                if len(self.message_history) > self.max_message_history:
                    # Remove oldest message IDs too
                    removed = self.message_history[:-self.max_message_history]
                    for m in removed:
                        self._message_ids.discard(m.message_id)
                    self.message_history = self.message_history[-self.max_message_history:]
        # ...

    def reset(self):
        """Reset temporary state for a new run."""
        self.subscribers.clear()
        self.message_history.clear()
        self._message_ids.clear()  # âœ… Clear set too
        self.action_logs.clear()
        logger.info("[FinAI MessageBus] Reset: subscribers + history cleared")
```

---

## âœ… VERIFICATION CHECKLIST

After applying fixes:

- [ ] `extract()` returns dict, not `None`
- [ ] Dead code removed from financial_data_extractor.py
- [ ] File line count reduced from 305 to ~215 lines
- [ ] Unit tests pass for FinancialDataExtractor
- [ ] Integration tests pass for multi-agent flow
- [ ] MCPToolAdapter validates arguments
- [ ] MessageBus deduplication uses Set

### Run Tests

```bash
cd /path/to/finai_project

# Test financial extractor
python -m pytest tests/unit/test_financial_extractor.py -v

# Test multi-agent flow
python -m pytest tests/integration/test_multi_agent_flow.py -v

# Full test suite
python -m pytest tests/ -v --cov=app.module.finai_agent
```

---

## ğŸ“ FILES TO MODIFY

|File|Action|Lines Changed|
|---|---|---|
|`layer_3_action/tools/financial_data_extractor.py`|FIX + DELETE dead code|~90 lines|
|`layer_2_cognition/mcp_tool_adapter.py`|FIX|~20 lines|
|`layer_2_cognition/message_bus.py`|FIX|~10 lines|

**Total LOC Changed:** ~120 lines

---

**Document End**

_Next Steps: After fixing bugs, proceed to `03_MCP_EXTERNAL_SERVER_IMPLEMENTATION.md`_

---
# PHáº¦N 3: FinAI Browser Agent - MCP External Server Implementation

**Version:** 1.0  
**Date:** 2025-12-20  
**Priority:** P0 - CRITICAL  
**Estimated Time:** 5-7 days

---

## ğŸ“‹ OVERVIEW

### What is MCP External Server?

The MCP (Model Context Protocol) External Server exposes FinAI capabilities to external clients like:

- **Claude Desktop** - Via stdio transport
- **Web Applications** - Via HTTP/SSE transport
- **CLI Tools** - Via stdio transport
- **Other AI Agents** - Via any supported transport

### Why is this Critical?

1. **SDD Compliance:** The SDD explicitly requires MCP integration for external access
2. **Core Value Proposition:** Without MCP, no external client can use FinAI
3. **Architecture Completeness:** Internal MCP (BrowserMCPServer) exists but no external wrapper

### Current State vs Required

|Component|Current|Required|
|---|---|---|
|BrowserMCPServer (internal)|âœ… Implemented|âœ… Keep|
|MCPToolAdapter (internal)|âœ… Implemented|âœ… Keep|
|MCP External Server|âŒ Missing|âœ… **IMPLEMENT**|
|MCP Tools (finai_*)|âŒ Missing|âœ… **IMPLEMENT**|
|MCP Resources|âŒ Missing|âœ… **IMPLEMENT**|
|Transport (stdio)|âŒ Missing|âœ… **IMPLEMENT**|
|Transport (HTTP/SSE)|âŒ Missing|âš ï¸ Optional|

---

## ğŸ—ï¸ ARCHITECTURE

### Directory Structure

```
app/module/finai_agent/mcp/
â”œâ”€â”€ __init__.py                      # Module exports
â”œâ”€â”€ server.py                        # Main MCP Server (~200 LOC)
â”œâ”€â”€ config.py                        # Configuration (~80 LOC)
â”‚
â”œâ”€â”€ tools/                           # Tool implementations (~500 LOC total)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_tool.py                 # Base tool class (~50 LOC)
â”‚   â”œâ”€â”€ analyze_tool.py              # finai_analyze (~120 LOC)
â”‚   â”œâ”€â”€ price_tool.py                # finai_get_price (~80 LOC)
â”‚   â”œâ”€â”€ extract_tool.py              # finai_extract (~100 LOC)
â”‚   â””â”€â”€ compare_tool.py              # finai_compare (~100 LOC)
â”‚
â”œâ”€â”€ resources/                       # Resource implementations (~300 LOC total)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_resource.py             # Base resource class (~50 LOC)
â”‚   â”œâ”€â”€ market_data.py               # market://data resource (~120 LOC)
â”‚   â””â”€â”€ company_info.py              # company://info resource (~100 LOC)
â”‚
â”œâ”€â”€ prompts/                         # Prompt templates (~150 LOC)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ analysis_prompts.py          # Analysis prompt templates
â”‚
â”œâ”€â”€ handlers/                        # Request handlers (~250 LOC total)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tool_handler.py              # Handle tool calls (~100 LOC)
â”‚   â”œâ”€â”€ resource_handler.py          # Handle resource reads (~80 LOC)
â”‚   â””â”€â”€ prompt_handler.py            # Handle prompt requests (~70 LOC)
â”‚
â”œâ”€â”€ adapters/                        # Service adapters (~200 LOC)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ finai_adapter.py             # Adapter to FinAI internals
â”‚
â””â”€â”€ transports/                      # Transport implementations
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ stdio.py                     # stdio transport (~100 LOC)
    â””â”€â”€ http_sse.py                  # HTTP/SSE transport (~150 LOC) [Optional]
```

**Total Estimated:** ~1,800-2,000 LOC

---

## ğŸ“ IMPLEMENTATION DETAILS

### Step 1: Create Module Structure

```bash
# Create directory structure
mkdir -p app/module/finai_agent/mcp/{tools,resources,prompts,handlers,adapters,transports}

# Create __init__.py files
touch app/module/finai_agent/mcp/__init__.py
touch app/module/finai_agent/mcp/tools/__init__.py
touch app/module/finai_agent/mcp/resources/__init__.py
touch app/module/finai_agent/mcp/prompts/__init__.py
touch app/module/finai_agent/mcp/handlers/__init__.py
touch app/module/finai_agent/mcp/adapters/__init__.py
touch app/module/finai_agent/mcp/transports/__init__.py
```

### Step 2: Configuration (`config.py`)

```python
"""
MCP Server Configuration for FinAI Browser Agent.
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from enum import Enum


class TransportType(Enum):
    """Supported transport types."""
    STDIO = "stdio"
    HTTP_SSE = "http_sse"


@dataclass
class MCPServerConfig:
    """Configuration for MCP Server."""
    
    # Server identity
    name: str = "finai-browser-agent"
    version: str = "1.0.0"
    description: str = "Financial AI Browser Agent - Extract and analyze financial data from the web"
    
    # Transport
    transport: TransportType = TransportType.STDIO
    http_host: str = "0.0.0.0"
    http_port: int = 8765
    
    # Capabilities
    enable_tools: bool = True
    enable_resources: bool = True
    enable_prompts: bool = True
    
    # Tool configuration
    tool_timeout_seconds: float = 300.0
    max_concurrent_tools: int = 3
    
    # Rate limiting
    rate_limit_enabled: bool = True
    rate_limit_requests_per_minute: int = 30
    
    # Logging
    log_level: str = "INFO"
    log_tool_calls: bool = True
    log_resource_reads: bool = True


@dataclass
class ToolConfig:
    """Configuration for individual tools."""
    enabled: bool = True
    timeout_seconds: float = 60.0
    rate_limit_per_minute: int = 10


# Default tool configurations
DEFAULT_TOOL_CONFIGS: Dict[str, ToolConfig] = {
    "finai_analyze": ToolConfig(timeout_seconds=120.0, rate_limit_per_minute=5),
    "finai_get_price": ToolConfig(timeout_seconds=30.0, rate_limit_per_minute=30),
    "finai_extract": ToolConfig(timeout_seconds=60.0, rate_limit_per_minute=15),
    "finai_compare": ToolConfig(timeout_seconds=180.0, rate_limit_per_minute=3),
}


def get_config() -> MCPServerConfig:
    """Get MCP server configuration from environment or defaults."""
    import os
    
    config = MCPServerConfig()
    
    # Override from environment
    if os.getenv("MCP_TRANSPORT"):
        config.transport = TransportType(os.getenv("MCP_TRANSPORT"))
    if os.getenv("MCP_HTTP_PORT"):
        config.http_port = int(os.getenv("MCP_HTTP_PORT"))
    if os.getenv("MCP_LOG_LEVEL"):
        config.log_level = os.getenv("MCP_LOG_LEVEL")
    
    return config
```

### Step 3: Main Server (`server.py`)

```python
"""
FinAI MCP Server - Main Entry Point.

This server exposes FinAI Browser Agent capabilities via MCP protocol.
Supports stdio transport for Claude Desktop and HTTP/SSE for web clients.
"""

import asyncio
import json
import sys
from typing import Dict, Any, List, Optional
from dataclasses import dataclass

from app.common.log import setup_logger
from app.module.finai_agent.mcp.config import MCPServerConfig, get_config, TransportType
from app.module.finai_agent.mcp.handlers.tool_handler import ToolHandler
from app.module.finai_agent.mcp.handlers.resource_handler import ResourceHandler
from app.module.finai_agent.mcp.handlers.prompt_handler import PromptHandler

logger = setup_logger(__name__)


@dataclass
class MCPRequest:
    """Incoming MCP request."""
    jsonrpc: str
    id: Optional[int]
    method: str
    params: Optional[Dict[str, Any]] = None


@dataclass  
class MCPResponse:
    """Outgoing MCP response."""
    jsonrpc: str = "2.0"
    id: Optional[int] = None
    result: Optional[Dict[str, Any]] = None
    error: Optional[Dict[str, Any]] = None


class FinAIMCPServer:
    """
    MCP Server for FinAI Browser Agent.
    
    Handles:
    - Tool discovery and execution
    - Resource listing and reading
    - Prompt templates
    """
    
    def __init__(self, config: Optional[MCPServerConfig] = None):
        self.config = config or get_config()
        self.tool_handler = ToolHandler()
        self.resource_handler = ResourceHandler()
        self.prompt_handler = PromptHandler()
        self._initialized = False
        
        logger.info(
            "[FinAI MCP] Server created: %s v%s",
            self.config.name,
            self.config.version,
        )
    
    async def initialize(self):
        """Initialize server and handlers."""
        if self._initialized:
            return
        
        await self.tool_handler.initialize()
        await self.resource_handler.initialize()
        await self.prompt_handler.initialize()
        
        self._initialized = True
        logger.info("[FinAI MCP] Server initialized")
    
    async def handle_request(self, request: MCPRequest) -> MCPResponse:
        """
        Handle incoming MCP request.
        
        Args:
            request: Parsed MCP request
            
        Returns:
            MCP response
        """
        logger.debug("[FinAI MCP] Handling: %s", request.method)
        
        try:
            if request.method == "initialize":
                return await self._handle_initialize(request)
            
            elif request.method == "tools/list":
                return await self._handle_tools_list(request)
            
            elif request.method == "tools/call":
                return await self._handle_tools_call(request)
            
            elif request.method == "resources/list":
                return await self._handle_resources_list(request)
            
            elif request.method == "resources/read":
                return await self._handle_resources_read(request)
            
            elif request.method == "prompts/list":
                return await self._handle_prompts_list(request)
            
            elif request.method == "prompts/get":
                return await self._handle_prompts_get(request)
            
            else:
                return MCPResponse(
                    id=request.id,
                    error={
                        "code": -32601,
                        "message": f"Method not found: {request.method}",
                    },
                )
        
        except Exception as e:
            logger.exception("[FinAI MCP] Error handling request: %s", e)
            return MCPResponse(
                id=request.id,
                error={
                    "code": -32603,
                    "message": f"Internal error: {str(e)}",
                },
            )
    
    async def _handle_initialize(self, request: MCPRequest) -> MCPResponse:
        """Handle initialize request."""
        await self.initialize()
        
        return MCPResponse(
            id=request.id,
            result={
                "protocolVersion": "2024-11-05",
                "serverInfo": {
                    "name": self.config.name,
                    "version": self.config.version,
                },
                "capabilities": {
                    "tools": {} if self.config.enable_tools else None,
                    "resources": {} if self.config.enable_resources else None,
                    "prompts": {} if self.config.enable_prompts else None,
                },
            },
        )
    
    async def _handle_tools_list(self, request: MCPRequest) -> MCPResponse:
        """Handle tools/list request."""
        tools = await self.tool_handler.list_tools()
        return MCPResponse(
            id=request.id,
            result={"tools": tools},
        )
    
    async def _handle_tools_call(self, request: MCPRequest) -> MCPResponse:
        """Handle tools/call request."""
        params = request.params or {}
        tool_name = params.get("name")
        arguments = params.get("arguments", {})
        
        result = await self.tool_handler.call_tool(tool_name, arguments)
        
        return MCPResponse(
            id=request.id,
            result=result,
        )
    
    async def _handle_resources_list(self, request: MCPRequest) -> MCPResponse:
        """Handle resources/list request."""
        resources = await self.resource_handler.list_resources()
        return MCPResponse(
            id=request.id,
            result={"resources": resources},
        )
    
    async def _handle_resources_read(self, request: MCPRequest) -> MCPResponse:
        """Handle resources/read request."""
        params = request.params or {}
        uri = params.get("uri")
        
        content = await self.resource_handler.read_resource(uri)
        
        return MCPResponse(
            id=request.id,
            result=content,
        )
    
    async def _handle_prompts_list(self, request: MCPRequest) -> MCPResponse:
        """Handle prompts/list request."""
        prompts = await self.prompt_handler.list_prompts()
        return MCPResponse(
            id=request.id,
            result={"prompts": prompts},
        )
    
    async def _handle_prompts_get(self, request: MCPRequest) -> MCPResponse:
        """Handle prompts/get request."""
        params = request.params or {}
        name = params.get("name")
        arguments = params.get("arguments", {})
        
        prompt = await self.prompt_handler.get_prompt(name, arguments)
        
        return MCPResponse(
            id=request.id,
            result=prompt,
        )
    
    async def run_stdio(self):
        """Run server with stdio transport."""
        logger.info("[FinAI MCP] Starting stdio transport...")
        
        await self.initialize()
        
        reader = asyncio.StreamReader()
        protocol = asyncio.StreamReaderProtocol(reader)
        await asyncio.get_event_loop().connect_read_pipe(
            lambda: protocol, sys.stdin
        )
        
        writer_transport, writer_protocol = await asyncio.get_event_loop().connect_write_pipe(
            asyncio.streams.FlowControlMixin, sys.stdout
        )
        writer = asyncio.StreamWriter(
            writer_transport, writer_protocol, reader, asyncio.get_event_loop()
        )
        
        logger.info("[FinAI MCP] stdio transport ready")
        
        while True:
            try:
                line = await reader.readline()
                if not line:
                    break
                
                data = json.loads(line.decode())
                request = MCPRequest(
                    jsonrpc=data.get("jsonrpc", "2.0"),
                    id=data.get("id"),
                    method=data["method"],
                    params=data.get("params"),
                )
                
                response = await self.handle_request(request)
                
                response_data = {
                    "jsonrpc": response.jsonrpc,
                    "id": response.id,
                }
                if response.result is not None:
                    response_data["result"] = response.result
                if response.error is not None:
                    response_data["error"] = response.error
                
                writer.write((json.dumps(response_data) + "\n").encode())
                await writer.drain()
                
            except json.JSONDecodeError as e:
                logger.error("[FinAI MCP] Invalid JSON: %s", e)
            except Exception as e:
                logger.exception("[FinAI MCP] Error in stdio loop: %s", e)
    
    async def shutdown(self):
        """Shutdown server and cleanup."""
        logger.info("[FinAI MCP] Shutting down...")
        await self.tool_handler.shutdown()
        await self.resource_handler.shutdown()
        logger.info("[FinAI MCP] Shutdown complete")


async def main():
    """Main entry point."""
    config = get_config()
    server = FinAIMCPServer(config)
    
    try:
        if config.transport == TransportType.STDIO:
            await server.run_stdio()
        elif config.transport == TransportType.HTTP_SSE:
            # TODO: Implement HTTP/SSE transport
            raise NotImplementedError("HTTP/SSE transport not yet implemented")
    finally:
        await server.shutdown()


if __name__ == "__main__":
    asyncio.run(main())
```

### Step 4: Tool Handler (`handlers/tool_handler.py`)

```python
"""
Tool Handler - Manages MCP tool discovery and execution.
"""

import asyncio
from typing import Dict, Any, List, Optional
from dataclasses import dataclass

from app.common.log import setup_logger
from app.module.finai_agent.mcp.tools import (
    AnalyzeTool,
    PriceTool,
    ExtractTool,
    CompareTool,
)
from app.module.finai_agent.mcp.tools.base_tool import BaseMCPTool

logger = setup_logger(__name__)


class ToolHandler:
    """
    Handles tool discovery and execution for MCP server.
    """
    
    def __init__(self):
        self._tools: Dict[str, BaseMCPTool] = {}
        self._initialized = False
    
    async def initialize(self):
        """Initialize all tools."""
        if self._initialized:
            return
        
        # Register tools
        self._tools = {
            "finai_analyze": AnalyzeTool(),
            "finai_get_price": PriceTool(),
            "finai_extract": ExtractTool(),
            "finai_compare": CompareTool(),
        }
        
        # Initialize each tool
        for name, tool in self._tools.items():
            await tool.initialize()
            logger.info("[ToolHandler] Registered tool: %s", name)
        
        self._initialized = True
        logger.info("[ToolHandler] Initialized with %d tools", len(self._tools))
    
    async def list_tools(self) -> List[Dict[str, Any]]:
        """
        List all available tools.
        
        Returns:
            List of tool definitions in MCP format
        """
        tools = []
        for name, tool in self._tools.items():
            tools.append({
                "name": name,
                "description": tool.description,
                "inputSchema": tool.input_schema,
            })
        return tools
    
    async def call_tool(
        self,
        name: str,
        arguments: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        Call a tool by name.
        
        Args:
            name: Tool name
            arguments: Tool arguments
            
        Returns:
            Tool result in MCP format
        """
        tool = self._tools.get(name)
        if not tool:
            return {
                "content": [
                    {
                        "type": "text",
                        "text": f"Error: Unknown tool '{name}'",
                    }
                ],
                "isError": True,
            }
        
        try:
            logger.info("[ToolHandler] Calling tool: %s", name)
            result = await tool.execute(arguments)
            
            return {
                "content": [
                    {
                        "type": "text",
                        "text": result if isinstance(result, str) else str(result),
                    }
                ],
            }
        
        except Exception as e:
            logger.exception("[ToolHandler] Tool execution failed: %s", e)
            return {
                "content": [
                    {
                        "type": "text",
                        "text": f"Error executing {name}: {str(e)}",
                    }
                ],
                "isError": True,
            }
    
    async def shutdown(self):
        """Shutdown all tools."""
        for name, tool in self._tools.items():
            try:
                await tool.shutdown()
            except Exception as e:
                logger.error("[ToolHandler] Error shutting down %s: %s", name, e)
```

### Step 5: Base Tool (`tools/base_tool.py`)

```python
"""
Base Tool - Abstract interface for MCP tools.
"""

from abc import ABC, abstractmethod
from typing import Dict, Any, Optional


class BaseMCPTool(ABC):
    """
    Base class for all MCP tools.
    
    Each tool must implement:
    - name: Tool name
    - description: Tool description
    - input_schema: JSON Schema for arguments
    - execute(): Execute the tool
    """
    
    @property
    @abstractmethod
    def name(self) -> str:
        """Tool name."""
        ...
    
    @property
    @abstractmethod
    def description(self) -> str:
        """Tool description."""
        ...
    
    @property
    @abstractmethod
    def input_schema(self) -> Dict[str, Any]:
        """JSON Schema for tool arguments."""
        ...
    
    async def initialize(self):
        """Initialize tool (optional)."""
        pass
    
    @abstractmethod
    async def execute(self, arguments: Dict[str, Any]) -> str:
        """
        Execute the tool.
        
        Args:
            arguments: Tool arguments matching input_schema
            
        Returns:
            Result as string (can be JSON formatted)
        """
        ...
    
    async def shutdown(self):
        """Shutdown tool (optional)."""
        pass
```

### Step 6: Analyze Tool (`tools/analyze_tool.py`)

```python
"""
finai_analyze - Comprehensive financial analysis tool.
"""

import json
from typing import Dict, Any

from app.module.finai_agent.mcp.tools.base_tool import BaseMCPTool
from app.module.finai_agent.mcp.adapters.finai_adapter import FinAIAdapter
from app.common.log import setup_logger

logger = setup_logger(__name__)


class AnalyzeTool(BaseMCPTool):
    """
    Comprehensive financial analysis tool.
    
    Analyzes a company's financial data from multiple sources
    and provides a detailed report.
    """
    
    def __init__(self):
        self.adapter = FinAIAdapter()
    
    @property
    def name(self) -> str:
        return "finai_analyze"
    
    @property
    def description(self) -> str:
        return (
            "Perform comprehensive financial analysis on a company. "
            "Extracts data from Yahoo Finance, Bloomberg, SEC filings, and other sources. "
            "Returns detailed metrics, charts, and analysis."
        )
    
    @property
    def input_schema(self) -> Dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "Natural language query (e.g., 'Analyze Apple's Q3 2024 performance')",
                },
                "company": {
                    "type": "string",
                    "description": "Company name or ticker symbol (e.g., 'Apple' or 'AAPL')",
                },
                "ticker": {
                    "type": "string",
                    "description": "Stock ticker symbol (e.g., 'AAPL')",
                },
                "metrics": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Specific metrics to analyze (e.g., ['revenue', 'eps', 'pe_ratio'])",
                    "default": [],
                },
                "time_period": {
                    "type": "string",
                    "description": "Time period for analysis (e.g., 'Q3 2024', '2024', 'last 5 years')",
                },
                "include_analysis": {
                    "type": "boolean",
                    "description": "Include AI-generated analysis and insights",
                    "default": True,
                },
                "output_format": {
                    "type": "string",
                    "enum": ["markdown", "json", "text"],
                    "description": "Output format for the report",
                    "default": "markdown",
                },
            },
            "anyOf": [
                {"required": ["query"]},
                {"required": ["company"]},
                {"required": ["ticker"]},
            ],
        }
    
    async def initialize(self):
        """Initialize adapter."""
        await self.adapter.initialize()
    
    async def execute(self, arguments: Dict[str, Any]) -> str:
        """
        Execute comprehensive analysis.
        
        Args:
            arguments: Tool arguments
            
        Returns:
            Analysis report as string
        """
        logger.info("[finai_analyze] Starting analysis: %s", arguments)
        
        # Extract parameters
        query = arguments.get("query", "")
        company = arguments.get("company", "")
        ticker = arguments.get("ticker", "")
        metrics = arguments.get("metrics", [])
        time_period = arguments.get("time_period", "current")
        include_analysis = arguments.get("include_analysis", True)
        output_format = arguments.get("output_format", "markdown")
        
        # Determine company to analyze
        target_company = company or ticker or self._extract_company_from_query(query)
        if not target_company:
            return "Error: Please specify a company name, ticker, or include it in your query."
        
        try:
            # Run analysis via adapter
            result = await self.adapter.analyze(
                company=target_company,
                metrics=metrics,
                time_period=time_period,
            )
            
            if result.get("status") == "error":
                return f"Error: {result.get('error', 'Unknown error')}"
            
            # Format output
            if output_format == "json":
                return json.dumps(result, indent=2)
            elif output_format == "markdown":
                return self._format_markdown(result, include_analysis)
            else:
                return self._format_text(result, include_analysis)
        
        except Exception as e:
            logger.exception("[finai_analyze] Analysis failed: %s", e)
            return f"Error: Analysis failed - {str(e)}"
    
    def _extract_company_from_query(self, query: str) -> str:
        """Extract company name from natural language query."""
        # Simple extraction - could be enhanced with NER
        query_lower = query.lower()
        
        # Common patterns
        for pattern in ["analyze ", "analysis of ", "about ", "for "]:
            if pattern in query_lower:
                idx = query_lower.index(pattern) + len(pattern)
                rest = query[idx:].strip()
                # Take first word/phrase before common stop words
                for stop in ["'s", " q", " 2", " performance", " stock", " financial"]:
                    if stop in rest.lower():
                        rest = rest[:rest.lower().index(stop)]
                return rest.strip()
        
        return ""
    
    def _format_markdown(self, result: Dict[str, Any], include_analysis: bool) -> str:
        """Format result as markdown."""
        lines = []
        
        # Header
        company = result.get("extracted_metrics", {}).get("company_name", "Unknown")
        lines.append(f"# Financial Analysis: {company}")
        lines.append("")
        
        # Metrics
        metrics = result.get("extracted_metrics", {})
        if metrics:
            lines.append("## Key Metrics")
            for key, value in metrics.items():
                if key != "company_name":
                    lines.append(f"- **{key.replace('_', ' ').title()}**: {value}")
            lines.append("")
        
        # Report
        if include_analysis and result.get("final_report"):
            lines.append("## Analysis")
            lines.append(result["final_report"])
            lines.append("")
        
        # Sources
        sources = result.get("source_attribution", [])
        if sources:
            lines.append("## Sources")
            for source in sources:
                url = source.get("url", "")
                lines.append(f"- {url}")
            lines.append("")
        
        # Metadata
        metadata = result.get("metadata", {})
        if metadata:
            lines.append("---")
            lines.append(f"*Confidence: {metadata.get('data_confidence', 0):.1%}*")
            lines.append(f"*Execution time: {metadata.get('execution_time_seconds', 0):.2f}s*")
        
        return "\n".join(lines)
    
    def _format_text(self, result: Dict[str, Any], include_analysis: bool) -> str:
        """Format result as plain text."""
        lines = []
        
        metrics = result.get("extracted_metrics", {})
        for key, value in metrics.items():
            lines.append(f"{key}: {value}")
        
        if include_analysis and result.get("final_report"):
            lines.append("")
            lines.append(result["final_report"])
        
        return "\n".join(lines)
    
    async def shutdown(self):
        """Shutdown adapter."""
        await self.adapter.shutdown()
```

### Step 7: FinAI Adapter (`adapters/finai_adapter.py`)

```python
"""
FinAI Adapter - Bridges MCP tools to FinAI internal implementation.
"""

from typing import Dict, Any, List, Optional

from app.common.log import setup_logger
from app.module.finai_agent.agent_entrypoint import FinAIBrowserAgent

logger = setup_logger(__name__)


class FinAIAdapter:
    """
    Adapter that connects MCP tools to FinAI Browser Agent internals.
    
    This provides a clean interface for MCP tools to use FinAI
    without knowing the internal implementation details.
    """
    
    def __init__(self):
        self._agent: Optional[FinAIBrowserAgent] = None
        self._initialized = False
    
    async def initialize(self):
        """Initialize the FinAI agent."""
        if self._initialized:
            return
        
        try:
            self._agent = FinAIBrowserAgent()
            self._initialized = True
            logger.info("[FinAIAdapter] Initialized")
        except Exception as e:
            logger.error("[FinAIAdapter] Failed to initialize: %s", e)
            raise
    
    async def analyze(
        self,
        company: str,
        metrics: Optional[List[str]] = None,
        time_period: Optional[str] = None,
        user_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Run comprehensive analysis on a company.
        
        Args:
            company: Company name or ticker
            metrics: Specific metrics to extract
            time_period: Time period for analysis
            user_id: Optional user ID for tracking
            
        Returns:
            Analysis result dict
        """
        if not self._initialized:
            await self.initialize()
        
        if not self._agent:
            return {
                "status": "error",
                "error": "Agent not initialized",
            }
        
        try:
            result = await self._agent.analyze(
                company=company,
                metrics=metrics,
                time_period=time_period,
                user_id=user_id,
            )
            return result
        except Exception as e:
            logger.exception("[FinAIAdapter] Analysis failed: %s", e)
            return {
                "status": "error",
                "error": str(e),
            }
    
    async def get_price(self, ticker: str) -> Dict[str, Any]:
        """
        Get current stock price for a ticker.
        
        Args:
            ticker: Stock ticker symbol
            
        Returns:
            Price data dict
        """
        if not self._initialized:
            await self.initialize()
        
        # Use analyze with minimal metrics
        result = await self.analyze(
            company=ticker,
            metrics=["current_price", "change_percent"],
        )
        
        return result
    
    async def extract_metrics(
        self,
        company: str,
        metrics: List[str],
    ) -> Dict[str, Any]:
        """
        Extract specific metrics for a company.
        
        Args:
            company: Company name or ticker
            metrics: List of metrics to extract
            
        Returns:
            Extracted metrics dict
        """
        return await self.analyze(company=company, metrics=metrics)
    
    async def compare_companies(
        self,
        companies: List[str],
        metrics: List[str],
    ) -> Dict[str, Any]:
        """
        Compare multiple companies.
        
        Args:
            companies: List of company names/tickers
            metrics: Metrics to compare
            
        Returns:
            Comparison result dict
        """
        if not self._initialized:
            await self.initialize()
        
        results = {}
        for company in companies:
            result = await self.analyze(company=company, metrics=metrics)
            results[company] = result.get("extracted_metrics", {})
        
        return {
            "status": "success",
            "comparison": results,
            "metrics_compared": metrics,
        }
    
    async def shutdown(self):
        """Shutdown the adapter."""
        self._agent = None
        self._initialized = False
        logger.info("[FinAIAdapter] Shutdown complete")
```

---

## ğŸ”§ CLAUDE DESKTOP CONFIGURATION

### Step 8: Create Claude Desktop Config

To use with Claude Desktop, users need to add this to their Claude config:

**macOS:** `~/Library/Application Support/Claude/claude_desktop_config.json`  
**Windows:** `%APPDATA%\Claude\claude_desktop_config.json`

```json
{
  "mcpServers": {
    "finai": {
      "command": "python",
      "args": [
        "-m",
        "app.module.finai_agent.mcp.server"
      ],
      "cwd": "/path/to/finai_project",
      "env": {
        "PYTHONPATH": "/path/to/finai_project",
        "OPENAI_API_KEY": "your-key-here"
      }
    }
  }
}
```

---

## âœ… VERIFICATION CHECKLIST

After implementation:

- [ ] `python -m app.module.finai_agent.mcp.server` runs without errors
- [ ] `tools/list` returns 4 tools
- [ ] `resources/list` returns 2 resources
- [ ] `prompts/list` returns prompt templates
- [ ] `tools/call` with `finai_analyze` executes successfully
- [ ] Claude Desktop can connect and use tools
- [ ] Error handling works for invalid inputs
- [ ] Logging captures all tool calls

### Test Script

```python
# test_mcp_server.py
import asyncio
import json

async def test_mcp_server():
    from app.module.finai_agent.mcp.server import FinAIMCPServer, MCPRequest
    
    server = FinAIMCPServer()
    
    # Test initialize
    init_req = MCPRequest(
        jsonrpc="2.0",
        id=1,
        method="initialize",
        params={},
    )
    init_resp = await server.handle_request(init_req)
    print("Initialize:", init_resp.result)
    
    # Test tools/list
    list_req = MCPRequest(
        jsonrpc="2.0",
        id=2,
        method="tools/list",
        params={},
    )
    list_resp = await server.handle_request(list_req)
    print("Tools:", [t["name"] for t in list_resp.result["tools"]])
    
    # Test tools/call
    call_req = MCPRequest(
        jsonrpc="2.0",
        id=3,
        method="tools/call",
        params={
            "name": "finai_analyze",
            "arguments": {
                "company": "Apple",
                "metrics": ["current_price"],
            },
        },
    )
    call_resp = await server.handle_request(call_req)
    print("Analyze result:", call_resp.result)
    
    await server.shutdown()
    print("âœ… All tests passed!")

if __name__ == "__main__":
    asyncio.run(test_mcp_server())
```

---

## ğŸ“ FILES TO CREATE

|File|LOC|Priority|
|---|---|---|
|`mcp/__init__.py`|20|P0|
|`mcp/config.py`|80|P0|
|`mcp/server.py`|250|P0|
|`mcp/tools/__init__.py`|20|P0|
|`mcp/tools/base_tool.py`|50|P0|
|`mcp/tools/analyze_tool.py`|180|P0|
|`mcp/tools/price_tool.py`|80|P1|
|`mcp/tools/extract_tool.py`|100|P1|
|`mcp/tools/compare_tool.py`|120|P1|
|`mcp/handlers/__init__.py`|10|P0|
|`mcp/handlers/tool_handler.py`|100|P0|
|`mcp/handlers/resource_handler.py`|80|P1|
|`mcp/handlers/prompt_handler.py`|70|P2|
|`mcp/adapters/__init__.py`|10|P0|
|`mcp/adapters/finai_adapter.py`|150|P0|
|`mcp/resources/__init__.py`|10|P1|
|`mcp/resources/base_resource.py`|50|P1|
|`mcp/resources/market_data.py`|120|P1|
|`mcp/transports/__init__.py`|10|P0|
|`mcp/transports/stdio.py`|100|P0|

**Total:** ~1,610 LOC

---

**Document End**

_Next Steps: After MCP implementation, proceed to `04_PRODUCTION_FEATURES.md`_

---
# PHáº¦N 4: FinAI Browser Agent - Production Features Implementation

**Version:** 1.0  
**Date:** 2025-12-20  
**Priority:** P1  
**Estimated Time:** 5-7 days

---

## ğŸ“‹ OVERVIEW

This document covers production-readiness features needed before deployment:

|Feature|Current Status|Priority|Effort|
|---|---|---|---|
|Rate Limiting|âŒ Stub only|P1|1 day|
|Redis Caching|âŒ Not implemented|P1|2 days|
|Circuit Breaker|âŒ Not implemented|P1|1 day|
|Prometheus Metrics|âŒ Not implemented|P2|1 day|
|Health Checks|âŒ Not implemented|P1|0.5 day|
|Graceful Shutdown|âŒ Not implemented|P1|0.5 day|
|Configuration Externalization|âš ï¸ Partial|P2|1 day|

---

## ğŸš¦ RATE LIMITING

### Location

`app/module/finai_agent/core/rate_limiter.py`

### Implementation

```python
"""
Rate Limiter - Token Bucket algorithm for FinAI.

Protects against:
- API abuse
- Resource exhaustion
- Cost overruns (LLM calls)
"""

import asyncio
import time
from typing import Dict, Optional
from dataclasses import dataclass
from enum import Enum

from app.common.log import setup_logger

logger = setup_logger(__name__)


class RateLimitScope(Enum):
    """Scope for rate limiting."""
    GLOBAL = "global"
    USER = "user"
    IP = "ip"
    API_KEY = "api_key"


@dataclass
class RateLimitConfig:
    """Rate limit configuration."""
    requests_per_minute: int = 30
    requests_per_hour: int = 500
    burst_size: int = 10  # Max burst
    scope: RateLimitScope = RateLimitScope.USER


class TokenBucket:
    """
    Token Bucket rate limiter.
    
    Allows burst traffic while maintaining average rate.
    """
    
    def __init__(
        self,
        rate: float,  # tokens per second
        capacity: int,  # max tokens (burst size)
    ):
        self.rate = rate
        self.capacity = capacity
        self.tokens = capacity
        self.last_update = time.monotonic()
        self._lock = asyncio.Lock()
    
    async def acquire(self, tokens: int = 1) -> bool:
        """
        Try to acquire tokens.
        
        Args:
            tokens: Number of tokens to acquire
            
        Returns:
            True if acquired, False if rate limited
        """
        async with self._lock:
            now = time.monotonic()
            elapsed = now - self.last_update
            
            # Add tokens based on elapsed time
            self.tokens = min(
                self.capacity,
                self.tokens + elapsed * self.rate,
            )
            self.last_update = now
            
            if self.tokens >= tokens:
                self.tokens -= tokens
                return True
            
            return False
    
    @property
    def available_tokens(self) -> float:
        """Get current available tokens."""
        return self.tokens


class RateLimiter:
    """
    Rate limiter with per-user/global limits.
    
    Uses token bucket for each scope.
    """
    
    def __init__(self, config: Optional[RateLimitConfig] = None):
        self.config = config or RateLimitConfig()
        self._buckets: Dict[str, TokenBucket] = {}
        self._global_bucket = TokenBucket(
            rate=self.config.requests_per_minute / 60.0,
            capacity=self.config.burst_size,
        )
        self._lock = asyncio.Lock()
    
    def _get_bucket_key(self, identifier: str) -> str:
        """Generate bucket key."""
        return f"{self.config.scope.value}:{identifier}"
    
    async def _get_bucket(self, identifier: str) -> TokenBucket:
        """Get or create bucket for identifier."""
        key = self._get_bucket_key(identifier)
        
        async with self._lock:
            if key not in self._buckets:
                self._buckets[key] = TokenBucket(
                    rate=self.config.requests_per_minute / 60.0,
                    capacity=self.config.burst_size,
                )
            return self._buckets[key]
    
    async def check(
        self,
        identifier: str,
        tokens: int = 1,
    ) -> tuple[bool, Optional[float]]:
        """
        Check if request is allowed.
        
        Args:
            identifier: User ID, IP, or API key
            tokens: Number of tokens to consume
            
        Returns:
            (allowed, retry_after_seconds)
        """
        # Check global limit first
        if not await self._global_bucket.acquire(tokens):
            retry_after = (tokens - self._global_bucket.available_tokens) / self._global_bucket.rate
            logger.warning(
                "[RateLimiter] Global rate limit hit, retry after %.1fs",
                retry_after,
            )
            return False, retry_after
        
        # Check per-identifier limit
        bucket = await self._get_bucket(identifier)
        if not await bucket.acquire(tokens):
            retry_after = (tokens - bucket.available_tokens) / bucket.rate
            logger.warning(
                "[RateLimiter] Rate limit hit for %s, retry after %.1fs",
                identifier,
                retry_after,
            )
            return False, retry_after
        
        return True, None
    
    async def cleanup_expired(self, max_age_seconds: float = 3600.0):
        """Remove old buckets to prevent memory leaks."""
        now = time.monotonic()
        
        async with self._lock:
            expired = [
                key for key, bucket in self._buckets.items()
                if (now - bucket.last_update) > max_age_seconds
            ]
            
            for key in expired:
                del self._buckets[key]
            
            if expired:
                logger.info(
                    "[RateLimiter] Cleaned up %d expired buckets",
                    len(expired),
                )


# Global rate limiter instance
_rate_limiter: Optional[RateLimiter] = None


def get_rate_limiter(config: Optional[RateLimitConfig] = None) -> RateLimiter:
    """Get or create global rate limiter."""
    global _rate_limiter
    if _rate_limiter is None:
        _rate_limiter = RateLimiter(config)
    return _rate_limiter


# Decorator for rate-limited functions
def rate_limited(
    identifier_arg: str = "user_id",
    tokens: int = 1,
):
    """
    Decorator to apply rate limiting to async functions.
    
    Usage:
        @rate_limited(identifier_arg="user_id")
        async def analyze(user_id: str, company: str):
            ...
    """
    def decorator(func):
        async def wrapper(*args, **kwargs):
            # Get identifier from kwargs
            identifier = kwargs.get(identifier_arg, "anonymous")
            
            limiter = get_rate_limiter()
            allowed, retry_after = await limiter.check(identifier, tokens)
            
            if not allowed:
                raise RateLimitExceeded(
                    f"Rate limit exceeded. Retry after {retry_after:.1f}s"
                )
            
            return await func(*args, **kwargs)
        
        return wrapper
    return decorator


class RateLimitExceeded(Exception):
    """Exception raised when rate limit is exceeded."""
    pass
```

---

## ğŸ’¾ REDIS CACHING

### Location

`app/module/finai_agent/core/cache.py`

### Implementation

```python
"""
Redis Cache - Caching layer for FinAI.

Caches:
- Financial data (short TTL - 5 mins)
- Company info (medium TTL - 1 hour)
- Static data (long TTL - 24 hours)
"""

import asyncio
import json
import hashlib
from typing import Any, Optional, TypeVar, Callable
from datetime import timedelta
from functools import wraps

from app.common.log import setup_logger
from app.common.config import settings

logger = setup_logger(__name__)

try:
    import redis.asyncio as redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    redis = None

T = TypeVar("T")


class CacheTTL:
    """Cache TTL presets."""
    REALTIME = timedelta(seconds=30)      # Stock prices
    SHORT = timedelta(minutes=5)           # Financial metrics
    MEDIUM = timedelta(hours=1)            # Company info
    LONG = timedelta(hours=24)             # Static data
    PERMANENT = timedelta(days=30)         # Reference data


class FinAICache:
    """
    Redis-backed cache for FinAI.
    
    Features:
    - TTL-based expiration
    - Key prefixing
    - JSON serialization
    - Fallback to in-memory when Redis unavailable
    """
    
    def __init__(self, prefix: str = "finai"):
        self.prefix = prefix
        self.redis_client: Optional[redis.Redis] = None
        self._memory_cache: dict = {}  # Fallback
        self._initialized = False
    
    async def initialize(self):
        """Initialize Redis connection."""
        if self._initialized:
            return
        
        if not REDIS_AVAILABLE:
            logger.warning("[FinAICache] Redis not available, using memory cache")
            self._initialized = True
            return
        
        try:
            redis_url = f"redis://{settings.REDIS_HOST}:{settings.REDIS_PORT}/{settings.REDIS_DB}"
            if getattr(settings, "REDIS_PASSWORD", None):
                redis_url = f"redis://:{settings.REDIS_PASSWORD}@{settings.REDIS_HOST}:{settings.REDIS_PORT}/{settings.REDIS_DB}"
            
            self.redis_client = redis.from_url(
                redis_url,
                decode_responses=True,
                socket_connect_timeout=5,
            )
            
            # Test connection
            await self.redis_client.ping()
            
            logger.info("[FinAICache] Connected to Redis")
            self._initialized = True
            
        except Exception as e:
            logger.error("[FinAICache] Redis connection failed: %s", e)
            self.redis_client = None
            self._initialized = True
    
    def _make_key(self, key: str) -> str:
        """Generate prefixed cache key."""
        return f"{self.prefix}:{key}"
    
    def _hash_key(self, *args, **kwargs) -> str:
        """Generate hash key from arguments."""
        data = json.dumps({"args": args, "kwargs": kwargs}, sort_keys=True)
        return hashlib.md5(data.encode()).hexdigest()
    
    async def get(self, key: str) -> Optional[Any]:
        """
        Get value from cache.
        
        Args:
            key: Cache key
            
        Returns:
            Cached value or None
        """
        if not self._initialized:
            await self.initialize()
        
        full_key = self._make_key(key)
        
        try:
            if self.redis_client:
                value = await self.redis_client.get(full_key)
                if value:
                    return json.loads(value)
            else:
                # Memory fallback
                if full_key in self._memory_cache:
                    return self._memory_cache[full_key]
        
        except Exception as e:
            logger.error("[FinAICache] Get error: %s", e)
        
        return None
    
    async def set(
        self,
        key: str,
        value: Any,
        ttl: timedelta = CacheTTL.SHORT,
    ) -> bool:
        """
        Set value in cache.
        
        Args:
            key: Cache key
            value: Value to cache (must be JSON serializable)
            ttl: Time to live
            
        Returns:
            True if successful
        """
        if not self._initialized:
            await self.initialize()
        
        full_key = self._make_key(key)
        
        try:
            serialized = json.dumps(value)
            
            if self.redis_client:
                await self.redis_client.setex(
                    full_key,
                    int(ttl.total_seconds()),
                    serialized,
                )
            else:
                # Memory fallback (no TTL support)
                self._memory_cache[full_key] = value
            
            return True
        
        except Exception as e:
            logger.error("[FinAICache] Set error: %s", e)
            return False
    
    async def delete(self, key: str) -> bool:
        """Delete key from cache."""
        if not self._initialized:
            await self.initialize()
        
        full_key = self._make_key(key)
        
        try:
            if self.redis_client:
                await self.redis_client.delete(full_key)
            else:
                self._memory_cache.pop(full_key, None)
            return True
        
        except Exception as e:
            logger.error("[FinAICache] Delete error: %s", e)
            return False
    
    async def clear_pattern(self, pattern: str) -> int:
        """Clear all keys matching pattern."""
        if not self._initialized:
            await self.initialize()
        
        full_pattern = self._make_key(pattern)
        
        try:
            if self.redis_client:
                keys = []
                async for key in self.redis_client.scan_iter(match=full_pattern):
                    keys.append(key)
                
                if keys:
                    await self.redis_client.delete(*keys)
                    return len(keys)
            else:
                # Memory fallback
                keys_to_delete = [
                    k for k in self._memory_cache.keys()
                    if k.startswith(full_pattern.replace("*", ""))
                ]
                for k in keys_to_delete:
                    del self._memory_cache[k]
                return len(keys_to_delete)
        
        except Exception as e:
            logger.error("[FinAICache] Clear pattern error: %s", e)
        
        return 0
    
    async def close(self):
        """Close Redis connection."""
        if self.redis_client:
            await self.redis_client.close()
            logger.info("[FinAICache] Connection closed")


# Global cache instance
_cache: Optional[FinAICache] = None


def get_cache() -> FinAICache:
    """Get or create global cache."""
    global _cache
    if _cache is None:
        _cache = FinAICache()
    return _cache


# Decorator for cached functions
def cached(
    ttl: timedelta = CacheTTL.SHORT,
    key_prefix: str = "",
):
    """
    Decorator to cache async function results.
    
    Usage:
        @cached(ttl=CacheTTL.MEDIUM, key_prefix="company_info")
        async def get_company_info(ticker: str):
            ...
    """
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        async def wrapper(*args, **kwargs) -> T:
            cache = get_cache()
            
            # Generate cache key
            hash_key = cache._hash_key(*args, **kwargs)
            cache_key = f"{key_prefix}:{func.__name__}:{hash_key}"
            
            # Try cache
            cached_value = await cache.get(cache_key)
            if cached_value is not None:
                logger.debug("[Cache] HIT: %s", cache_key)
                return cached_value
            
            # Execute function
            logger.debug("[Cache] MISS: %s", cache_key)
            result = await func(*args, **kwargs)
            
            # Store in cache
            await cache.set(cache_key, result, ttl)
            
            return result
        
        return wrapper
    return decorator
```

---

## ğŸ”Œ CIRCUIT BREAKER

### Location

`app/module/finai_agent/core/circuit_breaker.py`

### Implementation

```python
"""
Circuit Breaker - Prevent cascade failures.

States:
- CLOSED: Normal operation
- OPEN: All requests fail fast
- HALF_OPEN: Testing if service recovered
"""

import asyncio
import time
from typing import Optional, Callable, Any
from dataclasses import dataclass
from enum import Enum
from functools import wraps

from app.common.log import setup_logger

logger = setup_logger(__name__)


class CircuitState(Enum):
    """Circuit breaker states."""
    CLOSED = "closed"      # Normal operation
    OPEN = "open"          # Failing fast
    HALF_OPEN = "half_open"  # Testing recovery


@dataclass
class CircuitBreakerConfig:
    """Circuit breaker configuration."""
    failure_threshold: int = 5       # Failures before opening
    success_threshold: int = 3       # Successes before closing
    timeout_seconds: float = 30.0    # Time in OPEN before HALF_OPEN
    excluded_exceptions: tuple = ()  # Exceptions that don't count as failures


class CircuitBreaker:
    """
    Circuit breaker implementation.
    
    Prevents repeated calls to failing services.
    """
    
    def __init__(
        self,
        name: str,
        config: Optional[CircuitBreakerConfig] = None,
    ):
        self.name = name
        self.config = config or CircuitBreakerConfig()
        
        self._state = CircuitState.CLOSED
        self._failure_count = 0
        self._success_count = 0
        self._last_failure_time: Optional[float] = None
        self._lock = asyncio.Lock()
    
    @property
    def state(self) -> CircuitState:
        """Get current state, checking for timeout."""
        if self._state == CircuitState.OPEN and self._last_failure_time:
            elapsed = time.monotonic() - self._last_failure_time
            if elapsed >= self.config.timeout_seconds:
                logger.info(
                    "[CircuitBreaker:%s] Timeout elapsed, entering HALF_OPEN",
                    self.name,
                )
                self._state = CircuitState.HALF_OPEN
                self._success_count = 0
        
        return self._state
    
    async def can_execute(self) -> bool:
        """Check if request can proceed."""
        async with self._lock:
            state = self.state
            
            if state == CircuitState.CLOSED:
                return True
            
            if state == CircuitState.HALF_OPEN:
                return True  # Allow test request
            
            # OPEN - fail fast
            return False
    
    async def record_success(self):
        """Record successful execution."""
        async with self._lock:
            if self._state == CircuitState.HALF_OPEN:
                self._success_count += 1
                
                if self._success_count >= self.config.success_threshold:
                    logger.info(
                        "[CircuitBreaker:%s] Recovery confirmed, entering CLOSED",
                        self.name,
                    )
                    self._state = CircuitState.CLOSED
                    self._failure_count = 0
                    self._success_count = 0
            else:
                # Reset failure count on success in CLOSED state
                self._failure_count = 0
    
    async def record_failure(self, exception: Exception):
        """Record failed execution."""
        # Check if exception is excluded
        if isinstance(exception, self.config.excluded_exceptions):
            return
        
        async with self._lock:
            self._failure_count += 1
            self._last_failure_time = time.monotonic()
            
            if self._state == CircuitState.HALF_OPEN:
                logger.warning(
                    "[CircuitBreaker:%s] Failure in HALF_OPEN, returning to OPEN",
                    self.name,
                )
                self._state = CircuitState.OPEN
                self._success_count = 0
            
            elif self._state == CircuitState.CLOSED:
                if self._failure_count >= self.config.failure_threshold:
                    logger.warning(
                        "[CircuitBreaker:%s] Threshold reached (%d), entering OPEN",
                        self.name,
                        self._failure_count,
                    )
                    self._state = CircuitState.OPEN
    
    def get_stats(self) -> dict:
        """Get circuit breaker statistics."""
        return {
            "name": self.name,
            "state": self.state.value,
            "failure_count": self._failure_count,
            "success_count": self._success_count,
            "last_failure_time": self._last_failure_time,
        }


class CircuitOpenError(Exception):
    """Exception raised when circuit is open."""
    pass


# Registry of circuit breakers
_circuit_breakers: dict[str, CircuitBreaker] = {}


def get_circuit_breaker(
    name: str,
    config: Optional[CircuitBreakerConfig] = None,
) -> CircuitBreaker:
    """Get or create circuit breaker."""
    if name not in _circuit_breakers:
        _circuit_breakers[name] = CircuitBreaker(name, config)
    return _circuit_breakers[name]


# Decorator
def with_circuit_breaker(
    name: str,
    config: Optional[CircuitBreakerConfig] = None,
):
    """
    Decorator to wrap function with circuit breaker.
    
    Usage:
        @with_circuit_breaker("yahoo_finance")
        async def fetch_from_yahoo(ticker: str):
            ...
    """
    def decorator(func: Callable) -> Callable:
        breaker = get_circuit_breaker(name, config)
        
        @wraps(func)
        async def wrapper(*args, **kwargs) -> Any:
            if not await breaker.can_execute():
                raise CircuitOpenError(
                    f"Circuit breaker '{name}' is OPEN"
                )
            
            try:
                result = await func(*args, **kwargs)
                await breaker.record_success()
                return result
            
            except Exception as e:
                await breaker.record_failure(e)
                raise
        
        return wrapper
    return decorator
```

---

## ğŸ“Š PROMETHEUS METRICS

### Location

`app/module/finai_agent/core/metrics.py`

### Implementation

```python
"""
Prometheus Metrics - Observability for FinAI.

Metrics:
- Request counts
- Latency histograms
- Error rates
- Cache hit/miss rates
"""

from typing import Optional
from functools import wraps
import time

from app.common.log import setup_logger

logger = setup_logger(__name__)

try:
    from prometheus_client import Counter, Histogram, Gauge, generate_latest, REGISTRY
    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False
    logger.warning("[Metrics] prometheus_client not installed")


# Define metrics
if PROMETHEUS_AVAILABLE:
    # Request metrics
    REQUEST_COUNT = Counter(
        "finai_requests_total",
        "Total number of requests",
        ["method", "status"],
    )
    
    REQUEST_LATENCY = Histogram(
        "finai_request_latency_seconds",
        "Request latency in seconds",
        ["method"],
        buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0],
    )
    
    # Agent metrics
    AGENT_ACTIVE = Gauge(
        "finai_agents_active",
        "Number of active agents",
        ["agent_type"],
    )
    
    AGENT_MESSAGES = Counter(
        "finai_agent_messages_total",
        "Total agent messages",
        ["from_agent", "to_agent", "topic"],
    )
    
    # Cache metrics
    CACHE_HITS = Counter(
        "finai_cache_hits_total",
        "Cache hit count",
        ["cache_type"],
    )
    
    CACHE_MISSES = Counter(
        "finai_cache_misses_total",
        "Cache miss count",
        ["cache_type"],
    )
    
    # Browser metrics
    BROWSER_NAVIGATIONS = Counter(
        "finai_browser_navigations_total",
        "Browser navigation count",
        ["status"],
    )
    
    BROWSER_EXTRACTION_LATENCY = Histogram(
        "finai_browser_extraction_latency_seconds",
        "Data extraction latency",
        ["source"],
        buckets=[0.5, 1.0, 2.0, 5.0, 10.0, 30.0],
    )
    
    # LLM metrics
    LLM_CALLS = Counter(
        "finai_llm_calls_total",
        "LLM API calls",
        ["model", "status"],
    )
    
    LLM_TOKENS = Counter(
        "finai_llm_tokens_total",
        "LLM tokens used",
        ["model", "type"],  # type: input/output
    )


class MetricsCollector:
    """
    Centralized metrics collection.
    """
    
    @staticmethod
    def record_request(method: str, status: str, latency: float):
        """Record request metrics."""
        if PROMETHEUS_AVAILABLE:
            REQUEST_COUNT.labels(method=method, status=status).inc()
            REQUEST_LATENCY.labels(method=method).observe(latency)
    
    @staticmethod
    def record_agent_message(from_agent: str, to_agent: str, topic: str):
        """Record agent message."""
        if PROMETHEUS_AVAILABLE:
            AGENT_MESSAGES.labels(
                from_agent=from_agent,
                to_agent=to_agent,
                topic=topic,
            ).inc()
    
    @staticmethod
    def set_active_agents(agent_type: str, count: int):
        """Set active agent count."""
        if PROMETHEUS_AVAILABLE:
            AGENT_ACTIVE.labels(agent_type=agent_type).set(count)
    
    @staticmethod
    def record_cache_hit(cache_type: str):
        """Record cache hit."""
        if PROMETHEUS_AVAILABLE:
            CACHE_HITS.labels(cache_type=cache_type).inc()
    
    @staticmethod
    def record_cache_miss(cache_type: str):
        """Record cache miss."""
        if PROMETHEUS_AVAILABLE:
            CACHE_MISSES.labels(cache_type=cache_type).inc()
    
    @staticmethod
    def record_navigation(status: str):
        """Record browser navigation."""
        if PROMETHEUS_AVAILABLE:
            BROWSER_NAVIGATIONS.labels(status=status).inc()
    
    @staticmethod
    def record_extraction_latency(source: str, latency: float):
        """Record extraction latency."""
        if PROMETHEUS_AVAILABLE:
            BROWSER_EXTRACTION_LATENCY.labels(source=source).observe(latency)
    
    @staticmethod
    def record_llm_call(model: str, status: str):
        """Record LLM call."""
        if PROMETHEUS_AVAILABLE:
            LLM_CALLS.labels(model=model, status=status).inc()
    
    @staticmethod
    def record_llm_tokens(model: str, input_tokens: int, output_tokens: int):
        """Record LLM token usage."""
        if PROMETHEUS_AVAILABLE:
            LLM_TOKENS.labels(model=model, type="input").inc(input_tokens)
            LLM_TOKENS.labels(model=model, type="output").inc(output_tokens)
    
    @staticmethod
    def get_metrics() -> bytes:
        """Get metrics in Prometheus format."""
        if PROMETHEUS_AVAILABLE:
            return generate_latest(REGISTRY)
        return b""


# Decorator for timed functions
def timed(method_name: str):
    """
    Decorator to record function timing.
    
    Usage:
        @timed("analyze")
        async def analyze(...):
            ...
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start = time.monotonic()
            status = "success"
            
            try:
                result = await func(*args, **kwargs)
                return result
            except Exception as e:
                status = "error"
                raise
            finally:
                latency = time.monotonic() - start
                MetricsCollector.record_request(method_name, status, latency)
        
        return wrapper
    return decorator
```

---

## ğŸ¥ HEALTH CHECKS

### Location

`app/module/finai_agent/core/health.py`

### Implementation

```python
"""
Health Check - System health monitoring.
"""

import asyncio
from typing import Dict, Any, List
from dataclasses import dataclass
from enum import Enum
from datetime import datetime

from app.common.log import setup_logger

logger = setup_logger(__name__)


class HealthStatus(Enum):
    """Health status levels."""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"


@dataclass
class HealthCheckResult:
    """Result of a health check."""
    name: str
    status: HealthStatus
    message: str = ""
    latency_ms: float = 0.0
    details: Dict[str, Any] = None


class HealthChecker:
    """
    System health checker.
    
    Checks:
    - Redis connectivity
    - Browser availability
    - LLM API connectivity
    - Database connectivity
    """
    
    def __init__(self):
        self._checks: List[tuple] = []
    
    def register_check(self, name: str, check_func):
        """Register a health check function."""
        self._checks.append((name, check_func))
    
    async def check_redis(self) -> HealthCheckResult:
        """Check Redis connectivity."""
        import time
        start = time.monotonic()
        
        try:
            from app.module.finai_agent.core.cache import get_cache
            cache = get_cache()
            await cache.initialize()
            
            if cache.redis_client:
                await cache.redis_client.ping()
                latency = (time.monotonic() - start) * 1000
                
                return HealthCheckResult(
                    name="redis",
                    status=HealthStatus.HEALTHY,
                    message="Redis is responsive",
                    latency_ms=latency,
                )
            else:
                return HealthCheckResult(
                    name="redis",
                    status=HealthStatus.DEGRADED,
                    message="Using memory cache fallback",
                    latency_ms=(time.monotonic() - start) * 1000,
                )
        
        except Exception as e:
            return HealthCheckResult(
                name="redis",
                status=HealthStatus.UNHEALTHY,
                message=f"Redis error: {str(e)}",
                latency_ms=(time.monotonic() - start) * 1000,
            )
    
    async def check_browser(self) -> HealthCheckResult:
        """Check browser availability."""
        import time
        start = time.monotonic()
        
        try:
            # Just check if Playwright is importable
            from playwright.async_api import async_playwright
            
            return HealthCheckResult(
                name="browser",
                status=HealthStatus.HEALTHY,
                message="Playwright available",
                latency_ms=(time.monotonic() - start) * 1000,
            )
        
        except Exception as e:
            return HealthCheckResult(
                name="browser",
                status=HealthStatus.UNHEALTHY,
                message=f"Browser error: {str(e)}",
                latency_ms=(time.monotonic() - start) * 1000,
            )
    
    async def check_llm(self) -> HealthCheckResult:
        """Check LLM API connectivity."""
        import time
        start = time.monotonic()
        
        try:
            import os
            api_key = os.getenv("OPENAI_API_KEY")
            
            if not api_key:
                return HealthCheckResult(
                    name="llm",
                    status=HealthStatus.UNHEALTHY,
                    message="OPENAI_API_KEY not configured",
                    latency_ms=(time.monotonic() - start) * 1000,
                )
            
            return HealthCheckResult(
                name="llm",
                status=HealthStatus.HEALTHY,
                message="API key configured",
                latency_ms=(time.monotonic() - start) * 1000,
            )
        
        except Exception as e:
            return HealthCheckResult(
                name="llm",
                status=HealthStatus.UNHEALTHY,
                message=f"LLM error: {str(e)}",
                latency_ms=(time.monotonic() - start) * 1000,
            )
    
    async def run_all_checks(self) -> Dict[str, Any]:
        """Run all health checks."""
        results = await asyncio.gather(
            self.check_redis(),
            self.check_browser(),
            self.check_llm(),
            return_exceptions=True,
        )
        
        checks = {}
        overall_status = HealthStatus.HEALTHY
        
        for result in results:
            if isinstance(result, Exception):
                checks["error"] = {
                    "status": HealthStatus.UNHEALTHY.value,
                    "message": str(result),
                }
                overall_status = HealthStatus.UNHEALTHY
            else:
                checks[result.name] = {
                    "status": result.status.value,
                    "message": result.message,
                    "latency_ms": result.latency_ms,
                }
                
                if result.status == HealthStatus.UNHEALTHY:
                    overall_status = HealthStatus.UNHEALTHY
                elif result.status == HealthStatus.DEGRADED and overall_status == HealthStatus.HEALTHY:
                    overall_status = HealthStatus.DEGRADED
        
        return {
            "status": overall_status.value,
            "timestamp": datetime.now().isoformat(),
            "checks": checks,
        }


# Global health checker
_health_checker: HealthChecker = None


def get_health_checker() -> HealthChecker:
    """Get global health checker."""
    global _health_checker
    if _health_checker is None:
        _health_checker = HealthChecker()
    return _health_checker
```

---

## ğŸ›‘ GRACEFUL SHUTDOWN

### Location

`app/module/finai_agent/core/shutdown.py`

### Implementation

```python
"""
Graceful Shutdown - Handle termination signals.
"""

import asyncio
import signal
from typing import List, Callable, Awaitable
from contextlib import asynccontextmanager

from app.common.log import setup_logger

logger = setup_logger(__name__)


class GracefulShutdown:
    """
    Manages graceful shutdown on SIGTERM/SIGINT.
    
    Features:
    - Register cleanup handlers
    - Wait for in-flight requests
    - Timeout protection
    """
    
    def __init__(self, timeout_seconds: float = 30.0):
        self.timeout = timeout_seconds
        self._handlers: List[Callable[[], Awaitable[None]]] = []
        self._shutting_down = False
        self._in_flight = 0
        self._lock = asyncio.Lock()
    
    def register_handler(self, handler: Callable[[], Awaitable[None]]):
        """Register cleanup handler."""
        self._handlers.append(handler)
        logger.debug("[Shutdown] Registered handler: %s", handler.__name__)
    
    async def increment_in_flight(self):
        """Increment in-flight request count."""
        async with self._lock:
            if self._shutting_down:
                raise ShutdownInProgress("Server is shutting down")
            self._in_flight += 1
    
    async def decrement_in_flight(self):
        """Decrement in-flight request count."""
        async with self._lock:
            self._in_flight = max(0, self._in_flight - 1)
    
    @asynccontextmanager
    async def track_request(self):
        """Context manager to track in-flight requests."""
        await self.increment_in_flight()
        try:
            yield
        finally:
            await self.decrement_in_flight()
    
    async def shutdown(self):
        """Execute graceful shutdown."""
        async with self._lock:
            if self._shutting_down:
                return
            self._shutting_down = True
        
        logger.info("[Shutdown] Starting graceful shutdown...")
        
        # Wait for in-flight requests
        start_wait = asyncio.get_event_loop().time()
        while self._in_flight > 0:
            elapsed = asyncio.get_event_loop().time() - start_wait
            if elapsed > self.timeout:
                logger.warning(
                    "[Shutdown] Timeout waiting for %d in-flight requests",
                    self._in_flight,
                )
                break
            
            logger.info(
                "[Shutdown] Waiting for %d in-flight requests...",
                self._in_flight,
            )
            await asyncio.sleep(1)
        
        # Run cleanup handlers
        for handler in self._handlers:
            try:
                logger.info("[Shutdown] Running: %s", handler.__name__)
                await asyncio.wait_for(handler(), timeout=10.0)
            except asyncio.TimeoutError:
                logger.error("[Shutdown] Handler timeout: %s", handler.__name__)
            except Exception as e:
                logger.error("[Shutdown] Handler error %s: %s", handler.__name__, e)
        
        logger.info("[Shutdown] Graceful shutdown complete")
    
    def setup_signal_handlers(self, loop: asyncio.AbstractEventLoop):
        """Setup signal handlers for graceful shutdown."""
        
        def signal_handler(sig):
            logger.info("[Shutdown] Received signal: %s", sig.name)
            asyncio.create_task(self.shutdown())
        
        for sig in (signal.SIGTERM, signal.SIGINT):
            loop.add_signal_handler(sig, lambda s=sig: signal_handler(s))
        
        logger.info("[Shutdown] Signal handlers registered")


class ShutdownInProgress(Exception):
    """Exception raised when server is shutting down."""
    pass


# Global shutdown manager
_shutdown: GracefulShutdown = None


def get_shutdown_manager(timeout: float = 30.0) -> GracefulShutdown:
    """Get global shutdown manager."""
    global _shutdown
    if _shutdown is None:
        _shutdown = GracefulShutdown(timeout)
    return _shutdown
```

---

## âœ… INTEGRATION CHECKLIST

After implementing all features:

- [ ] Rate limiter integrated into API routes
- [ ] Cache decorators added to expensive operations
- [ ] Circuit breakers wrap external service calls
- [ ] Metrics endpoint `/metrics` exposed
- [ ] Health check endpoint `/health` working
- [ ] Graceful shutdown handles SIGTERM
- [ ] Configuration loaded from environment

### Files to Create/Modify

|File|Action|LOC|
|---|---|---|
|`core/rate_limiter.py`|CREATE|~180|
|`core/cache.py`|CREATE|~220|
|`core/circuit_breaker.py`|CREATE|~180|
|`core/metrics.py`|CREATE|~200|
|`core/health.py`|CREATE|~180|
|`core/shutdown.py`|CREATE|~120|
|`api/routes/health.py`|CREATE|~50|

**Total:** ~1,130 LOC

---

**Document End**

_Next Steps: See `05_TEST_COVERAGE_PLAN.md`_

---

# PHáº¦N 5: FinAI Browser Agent - Test Coverage Plan

**Version:** 1.0  
**Date:** 2025-12-20  
**Priority:** P1  
**Estimated Time:** 4-5 days  
**Target Coverage:** 80%+

---

## ğŸ“‹ CURRENT STATE

### Existing Tests

|File|LOC|Coverage|
|---|---|---|
|`tests/unit/test_chief_agent.py`|90|ChiefAgent|
|`tests/unit/test_message_bus.py`|72|MessageBus|
|`tests/unit/test_finai_agent_entrypoint.py`|154|FinAIBrowserAgent|
|`tests/integration/test_multi_agent_flow.py`|87|Multi-agent coordination|

**Total:** 403 LOC, ~40% coverage

### Missing Tests

|Component|Priority|Status|
|---|---|---|
|Navigator Agent|P1|âŒ Missing|
|Extractor Agent|P1|âŒ Missing|
|Verifier Agent|P1|âŒ Missing|
|Synthesizer Agent|P1|âŒ Missing|
|Planner Agent|P1|âŒ Missing|
|Financial Data Extractor|P1|âŒ Missing|
|PlaywrightController|P2|âŒ Missing|
|MCP External Server|P0|âŒ Missing (after implementation)|
|Rate Limiter|P2|âŒ Missing|
|Cache|P2|âŒ Missing|
|Circuit Breaker|P2|âŒ Missing|
|E2E Workflow|P1|âŒ Missing|

---

## ğŸ¯ TEST STRUCTURE

```
tests/
â”œâ”€â”€ conftest.py                          # Global fixtures
â”œâ”€â”€ __init__.py
â”‚
â”œâ”€â”€ unit/                                # Unit tests
â”‚   â”œâ”€â”€ conftest.py                      # Unit test fixtures
â”‚   â”œâ”€â”€ test_chief_agent.py              âœ… Existing
â”‚   â”œâ”€â”€ test_message_bus.py              âœ… Existing
â”‚   â”œâ”€â”€ test_finai_agent_entrypoint.py   âœ… Existing
â”‚   â”œâ”€â”€ test_planner_agent.py            ğŸ“ TODO
â”‚   â”œâ”€â”€ test_navigator_agent.py          ğŸ“ TODO
â”‚   â”œâ”€â”€ test_extractor_agent.py          ğŸ“ TODO
â”‚   â”œâ”€â”€ test_verifier_agent.py           ğŸ“ TODO
â”‚   â”œâ”€â”€ test_synthesizer_agent.py        ğŸ“ TODO
â”‚   â”œâ”€â”€ test_financial_data_extractor.py ğŸ“ TODO
â”‚   â”œâ”€â”€ test_playwright_controller.py    ğŸ“ TODO
â”‚   â”œâ”€â”€ test_rate_limiter.py             ğŸ“ TODO
â”‚   â”œâ”€â”€ test_cache.py                    ğŸ“ TODO
â”‚   â””â”€â”€ test_circuit_breaker.py          ğŸ“ TODO
â”‚
â”œâ”€â”€ integration/                         # Integration tests
â”‚   â”œâ”€â”€ conftest.py                      # Integration fixtures
â”‚   â”œâ”€â”€ test_multi_agent_flow.py         âœ… Existing
â”‚   â”œâ”€â”€ test_mcp_server.py               ğŸ“ TODO
â”‚   â”œâ”€â”€ test_browser_extraction.py       ğŸ“ TODO
â”‚   â””â”€â”€ test_api_endpoints.py            ğŸ“ TODO
â”‚
â”œâ”€â”€ e2e/                                 # End-to-end tests
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_finai_workflow.py           ğŸ“ TODO
â”‚   â””â”€â”€ test_claude_desktop_integration.py ğŸ“ TODO
â”‚
â””â”€â”€ performance/                         # Performance benchmarks
    â”œâ”€â”€ conftest.py
    â”œâ”€â”€ test_latency_benchmarks.py       ğŸ“ TODO
    â””â”€â”€ test_load_tests.py               ğŸ“ TODO
```

---

## ğŸ“ TEST IMPLEMENTATIONS

### 1. Planner Agent Unit Tests

**File:** `tests/unit/test_planner_agent.py`

```python
"""
Unit tests for PlannerAgent.

Tests:
- Plan generation for different query types
- URL construction for financial sources
- Step ordering
- Error handling
"""

import pytest
from unittest.mock import AsyncMock, MagicMock, patch
from app.module.finai_agent.layer_2_cognition.planner_agent import PlannerAgent
from app.module.finai_agent.layer_2_cognition.message_bus import Message, MessageBus


@pytest.fixture
def mock_bus():
    """Create mock message bus."""
    bus = MagicMock(spec=MessageBus)
    bus.subscribe = MagicMock()
    bus.publish = AsyncMock()
    bus.add_action_log = MagicMock()
    return bus


@pytest.fixture
def planner_agent(mock_bus):
    """Create PlannerAgent with mock bus."""
    agent = PlannerAgent(bus=mock_bus)
    return agent


class TestPlannerAgentInitialization:
    """Tests for PlannerAgent initialization."""
    
    def test_agent_name(self, planner_agent):
        """Test agent has correct name."""
        assert planner_agent.name == "FinAI_Planner"
    
    def test_subscribed_topics(self, planner_agent):
        """Test agent subscribes to correct topics."""
        assert "task_available" in planner_agent.subscribed_topics


class TestPlanGeneration:
    """Tests for plan generation."""
    
    @pytest.mark.asyncio
    async def test_generates_plan_for_stock_query(self, planner_agent, mock_bus):
        """Test generates navigation plan for stock query."""
        msg = Message(
            from_agent="Chief",
            to_agent="broadcast",
            topic="task_available",
            payload={
                "financial_query": {
                    "company": "Apple",
                    "ticker": "AAPL",
                    "metrics": ["current_price", "pe_ratio"],
                },
            },
        )
        
        await planner_agent._generate_plan(msg)
        
        # Verify plan_ready was published
        mock_bus.publish.assert_called_once()
        call_args = mock_bus.publish.call_args[0][0]
        assert call_args.topic == "plan_ready"
        assert "plan" in call_args.payload
        assert len(call_args.payload["plan"]) > 0
    
    @pytest.mark.asyncio
    async def test_includes_yahoo_finance_url(self, planner_agent, mock_bus):
        """Test plan includes Yahoo Finance URL for stock queries."""
        msg = Message(
            from_agent="Chief",
            to_agent="broadcast",
            topic="task_available",
            payload={
                "financial_query": {
                    "ticker": "AAPL",
                    "metrics": ["current_price"],
                },
            },
        )
        
        await planner_agent._generate_plan(msg)
        
        call_args = mock_bus.publish.call_args[0][0]
        plan = call_args.payload["plan"]
        
        urls = [step.get("url", "") for step in plan]
        assert any("yahoo.com" in url.lower() for url in urls)
    
    @pytest.mark.asyncio
    async def test_handles_missing_ticker(self, planner_agent, mock_bus):
        """Test handles query without ticker."""
        msg = Message(
            from_agent="Chief",
            to_agent="broadcast",
            topic="task_available",
            payload={
                "financial_query": {
                    "company": "Apple Inc",
                    "metrics": ["revenue"],
                },
            },
        )
        
        await planner_agent._generate_plan(msg)
        
        # Should still generate plan
        mock_bus.publish.assert_called_once()


class TestDecideNextAction:
    """Tests for action decision."""
    
    @pytest.mark.asyncio
    async def test_returns_generate_plan_for_task_available(self, planner_agent):
        """Test returns correct action for task_available topic."""
        msg = Message(
            from_agent="Chief",
            to_agent="broadcast",
            topic="task_available",
            payload={},
        )
        
        action = await planner_agent.decide_next_action(msg)
        assert action == "generate_plan"
    
    @pytest.mark.asyncio
    async def test_returns_wait_for_unknown_topic(self, planner_agent):
        """Test returns wait for unknown topics."""
        msg = Message(
            from_agent="Unknown",
            to_agent="broadcast",
            topic="unknown_topic",
            payload={},
        )
        
        action = await planner_agent.decide_next_action(msg)
        assert action == "wait"
```

### 2. Navigator Agent Unit Tests

**File:** `tests/unit/test_navigator_agent.py`

```python
"""
Unit tests for NavigatorAgent.

Tests:
- Navigation execution
- MCP vs legacy mode
- Browser guard integration
- Error handling
"""

import pytest
from unittest.mock import AsyncMock, MagicMock, patch
from app.module.finai_agent.layer_2_cognition.navigator_agent import NavigatorAgent
from app.module.finai_agent.layer_2_cognition.message_bus import Message, MessageBus


@pytest.fixture
def mock_bus():
    """Create mock message bus."""
    bus = MagicMock(spec=MessageBus)
    bus.subscribe = MagicMock()
    bus.publish = AsyncMock()
    bus.add_action_log = MagicMock()
    return bus


@pytest.fixture
def mock_mcp_adapter():
    """Create mock MCP adapter."""
    adapter = MagicMock()
    adapter.execute = AsyncMock(return_value=MagicMock(
        success=True,
        result={"html": "<html></html>", "url": "https://example.com"},
    ))
    return adapter


@pytest.fixture
def navigator_agent(mock_bus):
    """Create NavigatorAgent without MCP."""
    return NavigatorAgent(bus=mock_bus, mcp_adapter=None)


@pytest.fixture
def navigator_agent_mcp(mock_bus, mock_mcp_adapter):
    """Create NavigatorAgent with MCP."""
    return NavigatorAgent(bus=mock_bus, mcp_adapter=mock_mcp_adapter)


class TestNavigatorAgentInitialization:
    """Tests for initialization."""
    
    def test_agent_name(self, navigator_agent):
        """Test agent has correct name."""
        assert navigator_agent.name == "FinAI_Navigator"
    
    def test_subscribed_to_plan_ready(self, navigator_agent):
        """Test subscribes to plan_ready topic."""
        assert "plan_ready" in navigator_agent.subscribed_topics
    
    def test_mcp_mode_detection(self, navigator_agent, navigator_agent_mcp):
        """Test MCP mode is correctly detected."""
        assert navigator_agent.mcp is None
        assert navigator_agent_mcp.mcp is not None


class TestNavigationExecution:
    """Tests for navigation execution."""
    
    @pytest.mark.asyncio
    async def test_execute_empty_plan(self, navigator_agent, mock_bus):
        """Test handles empty navigation plan."""
        msg = Message(
            from_agent="Planner",
            to_agent="broadcast",
            topic="plan_ready",
            payload={"plan": []},
        )
        
        await navigator_agent._execute_navigation_plan(msg)
        
        # Should not publish page_ready for empty plan
        page_ready_calls = [
            call for call in mock_bus.publish.call_args_list
            if call[0][0].topic == "page_ready"
        ]
        assert len(page_ready_calls) == 0
    
    @pytest.mark.asyncio
    async def test_skips_step_without_url(self, navigator_agent, mock_bus):
        """Test skips steps without URL."""
        msg = Message(
            from_agent="Planner",
            to_agent="broadcast",
            topic="plan_ready",
            payload={
                "plan": [
                    {"action": "navigate"},  # Missing URL
                ],
            },
        )
        
        await navigator_agent._execute_navigation_plan(msg)
        
        # Should not crash, no page_ready published
        page_ready_calls = [
            call for call in mock_bus.publish.call_args_list
            if call[0][0].topic == "page_ready"
        ]
        assert len(page_ready_calls) == 0


class TestMCPMode:
    """Tests for MCP mode."""
    
    @pytest.mark.asyncio
    async def test_uses_mcp_when_available(self, navigator_agent_mcp, mock_mcp_adapter):
        """Test uses MCP adapter when available."""
        msg = Message(
            from_agent="Planner",
            to_agent="broadcast",
            topic="plan_ready",
            payload={
                "plan": [
                    {"action": "navigate", "url": "https://example.com"},
                ],
                "financial_query": {},
            },
        )
        
        with patch.object(
            navigator_agent_mcp,
            "_execute_step_mcp",
            new_callable=AsyncMock,
            return_value=("screenshot", {}, "<html>", "https://example.com"),
        ):
            await navigator_agent_mcp._execute_navigation_plan(msg)
        
        # Should have used MCP
        navigator_agent_mcp._execute_step_mcp.assert_called()


class TestBrowserGuards:
    """Tests for browser guard integration."""
    
    @pytest.mark.asyncio
    async def test_blocks_malicious_url(self, navigator_agent, mock_bus):
        """Test blocks navigation to malicious URLs."""
        msg = Message(
            from_agent="Planner",
            to_agent="broadcast",
            topic="plan_ready",
            payload={
                "plan": [
                    {"action": "navigate", "url": "javascript:alert(1)"},
                ],
                "financial_query": {},
            },
        )
        
        await navigator_agent._execute_navigation_plan(msg)
        
        # Should publish navigation_error, not page_ready
        error_calls = [
            call for call in mock_bus.publish.call_args_list
            if call[0][0].topic == "navigation_error"
        ]
        assert len(error_calls) >= 1
```

### 3. Financial Data Extractor Unit Tests

**File:** `tests/unit/test_financial_data_extractor.py`

```python
"""
Unit tests for FinancialDataExtractor.

Tests:
- extract() returns proper dict (BUG FIX verification)
- Yahoo Finance extraction
- Generic LLM extraction
- Table extraction
- Error handling
"""

import pytest
from unittest.mock import AsyncMock, MagicMock, patch
from app.module.finai_agent.layer_3_action.tools.financial_data_extractor import (
    FinancialDataExtractor,
)


@pytest.fixture
def extractor():
    """Create FinancialDataExtractor instance."""
    with patch(
        "app.module.finai_agent.layer_3_action.tools.financial_data_extractor.ChatOpenAI"
    ) as mock_llm:
        mock_llm.return_value = MagicMock()
        return FinancialDataExtractor()


class TestExtractMethod:
    """Critical tests for extract() method - BUG FIX verification."""
    
    @pytest.mark.asyncio
    async def test_extract_returns_dict_not_none(self, extractor):
        """CRITICAL: Verify extract() returns dict, not None."""
        result = await extractor.extract(
            a11y_tree={},
            html="<html><body>Test</body></html>",
            url="https://example.com",
            metrics=["price"],
        )
        
        assert result is not None, "BUG: extract() returned None!"
        assert isinstance(result, dict), f"BUG: extract() returned {type(result)}"
    
    @pytest.mark.asyncio
    async def test_extract_has_required_keys(self, extractor):
        """Verify extract() result has required keys."""
        result = await extractor.extract(
            a11y_tree={},
            html="<html></html>",
            url="https://example.com",
            metrics=[],
        )
        
        assert "metrics" in result
        assert "tables" in result
        assert "confidence" in result
    
    @pytest.mark.asyncio
    async def test_extract_metrics_is_dict(self, extractor):
        """Verify metrics is a dict."""
        result = await extractor.extract(
            a11y_tree={},
            html="<html></html>",
            url="https://example.com",
            metrics=[],
        )
        
        assert isinstance(result["metrics"], dict)
    
    @pytest.mark.asyncio
    async def test_extract_confidence_is_float(self, extractor):
        """Verify confidence is a float."""
        result = await extractor.extract(
            a11y_tree={},
            html="<html></html>",
            url="https://example.com",
            metrics=[],
        )
        
        assert isinstance(result["confidence"], (int, float))
        assert 0.0 <= result["confidence"] <= 1.0


class TestYahooFinanceExtraction:
    """Tests for Yahoo Finance specific extraction."""
    
    @pytest.mark.asyncio
    async def test_uses_yahoo_extractor_for_yahoo_url(self, extractor):
        """Test routes to Yahoo extractor for Yahoo URLs."""
        with patch.object(
            extractor,
            "_extract_from_yahoo",
            new_callable=AsyncMock,
            return_value={"metrics": {"price": "150"}, "tables": [], "confidence": 0.8},
        ) as mock_yahoo:
            result = await extractor.extract(
                a11y_tree={},
                html="<html></html>",
                url="https://finance.yahoo.com/quote/AAPL",
                metrics=["price"],
            )
            
            mock_yahoo.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_extracts_price_from_yahoo_html(self, extractor):
        """Test extracts price from Yahoo Finance HTML."""
        yahoo_html = """
        <html>
        <body>
            <fin-streamer data-field="regularMarketPrice">150.00</fin-streamer>
        </body>
        </html>
        """
        
        result = await extractor._extract_from_yahoo(
            a11y_tree={},
            html=yahoo_html,
            metrics=["current price"],
        )
        
        assert result["confidence"] > 0


class TestGenericExtraction:
    """Tests for generic LLM extraction."""
    
    @pytest.mark.asyncio
    async def test_uses_generic_for_unknown_url(self, extractor):
        """Test uses generic extractor for unknown URLs."""
        with patch.object(
            extractor,
            "_extract_generic",
            new_callable=AsyncMock,
            return_value={"metrics": {}, "tables": [], "confidence": 0.6},
        ) as mock_generic:
            result = await extractor.extract(
                a11y_tree={},
                html="<html></html>",
                url="https://random-finance.com/data",
                metrics=["price"],
            )
            
            mock_generic.assert_called_once()


class TestTableExtraction:
    """Tests for table extraction."""
    
    @pytest.mark.asyncio
    async def test_extracts_tables_from_html(self, extractor):
        """Test extracts tables from HTML."""
        html = """
        <html>
        <body>
            <table>
                <tr><th>Metric</th><th>Value</th></tr>
                <tr><td>Revenue</td><td>$100B</td></tr>
                <tr><td>Net Income</td><td>$25B</td></tr>
            </table>
        </body>
        </html>
        """
        
        tables = await extractor.extract_financial_tables(html)
        
        assert len(tables) == 1
        assert "rows" in tables[0]
        assert len(tables[0]["rows"]) == 3


class TestErrorHandling:
    """Tests for error handling."""
    
    @pytest.mark.asyncio
    async def test_handles_empty_html(self, extractor):
        """Test handles empty HTML gracefully."""
        result = await extractor.extract(
            a11y_tree={},
            html="",
            url="https://example.com",
            metrics=["price"],
        )
        
        assert result is not None
        assert result["confidence"] >= 0
    
    @pytest.mark.asyncio
    async def test_handles_malformed_html(self, extractor):
        """Test handles malformed HTML."""
        result = await extractor.extract(
            a11y_tree={},
            html="<html><body><div>Not closed",
            url="https://example.com",
            metrics=["price"],
        )
        
        assert result is not None
```

### 4. MCP Server Integration Tests

**File:** `tests/integration/test_mcp_server.py`

```python
"""
Integration tests for MCP External Server.

Tests:
- Server initialization
- Tool discovery
- Tool execution
- Resource listing
- Error handling
"""

import pytest
import asyncio
from unittest.mock import AsyncMock, patch


# Skip if MCP module not implemented yet
try:
    from app.module.finai_agent.mcp.server import FinAIMCPServer, MCPRequest
    MCP_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False


@pytest.mark.skipif(not MCP_AVAILABLE, reason="MCP module not implemented")
class TestMCPServerIntegration:
    """Integration tests for MCP server."""
    
    @pytest.fixture
    async def server(self):
        """Create and initialize MCP server."""
        server = FinAIMCPServer()
        await server.initialize()
        yield server
        await server.shutdown()
    
    @pytest.mark.asyncio
    async def test_initialize_response(self, server):
        """Test initialize method returns correct response."""
        request = MCPRequest(
            jsonrpc="2.0",
            id=1,
            method="initialize",
            params={},
        )
        
        response = await server.handle_request(request)
        
        assert response.error is None
        assert response.result is not None
        assert "protocolVersion" in response.result
        assert "serverInfo" in response.result
        assert "capabilities" in response.result
    
    @pytest.mark.asyncio
    async def test_tools_list_returns_tools(self, server):
        """Test tools/list returns available tools."""
        request = MCPRequest(
            jsonrpc="2.0",
            id=2,
            method="tools/list",
            params={},
        )
        
        response = await server.handle_request(request)
        
        assert response.error is None
        assert "tools" in response.result
        
        tool_names = [t["name"] for t in response.result["tools"]]
        assert "finai_analyze" in tool_names
    
    @pytest.mark.asyncio
    async def test_tools_call_analyze(self, server):
        """Test calling finai_analyze tool."""
        with patch(
            "app.module.finai_agent.mcp.adapters.finai_adapter.FinAIAdapter.analyze",
            new_callable=AsyncMock,
            return_value={
                "status": "success",
                "extracted_metrics": {"price": "150"},
                "final_report": "Analysis complete",
            },
        ):
            request = MCPRequest(
                jsonrpc="2.0",
                id=3,
                method="tools/call",
                params={
                    "name": "finai_analyze",
                    "arguments": {
                        "company": "Apple",
                        "metrics": ["price"],
                    },
                },
            )
            
            response = await server.handle_request(request)
            
            assert response.error is None
            assert "content" in response.result
    
    @pytest.mark.asyncio
    async def test_unknown_tool_returns_error(self, server):
        """Test calling unknown tool returns error."""
        request = MCPRequest(
            jsonrpc="2.0",
            id=4,
            method="tools/call",
            params={
                "name": "unknown_tool",
                "arguments": {},
            },
        )
        
        response = await server.handle_request(request)
        
        assert "content" in response.result
        assert response.result.get("isError", False) is True
    
    @pytest.mark.asyncio
    async def test_unknown_method_returns_error(self, server):
        """Test unknown method returns error."""
        request = MCPRequest(
            jsonrpc="2.0",
            id=5,
            method="unknown/method",
            params={},
        )
        
        response = await server.handle_request(request)
        
        assert response.error is not None
        assert response.error["code"] == -32601
```

### 5. E2E Workflow Tests

**File:** `tests/e2e/test_finai_workflow.py`

```python
"""
End-to-end tests for FinAI workflow.

Tests complete flow from API request to response.
"""

import pytest
from unittest.mock import AsyncMock, patch


class TestFinAIEndToEnd:
    """E2E tests for FinAI agent."""
    
    @pytest.fixture
    async def agent(self):
        """Create FinAI agent."""
        from app.module.finai_agent.agent_entrypoint import FinAIBrowserAgent
        agent = FinAIBrowserAgent()
        yield agent
    
    @pytest.mark.asyncio
    @pytest.mark.timeout(60)
    async def test_full_analysis_workflow(self, agent):
        """Test complete analysis workflow."""
        # Mock browser and LLM calls
        with patch(
            "app.module.finai_agent.layer_3_action.browser.playwright_controller.PlaywrightController"
        ) as mock_browser:
            mock_browser_instance = AsyncMock()
            mock_browser_instance.navigate = AsyncMock()
            mock_browser_instance.screenshot = AsyncMock(return_value="base64data")
            mock_browser_instance.get_a11y_tree = AsyncMock(return_value={})
            mock_browser_instance.extract_html = AsyncMock(
                return_value="<html><body>Price: $150</body></html>"
            )
            mock_browser_instance.get_current_url = AsyncMock(
                return_value="https://finance.yahoo.com/quote/AAPL"
            )
            mock_browser_instance.close = AsyncMock()
            mock_browser.return_value = mock_browser_instance
            
            result = await agent.analyze(
                company="Apple",
                metrics=["current_price"],
                time_period="current",
            )
        
        assert result is not None
        assert "status" in result
    
    @pytest.mark.asyncio
    async def test_handles_invalid_company(self, agent):
        """Test handles invalid company gracefully."""
        result = await agent.analyze(
            company="",
            metrics=["price"],
        )
        
        # Should return error, not crash
        assert result is not None
        assert "status" in result
```

---

## âš™ï¸ TEST CONFIGURATION

### pytest.ini Updates

```ini
[pytest]
asyncio_mode = auto
testpaths = tests
python_files = test_*.py
python_functions = test_*
addopts = -v --tb=short --cov=app.module.finai_agent --cov-report=html --cov-report=term-missing
markers =
    slow: marks tests as slow
    integration: marks integration tests
    e2e: marks end-to-end tests
timeout = 30
```

### conftest.py (Global Fixtures)

```python
"""
Global test fixtures.
"""

import pytest
import asyncio
from unittest.mock import MagicMock, AsyncMock


@pytest.fixture(scope="session")
def event_loop():
    """Create event loop for async tests."""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()


@pytest.fixture
def mock_llm():
    """Create mock LLM."""
    llm = MagicMock()
    llm.ainvoke = AsyncMock(return_value=MagicMock(content='{"result": "test"}'))
    return llm


@pytest.fixture
def mock_redis():
    """Create mock Redis client."""
    redis = AsyncMock()
    redis.get = AsyncMock(return_value=None)
    redis.setex = AsyncMock(return_value=True)
    redis.ping = AsyncMock(return_value=True)
    return redis


@pytest.fixture
def sample_financial_query():
    """Sample financial query fixture."""
    return {
        "company": "Apple Inc",
        "ticker": "AAPL",
        "metrics": ["current_price", "pe_ratio", "market_cap"],
        "time_period": "current",
    }


@pytest.fixture
def sample_html_with_price():
    """Sample HTML containing price data."""
    return """
    <html>
    <body>
        <div class="price-container">
            <fin-streamer data-field="regularMarketPrice">150.25</fin-streamer>
            <fin-streamer data-field="regularMarketChange">+2.50</fin-streamer>
        </div>
        <table class="financials">
            <tr><th>Metric</th><th>Value</th></tr>
            <tr><td>P/E Ratio</td><td>28.5</td></tr>
            <tr><td>Market Cap</td><td>2.5T</td></tr>
        </table>
    </body>
    </html>
    """
```

---

## ğŸ“Š COVERAGE TARGETS

|Component|Current|Target|
|---|---|---|
|Layer 0 (Governance)|~30%|80%|
|Layer 1 (Perception)|~40%|80%|
|Layer 2 (Cognition)|~45%|85%|
|Layer 3 (Action)|~20%|75%|
|MCP External Server|0%|80%|
|Core (Production)|0%|75%|
|**Overall**|**~40%**|**80%**|

---

## ğŸƒ RUNNING TESTS

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=app.module.finai_agent --cov-report=html

# Run only unit tests
pytest tests/unit/ -v

# Run only integration tests
pytest tests/integration/ -v -m integration

# Run specific test file
pytest tests/unit/test_financial_data_extractor.py -v

# Run with verbose output and no capture
pytest tests/ -v -s

# Run tests matching pattern
pytest tests/ -k "test_extract" -v
```

---

## âœ… VERIFICATION CHECKLIST

After implementing all tests:

- [ ] All unit tests pass
- [ ] All integration tests pass
- [ ] E2E tests pass
- [ ] Coverage report shows 80%+
- [ ] No flaky tests
- [ ] Tests run in CI/CD pipeline

---

**Document End**

_Final document in series. Begin implementation following priority order._