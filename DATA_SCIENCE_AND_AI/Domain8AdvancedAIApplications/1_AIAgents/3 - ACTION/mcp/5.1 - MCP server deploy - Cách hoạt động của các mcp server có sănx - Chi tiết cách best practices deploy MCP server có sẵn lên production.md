```bash
ƒê·ªÉ deploy¬†**official MCP servers**¬†(npx/uvx) l√™n production:

1. **KH√îNG TH·ªÇ**¬†d√πng tr·ª±c ti·∫øp (ch·ªâ c√≥ STDIO transport)
    
2. **PH·∫¢I**¬†convert sang HTTP b·∫±ng 1 trong 3 c√°ch:
    
    - ‚≠ê¬†**MCP Proxy**¬†(sparfenyuk) - Khuy·∫øn ngh·ªã cho 90% cases
    - üöÄ¬†**Ray Serve**¬†- Cho enterprise scale
    - üê≥¬†**Docker Gateway**¬†- Cho Docker users
3. **Best practice ƒë·∫ßy ƒë·ªß**¬†nh∆∞ custom servers:
    
    - Security (auth, rate limit, SSL)
    - Monitoring (logs, metrics, alerts)
    - Performance (resource limits, caching)
    - Reliability (health checks, backup)
```


ƒê√∫ng, v·ªÅ b·∫£n ch·∫•t l√† **ƒë√∫ng** ‚Äì ƒëa s·ªë m·∫•y server trong config ƒë√≥ **ƒë√£ ƒë∆∞·ª£c ‚Äúƒë√≥ng g√≥i & deploy s·∫µn‚Äù th√†nh c√¥ng c·ª• runnable**, n√™n Claude/Cursor ch·ªâ vi·ªác spawn process l√† ch·∫°y ngay, b·∫°n kh√¥ng ph·∫£i t·ª± build.

## 1. Nh·ªØng server trong config n√†y ƒëang ch·∫°y ki·ªÉu g√¨?

Nh√¨n v√†o c·∫•u h√¨nh:

- C√°c server d√πng `npx`:
    
    - `@modelcontextprotocol/server-sequential-thinking`
        
    - `@modelcontextprotocol/server-memory`
        
    - `chrome-devtools-mcp`, `mcp-excalidraw-server`, `@modelcontextprotocol/server-github`, v.v.  
        ‚Üí ƒê√¢y l√† **npm packages tr√™n registry**, m·ªói package **ƒë√£ ch·ª©a s·∫µn MCP server** (Node/TypeScript) v√† `npx` ch·ªâ vi·ªác:
        
    - t·∫£i v·ªÅ (n·∫øu ch∆∞a c√≥),
        
    - ch·∫°y command line entrypoint,
        
    - n√≥i chuy·ªán v·ªõi Claude/Cursor qua **STDIO**.
        
- C√°c server d√πng `uvx`:
    
    - `mcp-rubber-duck`, `mcp-server-git`, `mcp-server-filesystem`, `mcp-jupyter`, `mcp-server-sqlite`, `mcp-server-aws`, `mcp-server-gcp`, `mcp-server-kubernetes`, `mcp-server-docker`, v.v.  
        ‚Üí ƒê√¢y l√† **Python MCP servers ƒë√£ publish l√™n PyPI / uvx registry** (ho·∫∑c script entry), `uvx` lo:
        
    - install ƒë√∫ng package + version,
        
    - ch·∫°y MCP server theo ƒë√∫ng entrypoint,
        
    - giao ti·∫øp c≈©ng qua **STDIO**.
        
- M·ªôt s·ªë server custom:
    
    - `vnstock`: `"command": "python", "args": ["vnstock_mcp_run_fixed.py"]` ‚Üí ƒê√¢y l√† MCP server **do b·∫°n t·ª± vi·∫øt**, ch·∫°y local.
        
    - `GitKraken`: ch·∫°y exe c·ªßa GitKraken d∆∞·ªõi mode `mcp` ‚Üí GitLens team ƒë√£ implement MCP endpoint trong binary ƒë√≥.
        

=> T·∫•t c·∫£ c√°c entry trong JSON n√†y ƒë·ªÅu l√† **‚Äúc√°ch ƒë·ªÉ client (Claude/Cursor) kh·ªüi ch·∫°y MCP server d∆∞·ªõi d·∫°ng process local‚Äù**, kh√¥ng ph·∫£i b·∫°n ph·∫£i deploy HTTP service t·ª´ tr∆∞·ªõc.

## 2. N√≥ ‚Äúdeploy s·∫µn‚Äù ·ªü ƒë√¢u?

C√≥ 2 ki·ªÉu:

1. **Server do b√™n th·ª© ba build v√† publish**:
    
    - Ki·ªÉu `npx @modelcontextprotocol/server-xxx` ho·∫∑c `uvx mcp-server-xxx`.
        
    - H·ªç ƒë√£:
        
        - Vi·∫øt MCP server (Node/Python),
            
        - ƒê√≥ng g√≥i th√†nh npm / PyPI package,
            
        - Publish l√™n registry public.
            
    - B·∫°n ch·ªâ c·∫ßn c√≥ `node+npx` ho·∫∑c `uvx+python`, l√† **Claude/Cursor c√≥ th·ªÉ t·∫£i v√† ch·∫°y ngay**, kh√¥ng c·∫ßn t·ª± deploy HTTP.
        
2. **Server t·ª± vi·∫øt, ch·∫°y local**:
    
    - Nh∆∞ `vnstock`, ho·∫∑c b·∫•t k·ª≥ script Python n√†o b·∫°n t·ª± code.
        
    - ‚ÄúDeploy‚Äù ·ªü ƒë√¢y ch·ªâ l√†: file `.py` n·∫±m trong m√°y b·∫°n, Cursor/Claude spawn process `python vnstock_mcp_run_fixed.py` ‚Üí server ch·∫°y qua STDIO.
        

=> N√≥i n√¥m na:

- **ƒê√∫ng, m·∫•y MCP server ƒë√≥ ƒë√£ ·ªü tr·∫°ng th√°i ‚Äúrunnable package‚Äù / ‚Äúdeploy local binary‚Äù r·ªìi**, n√™n khi nh√∫ng v√†o Claude/Cursor:
    
    - Client spawn process,
        
    - G·∫Øn STDIO stream,
        
    - MCP protocol ch·∫°y lu√¥n ‚Üí b·∫°n th·∫•y ‚Äúc·∫Øm v√†o l√† d√πng ƒë∆∞·ª£c‚Äù.
        

## 3. Kh√°c g√¨ v·ªõi remote MCP server ki·ªÉu HTTP/Docker?

- ·ªû case JSON b·∫°n g·ª≠i:
    
    - **Transport = STDIO** (tr·ª´ khi package ƒë√≥ h·ªó tr·ª£ HTTP b√™n trong, nh∆∞ng Cursor/Claude ƒëang launch n√≥ nh∆∞ process local).
        
    - Kh√¥ng c·∫ßn URL, kh√¥ng c·∫ßn c·ªïng, kh√¥ng c·∫ßn Docker, kh√¥ng c·∫ßn cloud.
        
- ·ªû case **remote MCP server**:
    
    - B·∫°n ph·∫£i deploy MCP server (Python/Node/whatever) l√™n:
        
        - Docker container / Docker Compose,
            
        - Azure Functions,
            
        - EC2 / VPS / Cloud Run,‚Ä¶
            
    - Client config:
        
        json
        
        `{   "mcpServers": {    "parent-grade-mcp": {      "type": "http",      "url": "https://your-mcp-server.com/mcp",      "headers": {        "x-api-key": "..."      }    }  } }`
        
    - L√∫c n√†y **Claude/Cursor kh√¥ng spawn process**, m√† **g·ªçi qua HTTP**.
        

## 4. K·∫øt lu·∫≠n ng·∫Øn g·ªçn

- **ƒê√∫ng**:
    
    - C√°c MCP server nh∆∞ `server-sequential-thinking`, `server-memory`, `mcp-server-git`, `mcp-server-docker`,‚Ä¶ trong config ƒë√≥ **ƒë√£ ƒë∆∞·ª£c build & ƒë√≥ng g√≥i s·∫µn** (npm/PyPI/binary).
        
    - Khi b·∫°n th√™m v√†o config Claude/Cursor, client **ch·ªâ c·∫ßn ch·∫°y command t∆∞∆°ng ·ª©ng l√† server ho·∫°t ƒë·ªông ngay**, n√™n b·∫°n c·∫£m gi√°c ‚Äúc·∫Øm l√† ch·∫°y‚Äù.
        
- **Nh∆∞ng**:
    
    - Ch√∫ng **ch·∫°y local d∆∞·ªõi d·∫°ng process STDIO**, ch·ª© kh√¥ng ph·∫£i b·∫°n ƒëang n√≥i chuy·ªán v·ªõi 1 HTTP service deploy ƒë√¢u ƒë√≥ (tr·ª´ khi b·∫°n c·ªë t√¨nh d√πng `type: "http"` + URL).
        

N·∫øu mu·ªën, c√≥ th·ªÉ chuy·ªÉn m·ªôt trong c√°c server ki·ªÉu `python vnstock_mcp_run_fixed.py` th√†nh **Dockerized HTTP MCP service**, r·ªìi m√¨nh vi·∫øt cho b·∫°n 1 `docker-compose.yml` + config `type: "http"` t∆∞∆°ng ·ª©ng ƒë·ªÉ so s√°nh 2 mode side-by-side.

1. [https://www.perplexity.ai/search/step-by-step-trien-khai-mcp-se-QUHplDvCT_WtfTAYDlA7_w](https://www.perplexity.ai/search/step-by-step-trien-khai-mcp-se-QUHplDvCT_WtfTAYDlA7_w)



---

# ƒê√≥ng docker compose 


ƒêang t√¨m hi·ªÉu c√°c c√°ch tri·ªÉn khai MCP server:


[6 tools called]


D·ª±a tr√™n code v√† docs, ƒë√¢y l√† ph√¢n t√≠ch MECE:

## C√°ch tri·ªÉn khai hi·ªán t·∫°i

ƒêang d√πng: Docker Compose + HTTP Transport (streamable-http)
- MCP server ch·∫°y trong container ri√™ng
- Transport: HTTP/streamable-http
- K·∫øt n·ªëi: App container ‚Üí MCP container qua HTTP

---

## Ph√¢n t√≠ch MECE: C√°c c√°ch tri·ªÉn khai MCP Server

### 1. Theo Transport Protocol

#### A. STDIO Transport (nh∆∞ Cursor)
- C√°ch ho·∫°t ƒë·ªông: Process-based, app spawn process c·ªßa MCP server
- Code ƒë√£ c√≥: `ExternalMCPServerWrapper` h·ªó tr·ª£ STDIO
- ∆Øu ƒëi·ªÉm:
  - ƒê∆°n gi·∫£n, kh√¥ng c·∫ßn network
  - Ph√π h·ª£p single-user/local
  - Cursor/Claude Desktop d√πng c√°ch n√†y
- Nh∆∞·ª£c ƒëi·ªÉm:
  - Kh√≥ scale multi-user
  - Process management ph·ª©c t·∫°p
  - Kh√¥ng t·ªët cho production multi-user

#### B. HTTP Transport (ƒëang d√πng)
- C√°ch ho·∫°t ƒë·ªông: HTTP/streamable-http, MCP server l√† HTTP service
- ƒêang d√πng: `HTTPMCPServerWrapper`
- ∆Øu ƒëi·ªÉm:
  - Stateless, scale t·ªët
  - Multi-user support
  - Ph√π h·ª£p production/SaaS
- Nh∆∞·ª£c ƒëi·ªÉm:
  - C·∫ßn network infrastructure
  - Ph·ª©c t·∫°p h∆°n STDIO

---

### 2. Theo Deployment Method

#### A. Docker Compose (ƒëang d√πng)
```
docker compose -f docker-compose-mcp.yml up -d
```
- MCP server trong container ri√™ng
- T√°ch bi·ªát v·ªõi app container
- D·ªÖ qu·∫£n l√Ω lifecycle

#### B. Process-based (nh∆∞ Cursor)
```python
ExternalMCPServerWrapper(
    name="drive",
    command="npx",
    args=["-y", "@modelcontextprotocol/server-drive"]
)
```
- App spawn process c·ªßa MCP server
- Kh√¥ng c·∫ßn Docker
- Ph√π h·ª£p development/local

#### C. Kubernetes (production scale)
- Deploy MCP server nh∆∞ Kubernetes service
- Auto-scaling, service discovery
- Ph√π h·ª£p production l·ªõn

---

### 3. Theo Integration Type

#### A. External Server (ƒëang d√πng)
- MCP server ch·∫°y ri√™ng bi·ªát
- App connect qua HTTP
- ∆Øu ƒëi·ªÉm: T√°ch bi·ªát, d·ªÖ scale, d·ªÖ maintain

#### B. Internal Server
- MCP server l√† part c·ªßa app
- Code ƒë√£ c√≥: `InternalDriveMCPServer`
- ∆Øu ƒëi·ªÉm: ƒê∆°n gi·∫£n, kh√¥ng c·∫ßn network
- Nh∆∞·ª£c ƒëi·ªÉm: Tight coupling, kh√≥ scale ri√™ng

---

## So s√°nh v·ªõi Cursor

| Aspect      | Cursor (th∆∞·ªùng d√πng)     | B·∫°n (ƒëang d√πng)      |
| ----------- | ------------------------ | -------------------- |
| Transport   | STDIO                    | HTTP/streamable-http |
| Deployment  | Process-based            | Docker Compose       |
| Integration | ExternalMCPServerWrapper | HTTPMCPServerWrapper |
| Multi-user  | ‚ùå Kh√≥                    | ‚úÖ T·ªët                |
| Production  | ‚ö†Ô∏è H·∫°n ch·∫ø               | ‚úÖ Ph√π h·ª£p            |
| Complexity  | ‚úÖ ƒê∆°n gi·∫£n               | ‚ö†Ô∏è Ph·ª©c t·∫°p h∆°n      |

---

## K·∫øt lu·∫≠n

Hi·ªán t·∫°i d√πng Docker Compose + HTTP Transport ph√π h·ª£p cho production/multi-user.

C√°c c√°ch kh√°c (MECE):
1. STDIO + Process-based (nh∆∞ Cursor) - cho development
2. HTTP + Docker Compose (ƒëang d√πng) - cho production
3. HTTP + Kubernetes - cho scale l·ªõn
4. Internal server - ƒë∆°n gi·∫£n nh∆∞ng √≠t linh ho·∫°t

B·∫°n c√≥ mu·ªën th√™m support STDIO transport nh∆∞ Cursor kh√¥ng, hay gi·ªØ nguy√™n HTTP?


---


Tuy·ªát v·ªùi! B√¢y gi·ªù t√¥i c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ t·∫°o ph√¢n t√≠ch MECE ƒë·∫ßy ƒë·ªß. ƒê·ªÉ m√¨nh t·∫°o m·ªôt t√†i li·ªáu chi ti·∫øt v·ªÅ c√°c lo·∫°i MCP server v√† best practices cho t·ª´ng lo·∫°i:

---

# üìä PH√ÇN T√çCH MECE: C√ÅC LO·∫†I MCP SERVER & BEST PRACTICES PRODUCTION

## 1Ô∏è‚É£ C√ÅC LO·∫†I MCP SERVER (MECE Framework)

### A. Theo Ngu·ªìn G·ªëc (Origin)

#### üè¢ **Official Servers** (Do Anthropic/T·ªï ch·ª©c ch√≠nh th·ª©c ph√°t tri·ªÉn)

- **Danh s√°ch ph·ªï bi·∫øn:**
    
    - `@modelcontextprotocol/server-filesystem` - Truy c·∫≠p file system
    - `@modelcontextprotocol/server-memory` - Memory context
    - `@modelcontextprotocol/server-github` - GitHub integration
    - `@modelcontextprotocol/server-gdrive` - Google Drive
    - `@modelcontextprotocol/server-sqlite` - SQLite database
- **ƒê·∫∑c ƒëi·ªÉm:**
    
    - ‚úÖ ƒê∆∞·ª£c test k·ªπ l∆∞·ª°ng
    - ‚úÖ Documentation ƒë·∫ßy ƒë·ªß
    - ‚úÖ Security audit ch√≠nh th·ª©c
    - ‚ö†Ô∏è Ch·ªâ h·ªó tr·ª£ STDIO transport m·∫∑c ƒë·ªãnh
    - ‚ö†Ô∏è H·∫°n ch·∫ø customization

#### üë• **Community Servers** (Do c·ªông ƒë·ªìng ph√°t tri·ªÉn)

- **Danh s√°ch ph·ªï bi·∫øn 2026:**
    
    - `K2view` - Enterprise data fabric
    - `Vectara` - Semantic search & RAG
    - `Zapier` - 6,000+ app automations
    - `Notion` - Workspace integration
    - `Supabase` - Serverless Postgres
    - `Docker Hub` - Container management
    - `Slack`, `Discord` - Communication platforms
- **ƒê·∫∑c ƒëi·ªÉm:**
    
    - ‚úÖ ƒêa d·∫°ng t√≠nh nƒÉng
    - ‚úÖ C·∫≠p nh·∫≠t th∆∞·ªùng xuy√™n
    - ‚ö†Ô∏è Quality kh√¥ng ƒë·ªìng nh·∫•t
    - ‚ö†Ô∏è C·∫ßn verify security

#### üõ†Ô∏è **Custom Servers** (T·ª± ph√°t tri·ªÉn)

- **V√≠ d·ª•:** Server vnstock c·ªßa b·∫°n, parent-grade MCP
- **ƒê·∫∑c ƒëi·ªÉm:**
    - ‚úÖ T√πy ch·ªânh ho√†n to√†n
    - ‚úÖ H·ªó tr·ª£ HTTP + STDIO
    - ‚ö†Ô∏è Ph·∫£i t·ª± maintain
    - ‚ö†Ô∏è Tr√°ch nhi·ªám security thu·ªôc v·ªÅ b·∫°n

---

### B. Theo Ng√¥n Ng·ªØ L·∫≠p Tr√¨nh (Language)

#### üü® **JavaScript/TypeScript Servers**

- **C√¥ng c·ª• ch·∫°y:** `npx`
- **Package manager:** npm
- **V√≠ d·ª•:**
    
    ```bash
    npx -y @modelcontextprotocol/server-memory
    npx -y @modelcontextprotocol/server-github
    ```
    

#### üêç **Python Servers**

- **C√¥ng c·ª• ch·∫°y:** `uvx` ho·∫∑c `uv`
- **Package manager:** PyPI
- **V√≠ d·ª•:**
    
    ```bash
    uvx mcp-server-sqlite
    uvx mcp-server-fetch
    ```
    

#### ü¶Ä **Native Binary Servers** (Go, Rust, C++)

- **C√¥ng c·ª• ch·∫°y:** Direct executable
- **V√≠ d·ª•:**
    
    ```bash
    /usr/local/bin/mcp-custom-server --config server.json
    ```
    

---

### C. Theo Transport Protocol (Communication)

#### üì° **STDIO Transport** (Standard Input/Output)

- **ƒê·∫∑c ƒëi·ªÉm:**
    
    - Process-based communication
    - Local execution only
    - Kh√¥ng c·∫ßn network configuration
    - Client spawn server process tr·ª±c ti·∫øp
- **Config m·∫´u:**
    
    ```json
    {
      "mcpServers": {
        "filesystem": {
          "command": "npx",
          "args": ["-y", "@modelcontextprotocol/server-filesystem"]
        }
      }
    }
    ```
    

#### üåê **HTTP/SSE Transport**

- **ƒê·∫∑c ƒëi·ªÉm:**
    
    - Network-based communication
    - Remote execution
    - C·∫ßn authentication
    - Scale ƒë∆∞·ª£c nhi·ªÅu user
- **Config m·∫´u:**
    
    ```json
    {
      "mcpServers": {
        "remote-server": {
          "transport": "sse",
          "url": "https://mcp.example.com/sse",
          "headers": {
            "Authorization": "Bearer token"
          }
        }
      }
    }
    ```
    

---

### D. Theo Deployment Method (Tri·ªÉn khai)

#### üíª **Local Process-Based** (npx/uvx)

- Ch·∫°y tr·ª±c ti·∫øp tr√™n m√°y local
- Cursor, Claude Desktop th∆∞·ªùng d√πng

#### üê≥ **Docker Container**

- Ch·∫°y trong container
- Isolated environment
- Production-ready

#### ‚ò∏Ô∏è **Kubernetes/Cloud**

- Deploy l√™n cluster
- Auto-scaling
- Enterprise-grade

---

## 2Ô∏è‚É£ BEST PRACTICES PRODUCTION CHO T·ª™NG LO·∫†I

### üìå A. OFFICIAL SERVERS (npx/uvx)

#### ‚úÖ **Khi n√†o d√πng?**

- ‚úÖ Development/Testing local
- ‚úÖ Personal projects
- ‚úÖ Rapid prototyping
- ‚ùå **KH√îNG d√πng cho production multi-user**

#### üõ°Ô∏è **Best Practices**

##### 1. **H·∫°n ch·∫ø quy·ªÅn truy c·∫≠p**

```json
{
  "mcpServers": {
    "filesystem": {
      "command": "npx",
      "args": [
        "-y",
        "@modelcontextprotocol/server-filesystem",
        "/safe/path/only"  // Gi·ªõi h·∫°n path
      ]
    }
  }
}
```

##### 2. **Ch·∫°y v·ªõi non-root user**

```bash
# T·∫°o user ri√™ng cho MCP
sudo useradd -m -u 1001 mcp
sudo -u mcp npx -y @modelcontextprotocol/server-filesystem
```

##### 3. **Monitor logs**

```bash
# Cursor/Claude t·ª± log, nh∆∞ng n√™n enable debug mode
export DEBUG=mcp:*
```

##### 4. **Verify package integrity**

```bash
# Check npm package tr∆∞·ªõc khi ch·∫°y
npm view @modelcontextprotocol/server-filesystem
```

##### 5. **Update th∆∞·ªùng xuy√™n**

```bash
# X√≥a cache ƒë·ªÉ lu√¥n l·∫•y version m·ªõi
npx clear-npx-cache
```

#### ‚ö†Ô∏è **Security Checklist**

- [ ] Gi·ªõi h·∫°n filesystem access paths
- [ ] Ch·∫°y v·ªõi non-root user
- [ ] Kh√¥ng expose sensitive env vars
- [ ] Review package source code tr√™n GitHub
- [ ] Enable audit logging

---

### üìå B. CUSTOM SERVERS (Docker HTTP) - **FULL PRODUCTION**

#### ‚úÖ **Khi n√†o d√πng?**

- ‚úÖ Production multi-user
- ‚úÖ SaaS applications
- ‚úÖ Enterprise deployments
- ‚úÖ Khi c·∫ßn custom logic

#### üèóÔ∏è **BEST PRACTICES ƒê·∫¶Y ƒê·ª¶**

---

#### **1. üîê SECURITY (Quan tr·ªçng nh·∫•t)**

##### A. Authentication & Authorization

```python
# main.py
from fastapi import FastAPI, Security, HTTPException
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

app = FastAPI()
security = HTTPBearer()

API_KEYS = {"valid-key-123": {"user": "admin", "rate_limit": 1000}}

async def verify_token(credentials: HTTPAuthorizationCredentials = Security(security)):
    if credentials.credentials not in API_KEYS:
        raise HTTPException(status_code=403, detail="Invalid API key")
    return API_KEYS[credentials.credentials]
```

##### B. Rate Limiting

```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.post("/mcp/tools")
@limiter.limit("100/minute")
async def call_tool():
    pass
```

##### C. Input Validation

```python
from pydantic import BaseModel, validator, Field

class ToolRequest(BaseModel):
    tool_name: str = Field(..., regex="^[a-z_]+$")  # Ch·ªâ cho ph√©p lowercase + underscore
    arguments: dict
    
    @validator('tool_name')
    def validate_tool(cls, v):
        allowed = ['get_stock_data', 'get_grade']
        if v not in allowed:
            raise ValueError(f"Tool {v} not allowed")
        return v
```

##### D. Security Headers

```python
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.middleware.cors import CORSMiddleware

# CORS strict
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://your-app.com"],  # KH√îNG d√πng "*"
    allow_credentials=True,
    allow_methods=["POST"],
    allow_headers=["Content-Type", "Authorization"],
)

# Trusted hosts
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["yourdomain.com", "*.yourdomain.com"]
)
```

---

#### **2. üìä MONITORING & LOGGING**

##### A. Structured Logging

```python
import structlog
from datetime import datetime

logger = structlog.get_logger()

@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = datetime.utcnow()
    response = await call_next(request)
    duration = (datetime.utcnow() - start_time).total_seconds()
    
    logger.info(
        "mcp_request",
        method=request.method,
        path=request.url.path,
        status=response.status_code,
        duration_ms=duration * 1000,
        user_id=request.state.user_id if hasattr(request.state, 'user_id') else None
    )
    return response
```

##### B. Health Checks

```python
@app.get("/health")
async def health_check():
    checks = {
        "status": "healthy",
        "version": "1.0.0",
        "timestamp": datetime.utcnow().isoformat(),
        "checks": {
            "database": await check_database(),
            "redis": await check_redis(),
            "filesystem": check_filesystem(),
        }
    }
    
    # Return 503 n·∫øu c√≥ service unhealthy
    if any(not v for v in checks["checks"].values()):
        return JSONResponse(status_code=503, content=checks)
    
    return checks

async def check_database():
    try:
        await db.execute("SELECT 1")
        return True
    except:
        return False
```

##### C. Metrics (Prometheus)

```python
from prometheus_client import Counter, Histogram, generate_latest
from fastapi.responses import Response

# Metrics
request_count = Counter(
    'mcp_requests_total',
    'Total MCP requests',
    ['tool', 'status']
)

request_latency = Histogram(
    'mcp_request_duration_seconds',
    'MCP request duration',
    ['tool']
)

@app.get("/metrics")
async def metrics():
    return Response(
        content=generate_latest(),
        media_type="text/plain"
    )
```

---

#### **3. üöÄ PERFORMANCE & SCALABILITY**

##### A. Resource Limits (Docker Compose)

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  mcp-server:
    image: your-mcp-server:latest
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
      replicas: 3  # Multiple instances
    restart: unless-stopped
```

##### B. Connection Pooling

```python
from httpx import AsyncClient, Limits

# Reuse connections
http_client = AsyncClient(
    timeout=30.0,
    limits=Limits(
        max_connections=100,
        max_keepalive_connections=20
    )
)
```

##### C. Caching

```python
from functools import lru_cache
import redis.asyncio as redis

# Redis cache
redis_client = redis.from_url("redis://redis:6379")

async def get_cached(key: str):
    cached = await redis_client.get(key)
    if cached:
        return json.loads(cached)
    return None

async def set_cached(key: str, value: dict, ttl: int = 3600):
    await redis_client.setex(key, ttl, json.dumps(value))
```

##### D. Async Processing

```python
import asyncio

@app.post("/mcp/tools/batch")
async def batch_process(requests: list[ToolRequest]):
    # Process parallel thay v√¨ sequential
    tasks = [process_tool(req) for req in requests]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return results
```

---

#### **4. üîÑ RELIABILITY & ERROR HANDLING**

##### A. Graceful Shutdown

```python
import signal
import sys

def handle_shutdown(signum, frame):
    logger.info("Graceful shutdown initiated")
    
    # Close connections
    asyncio.run(http_client.aclose())
    asyncio.run(redis_client.close())
    
    # Save state if needed
    save_state()
    
    sys.exit(0)

signal.signal(signal.SIGTERM, handle_shutdown)
signal.signal(signal.SIGINT, handle_shutdown)
```

##### B. Retry Logic

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10),
    reraise=True
)
async def call_external_api(url: str):
    response = await http_client.get(url)
    response.raise_for_status()
    return response.json()
```

##### C. Circuit Breaker

```python
from circuitbreaker import circuit

@circuit(failure_threshold=5, recovery_timeout=60)
async def risky_operation():
    # Stop calling n·∫øu fail nhi·ªÅu l·∫ßn
    pass
```

##### D. Error Handling Middleware

```python
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger.error(
        "unhandled_exception",
        error=str(exc),
        path=request.url.path,
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "request_id": request.state.request_id
        }
    )
```

---

#### **5. üì¶ DEPLOYMENT**

##### A. Multi-Stage Dockerfile

```dockerfile
# Dockerfile.production
FROM python:3.11-slim AS builder

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Production stage
FROM python:3.11-slim

WORKDIR /app

# Copy dependencies
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages

# Copy code
COPY . .

# Non-root user (CRITICAL)
RUN useradd -m -u 1001 mcp && \
    chown -R mcp:mcp /app
USER mcp

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

##### B. Docker Compose Production

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  mcp-server:
    build:
      context: .
      dockerfile: Dockerfile.production
    image: mcp-server:${VERSION:-latest}
    
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
      - DATABASE_URL=${DATABASE_URL}
    
    env_file:
      - .env.production
    
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
      replicas: 2
    
    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    
    # Restart policy
    restart: unless-stopped
    
    # Security
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp
    
    networks:
      - mcp-network

  # Nginx reverse proxy
  nginx:
    image: nginx:alpine
    ports:
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      mcp-server:
        condition: service_healthy
    networks:
      - mcp-network

  # Redis cache
  redis:
    image: redis:7-alpine
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis-data:/data
    networks:
      - mcp-network

  # Prometheus monitoring
  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - mcp-network

  # Grafana dashboards
  grafana:
    image: grafana/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana-data:/var/lib/grafana
    ports:
      - "3000:3000"
    networks:
      - mcp-network

volumes:
  redis-data:
  prometheus-data:
  grafana-data:

networks:
  mcp-network:
    driver: bridge
```

##### C. Nginx Configuration

```nginx
# nginx.conf
upstream mcp_backend {
    least_conn;
    server mcp-server:8000 max_fails=3 fail_timeout=30s;
}

server {
    listen 443 ssl http2;
    server_name mcp.yourdomain.com;

    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    ssl_protocols TLSv1.2 TLSv1.3;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=mcp_limit:10m rate=10r/s;
    limit_req zone=mcp_limit burst=20 nodelay;

    location / {
        proxy_pass http://mcp_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    location /health {
        access_log off;
        proxy_pass http://mcp_backend/health;
    }
}
```

---

#### **6. üß™ TESTING & CI/CD**

##### A. Integration Tests

```python
# tests/test_integration.py
import pytest
from httpx import AsyncClient

@pytest.mark.asyncio
async def test_health_check():
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.get("/health")
        assert response.status_code == 200
        assert response.json()["status"] == "healthy"

@pytest.mark.asyncio
async def test_mcp_tool_requires_auth():
    async with AsyncClient(app=app, base_url="http://test") as client:
        # Without auth
        response = await client.post("/mcp/tools")
        assert response.status_code == 403
        
        # With valid auth
        headers = {"Authorization": "Bearer valid-key-123"}
        response = await client.post(
            "/mcp/tools",
            json={"tool_name": "get_stock_data", "arguments": {}},
            headers=headers
        )
        assert response.status_code == 200
```

##### B. Load Testing

```javascript
// k6-load-test.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  vus: 50,  // 50 virtual users
  duration: '30s',
};

export default function () {
  const res = http.post(
    'https://mcp.yourdomain.com/mcp/tools',
    JSON.stringify({
      tool_name: 'get_stock_data',
      arguments: { symbol: 'VNM' }
    }),
    {
      headers: {
        'Content-Type': 'application/json',
        'Authorization': 'Bearer test-key',
      },
    }
  );
  
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });
  
  sleep(1);
}
```

##### C. GitHub Actions CI/CD

```yaml
# .github/workflows/deploy.yml
name: Deploy MCP Server

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Run tests
        run: |
          docker compose -f docker-compose.test.yml up --abort-on-container-exit
      
      - name: Security scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'image'
          image-ref: 'mcp-server:latest'

  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Build and push
        run: |
          docker build -t mcp-server:${{ github.sha }} .
          docker push mcp-server:${{ github.sha }}
      
      - name: Deploy to production
        run: |
          ssh production "docker compose pull && docker compose up -d"
```

---

#### **7. üéØ PRODUCTION CHECKLIST**

##### Pre-Deployment

- [ ] Environment variables in `.env.production`
- [ ] Secrets management (AWS Secrets Manager/Vault)
- [ ] SSL certificates configured
- [ ] Database migrations tested
- [ ] Backup strategy defined
- [ ] Disaster recovery plan documented

##### Security

- [ ] API authentication enabled
- [ ] Rate limiting configured (100 req/min/user)
- [ ] Input validation on all endpoints
- [ ] CORS restricted to known domains
- [ ] Security headers (HSTS, CSP, X-Frame-Options)
- [ ] Dependency vulnerabilities scanned
- [ ] Non-root Docker user (UID 1001)
- [ ] Read-only filesystem where possible

##### Monitoring

- [ ] Structured logging enabled (JSON format)
- [ ] Health checks configured (30s interval)
- [ ] Metrics exposed (Prometheus `/metrics`)
- [ ] Alerts configured (PagerDuty/Slack)
- [ ] Error tracking (Sentry/DataDog)
- [ ] Dashboard created (Grafana)

##### Performance

- [ ] Resource limits set (CPU: 2.0, Mem: 2G)
- [ ] Auto-scaling rules defined
- [ ] CDN configured (if serving static assets)
- [ ] Database indexes optimized
- [ ] Caching strategy implemented (Redis)
- [ ] Connection pooling configured

##### Reliability

- [ ] Multi-replica deployment (‚â•2 replicas)
- [ ] Graceful shutdown implemented
- [ ] Circuit breakers for external calls
- [ ] Retry logic with exponential backoff
- [ ] Backup & restore tested monthly
- [ ] Load testing completed (50+ concurrent users)

##### Documentation

- [ ] API documentation (OpenAPI/Swagger)
- [ ] Deployment runbook
- [ ] Troubleshooting guide
- [ ] Rollback procedures
- [ ] On-call playbook

---

#### **8. üìñ DEPLOYMENT COMMANDS**

```bash
# Structure
production/
‚îú‚îÄ‚îÄ docker-compose.prod.yml
‚îú‚îÄ‚îÄ .env.production (gitignored)
‚îú‚îÄ‚îÄ nginx.conf
‚îú‚îÄ‚îÄ prometheus.yml
‚îú‚îÄ‚îÄ grafana/dashboards/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh
‚îÇ   ‚îú‚îÄ‚îÄ backup.sh
‚îÇ   ‚îú‚îÄ‚îÄ rollback.sh
‚îÇ   ‚îî‚îÄ‚îÄ health-check.sh
‚îî‚îÄ‚îÄ monitoring/alerts.yml

# Deploy
./scripts/deploy.sh production v1.2.0

# Monitor
docker compose -f docker-compose.prod.yml logs -f mcp-server
curl https://mcp.yourdomain.com/health
curl https://mcp.yourdomain.com/metrics

# Backup
./scripts/backup.sh

# Rollback if needed
./scripts/rollback.sh v1.1.0
```

---

## 3Ô∏è‚É£ SO S√ÅNH T·ªîNG QUAN

|Ti√™u ch√≠|Official Servers (npx/uvx)|Custom Servers (Docker HTTP)|
|---|---|---|
|**Transport**|STDIO only|HTTP/SSE + STDIO|
|**Deployment**|Local process|Docker/K8s|
|**Multi-user**|‚ùå Kh√≥ (1 process/user)|‚úÖ Shared service|
|**Security**|‚ö†Ô∏è Full host access|‚úÖ Sandboxed|
|**Production**|‚ùå Ch·ªâ dev/testing|‚úÖ Production-ready|
|**Monitoring**|‚ö†Ô∏è H·∫°n ch·∫ø|‚úÖ Full observability|
|**Scalability**|‚ùå Kh√¥ng scale|‚úÖ Horizontal scaling|
|**Maintenance**|‚úÖ Kh√¥ng c·∫ßn|‚ö†Ô∏è Ph·∫£i t·ª± maintain|
|**Best Practices**|5 ƒëi·ªÉm c∆° b·∫£n|8 ƒëi·ªÉm ƒë·∫ßy ƒë·ªß|
|**Cost**|‚úÖ Free|‚ö†Ô∏è Infrastructure cost|

---

## 4Ô∏è‚É£ DECISION FRAMEWORK

### ‚ùì D√πng Official Servers (npx/uvx) khi:

- ‚úÖ Personal projects
- ‚úÖ Development/Testing local
- ‚úÖ Rapid prototyping
- ‚úÖ Kh√¥ng x·ª≠ l√Ω sensitive data
- ‚úÖ Single user (ch·ªâ b·∫°n d√πng)

### ‚ùì D√πng Custom Docker Servers khi:

- ‚úÖ Production deployment
- ‚úÖ Multi-user application
- ‚úÖ SaaS platform
- ‚úÖ C·∫ßn custom business logic
- ‚úÖ Security requirements cao
- ‚úÖ C·∫ßn monitoring/scaling

---

## 5Ô∏è‚É£ C√îNG C·ª§ N√äN D√ôNG

### Security

- **Snyk** - Dependency vulnerability scanning
- **Trivy** - Container security scanning
- **Vault** - Secrets management

### Monitoring

- **Sentry** - Error tracking
- **Prometheus + Grafana** - Metrics & dashboards
- **DataDog** - All-in-one observability
- **ELK Stack** - Log aggregation

### Load Testing

- **k6** - Modern load testing
- **Locust** - Python-based load testing
- **Apache JMeter** - Traditional load testing

### CI/CD

- **GitHub Actions** - Integrated v·ªõi GitHub
- **GitLab CI** - Full DevOps platform
- **Jenkins** - Self-hosted automation

---

## üéì K·∫æT LU·∫¨N

1. **Official servers** (npx/uvx): D√πng cho dev/testing, √°p d·ª•ng **5 best practices c∆° b·∫£n** v·ªÅ security
2. **Custom servers** (Docker): D√πng cho production, √°p d·ª•ng **ƒê·∫¶Y ƒê·ª¶ 8 NH√ìM best practices**:
    - üîê Security (authentication, rate limiting, validation)
    - üìä Monitoring (logging, health checks, metrics)
    - üöÄ Performance (resource limits, caching, async)
    - üîÑ Reliability (graceful shutdown, retry, circuit breaker)
    - üì¶ Deployment (Docker, multi-stage build, CI/CD)
    - üß™ Testing (integration, load testing)
    - üéØ Checklist (40+ items pre-deployment)
    - üìñ Documentation (runbooks, playbooks)

**C√¢u tr·∫£ l·ªùi tr·ª±c ti·∫øp:**

- **C√ì**, v·ªõi official servers (npx/uvx) b·∫°n v·∫´n c·∫ßn best practices, nh∆∞ng **ch·ªâ 5 ƒëi·ªÉm c∆° b·∫£n** v·ªÅ security
- **B·∫ÆT BU·ªòC** ph·∫£i √°p d·ª•ng **ƒê·∫¶Y ƒê·ª¶ 8 NH√ìM best practices** n·∫øu b·∫°n deploy custom server l√™n production b·∫±ng Docker HTTP

B·∫°n c√≥ mu·ªën t√¥i t·∫°o **production-ready template** cho setup c·ª• th·ªÉ c·ªßa b·∫°n kh√¥ng? Bao g·ªìm t·∫•t c·∫£ file config + scripts + monitoring stack ƒë·∫ßy ƒë·ªß!


---
# Chi ti·∫øt c√°ch best practices deploy MCP server c√≥ s·∫µn l√™n production



Ho√†n h·∫£o! B√¢y gi·ªù t√¥i ƒë√£ c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß c√¢u h·ªèi. ƒê·ªÉ t√¥i t·∫°o h∆∞·ªõng d·∫´n chi ti·∫øt:

---

# üéØ C√ÅCH DEPLOY OFFICIAL/PRE-BUILT MCP SERVERS L√äN PRODUCTION

B·∫°n h·ªèi **ƒë√∫ng tr·ªçng t√¢m**! C√¢u tr·∫£ l·ªùi tr∆∞·ªõc **CH∆ØA N√ìI R√ï** ƒëi·ªÅu n√†y. ƒê√¢y l√† **3 C√ÅCH CH√çNH** ƒë·ªÉ deploy c√°c MCP server c√≥ s·∫µn (official/community) l√™n production:

---

## üî• V·∫§Nƒê·ªÄ C·ªêT L√ïI

**Official MCP servers (npx/uvx) CH·ªà H·ªñ TR·ª¢ STDIO transport** ‚Üí Kh√¥ng th·ªÉ d√πng tr·ª±c ti·∫øp cho production multi-user.

**Gi·∫£i ph√°p:** Ph·∫£i **CONVERT STDIO ‚Üí HTTP/SSE** b·∫±ng 1 trong 3 c√°ch sau:

---

## üìã 3 C√ÅCH CONVERT STDIO ‚Üí HTTP PRODUCTION

### **C√°ch 1: MCP Proxy/Wrapper** ‚≠ê **KHUY·∫æN NGH·ªä**

#### A. S·ª≠ d·ª•ng `mcp-proxy` (sparfenyuk)

**Nguy√™n l√Ω:** Wrap STDIO server trong HTTP/Streamable HTTP gateway

```bash
# Install
uv tool install mcp-proxy

# Run STDIO server qua HTTP
mcp-proxy --port=8080 --host=0.0.0.0 npx -y @modelcontextprotocol/server-filesystem /data

# Multiple servers
mcp-proxy --port=8080 \
  --named-server filesystem 'npx -y @modelcontextprotocol/server-filesystem /data' \
  --named-server github 'npx -y @modelcontextprotocol/server-github'
```

**Docker Compose Production:**

```yaml
# docker-compose-mcp-proxy.yml
version: '3.8'

services:
  # üî• MCP Proxy Gateway
  mcp-proxy:
    image: ghcr.io/sparfenyuk/mcp-proxy:latest
    container_name: mcp-proxy
    ports:
      - "8080:8080"
    command: >
      --port=8080 
      --host=0.0.0.0
      --pass-environment
      --allow-origin "*"
      --named-server-config /config/servers.json
    volumes:
      - ./servers.json:/config/servers.json:ro
      - ./data:/data:ro  # Mount data cho filesystem server
    environment:
      - GITHUB_PERSONAL_ACCESS_TOKEN=${GITHUB_TOKEN}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/status"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
    networks:
      - mcp-network

  # Nginx reverse proxy (optional nh∆∞ng n√™n c√≥)
  nginx:
    image: nginx:alpine
    ports:
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      mcp-proxy:
        condition: service_healthy
    networks:
      - mcp-network

networks:
  mcp-network:
    driver: bridge
```

**servers.json config:**

```json
{
  "mcpServers": {
    "filesystem": {
      "enabled": true,
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/data"],
      "transportType": "stdio"
    },
    "github": {
      "enabled": true,
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-github"],
      "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "${GITHUB_TOKEN}"
      },
      "transportType": "stdio"
    },
    "memory": {
      "enabled": true,
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-memory"],
      "transportType": "stdio"
    },
    "sqlite": {
      "enabled": true,
      "command": "uvx",
      "args": ["mcp-server-sqlite", "--db-path", "/data/database.db"],
      "transportType": "stdio"
    }
  }
}
```

**Client config (Cursor/Claude):**

```json
{
  "mcpServers": {
    "remote-filesystem": {
      "transport": "streamablehttp",
      "url": "https://your-domain.com/servers/filesystem/",
      "headers": {
        "Authorization": "Bearer your-token"
      }
    },
    "remote-github": {
      "transport": "streamablehttp",
      "url": "https://your-domain.com/servers/github/"
    }
  }
}
```

#### **‚úÖ ∆Øu ƒëi·ªÉm C√°ch 1:**

- ‚úÖ ƒê∆°n gi·∫£n nh·∫•t, kh√¥ng c·∫ßn code
- ‚úÖ Support NHI·ªÄU servers trong 1 proxy
- ‚úÖ Compatible v·ªõi M·ªåI STDIO servers
- ‚úÖ Active maintenance (GitHub: sparfenyuk/mcp-proxy)
- ‚úÖ H·ªó tr·ª£ OAuth2, SSL, CORS

#### **‚ö†Ô∏è Nh∆∞·ª£c ƒëi·ªÉm:**

- ‚ö†Ô∏è Th√™m 1 layer proxy (latency nh·ªè)
- ‚ö†Ô∏è C·∫ßn install Node.js/Python trong container

---

### **C√°ch 2: Ray Serve (Anyscale)** üöÄ **CHO SCALE L·ªöN**

**Nguy√™n l√Ω:** Wrap STDIO Docker image th√†nh HTTP service v·ªõi auto-scaling

```python
# deploy_mcp_ray.py
from ray import serve
import subprocess
import json

@serve.deployment
class MCPStdioProxy:
    def __init__(self, command: list[str]):
        self.command = command
    
    async def __call__(self, request):
        # Spawn STDIO process
        process = subprocess.Popen(
            self.command,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        # Forward request to STDIO
        mcp_request = await request.json()
        process.stdin.write(json.dumps(mcp_request).encode())
        process.stdin.flush()
        
        # Get response
        response = process.stdout.readline().decode()
        return json.loads(response)

# Deploy
filesystem_server = MCPStdioProxy.bind([
    "npx", "-y", "@modelcontextprotocol/server-filesystem", "/data"
])

serve.run(filesystem_server, route_prefix="/mcp/filesystem")
```

**Deploy l√™n Anyscale:**

```bash
# Upload code
anyscale workspace upload deploy_mcp_ray.py

# Deploy v·ªõi scaling
anyscale service deploy \
  --name mcp-filesystem \
  --num-replicas 3 \
  --ray-serve-config ray_serve_config.yaml
```

#### **‚úÖ ∆Øu ƒëi·ªÉm C√°ch 2:**

- ‚úÖ Auto-scaling t·ªët nh·∫•t
- ‚úÖ GPU support (n·∫øu c·∫ßn)
- ‚úÖ Load balancing built-in
- ‚úÖ Monitoring dashboard

#### **‚ö†Ô∏è Nh∆∞·ª£c ƒëi·ªÉm:**

- ‚ö†Ô∏è Ph·ª©c t·∫°p h∆°n
- ‚ö†Ô∏è Chi ph√≠ cao (Anyscale platform)
- ‚ö†Ô∏è Overkill cho small-medium projects

---

### **C√°ch 3: Docker MCP Gateway** üê≥ **OFFICIAL DOCKER**

**Nguy√™n l√Ω:** Docker‚Äôs official MCP solution

```yaml
# docker-compose-mcp-gateway.yml
version: '3.8'

services:
  # Docker MCP Gateway
  mcp-gateway:
    image: docker/mcp-gateway:latest
    ports:
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./mcp-catalog.json:/config/catalog.json
    environment:
      - MCP_CATALOG_PATH=/config/catalog.json
    restart: unless-stopped

  # Official MCP servers as containers
  mcp-filesystem:
    image: modelcontextprotocol/server-filesystem:latest
    volumes:
      - ./data:/data:ro
    environment:
      - ALLOWED_PATHS=/data

  mcp-github:
    image: modelcontextprotocol/server-github:latest
    environment:
      - GITHUB_PERSONAL_ACCESS_TOKEN=${GITHUB_TOKEN}
```

**mcp-catalog.json:**

```json
{
  "servers": {
    "filesystem": {
      "container": "mcp-filesystem",
      "enabled": true
    },
    "github": {
      "container": "mcp-github",
      "enabled": true
    }
  }
}
```

#### **‚úÖ ∆Øu ƒëi·ªÉm C√°ch 3:**

- ‚úÖ Official Docker solution
- ‚úÖ Docker Desktop integration
- ‚úÖ Secure secrets management
- ‚úÖ Container isolation

#### **‚ö†Ô∏è Nh∆∞·ª£c ƒëi·ªÉm:**

- ‚ö†Ô∏è C√≤n m·ªõi (2025), ch∆∞a stable ho√†n to√†n
- ‚ö†Ô∏è √çt documentation
- ‚ö†Ô∏è Requires Docker Engine

---

## üìä SO S√ÅNH 3 C√ÅCH

|Ti√™u ch√≠|MCP Proxy|Ray Serve|Docker Gateway|
|---|---|---|---|
|**ƒê·ªô ph·ª©c t·∫°p**|‚≠ê‚≠ê ƒê∆°n gi·∫£n|‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Ph·ª©c t·∫°p|‚≠ê‚≠ê‚≠ê Trung b√¨nh|
|**Setup time**|10 ph√∫t|2-3 gi·ªù|30 ph√∫t|
|**Multi-server**|‚úÖ Excellent|‚úÖ Good|‚úÖ Good|
|**Auto-scaling**|‚ùå Manual|‚úÖ T·ª± ƒë·ªông|‚ö†Ô∏è Gi·ªõi h·∫°n|
|**Cost**|$ R·∫ª|$$$ ƒê·∫Øt|$$ V·ª´a|
|**Production-ready**|‚úÖ S·∫µn s√†ng|‚úÖ Enterprise|‚ö†Ô∏è Beta|
|**Best for**|SMB, Startups|Enterprise scale|Docker users|

---

## üéØ KHUY·∫æN NGH·ªä THEO USE CASE

### ü•á **Cho h·∫ßu h·∫øt m·ªçi ng∆∞·ªùi: MCP Proxy (C√°ch 1)**

**Khi n√†o d√πng:**

- ‚úÖ Startup/SMB
- ‚úÖ < 1000 concurrent users
- ‚úÖ Budget limited
- ‚úÖ C·∫ßn deploy nhanh
- ‚úÖ Multiple official servers

**Deploy script:**

```bash
#!/bin/bash
# deploy-mcp-proxy.sh

# 1. Install dependencies
uv tool install mcp-proxy

# 2. Create config
cat > servers.json << 'EOF'
{
  "mcpServers": {
    "filesystem": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/data"]
    },
    "github": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-github"],
      "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "${GITHUB_TOKEN}"
      }
    }
  }
}
EOF

# 3. Start with Docker Compose
docker compose -f docker-compose-mcp-proxy.yml up -d

# 4. Verify
curl http://localhost:8080/status
curl http://localhost:8080/servers/filesystem/health
```

---

### ü•à **Cho enterprise scale: Ray Serve (C√°ch 2)**

**Khi n√†o d√πng:**

- ‚úÖ > 10,000 concurrent users
- ‚úÖ C·∫ßn GPU
- ‚úÖ Budget l·ªõn
- ‚úÖ Team DevOps c√≥ kinh nghi·ªám

---

### ü•â **Cho Docker enthusiasts: Docker Gateway (C√°ch 3)**

**Khi n√†o d√πng:**

- ‚úÖ ƒê√£ d√πng Docker Desktop
- ‚úÖ All-in-one solution
- ‚úÖ Ch·∫•p nh·∫≠n beta software

---

## üîê PRODUCTION BEST PRACTICES (√Åp d·ª•ng cho c·∫£ 3 c√°ch)

### 1. **Security**

```yaml
# Th√™m authentication middleware
services:
  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx-auth.conf:/etc/nginx/nginx.conf:ro
```

**nginx-auth.conf:**

```nginx
server {
    listen 443 ssl;
    
    # API key authentication
    location / {
        if ($http_x_api_key != "your-secret-key") {
            return 403;
        }
        proxy_pass http://mcp-proxy:8080;
    }
    
    # Rate limiting
    limit_req_zone $binary_remote_addr zone=mcp:10m rate=10r/s;
    limit_req zone=mcp burst=20 nodelay;
}
```

### 2. **Monitoring**

```yaml
# Th√™m v√†o docker-compose
services:
  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
```

**prometheus.yml:**

```yaml
scrape_configs:
  - job_name: 'mcp-proxy'
    static_configs:
      - targets: ['mcp-proxy:8080']
    metrics_path: '/metrics'
```

### 3. **Health Checks**

```python
# Th√™m health check endpoint cho mcp-proxy
@app.get("/health")
async def health_check():
    checks = {}
    for server_name in servers:
        try:
            # Test server connection
            response = await test_server(server_name)
            checks[server_name] = "healthy" if response else "unhealthy"
        except:
            checks[server_name] = "down"
    
    all_healthy = all(v == "healthy" for v in checks.values())
    status_code = 200 if all_healthy else 503
    
    return JSONResponse(
        status_code=status_code,
        content={"status": "healthy" if all_healthy else "degraded", "checks": checks}
    )
```

### 4. **Backup & Recovery**

```bash
# backup-mcp-data.sh
#!/bin/bash

# Backup config
tar -czf mcp-backup-$(date +%Y%m%d).tar.gz \
  servers.json \
  docker-compose-mcp-proxy.yml \
  nginx.conf \
  .env.production

# Upload to S3
aws s3 cp mcp-backup-*.tar.gz s3://your-backup-bucket/
```

---

## üöÄ COMPLETE PRODUCTION TEMPLATE

T√¥i t·∫°o template ƒë·∫ßy ƒë·ªß cho b·∫°n:

```bash
# Directory structure
mcp-production/
‚îú‚îÄ‚îÄ docker-compose-mcp-proxy.yml  # Main compose file
‚îú‚îÄ‚îÄ servers.json                   # MCP servers config
‚îú‚îÄ‚îÄ nginx.conf                     # Reverse proxy
‚îú‚îÄ‚îÄ prometheus.yml                 # Monitoring
‚îú‚îÄ‚îÄ .env.production                # Secrets (gitignored)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh                  # Deploy script
‚îÇ   ‚îú‚îÄ‚îÄ backup.sh                  # Backup script
‚îÇ   ‚îú‚îÄ‚îÄ rollback.sh                # Rollback script
‚îÇ   ‚îî‚îÄ‚îÄ health-check.sh            # Health check script
‚îî‚îÄ‚îÄ ssl/
    ‚îú‚îÄ‚îÄ cert.pem
    ‚îî‚îÄ‚îÄ key.pem
```

**Full docker-compose-mcp-proxy.yml:**

```yaml
version: '3.8'

services:
  mcp-proxy:
    image: ghcr.io/sparfenyuk/mcp-proxy:latest
    container_name: mcp-proxy
    command: >
      --port=8080 
      --host=0.0.0.0
      --pass-environment
      --allow-origin "*"
      --named-server-config /config/servers.json
    volumes:
      - ./servers.json:/config/servers.json:ro
      - ./data:/data:ro
    environment:
      - GITHUB_PERSONAL_ACCESS_TOKEN=${GITHUB_TOKEN}
      - LOG_LEVEL=INFO
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
    networks:
      - mcp-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  nginx:
    image: nginx:alpine
    ports:
      - "443:443"
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      mcp-proxy:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - mcp-network

  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    restart: unless-stopped
    networks:
      - mcp-network

  grafana:
    image: grafana/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
    ports:
      - "3000:3000"
    restart: unless-stopped
    networks:
      - mcp-network

volumes:
  prometheus-data:
  grafana-data:

networks:
  mcp-network:
    driver: bridge
```

**scripts/deploy.sh:**

```bash
#!/bin/bash
set -e

VERSION=${1:-latest}

echo "üöÄ Deploying MCP Proxy v${VERSION}..."

# 1. Backup current
./scripts/backup.sh

# 2. Pull latest images
docker compose -f docker-compose-mcp-proxy.yml pull

# 3. Deploy
docker compose -f docker-compose-mcp-proxy.yml up -d

# 4. Wait for health
echo "‚è≥ Waiting for services..."
sleep 10

# 5. Health check
./scripts/health-check.sh

echo "‚úÖ Deployment completed!"
```

---

## üìù T√ìM T·∫ÆT

**C√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn:**

ƒê·ªÉ deploy **official MCP servers** (npx/uvx) l√™n production:

1. **KH√îNG TH·ªÇ** d√πng tr·ª±c ti·∫øp (ch·ªâ c√≥ STDIO transport)
    
2. **PH·∫¢I** convert sang HTTP b·∫±ng 1 trong 3 c√°ch:
    
    - ‚≠ê **MCP Proxy** (sparfenyuk) - Khuy·∫øn ngh·ªã cho 90% cases
    - üöÄ **Ray Serve** - Cho enterprise scale
    - üê≥ **Docker Gateway** - Cho Docker users
3. **Best practice ƒë·∫ßy ƒë·ªß** nh∆∞ custom servers:
    
    - Security (auth, rate limit, SSL)
    - Monitoring (logs, metrics, alerts)
    - Performance (resource limits, caching)
    - Reliability (health checks, backup)

**Template ƒë·∫ßy ƒë·ªß:** T√¥i ƒë√£ t·∫°o complete production setup ph√≠a tr√™n!

B·∫°n mu·ªën t√¥i t·∫°o **working example c·ª• th·ªÉ** cho setup c·ªßa b·∫°n kh√¥ng? (v·ªõi filesystem + github + sqlite servers ch·∫≥ng h·∫°n?)


----


ƒêang ƒë√°nh gi√° setup hi·ªán t·∫°i so v·ªõi best practices production:


[3 tools called]


# ƒê√°nh gi√° setup hi·ªán t·∫°i

## T√≥m t·∫Øt

ƒêi·ªÉm: 5/10 ‚Äî ƒê·∫°t m·ª©c development/testing, ch∆∞a ƒë·ªß cho production.

---

## ƒêi·ªÉm m·∫°nh

1. HTTP transport (streamable-http) ‚Äî ph√π h·ª£p multi-user
2. Stateless mode ‚Äî d·ªÖ scale
3. OAuth 2.1 support ‚Äî multi-user authentication
4. Docker Compose ‚Äî d·ªÖ qu·∫£n l√Ω
5. Network isolation ‚Äî Docker network ri√™ng
6. Restart policy ‚Äî t·ª± ƒë·ªông restart khi crash

---

## Thi·∫øu s√≥t so v·ªõi best practices

### 1. Security (3/8)

| Ti√™u ch√≠ | Tr·∫°ng th√°i | M√¥ t·∫£ |
|----------|------------|-------|
| Authentication ·ªü MCP level | ‚ùå Thi·∫øu | Ch·ªâ c√≥ OAuth ·ªü app level, MCP server kh√¥ng c√≥ API key/auth |
| Rate limiting ·ªü MCP level | ‚ùå Thi·∫øu | Ch·ªâ c√≥ ·ªü app level, kh√¥ng c√≥ ·ªü MCP server |
| Input validation | ‚ùå Thi·∫øu | Kh√¥ng validate request t·ª´ app |
| Security headers | ‚ùå Thi·∫øu | Kh√¥ng c√≥ CORS, HSTS, CSP |
| Non-root user | ‚ùå Thi·∫øu | Dockerfile ch·∫°y root (security risk) |
| Secrets management | ‚ö†Ô∏è C∆° b·∫£n | D√πng env vars, ch∆∞a c√≥ Vault/secrets manager |
| SSL/TLS | ‚ùå Thi·∫øu | Kh√¥ng c√≥ HTTPS |
| API key protection | ‚ùå Thi·∫øu | MCP server expose tr·ª±c ti·∫øp, kh√¥ng c√≥ gateway |

### 2. Monitoring & Logging (1/6)

| Ti√™u ch√≠ | Tr·∫°ng th√°i | M√¥ t·∫£ |
|----------|------------|-------|
| Health checks | ‚ùå Disabled | ƒê√£ comment out trong docker-compose |
| Prometheus metrics | ‚ùå Thi·∫øu | Kh√¥ng expose `/metrics` |
| Grafana dashboards | ‚ùå Thi·∫øu | Kh√¥ng c√≥ visualization |
| Structured logging | ‚ùå Thi·∫øu | Ch·ªâ c√≥ LOG_LEVEL, kh√¥ng c√≥ JSON logs |
| Error tracking | ‚ùå Thi·∫øu | Kh√¥ng c√≥ Sentry/DataDog |
| Request logging | ‚ö†Ô∏è C∆° b·∫£n | C√≥ logs nh∆∞ng kh√¥ng structured |

### 3. Performance & Scalability (2/6)

| Ti√™u ch√≠ | Tr·∫°ng th√°i | M√¥ t·∫£ |
|----------|------------|-------|
| Resource limits | ‚ùå Thi·∫øu | Kh√¥ng c√≥ CPU/memory limits |
| Caching | ‚ùå Thi·∫øu | Kh√¥ng c√≥ Redis cache cho MCP |
| Connection pooling | ‚ùå Thi·∫øu | Kh√¥ng config connection reuse |
| Auto-scaling | ‚ùå Thi·∫øu | Kh√¥ng c√≥ horizontal scaling |
| Load balancing | ‚ùå Thi·∫øu | Kh√¥ng c√≥ Nginx/LB |
| Async processing | ‚úÖ OK | Stateless mode h·ªó tr·ª£ async |

### 4. Reliability (2/6)

| Ti√™u ch√≠ | Tr·∫°ng th√°i | M√¥ t·∫£ |
|----------|------------|-------|
| Graceful shutdown | ‚ùå Thi·∫øu | Kh√¥ng handle SIGTERM |
| Retry logic | ‚ùå Thi·∫øu | Kh√¥ng c√≥ retry cho failed requests |
| Circuit breaker | ‚ùå Thi·∫øu | Kh√¥ng c√≥ circuit breaker |
| Error handling | ‚ùå Thi·∫øu | Kh√¥ng c√≥ global error handler |
| Backup strategy | ‚ùå Thi·∫øu | Kh√¥ng c√≥ backup plan |
| Restart policy | ‚úÖ OK | C√≥ `unless-stopped` |

### 5. Deployment (2/8)

| Ti√™u ch√≠ | Tr·∫°ng th√°i | M√¥ t·∫£ |
|----------|------------|-------|
| Multi-stage Dockerfile | ‚ùå Thi·∫øu | Dockerfile ƒë∆°n gi·∫£n, kh√¥ng optimize |
| Nginx reverse proxy | ‚ùå Thi·∫øu | Expose tr·ª±c ti·∫øp port 30024 |
| SSL/TLS | ‚ùå Thi·∫øu | Kh√¥ng c√≥ HTTPS |
| CI/CD pipeline | ‚ùå Thi·∫øu | Kh√¥ng c√≥ automated deployment |
| Version tagging | ‚ùå Thi·∫øu | Kh√¥ng tag Docker images |
| Rollback strategy | ‚ùå Thi·∫øu | Kh√¥ng c√≥ rollback plan |
| Blue-green deployment | ‚ùå Thi·∫øu | Kh√¥ng c√≥ zero-downtime deploy |
| Docker Compose | ‚úÖ OK | C√≥ docker-compose config |

### 6. Testing (0/3)

| Ti√™u ch√≠ | Tr·∫°ng th√°i | M√¥ t·∫£ |
|----------|------------|-------|
| Integration tests | ‚ùå Thi·∫øu | Kh√¥ng c√≥ tests cho MCP integration |
| Load testing | ‚ùå Thi·∫øu | Kh√¥ng c√≥ k6/Locust tests |
| Health check tests | ‚ùå Thi·∫øu | Healthcheck b·ªã disable |

---

## Checklist nhanh

### Critical (ph·∫£i c√≥ cho production)

- [ ] Enable health checks
- [ ] Th√™m resource limits (CPU/memory)
- [ ] Non-root user trong Dockerfile
- [ ] Nginx reverse proxy v·ªõi SSL
- [ ] API authentication ·ªü MCP level
- [ ] Rate limiting ·ªü MCP level
- [ ] Structured logging (JSON)
- [ ] Prometheus metrics

### Important (n√™n c√≥)

- [ ] Multi-stage Dockerfile
- [ ] Graceful shutdown
- [ ] Retry logic v·ªõi exponential backoff
- [ ] Error tracking (Sentry)
- [ ] Backup strategy
- [ ] CI/CD pipeline
- [ ] Load testing

### Nice to have

- [ ] Grafana dashboards
- [ ] Circuit breaker
- [ ] Blue-green deployment
- [ ] Auto-scaling config

---

## So s√°nh v·ªõi best practices

| Nh√≥m | Best Practices | Setup hi·ªán t·∫°i | ƒêi·ªÉm |
|------|---------------|----------------|------|
| Security | 8 ƒëi·ªÉm | 3 ƒëi·ªÉm | 37.5% |
| Monitoring | 6 ƒëi·ªÉm | 1 ƒëi·ªÉm | 16.7% |
| Performance | 6 ƒëi·ªÉm | 2 ƒëi·ªÉm | 33.3% |
| Reliability | 6 ƒëi·ªÉm | 2 ƒëi·ªÉm | 33.3% |
| Deployment | 8 ƒëi·ªÉm | 2 ƒëi·ªÉm | 25% |
| Testing | 3 ƒëi·ªÉm | 0 ƒëi·ªÉm | 0% |
| T·ªïng | 37 ƒëi·ªÉm | 10 ƒëi·ªÉm | 27% |

---

## K·∫øt lu·∫≠n

- ƒê·∫°t: Development/testing, multi-user support, Docker setup c∆° b·∫£n.
- Ch∆∞a ƒë·∫°t: Security, monitoring, performance optimization, reliability, production deployment.

Khuy·∫øn ngh·ªã:
- N·∫øu ƒëang development/testing: OK, c√≥ th·ªÉ ti·∫øp t·ª•c.
- N·∫øu production: C·∫ßn b·ªï sung √≠t nh·∫•t c√°c m·ª•c Critical tr∆∞·ªõc khi deploy.

---

## Template production-ready

B·∫°n c√≥ mu·ªën t√¥i t·∫°o:
1. Production-ready docker-compose v·ªõi ƒë·∫ßy ƒë·ªß best practices
2. Dockerfile c·∫£i ti·∫øn (multi-stage, non-root user)
3. Nginx config v·ªõi SSL
4. Prometheus + Grafana setup
5. Health checks v√† monitoring scripts

B·∫°n mu·ªën t√¥i t·∫°o template n√†o tr∆∞·ªõc?


---
<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# B√°o C√°o K·ªπ Thu·∫≠t: T√≠ch H·ª£p LangChain/LangGraph v·ªõi MCP Server B√™n Ngo√†i

## T√≥m T·∫Øt ƒêi·ªÅu H√†nh

B√°o c√°o n√†y ph√¢n t√≠ch chi·∫øn l∆∞·ª£c t√≠ch h·ª£p LangChain v√† LangGraph v·ªõi MCP servers b√™n ngo√†i trong m√¥i tr∆∞·ªùng production, t·∫≠p trung v√†o ki·∫øn tr√∫c an to√†n, l·ª±a ch·ªçn transport protocol, v√† patterns tri·ªÉn khai th·ª±c t·∫ø. Ph√¢n t√≠ch ƒë·ªÅ xu·∫•t framework ra quy·∫øt ƒë·ªãnh d·ª±a tr√™n y√™u c·∫ßu v·ªÅ latency, security, v√† scalability, v·ªõi implementation examples cho fintech AI agents.

***

## 1. H·ªá Sinh Th√°i MCP Server B√™n Ngo√†i

### 1.1 Ph√¢n Lo·∫°i v√† V√≠ D·ª• Th·ª±c T·∫ø

H·ªá sinh th√°i MCP server b√™n ngo√†i ph√°t tri·ªÉn m·∫°nh m·∫Ω v·ªõi h∆°n 200+ implementations, ƒë∆∞·ª£c ph√¢n lo·∫°i theo use case:[^1][^2]


| Category | V√≠ D·ª• N·ªïi B·∫≠t | Transport | Authentication | Use Case Fintech |
| :-- | :-- | :-- | :-- | :-- |
| **Cloud Infrastructure** | AWS, GCP, Azure MCP | HTTP/SSE | OAuth 2.0 | Infrastructure management |
| **Databases** | PostgreSQL, ClickHouse, Couchbase | Stdio/HTTP | API Key | Analytics \& reporting |
| **Financial APIs** | Mercado Pago, Stripe MCP | HTTP | API Key | Payment processing |
| **Observability** | Datadog, Cloudflare MCP | HTTP | Bearer Token | Monitoring \& alerting |
| **Business Tools** | Salesforce, Notion, Zapier | HTTP | OAuth | CRM \& workflow automation |

**C√°c server production-ready**:[^3][^2]

- **Mercado Pago MCP**: `https://mcp.mercadopago.com/mcp` - Payment processing v·ªõi API key authentication
- **AWS MCP**: `npx @awslabs/mcp` - AWS resource management qua SSO
- **ClickHouse MCP**: `mcp-clickhouse` - High-performance analytics queries
- **Datadog MCP**: Observability data integration cho AI-driven incident response


### 1.2 Discovery v√† Registry

Hai c∆° ch·∫ø discovery ch√≠nh:[^4]

- **Static Configuration**: ƒê·ªãnh nghƒ©a server URLs v√† credentials trong config file
- **Dynamic Service Discovery**: S·ª≠ d·ª•ng service registry (Consul, Eureka) cho auto-scaling deployments

```python
# Static configuration pattern
mcp_servers = {
    "finance_api": {
        "server_url": "https://mcp.financeprovider.com/sse",
        "headers": {"Authorization": "Bearer ${FINANCE_API_KEY}"}
    },
    "internal_db": {
        "command": "python",
        "args": ["mcp_postgres_server.py"],
        "transport": "stdio"
    }
}
```


***

## 2. Ki·∫øn Tr√∫c T√≠ch H·ª£p v·ªõi LangChain/LangGraph

### 2.1 Multi-Server MCP Client Pattern

LangChain cung c·∫•p `MultiServerMCPClient` ƒë·ªÉ qu·∫£n l√Ω concurrent connections:[^5]

```python
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
import asyncio

async def create_fintech_agent():
    # Kh·ªüi t·∫°o client v·ªõi multiple external servers
    async with MultiServerMCPClient({
        "market_data": {
            "transport": "http",
            "server_url": "https://mcp.marketdata.com/sse",
            "headers": {"X-API-Key": os.getenv("MARKET_DATA_KEY")}
        },
        "risk_engine": {
            "transport": "stdio",
            "command": "docker",
            "args": ["run", "--rm", "risk-mcp-server:latest"]
        },
        "compliance_api": {
            "transport": "http",
            "server_url": "https://mcp.compliance.gov/api",
            "headers": {"Authorization": f"Bearer {os.getenv('COMPLIANCE_TOKEN')}"}
        }
    }) as client:
        
        # Auto-discover v√† convert tools
        tools = await client.get_tools()
        
        # T·∫°o LangGraph agent v·ªõi checkpointing
        agent = create_react_agent(
            model="gpt-4o",
            tools=tools,
            checkpointer=MemorySaver()
        )
        
        return agent

# S·ª≠ d·ª•ng trong async context
agent = asyncio.run(create_fintech_agent())
```

**L·ª£i √≠ch ki·∫øn tr√∫c**:[^4]

- **Connection Pooling**: T√°i s·ª≠ d·ª•ng connections gi·ªØa c√°c tool calls
- **Error Isolation**: L·ªói ·ªü m·ªôt server kh√¥ng ·∫£nh h∆∞·ªüng others
- **Credential Management**: Secrets kh√¥ng expose trong agent code


### 2.2 Stateful Orchestration v·ªõi External Tools

LangGraph cho ph√©p orchestration ph·ª©c t·∫°p v·ªõi external MCP tools:[^6]

```python
from langgraph.graph import StateGraph, START, END
from typing import TypedDict, Annotated
from langgraph.checkpoint.memory import MemorySaver

class TradingState(TypedDict):
    order_params: dict
    risk_check: dict
    compliance_approval: bool
    execution_result: Optional[dict]
    error_count: int

# Node implementations g·ªçi external MCP tools
async def risk_check_node(state: TradingState, config: RunnableConfig):
    tools = config["configurable"]["mcp_tools"]
    
    # G·ªçi external risk engine
    risk_result = await tools["calculate_risk"].ainvoke({
        "portfolio_id": state["order_params"]["portfolio_id"],
        "order_value": state["order_params"]["value"]
    })
    
    return {"risk_check": risk_result, "error_count": 0}

async def compliance_node(state: TradingState, config: RunnableConfig):
    if state["risk_check"]["risk_score"] > 0.8:
        tools = config["configurable"]["mcp_tools"]
        
        # G·ªçi external compliance API
        approval = await tools["request_approval"].ainvoke({
            "risk_score": state["risk_check"]["risk_score"],
            "trader_id": config["configurable"]["user_id"]
        })
        
        return {"compliance_approval": approval["approved"]}
    
    return {"compliance_approval": True}

# Conditional routing d·ª±a tr√™n external tool responses
def route_execution(state: TradingState) -> str:
    if not state["compliance_approval"]:
        return "human_review"
    elif state["risk_check"]["risk_score"] > 0.9:
        return "reject_order"
    else:
        return "execute_order"

# Build graph
builder = StateGraph(TradingState)
builder.add_node("risk_check", risk_check_node)
builder.add_node("compliance", compliance_node)
builder.add_node("execute", execution_node)
builder.add_node("human_review", human_review_node)

builder.add_edge(START, "risk_check")
builder.add_edge("risk_check", "compliance")
builder.add_conditional_edges("compliance", route_execution)
builder.add_edge("execute", END)
builder.add_edge("human_review", END)

# Compile v·ªõi checkpointing
graph = builder.compile(checkpointer=MemorySaver())
```


***

## 3. Transport Protocol: L·ª±a Ch·ªçn v√† Trade-offs

### 3.1 So S√°nh Chi Ti·∫øt Transport Options

| Transport | Latency | Remote Access | Multi-Client | Security Model | Use Case Ph√π H·ª£p |
| :-- | :-- | :-- | :-- | :-- | :-- |
| **Stdio** | <1ms | ‚ùå No | ‚ùå No | Process isolation | Local CLI tools, containers |
| **HTTP** | 10-50ms | ‚úÖ Yes | ‚úÖ Yes | API keys, OAuth | Cloud APIs, microservices |
| **SSE** | 20-100ms | ‚úÖ Yes | ‚úÖ Yes | Bearer tokens | Real-time streaming |
| **StreamableHTTP** | 10-30ms | ‚úÖ Yes | ‚úÖ Yes | mTLS, JWT | Production web services |

**Performance Benchmark**:[^7]

- **In-Memory**: 500x nhanh h∆°n stdio (ch·ªâ cho same-process)
- **Stdio**: 10,000+ ops/sec, ph√π h·ª£p cho local tools
- **HTTP**: 100-1,000 ops/sec, ph·ª• thu·ªôc network conditions


### 3.2 Decision Framework

```python
def select_transport(requirements: dict) -> str:
    """
    Framework ch·ªçn transport d·ª±a tr√™n y√™u c·∫ßu
    """
    if requirements.get("local_only") and requirements.get("low_latency"):
        return "stdio"  # Local database connectors, CLI tools
    
    elif requirements.get("real_time") and requirements.get("streaming"):
        return "sse"  # Market data streaming, log aggregation
    
    elif requirements.get("web_access") and requirements.get("scalable"):
        return "streamable_http"  # Cloud APIs, multi-tenant services
    
    elif requirements.get("simple_web"):
        return "http"  # REST-like MCP servers
    
    else:
        return "streamable_http"  # Default for production
```

**V√≠ d·ª• √°p d·ª•ng**:[^8]

- **Stdio**: `mcp-postgres-server` ch·∫°y trong Docker container, agent spawn process
- **StreamableHTTP**: `https://mcp.financeapi.com/sse` cho global market data access
- **HTTP**: `https://mcp.compliance.gov/api` cho regulatory reporting APIs

***

## 4. Security Framework cho External MCP

### 4.1 Multi-Layer Security Architecture

Security implementation ph·∫£i bao g·ªìm 5 l·ªõp:[^9][^6]

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Layer 5: Application Security            ‚îÇ
‚îÇ                    (Input validation, Rate limiting)        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                    Layer 4: Transport Security              ‚îÇ
‚îÇ                    (mTLS, WAF, API Gateway)                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                    Layer 3: Authentication                  ‚îÇ
‚îÇ                    (OAuth 2.0, JWT, API Keys)               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                    Layer 2: Network Isolation               ‚îÇ
‚îÇ                    (VPC, Private Subnets, IP Whitelisting)  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                    Layer 1: Secrets Management              ‚îÇ
‚îÇ                    (HashiCorp Vault, AWS Secrets Manager)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```


### 4.2 Authentication Patterns

**Pattern 1: API Key Rotation**

```python
from langchain_mcp_adapters.client import MultiServerMCPClient
import boto3

async def get_rotated_api_key(service_name: str) -> str:
    """L·∫•y API key t·ª´ Secrets Manager v·ªõi auto-rotation"""
    secrets_client = boto3.client('secretsmanager')
    response = secrets_client.get_secret_value(SecretId=f"mcp/{service_name}")
    return json.loads(response['SecretString'])['api_key']

# S·ª≠ d·ª•ng dynamic key fetching
client = MultiServerMCPClient({
    "market_data": {
        "transport": "http",
        "server_url": "https://mcp.marketdata.com/sse",
        "headers": lambda: {"X-API-Key": await get_rotated_api_key("market_data")}
    }
})
```

**Pattern 2: OAuth 2.0 Flow**

```python
from authlib.integrations.httpx_client import OAuth2Client

async def get_oauth_token() -> str:
    """L·∫•y OAuth token v·ªõi refresh logic"""
    client = OAuth2Client(
        client_id=os.getenv("MCP_CLIENT_ID"),
        client_secret=os.getenv("MCP_CLIENT_SECRET"),
        token_endpoint="https://auth.provider.com/oauth/token"
    )
    token = await client.fetch_token()
    return token["access_token"]

# MCP client v·ªõi OAuth
client = MultiServerMCPClient({
    "compliance_api": {
        "transport": "http",
        "server_url": "https://mcp.compliance.gov/api",
        "headers": lambda: {"Authorization": f"Bearer {await get_oauth_token()}"}
    }
})
```

**Pattern 3: mTLS cho Internal Services**

```python
# MCP server config v·ªõi mTLS
client = MultiServerMCPClient({
    "internal_risk_engine": {
        "transport": "http",
        "server_url": "https://risk-engine.internal:8443/mcp",
        "ssl_cert": "/certs/client.crt",
        "ssl_key": "/certs/client.key",
        "ca_cert": "/certs/ca.crt"
    }
})
```


### 4.3 Network Security Best Practices

**Micro-segmentation**:[^6]

- Deploy MCP servers trong private subnets kh√¥ng c√≥ internet access
- S·ª≠ d·ª•ng VPC endpoints cho AWS services
- Implement IP whitelisting t·∫°i security group level

**API Gateway Pattern**:

```
[LangGraph Agent] ‚Üí [API Gateway] ‚Üí [WAF] ‚Üí [MCP Server]
                      (Rate limit)    (DDoS protection)
```


***

## 5. Production Deployment Strategies

### 5.1 Container Orchestration v·ªõi Kubernetes

**Deployment YAML**:[^10][^11]

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mcp-finance-server
spec:
  replicas: 3
  selector:
    matchLabels:
      app: mcp-finance
  template:
    metadata:
      labels:
        app: mcp-finance
    spec:
      containers:
      - name: mcp-server
        image: mcp-finance:latest
        ports:
        - containerPort: 8080
        env:
        - name: API_KEY
          valueFrom:
            secretKeyRef:
              name: mcp-secrets
              key: finance-api-key
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: mcp-secrets
              key: database-url
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: mcp-finance-service
spec:
  selector:
    app: mcp-finance
  ports:
  - port: 80
    targetPort: 8080
  type: ClusterIP
```

**Horizontal Pod Autoscaler**:[^12]

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: mcp-finance-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: mcp-finance-server
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "1000"
```


### 5.2 CI/CD Pipeline

**GitHub Actions Workflow**:[^12]

```yaml
name: Deploy MCP Server

on:
  push:
    branches: [main]
    paths:
      - 'mcp-servers/finance/**'

jobs:
  test-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Run security scan
      run: |
        bandit -r mcp_servers/ -f json -o bandit-report.json
    
    - name: Run tests
      run: |
        pytest tests/ --cov=mcp_servers --cov-report=xml
    
    - name: Build Docker image
      run: |
        docker build -t mcp-finance:${{ github.sha }} \
                     -t mcp-finance:latest .
    
    - name: Push to registry
      run: |
        echo ${{ secrets.DOCKER_PASSWORD }} |
<span style="display:none">[^13][^14][^15][^16][^17][^18][^19][^20][^21]</span>

<div align="center">‚ÅÇ</div>

[^1]: https://mcpservers.org
[^2]: https://github.com/punkpeye/awesome-mcp-servers
[^3]: https://github.com/jaw9c/awesome-remote-mcp-servers
[^4]: https://latenode.com/blog/ai-frameworks-technical-infrastructure/langgraph-multi-agent-orchestration/langgraph-mcp-integration-complete-model-context-protocol-setup-guide-working-examples-2025
[^5]: https://changelog.langchain.com/announcements/mcp-adapters-for-langchain-and-langgraph
[^6]: https://sparkco.ai/blog/enterprise-mcp-security-best-practices-an-in-depth-guide
[^7]: https://www.reddit.com/r/mcp/comments/1kssu2g/mcp_server_transports_inmemory_vs_httpsse_vs_stdio/
[^8]: https://mcpcat.io/guides/comparing-stdio-sse-streamablehttp/
[^9]: https://modelcontextprotocol.io/specification/draft/basic/security_best_practices
[^10]: https://milvus.io/ai-quick-reference/whats-the-best-way-to-deploy-an-model-context-protocol-mcp-server-to-production
[^11]: https://github.com/BigUncle/MCP-Server-Unified-Deployment
[^12]: https://collabnix.com/how-to-use-mcp-in-production-a-practical-guide/
[^13]: https://modelcontextprotocol.io/examples
[^14]: https://www.k2view.com/blog/awesome-mcp-servers
[^15]: https://docs.databricks.com/aws/en/generative-ai/mcp/external-mcp
[^16]: https://www.youtube.com/watch?v=hblrscBO2x0
[^17]: https://mcp-framework.com/docs/Transports/stdio-transport/
[^18]: https://obot.ai/resources/learning-center/mcp-servers/
[^19]: https://docs.opensearch.org/latest/vector-search/ai-search/agentic-search/mcp-server/
[^20]: https://generect.com/blog/langgraph-mcp/
[^21]: https://modelcontextprotocol.io/specification/2025-03-26/basic/transports```


---
<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# üìö H∆∞·ªõng D·∫´n Chi Ti·∫øt: Tri·ªÉn Khai MCP Server B√™n Ngo√†i v√†o Production

D·ª±a tr√™n code c·ªßa b·∫°n (LangChain + LangGraph + MCP), t√¥i s·∫Ω cung c·∫•p **step-by-step implementation guide** t·ª´ local development ƒë·∫øn production.

***

## üìã Table of Contents

1. [Ki·∫øn Tr√∫c T√≠ch H·ª£p MCP B√™n Ngo√†i](#1-ki%E1%BA%BFn-tr%C3%BAc-t%C3%ADch-h%E1%BB%A3p-mcp-b%C3%AAn-ngo%C3%A0i)
2. [Setup Local Development](#2-setup-local-development)
3. [Tri·ªÉn Khai MCP Server B√™n Ngo√†i](#3-tri%E1%BB%83n-khai-mcp-server-b%C3%AAn-ngo%C3%A0i)
4. [Integration v·ªõi Existing Code](#4-integration-v%E1%BB%9Bi-existing-code)
5. [Production Deployment](#5-production-deployment)
6. [Monitoring \& Debugging](#6-monitoring--debugging)

***

## 1. Ki·∫øn Tr√∫c T√≠ch H·ª£p MCP B√™n Ngo√†i

### 1.1 Topology Hi·ªán T·∫°i vs Sau Khi Integrate

**Current Architecture (Local + In-Process)**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    FastAPI Application              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ MultiAgentOrchestrator       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ PlannerAgent            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ RouterAgent             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ ExecutorAgent           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ SynthesizerAgent        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ           ‚ñº                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ MCP Tool Adapters (Local)    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ BrowserMCP (Playwright)  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ MathMCP                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ DriveMCP (OAuth)         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ YoutubeMCP               ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ           ‚ñº                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Redis Pub/Sub (MessageBus)   ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**After Integration (Hybrid - Local + External)**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   FastAPI Application                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ LangGraph Orchestrator (New)                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ StateGraph with checkpointing                      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ Conditional edge routing                          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚ñº                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ MultiServerMCPClient (NEW - Central Hub)                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ Internal MCP Servers (Stdio)                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ BrowserMCP                                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ MathMCP                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ DriveMCP                                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                                                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ External MCP Servers (HTTP)                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ      ‚îú‚îÄ‚îÄ FinanceAPI MCP (Remote)                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ      ‚îú‚îÄ‚îÄ ComplianceAPI MCP (Remote)                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ      ‚îî‚îÄ‚îÄ DataWarehouse MCP (Remote)                     ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚ñº                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ           LangChain Agents & Tools                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ create_react_agent()                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ Tool Executor with interceptors                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñ≤                              ‚ñ≤                 ‚ñ≤
         ‚îÇ (Stdio)                      ‚îÇ (HTTP)         ‚îÇ (HTTP)
         ‚îÇ                              ‚îÇ                ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Internal   ‚îÇ            ‚îÇ   External    ‚îÇ    ‚îÇ  External    ‚îÇ
    ‚îÇ   MCP       ‚îÇ            ‚îÇ  FinanceAPI   ‚îÇ    ‚îÇ Compliance   ‚îÇ
    ‚îÇ  Servers    ‚îÇ            ‚îÇ     MCP       ‚îÇ    ‚îÇ     MCP      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    (Same Process)          (Remote Services)    (Remote Services)
```


### 1.2 Communication Protocols

| Layer | Protocol | Topology | Use Case |
| :-- | :-- | :-- | :-- |
| **Internal MCPs** | Stdio (JSON-RPC) | Subprocess | Fast, co-located tools |
| **External MCPs** | Streamable HTTP | Network | Scalable remote services |
| **Tools ‚Üî Agent** | Python async/await | In-process | Tool discovery \& execution |
| **State Management** | LangGraph Checkpointer | Database (optional) | Persistence \& recovery |


***

## 2. Setup Local Development

### 2.1 Install Dependencies

```bash
# Update pyproject.toml
cat >> pyproject.toml << 'EOF'

# Existing dependencies
langchain = ">=0.3.27"
langgraph = ">=0.6.8"
langchain-openai = ">=0.3.33"

# NEW: MCP Adapters (the key integration library)
langchain-mcp-adapters = ">=0.5.0"

# FastMCP for creating MCP servers
fastmcp = ">=0.5.0"

# For external HTTP MCP connections
httpx = ">=0.27.0"

# For async context management
aiohttp = ">=3.10.0"

EOF

# Install
pip install -e .
```


### 2.2 Project Structure After Integration

```
your_project/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                          # FastAPI entry
‚îÇ   ‚îú‚îÄ‚îÄ config.py                        # MCP config (NEW)
‚îÇ   ‚îú‚îÄ‚îÄ module/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mcp/                         # (NEW) MCP Integration
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client_manager.py        # MultiServerMCPClient wrapper
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ interceptors.py          # Tool interceptors (auth, retry)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ callbacks.py             # Progress/logging callbacks
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ servers/                 # Internal MCP server definitions
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ math_server.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ browser_server.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ drive_server.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ multi_agents/                # Existing agents
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent_entrypoint.py      # MODIFIED: Use MCP client
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ workflows/                   # (NEW) LangGraph workflows
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ complex_analysis.py      # Use MCP tools
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ financial_report.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îî‚îÄ‚îÄ mcp_service.py               # (NEW) Service layer
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ mcp_servers.yaml                 # External server configs
‚îÇ   ‚îú‚îÄ‚îÄ .env.example
‚îÇ   ‚îî‚îÄ‚îÄ .env (production)
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_mcp_integration.py
‚îÇ
‚îî‚îÄ‚îÄ docker-compose.yml                    # For MCP servers
```


***

## 3. Tri·ªÉn Khai MCP Server B√™n Ngo√†i

### 3.1 Step 1: T·∫°o External MCP Server (Finance Example)

**File: `mcp_servers/finance_server.py`** (Deployed separately)

```python
#!/usr/bin/env python3
"""
External Finance MCP Server
Deploy n√†y tr√™n remote server, ch·∫°y as standalone service
"""

from fastmcp import FastMCP
from typing import Optional
import httpx
import os

# Initialize FastMCP server
mcp = FastMCP("FinanceAPI")

# Database connection (example with environment variable)
FINANCE_API_BASE = os.getenv("FINANCE_API_BASE", "https://api.financeprovider.com")
API_KEY = os.getenv("FINANCE_API_KEY")

# ==================== TOOLS ====================

@mcp.tool()
async def get_stock_price(ticker: str, date: Optional[str] = None) -> dict:
    """
    L·∫•y gi√° c·ªï phi·∫øu hi·ªán t·∫°i ho·∫∑c l·ªãch s·ª≠
    
    Args:
        ticker: M√£ c·ªï phi·∫øu (VD: VNM, FPT)
        date: Ng√†y (YYYY-MM-DD), n·∫øu None th√¨ l·∫•y hi·ªán t·∫°i
    
    Returns:
        dict: {price, change_percent, timestamp, volume}
    """
    async with httpx.AsyncClient() as client:
        params = {"ticker": ticker}
        if date:
            params["date"] = date
        
        response = await client.get(
            f"{FINANCE_API_BASE}/stocks/price",
            params=params,
            headers={"X-API-Key": API_KEY}
        )
        response.raise_for_status()
        return response.json()

@mcp.tool()
async def get_financial_statements(
    ticker: str, 
    year: int,
    statement_type: str = "income"  # income, balance_sheet, cash_flow
) -> dict:
    """
    L·∫•y b√°o c√°o t√†i ch√≠nh
    
    Args:
        ticker: M√£ c·ªï phi·∫øu
        year: NƒÉm t√†i ch√≠nh
        statement_type: Lo·∫°i b√°o c√°o
    
    Returns:
        dict: Structured financial data
    """
    async with httpx.AsyncClient() as client:
        response = await client.get(
            f"{FINANCE_API_BASE}/financials/{ticker}",
            params={
                "year": year,
                "type": statement_type
            },
            headers={"X-API-Key": API_KEY}
        )
        response.raise_for_status()
        return response.json()

@mcp.tool()
async def calculate_valuation(
    ticker: str,
    method: str = "dcf"  # dcf, pe_ratio, peg
) -> dict:
    """
    T√≠nh ƒë·ªãnh gi√° c·ªï phi·∫øu
    
    Args:
        ticker: M√£ c·ªï phi·∫øu
        method: Ph∆∞∆°ng ph√°p ƒë·ªãnh gi√°
    
    Returns:
        dict: Valuation result with fair_value, upside_downside, confidence
    """
    async with httpx.AsyncClient() as client:
        response = await client.post(
            f"{FINANCE_API_BASE}/valuation/calculate",
            json={
                "ticker": ticker,
                "method": method
            },
            headers={"X-API-Key": API_KEY}
        )
        response.raise_for_status()
        return response.json()

@mcp.tool()
async def search_analyst_reports(
    ticker: str,
    limit: int = 10
) -> list:
    """
    T√¨m ki·∫øm b√°o c√°o ph√¢n t√≠ch
    
    Args:
        ticker: M√£ c·ªï phi·∫øu
        limit: S·ªë b√°o c√°o t·ªëi ƒëa
    
    Returns:
        list: [{title, analyst, rating, date, url}]
    """
    async with httpx.AsyncClient() as client:
        response = await client.get(
            f"{FINANCE_API_BASE}/reports/search",
            params={
                "ticker": ticker,
                "limit": limit
            },
            headers={"X-API-Key": API_KEY}
        )
        response.raise_for_status()
        return response.json()["reports"]

# ==================== RESOURCES ====================

@mcp.resource("file:///reports")
async def list_reports() -> str:
    """Danh s√°ch c√°c b√°o c√°o c√≥ s·∫µn"""
    async with httpx.AsyncClient() as client:
        response = await client.get(
            f"{FINANCE_API_BASE}/reports/list",
            headers={"X-API-Key": API_KEY}
        )
        response.raise_for_status()
        reports = response.json()
        return "\n".join([f"- {r['name']}" for r in reports])

# ==================== MAIN ====================

if __name__ == "__main__":
    # Run with Streamable HTTP transport (cho production)
    import uvicorn
    
    app = mcp.mcp_asgi_app()
    
    uvicorn.run(
        app,
        host="0.0.0.0",  # Bind to all interfaces (use reverse proxy in production)
        port=8001,       # Custom port
        log_level="info"
    )
    
    # Ho·∫∑c d√πng stdio transport cho local testing:
    # mcp.run(transport="stdio")
```


### 3.2 Step 2: Deploy External MCP Server

**File: `Dockerfile` (cho Finance MCP Server)**

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy server code
COPY mcp_servers/ .

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import httpx; httpx.get('http://localhost:8001/health').raise_for_status()"

# Expose MCP endpoint
EXPOSE 8001

# Run server
CMD ["python", "-m", "uvicorn", "finance_server:app", \
     "--host", "0.0.0.0", "--port", "8001"]
```

**File: `docker-compose.yml` (Local + External Services)**

```yaml
version: '3.8'

services:
  # External Finance MCP Server (simulate remote)
  finance-mcp-server:
    build:
      context: ./mcp_servers
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    environment:
      FINANCE_API_BASE: "https://api.example.com"
      FINANCE_API_KEY: "${FINANCE_API_KEY}"
    networks:
      - mcp-network
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # External Compliance MCP Server
  compliance-mcp-server:
    build:
      context: ./mcp_servers/compliance
      dockerfile: Dockerfile
    ports:
      - "8002:8002"
    environment:
      COMPLIANCE_API_BASE: "https://regulatory-api.example.com"
      COMPLIANCE_API_KEY: "${COMPLIANCE_API_KEY}"
    networks:
      - mcp-network
    restart: always

  # Your main FastAPI application
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      # MCP Server URLs (externally accessible)
      MCP_FINANCE_URL: "http://finance-mcp-server:8001/mcp"
      MCP_COMPLIANCE_URL: "http://compliance-mcp-server:8002/mcp"
      # Internal API keys
      FINANCE_API_KEY: "${FINANCE_API_KEY}"
      COMPLIANCE_API_KEY: "${COMPLIANCE_API_KEY}"
    depends_on:
      finance-mcp-server:
        condition: service_healthy
      compliance-mcp-server:
        condition: service_healthy
    networks:
      - mcp-network
    restart: always

networks:
  mcp-network:
    driver: bridge
```


***

## 4. Integration v·ªõi Existing Code

### 4.1 Step 1: Create MCP Client Manager

**File: `app/module/mcp/client_manager.py`** (Wrapper around MultiServerMCPClient)

```python
"""
MCP Client Manager - Central hub cho t·∫•t c·∫£ MCP servers
"""

from typing import Dict, List, Optional, Any
import os
import logging
from functools import lru_cache
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_mcp_adapters.callbacks import Callbacks, CallbackContext
from langchain_mcp_adapters.interceptors import MCPToolCallRequest
from langchain_core.tools import BaseTool
import asyncio

logger = logging.getLogger(__name__)

class MCPClientManager:
    """
    Qu·∫£n l√Ω t·∫•t c·∫£ MCP connections (internal + external)
    
    Features:
    - Connection pooling
    - Error handling & retry
    - Tool caching
    - Interceptors for auth/context
    """
    
    def __init__(self):
        self._client: Optional[MultiServerMCPClient] = None
        self._tools_cache: Optional[List[BaseTool]] = None
        self._lock = asyncio.Lock()
    
    async def initialize(self) -> None:
        """Initialize MCP client with all servers"""
        if self._client is not None:
            return
        
        async with self._lock:
            if self._client is not None:
                return
            
            # Build server configurations
            servers_config = self._build_servers_config()
            
            # Create client with interceptors
            self._client = MultiServerMCPClient(
                servers=servers_config,
                tool_interceptors=[
                    self._auth_interceptor,
                    self._retry_interceptor,
                    self._context_interceptor,
                ],
                callbacks=Callbacks(
                    on_logging_message=self._on_logging_message,
                    on_progress=self._on_progress,
                ),
            )
            
            logger.info("MCP Client initialized successfully")
    
    def _build_servers_config(self) -> Dict[str, Dict[str, Any]]:
        """Build MCP server configurations from environment"""
        
        return {
            # ===== INTERNAL MCP SERVERS (Stdio) =====
            "math": {
                "transport": "stdio",
                "command": "python",
                "args": [
                    os.path.join(os.path.dirname(__file__), "servers/math_server.py")
                ],
            },
            "browser": {
                "transport": "stdio",
                "command": "python",
                "args": [
                    os.path.join(os.path.dirname(__file__), "servers/browser_server.py")
                ],
            },
            "drive": {
                "transport": "stdio",
                "command": "python",
                "args": [
                    os.path.join(os.path.dirname(__file__), "servers/drive_server.py")
                ],
            },
            
            # ===== EXTERNAL MCP SERVERS (HTTP) =====
            "finance": {
                "transport": "http",
                "url": os.getenv(
                    "MCP_FINANCE_URL",
                    "http://localhost:8001/mcp"
                ),
                "headers": {
                    "Authorization": f"Bearer {os.getenv('MCP_FINANCE_TOKEN', '')}",
                    "X-Request-ID": "{request_id}",  # Will be injected by interceptor
                },
            },
            "compliance": {
                "transport": "http",
                "url": os.getenv(
                    "MCP_COMPLIANCE_URL",
                    "http://localhost:8002/mcp"
                ),
                "headers": {
                    "Authorization": f"Bearer {os.getenv('MCP_COMPLIANCE_TOKEN', '')}",
                },
            },
        }
    
    # ==================== INTERCEPTORS ====================
    
    async def _auth_interceptor(
        self,
        request: MCPToolCallRequest,
        handler,
    ):
        """Inject authentication headers based on runtime context"""
        try:
            # Get user context from runtime
            runtime = getattr(request, 'runtime', None)
            if runtime and hasattr(runtime, 'context'):
                user_id = runtime.context.get('user_id')
                api_key = runtime.context.get('api_key')
                
                # Modify request with user-specific credentials
                if api_key and request.name == "finance_tool":
                    modified_request = request.override(
                        headers={
                            **request.headers,
                            "X-User-ID": user_id,
                            "X-API-Key": api_key,
                        }
                    )
                    return await handler(modified_request)
        except Exception as e:
            logger.warning(f"Auth interceptor error: {e}")
        
        return await handler(request)
    
    async def _retry_interceptor(
        self,
        request: MCPToolCallRequest,
        handler,
        max_retries: int = 3,
        base_delay: float = 1.0,
    ):
        """Retry failed requests with exponential backoff"""
        last_error = None
        
        for attempt in range(max_retries):
            try:
                return await handler(request)
            except Exception as e:
                last_error = e
                
                if attempt < max_retries - 1:
                    delay = base_delay * (2 ** attempt)
                    logger.warning(
                        f"Tool {request.name} failed (attempt {attempt + 1}/{max_retries}), "
                        f"retrying in {delay}s... Error: {e}"
                    )
                    await asyncio.sleep(delay)
                else:
                    logger.error(
                        f"Tool {request.name} failed after {max_retries} attempts"
                    )
        
        raise last_error
    
    async def _context_interceptor(
        self,
        request: MCPToolCallRequest,
        handler,
    ):
        """Inject runtime context into tool arguments"""
        # Add tracing context
        modified_request = request.override(
            args={
                **request.args,
                "_trace_id": getattr(request, 'trace_id', None),
                "_user_id": getattr(request, 'user_id', None),
            }
        )
        
        return await handler(modified_request)
    
    # ==================== CALLBACKS ====================
    
    async def _on_logging_message(self, params, context: CallbackContext):
        """Handle MCP server logging messages"""
        logger.log(
            level=getattr(logging, params.level.upper(), logging.INFO),
            msg=f"[{context.server_name}] {params.data}"
        )
    
    async def _on_progress(self, progress, total, message, context: CallbackContext):
        """Handle progress notifications from long-running tools"""
        percent = (progress / total * 100) if total else progress
        logger.info(
            f"Progress [{context.server_name}/{context.tool_name}]: "
            f"{percent:.1f}% - {message}"
        )
    
    # ==================== PUBLIC API ====================
    
    async def get_tools(self, server_name: Optional[str] = None) -> List[BaseTool]:
        """
        Get tools from MCP servers
        
        Args:
            server_name: Specific server name, or None for all
        
        Returns:
            List of LangChain BaseTool objects
        """
        await self.initialize()
        
        if server_name:
            return await self._client.get_tools(server_name=server_name)
        else:
            return await self._client.get_tools()
    
    async def execute_tool(
        self,
        tool_name: str,
        **kwargs
    ) -> Any:
        """Direct tool execution without LangChain"""
        tools = await self.get_tools()
        tool = next((t for t in tools if t.name == tool_name), None)
        
        if not tool:
            raise ValueError(f"Tool not found: {tool_name}")
        
        return await tool.ainvoke(kwargs)
    
    async def close(self) -> None:
        """Close all MCP connections"""
        if self._client:
            # MultiServerMCPClient doesn't have explicit close in v0.5
            # But you should implement cleanup if needed
            self._client = None
            self._tools_cache = None
            logger.info("MCP Client closed")
    
    async def health_check(self) -> Dict[str, bool]:
        """Check health of all MCP servers"""
        await self.initialize()
        
        health_status = {}
        
        for server_name in self._build_servers_config().keys():
            try:
                # Try to get tools from server
                tools = await self._client.get_tools(server_name=server_name)
                health_status[server_name] = len(tools) > 0
            except Exception as e:
                logger.error(f"Health check failed for {server_name}: {e}")
                health_status[server_name] = False
        
        return health_status


# Global singleton instance
_mcp_manager: Optional[MCPClientManager] = None

def get_mcp_manager() -> MCPClientManager:
    """Get global MCP manager instance"""
    global _mcp_manager
    if _mcp_manager is None:
        _mcp_manager = MCPClientManager()
    return _mcp_manager
```


### 4.2 Step 2: Modify Agent Entrypoint

**File: `app/module/multi_agents/agent_entrypoint.py`** (MODIFIED)

```python
"""
Modified agent entrypoint to use MCP Client
"""

from typing import Dict, List, Optional, Any
import logging
from app.module.mcp.client_manager import get_mcp_manager
from langchain.agents import create_react_agent
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from typing_extensions import TypedDict
import asyncio

logger = logging.getLogger(__name__)

class FinAIAgentState(TypedDict):
    """State for FinAI multi-agent orchestration"""
    query: str
    user_id: str
    tools_available: List[Dict[str, Any]]
    analysis_results: Dict[str, Any]
    final_response: str
    error: Optional[str]

class FinAIAgentEntrypoint:
    """Updated entrypoint using MCP tools"""
    
    def __init__(self):
        self.mcp_manager = get_mcp_manager()
        self.llm = ChatOpenAI(model="gpt-4-turbo-preview")
    
    async def execute(
        self,
        query: str,
        user_id: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Execute financial AI query using MCP tools
        
        Args:
            query: User query
            user_id: User identifier
            context: Additional context (API keys, etc.)
        
        Returns:
            Analysis result with final response
        """
        
        # Initialize MCP client
        await self.mcp_manager.initialize()
        
        # Get available tools from all MCP servers
        all_tools = await self.mcp_manager.get_tools()
        
        # Filter tools based on query type
        relevant_tools = self._filter_tools_by_query(all_tools, query)
        
        # Create ReAct agent with MCP tools
        agent = create_react_agent(
            model=self.llm,
            tools=relevant_tools,
            prompt=self._get_system_prompt(user_id),
        )
        
        # Execute agent
        try:
            result = await agent.ainvoke(
                {
                    "messages": [
                        {
                            "role": "user",
                            "content": query,
                        }
                    ],
                    "user_id": user_id,
                    "context": context or {},
                }
            )
            
            return {
                "status": "success",
                "response": result.get("messages", [])[-1].content,
                "tools_used": self._extract_tools_used(result),
            }
        
        except Exception as e:
            logger.error(f"Agent execution failed: {e}")
            return {
                "status": "error",
                "error": str(e),
            }
    
    def _filter_tools_by_query(
        self,
        tools: List,
        query: str
    ) -> List:
        """Filter relevant tools based on query keywords"""
        
        # Simple keyword-based filtering
        keywords_to_tools = {
            "math": ["mcp_add", "mcp_subtract", "mcp_multiply"],
            "stock": ["get_stock_price", "get_financial_statements"],
            "drive": ["list_files", "read_file"],
            "browser": ["take_screenshot", "navigate"],
        }
        
        selected_tools = []
        query_lower = query.lower()
        
        for tool in tools:
            for keyword, tool_names in keywords_to_tools.items():
                if keyword in query_lower and tool.name in tool_names:
                    selected_tools.append(tool)
                    break
        
        # If no tools matched, return all (let agent decide)
        return selected_tools if selected_tools else tools
    
    def _get_system_prompt(self, user_id: str) -> str:
        """Get system prompt for agent"""
        return f"""You are a helpful financial AI assistant for user {user_id}.
        
You have access to various tools to help analyze financial data.
- Use math tools for calculations
- Use stock tools for market data
- Use drive tools for document retrieval
- Use browser tools for web scraping

Always explain your reasoning before using tools.
When unsure, ask clarifying questions.
"""
    
    def _extract_tools_used(self, result: Dict) -> List[str]:
        """Extract which tools were actually used"""
        tools_used = []
        
        for message in result.get("messages", []):
            if hasattr(message, 'tool_calls'):
                tools_used.extend([
                    call['tool'] for call in message.tool_calls
                ])
        
        return tools_used
```


### 4.3 Step 3: Create LangGraph Workflow (Optional for Complex Cases)

**File: `app/module/workflows/complex_analysis.py`** (Using MCP tools with LangGraph)

```python
"""
Complex Financial Analysis Workflow using LangGraph + MCP
"""

from typing import TypedDict, Optional, List, Any
import logging
from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI
from app.module.mcp.client_manager import get_mcp_manager

logger = logging.getLogger(__name__)

class AnalysisState(TypedDict):
    """State for complex financial analysis"""
    ticker: str
    user_id: str
    
    # Analysis stages
    stock_data: Optional[Dict[str, Any]]
    financial_statements: Optional[Dict[str, Any]]
    valuation: Optional[Dict[str, Any]]
    analyst_reports: Optional[List[Dict[str, Any]]]
    
    # Synthesis
    recommendation: Optional[str]
    confidence: float
    
    # Metadata
    errors: List[str]

class ComplexAnalysisWorkflow:
    """Orchestrate complex financial analysis using LangGraph + MCP"""
    
    def __init__(self):
        self.mcp_manager = get_mcp_manager()
        self.llm = ChatOpenAI(model="gpt-4-turbo-preview")
    
    def build_graph(self):
        """Build LangGraph workflow"""
        
        builder = StateGraph(AnalysisState)
        
        # Add nodes
        builder.add_node("fetch_stock_data", self.fetch_stock_data_node)
        builder.add_node("fetch_financials", self.fetch_financials_node)
        builder.add_node("calculate_valuation", self.calculate_valuation_node)
        builder.add_node("fetch_analyst_reports", self.fetch_analyst_reports_node)
        builder.add_node("synthesize", self.synthesize_node)
        builder.add_node("human_review", self.human_review_node)
        
        # Add edges
        builder.add_edge(START, "fetch_stock_data")
        builder.add_edge("fetch_stock_data", "fetch_financials")
        builder.add_edge("fetch_financials", "calculate_valuation")
        builder.add_edge("calculate_valuation", "fetch_analyst_reports")
        builder.add_edge("fetch_analyst_reports", "synthesize")
        
        # Conditional: if confidence < 0.7, go to human review
        builder.add_conditional_edges(
            "synthesize",
            self._should_review,
            {
                "review": "human_review",
                "end": END,
            }
        )
        builder.add_edge("human_review", END)
        
        return builder.compile()
    
    async def fetch_stock_data_node(self, state: AnalysisState) -> Dict:
        """Node: Fetch stock price data"""
        try:
            stock_data = await self.mcp_manager.execute_tool(
                "get_stock_price",
                ticker=state["ticker"]
            )
            return {"stock_data": stock_data}
        except Exception as e:
            logger.error(f"Failed to fetch stock data: {e}")
            return {
                "stock_data": None,
                "errors": state["errors"] + [f"Stock data fetch: {str(e)}"],
            }
    
    async def fetch_financials_node(self, state: AnalysisState) -> Dict:
        """Node: Fetch financial statements"""
        try:
            financials = await self.mcp_manager.execute_tool(
                "get_financial_statements",
                ticker=state["ticker"],
                year=2024,
                statement_type="income"
            )
            return {"financial_statements": financials}
        except Exception as e:
            logger.error(f"Failed to fetch financials: {e}")
            return {
                "financial_statements": None,
                "errors": state["errors"] + [f"Financials fetch: {str(e)}"],
            }
    
    async def calculate_valuation_node(self, state: AnalysisState) -> Dict:
        """Node: Calculate valuation"""
        try:
            valuation = await self.mcp_manager.execute_tool(
                "calculate_valuation",
                ticker=state["ticker"],
                method="dcf"
            )
            return {"valuation": valuation}
        except Exception as e:
            logger.error(f"Failed to calculate valuation: {e}")
            return {
                "valuation": None,
                "errors": state["errors"] + [f"Valuation: {str(e)}"],
            }
    
    async def fetch_analyst_reports_node(self, state: AnalysisState) -> Dict:
        """Node: Fetch analyst reports"""
        try:
            reports = await self.mcp_manager.execute_tool(
                "search_analyst_reports",
                ticker=state["ticker"],
                limit=5
            )
            return {"analyst_reports": reports}
        except Exception as e:
            logger.error(f"Failed to fetch reports: {e}")
            return {
                "analyst_reports": None,
                "errors": state["errors"] + [f"Reports fetch: {str(e)}"],
            }
    
    async def synthesize_node(self, state: AnalysisState) -> Dict:
        """Node: Synthesize all data into recommendation"""
        
        # Prepare context for LLM
        context = f"""
        Ticker: {state['ticker']}
        
        Stock Data: {state.get('stock_data', {})}
        
        Financial Statements: {state.get('financial_statements', {})}
        
        Valuation: {state.get('valuation', {})}
        
        Analyst Reports: {state.get('analyst_reports', [])}
        """
        
        prompt = f"""Based on the following financial data for {state['ticker']},
        provide an investment recommendation:
        
        {context}
        
        Format your response as:
        1. Summary of key metrics
        2. Investment recommendation (Buy/Hold/Sell)
        3. Confidence level (0-1)
        4. Key risks
        """
        
        try:
            response = await self.llm.ainvoke(prompt)
            
            # Extract recommendation and confidence
            recommendation = self._parse_recommendation(response.content)
            confidence = self._parse_confidence(response.content)
            
            return {
                "recommendation": recommendation,
                "confidence": confidence,
            }
        except Exception as e:
            logger.error(f"Synthesis failed: {e}")
            return {
                "recommendation": None,
                "confidence": 0.0,
                "errors": state["errors"] + [f"Synthesis: {str(e)}"],
            }
    
    async def human_review_node(self, state: AnalysisState) -> Dict:
        """Node: Request human review if confidence is low"""
        
        logger.warning(
            f"Low confidence ({state['confidence']}) for {state['ticker']}, "
            f"requesting human review"
        )
        
        # In production, this would integrate with approval workflow
        # For now, mark as reviewed
        return {
            "recommendation": f"[PENDING REVIEW] {state['recommendation']}",
        }
    
    def _should_review(self, state: AnalysisState) -> str:
        """Decide if human review is needed"""
        if state.get("confidence", 0) < 0.7:
            return "review"
        return "end"
    
    def _parse_recommendation(self, response: str) -> str:
        """Extract recommendation from LLM response"""
        for line in response.split('\n'):
            if "Buy" in line or "Hold" in line or "Sell" in line:
                return line.strip()
        return "Unknown"
    
    def _parse_confidence(self, response: str) -> float:
        """Extract confidence from LLM response"""
        # Simple regex-based extraction
        import re
        match = re.search(r'Confidence.*?(\d+\.?\d*)', response, re.IGNORECASE)
        if match:
            return float(match.group(1))
        return 0.5
    
    async def execute(self, ticker: str, user_id: str) -> Dict[str, Any]:
        """Execute the workflow"""
        
        graph = self.build_graph()
        
        initial_state = AnalysisState(
            ticker=ticker,
            user_id=user_id,
            stock_data=None,
            financial_statements=None,
            valuation=None,
            analyst_reports=None,
            recommendation=None,
            confidence=0.0,
            errors=[],
        )
        
        result = await graph.ainvoke(initial_state)
        
        return result
```


***

## 5. Production Deployment

### 5.1 Environment Configuration

**File: `.env.production`**

```bash
# FastAPI
FASTAPI_ENV=production
DEBUG=false
LOG_LEVEL=info

# LLM
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4-turbo-preview

# Internal MCP Servers (Stdio - local)
MCP_MATH_ENABLED=true
MCP_BROWSER_ENABLED=true
MCP_DRIVE_ENABLED=true

# External MCP Servers (HTTP - remote)
MCP_FINANCE_URL=https://mcp-finance.prod.example.com/mcp
MCP_FINANCE_TOKEN=bearer_token_here

MCP_COMPLIANCE_URL=https://mcp-compliance.prod.example.com/mcp
MCP_COMPLIANCE_TOKEN=bearer_token_here

# Security
MCP_VERIFY_SSL=true
MCP_REQUEST_TIMEOUT=30
MCP_MAX_RETRIES=3
MCP_RETRY_BACKOFF=2.0

# Database (for checkpointing if using LangGraph)
POSTGRES_URL=postgresql://user:pass@db:5432/finai_db
```


### 5.2 Kubernetes Deployment

**File: `k8s/deployment.yaml`**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: finai-agent
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: finai-agent
  template:
    metadata:
      labels:
        app: finai-agent
    spec:
      serviceAccountName: finai-agent
      containers:
      - name: finai-agent
        image: your-registry/finai-agent:latest
        imagePullPolicy: Always
        
        ports:
        - containerPort: 8000
          name: http
        
        env:
        - name: FASTAPI_ENV
          value: "production"
        
        - name: MCP_FINANCE_URL
          valueFrom:
            configMapKeyRef:
              name: mcp-config
              key: finance-url
        
        - name: MCP_FINANCE_TOKEN
          valueFrom:
            secretKeyRef:
              name: mcp-secrets
              key: finance-token
        
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: ai-secrets
              key: openai-api-key
        
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
---
apiVersion: v1
kind: Service
metadata:
  name: finai-agent-svc
  namespace: production
spec:
  selector:
    app: finai-agent
  ports:
  - port: 80
    targetPort: 8000
    name: http
  type: LoadBalancer
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: finai-agent-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: finai-agent
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```


***

## 6. Monitoring \& Debugging

### 6.1 Health Check \& Observability

**File: `app/routes/health.py`**

```python
from fastapi import APIRouter, HTTPException
from app.module.mcp.client_manager import get_mcp_manager
import logging

router = APIRouter(prefix="/health", tags=["health"])
logger = logging.getLogger(__name__)

@router.get("/")
async def health_check():
    """Basic health check"""
    return {
        "status": "healthy",
        "service": "finai-agent",
    }

@router.get("/ready")
async def readiness_check():
    """Readiness check - include MCP servers"""
    try:
        mcp_manager = get_mcp_manager()
        mcp_health = await mcp_manager.health_check()
        
        # All servers must be reachable
        all_healthy = all(mcp_health.values())
        
        if not all_healthy:
            failing = [k for k, v in mcp_health.items() if not v]
            raise HTTPException(
                status_code=503,
                detail=f"MCP servers unavailable: {failing}"
            )
        
        return {
            "status": "ready",
            "mcp_servers": mcp_health,
        }
    
    except Exception as e:
        logger.error(f"Readiness check failed: {e}")
        raise HTTPException(status_code=503, detail=str(e))

@router.get("/mcp-status")
async def mcp_status():
    """Detailed MCP server status"""
    mcp_manager = get_mcp_manager()
    return await mcp_manager.health_check()
```


### 6.2 Observability Integration

**File: `app/observability/tracing.py`**

```python
from opentelemetry import trace, metrics
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
import logging

logger = logging.getLogger(__name__)

def setup_tracing():
    """Setup OpenTelemetry tracing for MCP calls"""
    
    jaeger_exporter = JaegerExporter(
        agent_host_name="localhost",
        agent_port=6831,
    )
    
    trace.set_tracer_provider(
        TracerProvider(active_span_processor=BatchSpanProcessor(jaeger_exporter))
    )
    
    logger.info("Tracing configured with Jaeger")

# Usage in MCP manager
tracer = trace.get_tracer(__name__)

async def execute_with_tracing(tool_name: str, **kwargs):
    """Execute MCP tool with OpenTelemetry tracing"""
    with tracer.start_as_current_span(f"mcp.tool.{tool_name}") as span:
        span.set_attribute("tool_name", tool_name)
        span.set_attribute("args", str(kwargs))
        
        # Execute tool
        result = await mcp_manager.execute_tool(tool_name, **kwargs)
        
        span.set_attribute("result", str(result))
        return result
```


***

## üìù T√≥m T·∫Øt Tri·ªÉn Khai

### Checklist

- [ ] Install `langchain-mcp-adapters` v√† `fastmcp`
- [ ] T·∫°o external MCP servers (Finance, Compliance, etc.)
- [ ] Vi·∫øt `MCPClientManager` wrapper
- [ ] Update `agent_entrypoint.py` ƒë·ªÉ d√πng MCP tools
- [ ] (Optional) T·∫°o LangGraph workflows cho complex cases
- [ ] Setup environment variables cho external servers
- [ ] Deploy MCP servers (Docker/Kubernetes)
- [ ] Integrate health checks v√†o FastAPI
- [ ] Setup observability (Jaeger, Prometheus)
- [ ] Test end-to-end in staging
- [ ] Deploy to production


### Expected Benefits

‚úÖ **Scalability**: MCP servers can scale independently
‚úÖ **Flexibility**: Mix local (stdio) + remote (HTTP) tools seamlessly
‚úÖ **Maintainability**: Clear separation between agents \& tools
‚úÖ **Observability**: Built-in MCP callbacks for logging/progress
‚úÖ **Security**: Interceptor-based auth, context injection

***

B·∫°n c√≥ c√¢u h·ªèi c·ª• th·ªÉ n√†o v·ªÅ implementation kh√¥ng? Ho·∫∑c mu·ªën t√¥i deep-dive v√†o b·∫•t k·ª≥ ph·∫ßn n√†o?


---
### √ù t∆∞·ªüng chung

- **External MCP server** (Playwright MCP, GitHub MCP, Drive MCP npm package, ‚Ä¶)  
  - Ch·∫°y nh∆∞ **process ri√™ng** (th∆∞·ªùng l√† `node`/`npx`), expose tool qua **MCP protocol** (stdio ho·∫∑c HTTP).
- Mu·ªën d√πng trong **LangChain / LangGraph**:
  1. D√πng **MCP client** trong Python ƒë·ªÉ connect ƒë·∫øn server, `list_tools`, `call_tool`.
  2. **Wrap** c√°c MCP tools ƒë√≥ th√†nh **LangChain `StructuredTool`**.
  3. D√πng nh∆∞ tools b√¨nh th∆∞·ªùng trong **agent LangChain** ho·∫∑c **nodes trong LangGraph**.

D∆∞·ªõi ƒë√¢y l√† **demo t·ªëi gi·∫£n**, d·ªÖ hi·ªÉu, c√≥ th·ªÉ d√πng production sau khi th√™m retry/logging.

---

### 1. MCP client wrapper cho external server (vd: Playwright MCP)

V√≠ d·ª•: server Playwright l√† npm package `@modelcontextprotocol/server-playwright`.

```python
"""
External MCP Client Wrapper cho server Playwright (ho·∫∑c b·∫•t k·ª≥ MCP server n√†o)
- Transport: stdio (npx / node)
"""

import asyncio
from typing import Any, Dict, List, Optional

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client


class ExternalMCPClient:
    """Client Python ƒë·ªÉ n√≥i chuy·ªán v·ªõi external MCP server (Playwright, GitHub, ...)."""

    def __init__(
        self,
        name: str,
        command: str,
        args: Optional[List[str]] = None,
        env: Optional[Dict[str, str]] = None,
        cwd: Optional[str] = None,
    ):
        self.name = name
        self.command = command
        self.args = args or []
        self.env = env or {}
        self.cwd = cwd

        self._session: Optional[ClientSession] = None
        self._read = None
        self._write = None
        self._ctx = None  # stdio context
        self._tools_cache: Optional[List[Dict[str, Any]]] = None

    async def _ensure_connected(self):
        """Connect ƒë·∫øn MCP server n·∫øu ch∆∞a connect."""
        if self._session is not None:
            return

        params = StdioServerParameters(
            command=self.command,
            args=self.args,
            env=self.env or None,
            cwd=self.cwd,
        )
        self._ctx = stdio_client(params)
        self._read, self._write = await self._ctx.__aenter__()
        self._session = ClientSession(self._read, self._write)
        await self._session.initialize()

    async def list_tools(self) -> List[Dict[str, Any]]:
        """G·ªçi `tools/list` v√† cache k·∫øt qu·∫£."""
        if self._tools_cache is not None:
            return self._tools_cache

        await self._ensure_connected()
        resp = await self._session.list_tools()
        tools = []
        for t in resp.tools:
            tools.append(
                {
                    "name": t.name,
                    "description": t.description or "",
                    "input_schema": t.inputSchema or {},
                }
            )
        self._tools_cache = tools
        return tools

    async def call_tool(self, name: str, arguments: Dict[str, Any]) -> Any:
        """G·ªçi `tools/call`."""
        await self._ensure_connected()
        result = await self._session.call_tool(name, arguments)

        if result.isError:
            # Tr·∫£ v·ªÅ error c√≥ c·∫•u tr√∫c
            msg = result.content[0].text if result.content else "Unknown error"
            return {"success": False, "error": msg}

        # Gom text/data t·ª´ content
        text = ""
        for item in result.content or []:
            if hasattr(item, "text"):
                text += item.text
            elif hasattr(item, "data"):
                text += str(item.data)
        return {"success": True, "result": text or result.content}

    async def close(self):
        """ƒê√≥ng k·∫øt n·ªëi."""
        if self._ctx is not None:
            await self._ctx.__aexit__(None, None, None)
            self._ctx = None
        self._session = None
        self._read = None
        self._write = None
```

V√≠ d·ª• d√πng v·ªõi Playwright MCP:

```python
playwright_client = ExternalMCPClient(
    name="playwright",
    command="npx",
    args=["-y", "@modelcontextprotocol/server-playwright"],
    env={},  # th√™m token, config n·∫øu server c·∫ßn
)
```

---

### 2. Adapter: MCP tools ‚Üí LangChain `StructuredTool`

```python
from typing import Any, Dict, List, Optional
from langchain_core.tools import StructuredTool
from langchain_core.pydantic_v1 import BaseModel as LCBaseModel, Field


class ExternalMCPToLangChainAdapter:
    """Convert tools t·ª´ ExternalMCPClient ‚Üí LangChain StructuredTool."""

    def __init__(self, client: ExternalMCPClient):
        self.client = client
        self._tools: Optional[List[StructuredTool]] = None

    async def get_tools(self) -> List[StructuredTool]:
        if self._tools is not None:
            return self._tools

        mcp_tools = await self.client.list_tools()
        tools: List[StructuredTool] = []
        for t in mcp_tools:
            tools.append(self._to_structured_tool(t))
        self._tools = tools
        return tools

    def _to_structured_tool(self, mcp_tool: Dict[str, Any]) -> StructuredTool:
        name = mcp_tool["name"]
        description = mcp_tool["description"]
        schema = mcp_tool["input_schema"]

        # 1) JSON Schema ‚Üí Pydantic model (simple version)
        props = schema.get("properties", {})
        required = set(schema.get("required", []))

        fields = {}
        for prop_name, prop_schema in props.items():
            json_type = prop_schema.get("type", "string")
            py_type = self._json_type_to_python(json_type)
            desc = prop_schema.get("description", "")

            if prop_name in required:
                fields[prop_name] = (py_type, Field(description=desc))
            else:
                fields[prop_name] = (Optional[py_type], Field(default=None, description=desc))

        model_name = f"{self.client.name}_{name}_Input"
        ArgsModel = type(model_name, (LCBaseModel,), fields)

        # 2) H√†m g·ªçi MCP tool
        async def _call(**kwargs) -> str:
            res = await self.client.call_tool(name, kwargs)
            import json
            return json.dumps(res, ensure_ascii=False, indent=2)

        # 3) StructuredTool
        return StructuredTool(
            name=name,
            description=description,
            args_schema=ArgsModel,
            func=_call,
            coroutine=_call,
        )

    def _json_type_to_python(self, t: str):
        return {
            "string": str,
            "number": float,
            "integer": int,
            "boolean": bool,
            "array": list,
            "object": dict,
        }.get(t, str)
```

---

### 3. D√πng trong **LangChain Agent**

```python
import asyncio
from langchain_openai import ChatOpenAI
from langchain.agents import create_openai_tools_agent, AgentExecutor
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder


async def build_playwright_langchain_agent() -> AgentExecutor:
    # 1. T·∫°o MCP client cho Playwright
    client = ExternalMCPClient(
        name="playwright",
        command="npx",
        args=["-y", "@modelcontextprotocol/server-playwright"],
    )

    # 2. Convert tools ‚Üí LangChain tools
    adapter = ExternalMCPToLangChainAdapter(client)
    tools = await adapter.get_tools()

    # 3. LLM
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    # 4. Prompt
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", "B·∫°n l√† AI, c√≥ th·ªÉ d√πng Playwright MCP tools ƒë·ªÉ duy·ªát web v√† tr·∫£ l·ªùi."),
            ("human", "{input}"),
            MessagesPlaceholder("agent_scratchpad"),
        ]
    )

    # 5. T·∫°o agent
    agent = create_openai_tools_agent(llm, tools, prompt)

    # 6. Executor
    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
    return executor


async def demo_langchain():
    agent = await build_playwright_langchain_agent()
    result = await agent.ainvoke(
        {"input": "M·ªü trang https://example.com v√† cho t√¥i bi·∫øt title l√† g√¨."}
    )
    print(result["output"])


# asyncio.run(demo_langchain())
```

---

### 4. D√πng trong **LangGraph**

```python
from typing import TypedDict, Annotated, Optional
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, ToolExecutor
from langchain_openai import ChatOpenAI


class GraphState(TypedDict):
    messages: Annotated[list, add_messages]


async def build_playwright_langgraph_app():
    # MCP client + tools
    client = ExternalMCPClient(
        name="playwright",
        command="npx",
        args=["-y", "@modelcontextprotocol/server-playwright"],
    )
    adapter = ExternalMCPToLangChainAdapter(client)
    tools = await adapter.get_tools()

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    llm_with_tools = llm.bind_tools(tools)
    tool_executor = ToolExecutor(tools)

    def agent_node(state: GraphState):
        msgs = state["messages"]
        resp = llm_with_tools.invoke(msgs)
        return {"messages": [resp]}

    async def tools_node(state: GraphState):
        msgs = state["messages"]
        last = msgs[-1]
        res = await tool_executor.ainvoke({"messages": [last]})
        return {"messages": res["messages"]}

    def should_continue(state: GraphState) -> str:
        last = state["messages"][-1]
        if getattr(last, "tool_calls", None):
            return "tools"
        return "end"

    graph = StateGraph(GraphState)
    graph.add_node("agent", agent_node)
    graph.add_node("tools", tools_node)
    graph.set_entry_point("agent")
    graph.add_conditional_edges(
        "agent",
        should_continue,
        {"tools": "tools", "end": END},
    )
    graph.add_edge("tools", "agent")
    app = graph.compile()
    return app


async def demo_langgraph():
    from langchain_core.messages import HumanMessage

    app = await build_playwright_langgraph_app()
    result = await app.ainvoke(
        {"messages": [HumanMessage(content="D√πng browser ƒë·ªÉ m·ªü https://example.com v√† ƒë·ªçc title.")]}
    )
    print(result["messages"][-1].content)


# asyncio.run(demo_langgraph())
```

---

### 5. T√≥m t·∫Øt quy tr√¨nh cho **m·ªçi external MCP server** (Playwright, GitHub, ‚Ä¶)

- **B∆∞·ªõc 1**: Kh·ªüi ch·∫°y server (docker / `npx @modelcontextprotocol/server-xyz`).
- **B∆∞·ªõc 2**: T·∫°o `ExternalMCPClient`:
  - N·∫øu server stdio ‚Üí d√πng `mcp.client.stdio`.
  - N·∫øu server HTTP (nh∆∞ Google Workspace MCP) ‚Üí d√πng `httpx` (gi·ªëng `HTTPMCPServerWrapper` trong repo c·ªßa b·∫°n).
- **B∆∞·ªõc 3**: `list_tools()` ‚Üí convert th√†nh `StructuredTool` (adapter).
- **B∆∞·ªõc 4**:
  - LangChain: d√πng `create_openai_tools_agent` + `AgentExecutor`.
  - LangGraph: bind tools v√†o LLM + `ToolExecutor` + `ToolNode`.

N·∫øu b·∫°n mu·ªën, m√¨nh c√≥ th·ªÉ vi·∫øt ri√™ng m·ªôt phi√™n b·∫£n **HTTP MCP client adapter** (gi·ªëng Google Workspace MCP) nh∆∞ng r√∫t g·ªçn, ƒë·ªÉ b·∫°n c·∫Øm nhanh b·∫•t k·ª≥ MCP server HTTP n√†o (kh√¥ng ch·ªâ Playwright).

---
ƒêang ki·ªÉm tra c√°ch deploy MCP server hi·ªán t·∫°i trong codebase v√† c√°c best practices:


[5 tools called]


T·ªïng h·ª£p best practices ƒë·ªÉ deploy MCP server chu·∫©n, d·ª±a tr√™n codebase hi·ªán t·∫°i v√† industry standards:

## Best practices: Deploy MCP server chu·∫©n

### 1. Ch·ªçn transport: stdio vs HTTP

#### Option A: stdio (cho development/local, single-user)

∆Øu ƒëi·ªÉm:
- ƒê∆°n gi·∫£n, kh√¥ng c·∫ßn network
- Ph√π h·ª£p single-user, local development
- √çt overhead

Nh∆∞·ª£c ƒëi·ªÉm:
- Kh√¥ng scale ƒë∆∞·ª£c (1 process = 1 connection)
- Kh√¥ng ph√π h·ª£p multi-user
- Kh√≥ monitor/debug

Khi n√†o d√πng:
- Development
- Single-user desktop apps
- Testing

```python
# Client connect qua stdio
client = ExternalMCPClient(
    name="playwright",
    command="npx",
    args=["-y", "@modelcontextprotocol/server-playwright"],
)
```

#### Option B: HTTP (cho production, multi-user) ‚Äî khuy·∫øn ngh·ªã

∆Øu ƒëi·ªÉm:
- Stateless, scale ƒë∆∞·ª£c
- Multi-user support (bearer tokens)
- D·ªÖ monitor, health check
- Load balancing ƒë∆∞·ª£c
- Ph√π h·ª£p microservices

Nh∆∞·ª£c ƒëi·ªÉm:
- C·∫ßn HTTP server
- Ph·ª©c t·∫°p h∆°n m·ªôt ch√∫t

Khi n√†o d√πng:
- Production
- Multi-user systems
- Cloud deployment
- Microservices architecture

```python
# Server ch·∫°y HTTP mode
CMD ["uv", "run", "main.py", "--transport", "streamable-http"]
```

Khuy·∫øn ngh·ªã: D√πng HTTP cho production.

---

### 2. Deployment patterns

#### Pattern 1: Docker Compose (development/staging)

```yaml
# docker-compose-mcp.yml
version: '3.8'

services:
  # MCP Server v·ªõi HTTP transport
  playwright-mcp:
    build:
      context: ./mcp-servers/playwright-mcp
      dockerfile: Dockerfile
    container_name: mcp-playwright
    ports:
      - "${PLAYWRIGHT_MCP_PORT:-8001}:8000"
    environment:
      - MCP_TRANSPORT=http
      - MCP_PORT=8000
      - LOG_LEVEL=INFO
      # Secrets t·ª´ .env
      - PLAYWRIGHT_BROWSER_PATH=/usr/bin/chromium
    restart: unless-stopped
    networks:
      - mcp-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # GitHub MCP Server
  github-mcp:
    build:
      context: ./mcp-servers/github-mcp
    container_name: mcp-github
    ports:
      - "${GITHUB_MCP_PORT:-8002}:8000"
    environment:
      - MCP_TRANSPORT=http
      - GITHUB_TOKEN=${GITHUB_TOKEN}  # Secret t·ª´ .env
    restart: unless-stopped
    networks:
      - mcp-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  mcp-network:
    driver: bridge
    name: mcp-network

# Volumes cho persistent data (n·∫øu c·∫ßn)
volumes:
  playwright-data:
```

Dockerfile m·∫´u:

```dockerfile
# Dockerfile cho MCP Server (v√≠ d·ª•: Playwright)
FROM node:20-slim

WORKDIR /app

# Install Playwright browsers
RUN npx playwright install chromium --with-deps

# Install MCP server package
RUN npm install -g @modelcontextprotocol/server-playwright

# Expose port
EXPOSE 8000

# Health check script
COPY healthcheck.sh /healthcheck.sh
RUN chmod +x /healthcheck.sh

# Run v·ªõi HTTP transport
CMD ["npx", "@modelcontextprotocol/server-playwright", "--transport", "http", "--port", "8000"]
```

#### Pattern 2: Kubernetes (production)

```yaml
# k8s/mcp-servers/playwright-mcp.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: playwright-mcp
  namespace: mcp-servers
spec:
  replicas: 3  # Scale horizontally
  selector:
    matchLabels:
      app: playwright-mcp
  template:
    metadata:
      labels:
        app: playwright-mcp
    spec:
      containers:
      - name: playwright-mcp
        image: your-registry/playwright-mcp:latest
        ports:
        - containerPort: 8000
        env:
        - name: MCP_TRANSPORT
          value: "http"
        - name: MCP_PORT
          value: "8000"
        - name: LOG_LEVEL
          value: "INFO"
        # Secrets t·ª´ Kubernetes Secret
        - name: PLAYWRIGHT_BROWSER_PATH
          value: "/usr/bin/chromium"
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: playwright-mcp-service
  namespace: mcp-servers
spec:
  selector:
    app: playwright-mcp
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP  # Internal only
---
# Ingress (n·∫øu c·∫ßn expose public)
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: playwright-mcp-ingress
  namespace: mcp-servers
spec:
  rules:
  - host: mcp-playwright.yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: playwright-mcp-service
            port:
              number: 80
```

#### Pattern 3: Serverless (AWS Lambda, Cloud Functions)

```python
# serverless_mcp_handler.py
import json
from mcp.server.fastmcp import FastMCP

# FastMCP cho serverless
mcp = FastMCP("playwright-mcp")

@mcp.tool()
async def navigate(url: str) -> str:
    """Navigate to URL."""
    # Implementation
    return f"Navigated to {url}"

# Lambda handler
def lambda_handler(event, context):
    """AWS Lambda handler."""
    # Parse MCP request t·ª´ event
    mcp_request = json.loads(event["body"])
    
    # Process request
    response = mcp.handle_request(mcp_request)
    
    return {
        "statusCode": 200,
        "body": json.dumps(response),
    }
```

---

### 3. Multi-user support (OAuth 2.1)

#### Architecture: Stateless HTTP + Bearer Tokens

```yaml
# docker-compose.yml
services:
  google-workspace-mcp:
    build: ./google-workspace-mcp
    environment:
      # ‚úÖ Stateless mode cho multi-user
      - WORKSPACE_MCP_STATELESS_MODE=true
      - MCP_ENABLE_OAUTH21=true
      - WORKSPACE_MCP_PORT=8000
    # ‚úÖ Kh√¥ng c·∫ßn volumes (stateless)
    # ‚úÖ M·ªói request t·ª± inject token
```

Client code:

```python
# HTTP MCP Client v·ªõi token injection
class HTTPMCPServerWrapper:
    async def _get_headers(self, user_id: Optional[str] = None) -> Dict[str, str]:
        headers = {"Content-Type": "application/json"}
        
        # ‚úÖ Inject bearer token t·ª´ OAuth repository
        if user_id:
            token = await get_google_token_for_user(user_id)
            if token:
                headers["Authorization"] = f"Bearer {token}"
        
        return headers
```

---

### 4. Security best practices

#### A. Secrets management

```yaml
# ‚ùå KH√îNG l√†m th·∫ø n√†y
environment:
  - GITHUB_TOKEN=ghp_abc123  # Hard-coded secret

# ‚úÖ L√†m th·∫ø n√†y
environment:
  - GITHUB_TOKEN=${GITHUB_TOKEN}  # T·ª´ .env ho·∫∑c secret manager
```

D√πng Kubernetes Secrets:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: github-mcp-secrets
type: Opaque
stringData:
  GITHUB_TOKEN: "ghp_abc123"
---
env:
- name: GITHUB_TOKEN
  valueFrom:
    secretKeyRef:
      name: github-mcp-secrets
      key: GITHUB_TOKEN
```

#### B. Network isolation

```yaml
# ‚úÖ Internal network only
networks:
  mcp-network:
    driver: bridge
    internal: true  # Kh√¥ng expose ra ngo√†i

# ‚úÖ Service discovery qua service name
services:
  app:
    environment:
      - PLAYWRIGHT_MCP_URL=http://playwright-mcp:8000  # Internal DNS
```

#### C. Authentication & Authorization

```python
# ‚úÖ Validate bearer token trong MCP server
async def validate_token(token: str) -> Optional[str]:
    """Validate token v√† return user_id."""
    # Verify JWT ho·∫∑c check v·ªõi auth service
    payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
    return payload.get("user_id")

# ‚úÖ Inject v√†o MCP request
headers = {
    "Authorization": f"Bearer {token}",
    "X-User-ID": user_id,  # Optional: explicit user context
}
```

---

### 5. Monitoring & observability

#### A. Health checks

```python
# healthcheck.py trong MCP server
from fastapi import FastAPI

app = FastAPI()

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {
        "status": "healthy",
        "version": "1.0.0",
        "tools_count": len(discovered_tools),
    }
```

Docker healthcheck:

```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s
```

#### B. Logging

```python
# Structured logging
import structlog

logger = structlog.get_logger()

logger.info(
    "mcp_tool_called",
    tool_name="playwright_navigate",
    user_id=user_id,
    duration_ms=150,
    success=True,
)
```

#### C. Metrics (Prometheus)

```python
from prometheus_client import Counter, Histogram

tool_calls_total = Counter(
    "mcp_tool_calls_total",
    "Total tool calls",
    ["tool_name", "status"],
)

tool_duration = Histogram(
    "mcp_tool_duration_seconds",
    "Tool execution duration",
    ["tool_name"],
)

# Trong tool handler
with tool_duration.labels(tool_name="navigate").time():
    result = await execute_tool(...)
    tool_calls_total.labels(
        tool_name="navigate",
        status="success" if result else "error",
    ).inc()
```

---

### 6. Scaling strategies

#### A. Horizontal scaling (HTTP transport)

```yaml
# Kubernetes: Scale replicas
replicas: 5

# Load balancer
apiVersion: v1
kind: Service
spec:
  type: LoadBalancer
  sessionAffinity: None  # Stateless ‚Üí no affinity needed
```

#### B. Connection pooling (client-side)

```python
import httpx

# ‚úÖ Connection pool cho HTTP client
class HTTPMCPServerWrapper:
    def __init__(self, base_url: str):
        self._client = httpx.AsyncClient(
            base_url=base_url,
            limits=httpx.Limits(
                max_keepalive_connections=20,
                max_connections=100,
            ),
            timeout=30.0,
        )
```

#### C. Rate limiting

```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/mcp")
@limiter.limit("100/minute")  # Rate limit
async def handle_mcp_request(request: Request):
    # Process request
    pass
```

---

### 7. Deployment checklist

```markdown
## ‚úÖ Pre-Deployment Checklist

### Infrastructure
- [ ] Docker image built v√† tested
- [ ] Health check endpoint implemented
- [ ] Logging configured (structured logs)
- [ ] Metrics exposed (Prometheus format)
- [ ] Secrets managed (kh√¥ng hard-code)

### Network
- [ ] Internal network configured
- [ ] Service discovery working
- [ ] Firewall rules set
- [ ] Load balancer configured (n·∫øu c·∫ßn)

### Security
- [ ] Authentication implemented (OAuth/Bearer tokens)
- [ ] Authorization checked (per-user permissions)
- [ ] Secrets t·ª´ secret manager
- [ ] Network isolation (internal only)

### Monitoring
- [ ] Health checks working
- [ ] Logs aggregated (ELK/CloudWatch)
- [ ] Metrics collected (Prometheus)
- [ ] Alerts configured (PagerDuty/Slack)

### Testing
- [ ] Unit tests passed
- [ ] Integration tests passed
- [ ] Load testing done
- [ ] Fallback tested (n·∫øu c√≥ internal MCP)
```

---

### 8. Recommended architecture (production)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Production Architecture                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Load      ‚îÇ
                    ‚îÇ  Balancer   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                  ‚îÇ                  ‚îÇ
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ MCP     ‚îÇ       ‚îÇ MCP     ‚îÇ       ‚îÇ MCP     ‚îÇ
   ‚îÇ Server  ‚îÇ       ‚îÇ Server  ‚îÇ       ‚îÇ Server  ‚îÇ
   ‚îÇ (Pod 1) ‚îÇ       ‚îÇ (Pod 2) ‚îÇ       ‚îÇ (Pod 3) ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                  ‚îÇ                  ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Redis     ‚îÇ
                    ‚îÇ  (Cache)    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ PostgreSQL  ‚îÇ
                    ‚îÇ  (Tokens)   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### T√≥m t·∫Øt: Best practices

1. Transport: HTTP cho production (stateless, scalable)
2. Deployment: Docker Compose (dev) ‚Üí Kubernetes (prod)
3. Multi-user: Stateless mode + Bearer tokens
4. Security: Secrets management, network isolation, auth
5. Monitoring: Health checks, structured logs, metrics
6. Scaling: Horizontal scaling v·ªõi load balancer
7. Testing: Health checks, integration tests, load testing

Khuy·∫øn ngh·ªã: D√πng HTTP transport + Docker/Kubernetes + OAuth 2.1 + health checks + monitoring. ƒê√¢y l√† c√°ch chu·∫©n nh·∫•t cho production.


### √ù ng·∫Øn g·ªçn: Deploy b·∫±ng Docker Compose xong th√¨ d√πng nh∆∞ **1 HTTP service** b√¨nh th∆∞·ªùng

B·∫°n ƒë√£ c√≥ s·∫µn flow chu·∫©n trong repo r·ªìi (Google Workspace MCP l√† v√≠ d·ª• ho√†n ch·ªânh). C√°ch d√πng sau khi `docker-compose` r·∫•t ƒë∆°n gi·∫£n, theo 3 b∆∞·ªõc:

---

### 1. Ch·∫°y MCP server b·∫±ng Docker Compose

V√≠ d·ª• v·ªõi Google Workspace MCP:

```bash
cd deploy
docker-compose -f docker-compose-mcp.yml up -d google-workspace-mcp
```

N√≥ s·∫Ω ch·∫°y MCP server ·ªü `http://localhost:8000` (trong compose ƒë√£ mapping port 8000).

---

### 2. C·∫•u h√¨nh app ƒë·ªÉ tr·ªè t·ªõi MCP server

Trong `.env` c·ªßa app Python:

```bash
GOOGLE_WORKSPACE_MCP_ENABLED=true
GOOGLE_WORKSPACE_MCP_URL=http://localhost:8000
GOOGLE_WORKSPACE_MCP_TIMEOUT=30
```

`app.common.config.Settings` s·∫Ω ƒë·ªçc c√°c bi·∫øn n√†y, v√† trong `mcp_init.py` b·∫°n ƒë√£ c√≥:

```python
if settings.GOOGLE_WORKSPACE_MCP_ENABLED:
    from app.module.multi_agents.layer_3_action.internal_mcp_servers.http_mcp_wrapper import (
        HTTPMCPServerWrapper,
        get_google_token_for_user,
    )

    drive_server = HTTPMCPServerWrapper(
        name="google_workspace",
        base_url=settings.GOOGLE_WORKSPACE_MCP_URL,
        get_token_callback=get_google_token_for_user,
        timeout=settings.GOOGLE_WORKSPACE_MCP_TIMEOUT,
    )
else:
    drive_server = InternalDriveMCPServer()
```

‚Üí Ch·ªâ c·∫ßn **b·∫≠t flag + URL ƒë√∫ng**, app s·∫Ω t·ª± d√πng external MCP server ƒëang ch·∫°y trong Docker.

---

### 3. App/agent d√πng MCP server nh∆∞ th·∫ø n√†o?

V·ªõi multi-agent hi·ªán t·∫°i, flow ƒë√£ wired s·∫µn:

- `init_mcp()`:
  - T·∫°o `HTTPMCPServerWrapper` (n·∫øu ENABLED)
  - `registry.register_mcp_server("drive", drive_server)`
  - `adapter = MCPToolAdapter(bus=bus, registry=registry)`

- Agent (v√≠ d·ª• `DriveAgent`) ch·ªâ c·∫ßn g·ªçi:

```python
res = await self.mcp.execute(
    MCPToolRequest(
        agent_name=self.name,
        tool_server="drive",           # ch√≠nh l√† HTTPMCPServerWrapper ƒëang tr·ªè ra Docker MCP
        tool_name="drive_list_files",  # ho·∫∑c t√™n tool b·∫°n mu·ªën
        arguments={"folder_id": None},
    )
)
```

Kh√¥ng c·∫ßn quan t√¢m Docker hay internal, v√¨:
- Docker MCP ‚Üí HTTPMCPServerWrapper ‚Üí ToolRegistry ‚Üí MCPToolAdapter ‚Üí Agent  
- N·∫øu t·∫Øt external (ENABLE=false) ‚Üí fallback `InternalDriveMCPServer` c√πng interface.

---

### 4. N·∫øu b·∫°n mu·ªën test g·ªçi tr·ª±c ti·∫øp (kh√¥ng qua agent)

V√≠ d·ª•: g·ªçi th·∫≥ng tool t·ª´ HTTPMCPServerWrapper:

```python
from app.module.multi_agents.layer_3_action.internal_mcp_servers.http_mcp_wrapper import (
    HTTPMCPServerWrapper,
    get_google_token_for_user,
)
from app.common.config import settings

server = HTTPMCPServerWrapper(
    name="google_workspace",
    base_url=settings.GOOGLE_WORKSPACE_MCP_URL,
    get_token_callback=get_google_token_for_user,
    timeout=settings.GOOGLE_WORKSPACE_MCP_TIMEOUT,
)

# Discover tools (HTTP POST /mcp method=tools/list)
tools = await server.discover_tools()
print([t.name for t in tools])

# Call 1 tool (HTTP POST /mcp method=tools/call)
result = await server.call_tool(
    tool_name="drive_list_files",
    arguments={"page_size": 5},
    user_id="user_a",  # ƒë·ªÉ wrapper t·ª± inject Bearer token
)
print(result)
```

---

### T√≥m t·∫Øt

- **Deploy**: `docker-compose -f docker-compose-mcp.yml up -d` ‚Üí MCP l·∫Øng nghe HTTP (port 8000).
- **Config app**: `GOOGLE_WORKSPACE_MCP_ENABLED=true`, `GOOGLE_WORKSPACE_MCP_URL=http://localhost:8000`.
- **S·ª≠ d·ª•ng**:
  - Multi-agent: qua `MCPToolAdapter` + `tool_server="drive"`.
  - Ho·∫∑c tr·ª±c ti·∫øp: d√πng `HTTPMCPServerWrapper.call_tool(...)`.

B·∫°n ch·ªâ c·∫ßn nh·ªõ: **Docker Compose ch·ªâ l√†m nhi·ªám v·ª• ch·∫°y MCP server; code Python c·ªßa b·∫°n n√≥i chuy·ªán v·ªõi n√≥ nh∆∞ 1 HTTP MCP service qua `HTTPMCPServerWrapper`.**