
1. https://dev.to/rajeev_3ce9f280cbae73b234/building-smarter-local-ai-agents-with-mcp-a-simple-client-server-example-4lfm
2. 
![](https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Felrj904jg9ydlofywwdl.png)



```
ALL IN ONE , MECE, DEEP RESEARCH HÆ°á»›ng dáº«n CHI TIáº¾T vá» architect, cÃ¡ch dÃ¹ng, cÃ¡ch triá»ƒn khai,  mcp tools trong cÃ¡c luá»“ng agent??Â 
 MECE táº¥t cáº£ cÃ¡c loáº¡i tools, vÃ  táº¥t cáº£ cÃ¡c loáº¡i cÃ¡ch triá»ƒn khai - Full code

```

```
HÆ°á»›ng dáº«n vá» cÃ¡ch dÃ¹ng mcp tools trong cÃ¡c luá»“ng agent?? 
Full code
```


<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# HÆ°á»›ng dáº«n vá» cÃ¡ch dÃ¹ng mcp tools trong cÃ¡c luá»“ng agent??

Full code

TÃ´i Ä‘Ã£ tÃ¬m hiá»ƒu chi tiáº¿t vá» cÃ¡ch sá»­ dá»¥ng MCP tools trong cÃ¡c luá»“ng agent vÃ  tá»•ng há»£p thÃ nh hÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§ vá»›i code hoÃ n chá»‰nh dÆ°á»›i Ä‘Ã¢y.

# HÆ°á»›ng Dáº«n Äáº§y Äá»§: Sá»­ Dá»¥ng MCP Tools Trong Luá»“ng Agent

## Tá»•ng Quan

Model Context Protocol (MCP) lÃ  giao thá»©c chuáº©n giÃºp káº¿t ná»‘i AI agents vá»›i cÃ¡c cÃ´ng cá»¥ vÃ  nguá»“n dá»¯ liá»‡u bÃªn ngoÃ i. MCP hoáº¡t Ä‘á»™ng theo kiáº¿n trÃºc client-server, cho phÃ©p LLM Ä‘á»™ng sá»­ dá»¥ng tools thÃ´ng qua má»™t giao thá»©c thá»‘ng nháº¥t.[^1][^2][^3][^4]

**Kiáº¿n trÃºc MCP:**

- **MCP Server**: Cung cáº¥p tools, resources, prompts cho agents
- **MCP Client**: Náº±m trong agent, giao tiáº¿p vá»›i server
- **Transport**: stdio (local), HTTP/SSE (remote), Streamable HTTP


## 1. XÃ¢y Dá»±ng MCP Server

### Setup MÃ´i TrÆ°á»ng

```bash
# CÃ i Ä‘áº·t UV package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# Táº¡o project
uv init mcp-agent-demo
cd mcp-agent-demo

# CÃ i Ä‘áº·t dependencies
uv add "mcp[cli]" httpx
```


### Code MCP Server HoÃ n Chá»‰nh

**File: `mcp_server/agent_tools_server.py`**

```python
from typing import Any
from mcp.server.fastmcp import FastMCP
import httpx

# Khá»Ÿi táº¡o FastMCP server
mcp = FastMCP("agent_tools")

# Constants
API_BASE = "https://api.example.com"
USER_AGENT = "mcp-agent/1.0"

# ==================== HELPER FUNCTIONS ====================

async def make_api_request(url: str) -> dict[str, Any] | None:
    """Thá»±c hiá»‡n API request vá»›i error handling."""
    headers = {"User-Agent": USER_AGENT, "Accept": "application/json"}
    
    async with httpx.AsyncClient() as client:
        try:
            response = await client.get(url, headers=headers, timeout=30.0)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"API Error: {e}")
            return None

# ==================== TOOLS ====================

@mcp.tool()
async def search_data(query: str, limit: int = 10) -> str:
    """TÃ¬m kiáº¿m dá»¯ liá»‡u tá»« API.
    
    Args:
        query: Tá»« khÃ³a tÃ¬m kiáº¿m
        limit: Sá»‘ lÆ°á»£ng káº¿t quáº£ tá»‘i Ä‘a
    """
    url = f"{API_BASE}/search?q={query}&limit={limit}"
    data = await make_api_request(url)
    
    if not data:
        return "KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£."
    
    results = []
    for item in data.get("items", []):
        results.append(f"- {item.get('title')}: {item.get('description')}")
    
    return "\n".join(results) if results else "KhÃ´ng cÃ³ dá»¯ liá»‡u."

@mcp.tool()
async def calculate(expression: str) -> str:
    """TÃ­nh toÃ¡n biá»ƒu thá»©c toÃ¡n há»c.
    
    Args:
        expression: Biá»ƒu thá»©c cáº§n tÃ­nh (vd: "2 + 2", "10 * 5")
    """
    try:
        # Chá»‰ cho phÃ©p cÃ¡c phÃ©p tÃ­nh an toÃ n
        result = eval(expression, {"__builtins__": {}}, {})
        return f"Káº¿t quáº£: {result}"
    except Exception as e:
        return f"Lá»—i tÃ­nh toÃ¡n: {str(e)}"

@mcp.tool()
async def fetch_weather(city: str) -> str:
    """Láº¥y thÃ´ng tin thá»i tiáº¿t cho thÃ nh phá»‘.
    
    Args:
        city: TÃªn thÃ nh phá»‘
    """
    url = f"https://api.weatherapi.com/v1/current.json?q={city}"
    data = await make_api_request(url)
    
    if not data:
        return f"KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin thá»i tiáº¿t cho {city}."
    
    current = data.get("current", {})
    return f"""
Thá»i tiáº¿t táº¡i {city}:
- Nhiá»‡t Ä‘á»™: {current.get('temp_c')}Â°C
- Äiá»u kiá»‡n: {current.get('condition', {}).get('text')}
- Äá»™ áº©m: {current.get('humidity')}%
"""

@mcp.tool()
async def get_user_info(user_id: int) -> str:
    """Láº¥y thÃ´ng tin ngÆ°á»i dÃ¹ng tá»« database.
    
    Args:
        user_id: ID cá»§a ngÆ°á»i dÃ¹ng
    """
    # Giáº£ láº­p database query
    users = {
        1: {"name": "Nguyá»…n VÄƒn A", "email": "nva@example.com", "role": "Admin"},
        2: {"name": "Tráº§n Thá»‹ B", "email": "ttb@example.com", "role": "User"}
    }
    
    user = users.get(user_id)
    if not user:
        return f"KhÃ´ng tÃ¬m tháº¥y user vá»›i ID {user_id}."
    
    return f"User: {user['name']}\nEmail: {user['email']}\nRole: {user['role']}"

# ==================== PROMPTS ====================

@mcp.prompt()
async def analyst_prompt(task: str) -> str:
    """Prompt cho agent phÃ¢n tÃ­ch dá»¯ liá»‡u.
    
    Args:
        task: Nhiá»‡m vá»¥ cáº§n phÃ¢n tÃ­ch
    """
    return f"""Báº¡n lÃ  má»™t data analyst chuyÃªn nghiá»‡p. 
Nhiá»‡m vá»¥ cá»§a báº¡n: {task}

HÃ£y:
1. PhÃ¢n tÃ­ch dá»¯ liá»‡u má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng
2. ÄÆ°a ra insights quan trá»ng
3. Äá» xuáº¥t actions cá»¥ thá»ƒ"""

@mcp.prompt()
async def researcher_prompt(topic: str) -> str:
    """Prompt cho agent nghiÃªn cá»©u.
    
    Args:
        topic: Chá»§ Ä‘á» nghiÃªn cá»©u
    """
    return f"""Báº¡n lÃ  má»™t researcher chuyÃªn sÃ¢u vá» {topic}.
HÃ£y tÃ¬m hiá»ƒu toÃ n diá»‡n vÃ  trÃ¬nh bÃ y:
- Tá»•ng quan
- PhÃ¢n tÃ­ch chi tiáº¿t
- Xu hÆ°á»›ng hiá»‡n táº¡i
- Khuyáº¿n nghá»‹"""

# ==================== RESOURCES ====================

@mcp.resource("config://settings")
async def get_config() -> str:
    """Resource chá»©a cáº¥u hÃ¬nh há»‡ thá»‘ng."""
    return """
{
  "api_version": "v1",
  "timeout": 30,
  "max_retries": 3,
  "enabled_features": ["search", "weather", "calculate"]
}
"""

# ==================== MAIN ====================

def main():
    """Khá»Ÿi Ä‘á»™ng MCP server."""
    print("ğŸš€ Starting MCP Agent Tools Server...")
    mcp.run(transport="stdio")

if __name__ == "__main__":
    main()
```


### Giáº£i ThÃ­ch Code Server

1. **FastMCP Framework**: Sá»­ dá»¥ng decorator `@mcp.tool()` Ä‘á»ƒ tá»± Ä‘á»™ng generate tool schemas[^5][^6]
2. **Tools**: CÃ¡c function Python Ä‘Æ°á»£c expose thÃ nh MCP tools vá»›i type hints vÃ  docstrings[^4][^5]
3. **Async Design**: Táº¥t cáº£ tools Ä‘á»u async Ä‘á»ƒ xá»­ lÃ½ I/O hiá»‡u quáº£
4. **Error Handling**: Má»—i tool cÃ³ try-catch Ä‘á»ƒ xá»­ lÃ½ lá»—i gracefully
5. **Prompts \& Resources**: Cung cáº¥p templates vÃ  config cho agents[^7][^5]

## 2. XÃ¢y Dá»±ng MCP Client + Agent

### Client Vá»›i OpenAI Agent

**File: `agent_client/openai_agent.py`**

```python
import asyncio
import os
import sys
from contextlib import AsyncExitStack
from typing import Optional

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from openai import OpenAI
import json

class MCPAgentClient:
    """MCP Client tÃ­ch há»£p OpenAI Agent."""
    
    def __init__(self):
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        
        # Khá»Ÿi táº¡o OpenAI client
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise RuntimeError("OPENAI_API_KEY khÃ´ng Ä‘Æ°á»£c set!")
        
        self.openai = OpenAI(api_key=api_key)
        self.model = "gpt-4o"
        self.max_tokens = 2000
    
    # ==================== CONNECTION ====================
    
    async def __aenter__(self):
        """Káº¿t ná»‘i Ä‘áº¿n MCP server khi enter context."""
        return self
    
    async def __aexit__(self, *args):
        """Cleanup khi exit context."""
        await self.exit_stack.aclose()
    
    async def connect_to_server(self, server_path: str):
        """Káº¿t ná»‘i Ä‘áº¿n MCP server.
        
        Args:
            server_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file server.py
        """
        try:
            # Thiáº¿t láº­p stdio transport
            server_params = StdioServerParameters(
                command="python",
                args=[server_path],
                env=None
            )
            
            # Káº¿t ná»‘i Ä‘áº¿n server
            stdio_transport = await self.exit_stack.enter_async_context(
                stdio_client(server_params)
            )
            
            read, write = stdio_transport
            
            # Táº¡o client session
            self.session = await self.exit_stack.enter_async_context(
                ClientSession(read, write)
            )
            
            # Initialize session
            await self.session.initialize()
            
            # List available tools
            tools_response = await self.session.list_tools()
            print(f"âœ… ÄÃ£ káº¿t ná»‘i! Tools: {[t.name for t in tools_response.tools]}")
            
        except Exception as e:
            raise RuntimeError(f"Lá»—i káº¿t ná»‘i server: {e}")
    
    # ==================== TOOL HANDLING ====================
    
    async def _get_mcp_tools(self) -> list:
        """Láº¥y danh sÃ¡ch tools tá»« MCP server vÃ  format cho OpenAI."""
        response = await self.session.list_tools()
        
        openai_tools = []
        for tool in response.tools:
            openai_tools.append({
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description or "No description",
                    "parameters": getattr(
                        tool, 
                        "inputSchema", 
                        {"type": "object", "properties": {}}
                    )
                }
            })
        
        return openai_tools
    
    async def _execute_tool(self, tool_call) -> dict:
        """Thá»±c thi MCP tool call.
        
        Args:
            tool_call: Tool call object tá»« OpenAI
            
        Returns:
            Dict chá»©a log vÃ  message cho OpenAI
        """
        tool_name = tool_call.function.name
        tool_args = json.loads(tool_call.function.arguments or "{}")
        
        print(f"ğŸ”§ Executing: {tool_name}({tool_args})")
        
        try:
            # Call MCP tool
            result = await self.session.call_tool(tool_name, tool_args)
            
            # Extract content
            content = result.content[^0].text if result.content else ""
            log = f"[âœ“ {tool_name} completed]"
            
        except Exception as e:
            content = f"Error: {str(e)}"
            log = f"[âœ— {tool_name} failed: {e}]"
        
        return {
            "log": log,
            "message": {
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": content
            }
        }
    
    # ==================== AGENT WORKFLOW ====================
    
    async def process_query(self, query: str) -> str:
        """Xá»­ lÃ½ query vá»›i agent workflow hoÃ n chá»‰nh.
        
        Workflow:
        1. Gá»­i query Ä‘áº¿n LLM vá»›i tools
        2. LLM quyáº¿t Ä‘á»‹nh tool nÃ o cáº§n dÃ¹ng
        3. Execute tools thÃ´ng qua MCP
        4. Gá»­i káº¿t quáº£ vá» LLM
        5. LLM táº¡o response cuá»‘i cÃ¹ng
        
        Args:
            query: User query
            
        Returns:
            Final response tá»« agent
        """
        # Khá»Ÿi táº¡o conversation
        messages = [{"role": "user", "content": query}]
        
        # Láº¥y available tools
        tools = await self._get_mcp_tools()
        
        # ===== BÆ¯á»šC 1: Initial LLM Call =====
        print(f"\nğŸ’­ Sending to LLM: {query}")
        
        response = self.openai.chat.completions.create(
            model=self.model,
            max_tokens=self.max_tokens,
            messages=messages,
            tools=tools
        )
        
        current_message = response.choices[^0].message
        result_parts = []
        
        # LÆ°u text response náº¿u cÃ³
        if current_message.content:
            result_parts.append(current_message.content)
        
        # ===== BÆ¯á»šC 2: Tool Execution Loop =====
        if tool_calls := current_message.tool_calls:
            print(f"\nğŸ”§ LLM muá»‘n dÃ¹ng {len(tool_calls)} tool(s)")
            
            # ThÃªm assistant message vÃ o history
            messages.append({
                "role": "assistant",
                "content": current_message.content or "",
                "tool_calls": tool_calls
            })
            
            # Execute tá»«ng tool
            for tool_call in tool_calls:
                tool_result = await self._execute_tool(tool_call)
                result_parts.append(tool_result["log"])
                messages.append(tool_result["message"])
            
            # ===== BÆ¯á»šC 3: Final LLM Call vá»›i Tool Results =====
            print("\nğŸ’­ Sending tool results back to LLM...")
            
            final_response = self.openai.chat.completions.create(
                model=self.model,
                max_tokens=self.max_tokens,
                messages=messages
            )
            
            # Láº¥y final response
            if content := final_response.choices[^0].message.content:
                result_parts.append(content)
        
        return "\n\n".join(result_parts)
    
    # ==================== CHAT INTERFACE ====================
    
    async def chat_loop(self):
        """Interactive chat loop vá»›i agent."""
        print("\n" + "="*50)
        print("ğŸ¤– MCP Agent Chat Started!")
        print("Commands: 'quit' Ä‘á»ƒ thoÃ¡t, 'help' Ä‘á»ƒ xem hÆ°á»›ng dáº«n")
        print("="*50 + "\n")
        
        while True:
            try:
                # Nháº­n input tá»« user
                user_input = input("\nğŸ‘¤ You: ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() == 'quit':
                    print("\nğŸ‘‹ Goodbye!")
                    break
                
                if user_input.lower() == 'help':
                    print("""
ğŸ“š CÃ¡c lá»‡nh cÃ³ thá»ƒ dÃ¹ng:
- search_data: TÃ¬m kiáº¿m dá»¯ liá»‡u
- calculate: TÃ­nh toÃ¡n
- fetch_weather: Xem thá»i tiáº¿t
- get_user_info: Láº¥y thÃ´ng tin user

VÃ­ dá»¥: "TÃ¬m kiáº¿m thÃ´ng tin vá» AI" hoáº·c "TÃ­nh 25 * 4"
                    """)
                    continue
                
                # Process query
                print("\nğŸ¤” Agent Ä‘ang suy nghÄ©...")
                response = await self.process_query(user_input)
                
                print(f"\nğŸ¤– Agent: {response}")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Interrupted. Goodbye!")
                break
            except Exception as e:
                print(f"\nâŒ Error: {str(e)}")

# ==================== MAIN ====================

async def main():
    """Main entry point."""
    if len(sys.argv) < 2:
        print("Usage: python openai_agent.py <path_to_server.py>")
        sys.exit(1)
    
    server_path = sys.argv[^1]
    
    print(f"ğŸš€ Starting MCP Agent Client...")
    print(f"ğŸ“‚ Server: {server_path}")
    
    async with MCPAgentClient() as client:
        await client.connect_to_server(server_path)
        await client.chat_loop()

if __name__ == "__main__":
    asyncio.run(main())
```


## 3. TÃ­ch Há»£p Vá»›i Frameworks Phá»• Biáº¿n

### 3.1 CrewAI Integration

**File: `frameworks/crewai_mcp_agent.py`**

```python
from crewai import Agent, Task, Crew
from crewai.mcp import MCPServerStdio

# ===== CÃ¡ch 1: String-based (ÄÆ¡n giáº£n) =====

agent_simple = Agent(
    role="Research Analyst",
    goal="PhÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  Ä‘Æ°a ra insights",
    backstory="Expert researcher with MCP tools access",
    mcps=[
        "https://mcp.exa.ai/mcp?api_key=your_key",  # External MCP
        "crewai-amp:financial-data",  # CrewAI marketplace
    ]
)

# ===== CÃ¡ch 2: Structured Config (Kiá»ƒm soÃ¡t Ä‘áº§y Ä‘á»§) =====

from crewai.mcp.filters import create_static_tool_filter

agent_advanced = Agent(
    role="Data Engineer", 
    goal="Process vÃ  transform data",
    backstory="Senior engineer with full MCP control",
    mcps=[
        # Stdio transport cho local server
        MCPServerStdio(
            command="python",
            args=["mcp_server/agent_tools_server.py"],
            env={"API_KEY": "your_key"},
            tool_filter=create_static_tool_filter(
                allowed_tool_names=["search_data", "calculate"]
            ),
            cache_tools_list=True
        )
    ]
)

# Táº¡o task vÃ  crew
task = Task(
    description="PhÃ¢n tÃ­ch dá»¯ liá»‡u thá»‹ trÆ°á»ng AI trong Q1 2025",
    expected_output="BÃ¡o cÃ¡o phÃ¢n tÃ­ch vá»›i insights vÃ  recommendations",
    agent=agent_advanced
)

crew = Crew(
    agents=[agent_advanced],
    tasks=[task],
    verbose=True
)

# Cháº¡y crew
result = crew.kickoff()
print(result)
```


### 3.2 AutoGen Integration

**File: `frameworks/autogen_mcp_agent.py`**

```python
import asyncio
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.ui import Console
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools

async def main():
    # ===== Setup MCP Server =====
    mcp_server = StdioServerParams(
        command="python",
        args=["mcp_server/agent_tools_server.py"],
        read_timeout_seconds=100
    )
    
    # Load MCP tools
    tools = await mcp_server_tools(mcp_server)
    print(f"âœ… Loaded {len(tools)} tools from MCP server")
    
    # ===== Create Agent =====
    model_client = OpenAIChatCompletionClient(model="gpt-4o")
    
    agent = AssistantAgent(
        name="mcp_agent",
        model_client=model_client,
        tools=tools,  # MCP tools Ä‘Æ°á»£c inject vÃ o agent
        system_message="Báº¡n lÃ  AI agent vá»›i quyá»n truy cáº­p MCP tools.",
        reflect_on_tool_use=True  # Agent tá»± reflect vá» cÃ¡ch dÃ¹ng tools
    )
    
    # ===== Run Agent =====
    await Console(
        agent.run_stream(
            task="TÃ¬m kiáº¿m thÃ´ng tin vá» 'Machine Learning' vÃ  tÃ­nh 15 * 23"
        )
    )

if __name__ == "__main__":
    asyncio.run(main())
```


### 3.3 LangGraph Integration

**File: `frameworks/langgraph_mcp_agent.py`**

```python
import asyncio
from typing import Annotated, TypedDict
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_openai import ChatOpenAI
from langchain_mcp import MCPAdapter
from mcp import StdioServerParameters

# ===== Define State =====

class AgentState(TypedDict):
    messages: list
    next: str

# ===== Setup MCP =====

async def setup_mcp_tools():
    """Load MCP tools vÃ o LangGraph."""
    mcp_adapter = MCPAdapter(
        server_command=["python", "mcp_server/agent_tools_server.py"],
        transport_type="stdio"
    )
    
    await mcp_adapter.connect()
    tools = await mcp_adapter.get_tools()
    
    print(f"âœ… Loaded {len(tools)} MCP tools")
    return tools

# ===== Agent Node =====

async def agent_node(state: AgentState):
    """Node cháº¡y agent reasoning."""
    llm = ChatOpenAI(model="gpt-4o")
    tools = await setup_mcp_tools()
    
    llm_with_tools = llm.bind_tools(tools)
    response = await llm_with_tools.ainvoke(state["messages"])
    
    return {
        "messages": state["messages"] + [response],
        "next": "tools" if response.tool_calls else "end"
    }

# ===== Tool Node =====

async def tool_node(state: AgentState):
    """Node execute MCP tools."""
    tool_node = ToolNode(await setup_mcp_tools())
    result = await tool_node.ainvoke(state)
    
    return {
        "messages": result["messages"],
        "next": "agent"
    }

# ===== Build Graph =====

def create_agent_graph():
    """Táº¡o LangGraph workflow."""
    workflow = StateGraph(AgentState)
    
    # Add nodes
    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tool_node)
    
    # Add edges
    workflow.set_entry_point("agent")
    workflow.add_conditional_edges(
        "agent",
        lambda x: x["next"],
        {
            "tools": "tools",
            "end": END
        }
    )
    workflow.add_edge("tools", "agent")
    
    return workflow.compile()

# ===== Run =====

async def main():
    graph = create_agent_graph()
    
    result = await graph.ainvoke({
        "messages": [{"role": "user", "content": "TÃ­nh 100 * 25"}],
        "next": ""
    })
    
    print(result["messages"][-1]["content"])

if __name__ == "__main__":
    asyncio.run(main())
```


## 4. Best Practices \& Patterns

### Security Considerations

```python
# âŒ KHÃ”NG NÃŠN: Expose táº¥t cáº£ tools
mcps=["https://untrusted-server.com/mcp"]

# âœ… NÃŠN: Filter tools cáº©n tháº­n
from crewai.mcp.filters import create_dynamic_tool_filter

def safe_filter(context, tool):
    # Chá»‰ cho phÃ©p read operations
    dangerous_keywords = ["delete", "write", "modify", "exec"]
    tool_name = tool.get("name", "").lower()
    
    return not any(keyword in tool_name for keyword in dangerous_keywords)

agent = Agent(
    role="Safe Agent",
    mcps=[
        MCPServerStdio(
            command="python",
            args=["server.py"],
            tool_filter=safe_filter
        )
    ]
)
```


### Error Handling Pattern

```python
async def robust_tool_execution(session, tool_name, args):
    """Execute tool vá»›i retry vÃ  fallback."""
    max_retries = 3
    
    for attempt in range(max_retries):
        try:
            result = await session.call_tool(tool_name, args)
            return result
        
        except TimeoutError:
            if attempt < max_retries - 1:
                await asyncio.sleep(2 ** attempt)  # Exponential backoff
                continue
            return {"error": "Tool timeout after retries"}
        
        except Exception as e:
            return {"error": f"Tool execution failed: {str(e)}"}
```


### Performance Optimization

```python
# Cache tools list Ä‘á»ƒ giáº£m latency
MCPServerStdio(
    command="python",
    args=["server.py"],
    cache_tools_list=True,  # âœ… Cache
    connect_timeout=60       # âœ… TÄƒng timeout cho servers cháº­m
)
```


## 5. Cháº¡y á»¨ng Dá»¥ng

### Setup

```bash
# Clone vÃ  setup
git clone <your-repo>
cd mcp-agent-demo

# Install dependencies
uv add mcp openai anthropic crewai langchain-mcp-adapters autogen-agentchat

# Set API keys
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."
```


### Cháº¡y OpenAI Agent

```bash
# Terminal 1: KhÃ´ng cáº§n start server riÃªng (stdio tá»± Ä‘á»™ng)

# Terminal 1: Cháº¡y agent
uv run python agent_client/openai_agent.py mcp_server/agent_tools_server.py
```


### Cháº¡y CrewAI

```bash
uv run python frameworks/crewai_mcp_agent.py
```


### Cháº¡y AutoGen

```bash
uv run python frameworks/autogen_mcp_agent.py
```


## 6. Troubleshooting

| Lá»—i | NguyÃªn nhÃ¢n | Giáº£i phÃ¡p |
| :-- | :-- | :-- |
| `Connection refused` | Server path sai | Kiá»ƒm tra Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i[^8][^9] |
| `Tool not found` | Tool name khÃ´ng khá»›p | Cháº¡y `--members` Ä‘á»ƒ list tools[^9] |
| `Timeout` | Server khá»Ÿi Ä‘á»™ng cháº­m | TÄƒng `connect_timeout=60`[^10][^11] |
| `Import error` | Thiáº¿u dependencies | `uv add <package>`[^4] |

## 7. TÃ i NguyÃªn Tham Kháº£o

- **MCP Specification**: https://modelcontextprotocol.io[^12]
- **FastMCP Docs**: https://github.com/jlowin/fastmcp[^6]
- **CrewAI MCP**: https://docs.crewai.com/en/mcp/overview[^10]
- **AutoGen MCP**: https://microsoft.github.io/autogen[^13][^14]

***

**Káº¿t luáº­n**: HÆ°á»›ng dáº«n nÃ y cung cáº¥p full code Ä‘á»ƒ xÃ¢y dá»±ng MCP server, client vÃ  tÃ­ch há»£p vá»›i cÃ¡c framework agent phá»• biáº¿n. Pattern nÃ y cho phÃ©p agents Ä‘á»™ng sá»­ dá»¥ng tools thÃ´ng qua giao thá»©c chuáº©n, dá»… má»Ÿ rá»™ng vÃ  báº£o trÃ¬.[^2][^3][^1][^4]
<span style="display:none">[^15][^16][^17][^18][^19][^20][^21][^22][^23][^24][^25][^26][^27][^28][^29][^30][^31][^32][^33][^34][^35][^36][^37][^38][^39][^40][^41][^42][^43][^44][^45][^46][^47][^48][^49][^50][^51][^52][^53]</span>

<div align="center">â‚</div>

[^1]: https://viblo.asia/p/gioi-thieu-ve-model-context-protocol-mcp-BQyJKEOWVMe

[^2]: https://vinbigdata.com/kham-pha/giai-ma-mcp-chuan-ket-noi-moi-cho-ai-agents.html

[^3]: https://learn.microsoft.com/en-us/agent-framework/user-guide/model-context-protocol/using-mcp-tools

[^4]: https://openai.github.io/openai-agents-python/mcp/

[^5]: https://modelcontextprotocol.io/docs/develop/build-server

[^6]: https://github.com/jlowin/fastmcp

[^7]: https://modelcontextprotocol.io/specification/2025-06-18/server/tools

[^8]: https://mcpcn.com/en/docs/tutorials/building-a-client/

[^9]: https://realpython.com/python-mcp-client/

[^10]: https://docs.crewai.com/en/mcp/overview

[^11]: https://docs.crewai.com/en/mcp/multiple-servers

[^12]: https://modelcontextprotocol.io/specification/2025-11-25

[^13]: https://newsletter.victordibia.com/p/how-to-use-mcp-anthropic-mcp-tools

[^14]: https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/components/workbench.html

[^15]: https://www.youtube.com/watch?v=x0C003ePDlk

[^16]: https://www.facebook.com/groups/miaigroup/posts/1952211818883414/

[^17]: https://www.youtube.com/watch?v=XKae3FgKZnM

[^18]: https://www.merge.dev/blog/mcp-integration-examples

[^19]: https://superagi.com/mastering-mcp-servers-in-2025-a-beginners-guide-to-model-context-protocol-implementation/

[^20]: https://viblo.asia/p/giao-thuc-model-context-protocol-mcp-trong-net-xay-dung-ai-agent-thong-minh-voi-openai-mcp-3RlL5B9zVbB

[^21]: https://www.bitcot.com/how-to-build-ai-agents-using-mcp-a-complete-guide/

[^22]: https://www.strategysoftware.com/strategyone/whats-new/model-context-protocol-mcp-integration-for-agents

[^23]: https://obot.ai/resources/learning-center/mcp-tools/

[^24]: https://www.reddit.com/r/ChatGPTCoding/comments/1jd9lfa/learn_mcp_by_building_an_sql_ai_agent/

[^25]: https://composio.dev/blog/the-complete-guide-to-building-mcp-agents

[^26]: https://learn.microsoft.com/en-us/dynamics365/release-plan/2025wave2/service/dynamics365-customer-service/connect-ai-agents-using-model-context-protocol-server

[^27]: https://base.vn/blog/model-context-protocol-mcp-la-gi/

[^28]: https://modelcontextprotocol.info/docs/tutorials/writing-effective-tools/

[^29]: https://cyclr.com/resources/ai/model-context-protocol-mcp-for-ai-integration

[^30]: https://latenode.com/blog/ai-frameworks-technical-infrastructure/langchain-setup-tools-agents-memory/langchain-mcp-integration-complete-guide-to-mcp-adapters

[^31]: https://huggingface.co/blog/python-tiny-agents

[^32]: https://www.mintmcp.com/blog/connect-ai-chains-to enterprise-data-source

[^33]: https://github.com/crewAIInc/crewAI-tools

[^34]: https://docs.langchain.com/oss/python/langchain/mcp

[^35]: https://docs.crewai.com/en/concepts/tools

[^36]: https://phucnt.substack.com/p/mcp-truyen-thong-code-execution-va

[^37]: https://realpython.com/python-mcp/

[^38]: https://www.leanware.co/insights/langchain-mcp-integrating-langchain-with-model-context-protocol

[^39]: https://snyk.io/articles/building-interactive-mcp-servers-experience-on-the-terminal-using-python/

[^40]: https://www.leanware.co/insights/langgraph-mcp-building-powerful-agents-with-mcp-integration

[^41]: https://latenode.com/blog/ai-frameworks-technical-infrastructure/langgraph-multi-agent-orchestration/langgraph-mcp-integration-complete-model-context-protocol-setup-guide-working-examples-2025

[^42]: https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.mcp.html

[^43]: https://developers.redhat.com/articles/2025/08/12/how-build-simple-agentic-ai-server-mcp

[^44]: https://github.com/hirokiyn/mcp-langgraph

[^45]: https://www.youtube.com/watch?v=MDBG2MOp4Go

[^46]: https://generect.com/blog/langgraph-mcp/

[^47]: https://skywork.ai/skypage/en/Mastering-AI-Tool-Integration:-A-Deep-Dive-into-the-mcp_autogen_sse_stdio-MCP-Server-Example/1972504582783287296

[^48]: https://dev.to/rajeev_3ce9f280cbae73b234/building-smarter-local-ai-agents-with-mcp-a-simple-client-server-example-4lfm

[^49]: https://gofastmcp.com/tutorials/create-mcp-server

[^50]: https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/agent-as-mcp-tool

[^51]: https://www.youtube.com/watch?v=je6ZW3rWWMw

[^52]: https://towardsdatascience.com/model-context-protocol-mcp-tutorial-build-your-first-mcp-server-in-6-steps/

[^53]: https://modelcontextprotocol.io/docs/develop/build-client


---
<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# ko hiá»ƒu láº¯m, giáº£i thÃ­ch Ä‘Æ¡n giáº£n hÆ¡n vÃ  MECE toÃ n bá»™ cÃ¡c cÃ¡ch triá»ƒn khai

ÄÆ°á»£c rá»“i, mÃ¬nh sáº½ giáº£i thÃ­ch cá»±c ká»³ Ä‘Æ¡n giáº£n vÃ  MECE (Mutually Exclusive, Collectively Exhaustive) táº¥t cáº£ cÃ¡c cÃ¡ch triá»ƒn khai MCP tools.

# Táº¥t Cáº£ CÃ¡ch Triá»ƒn Khai MCP Tools (ÄÆ¡n Giáº£n \& MECE)

## Framework MECE: 2 Chiá»u PhÃ¢n Loáº¡i

CÃ³ **2 cÃ¢u há»i** quyáº¿t Ä‘á»‹nh cÃ¡ch báº¡n deploy MCP:

### CÃ¢u 1: Server cháº¡y á»Ÿ Ä‘Ã¢u?

- **Local** (mÃ¡y agent)
- **Remote** (mÃ¡y khÃ¡c/cloud)


### CÃ¢u 2: Bao nhiÃªu user dÃ¹ng chung?

- **Single-tenant** (1 user = 1 server riÃªng)
- **Multi-tenant** (nhiá»u user â†’ 1 server chung)

â†’ **Tá»• há»£p = 3 patterns chÃ­nh** (vÃ¬ Local khÃ´ng cÃ³ multi-tenant)

***

## Pattern 1: **Workstation Deployment** (Local + Single-tenant)

### Server cháº¡y á»Ÿ Ä‘Ã¢u?

**Cháº¡y trÃªn mÃ¡y cá»§a agent** - nhÆ° subprocess

### Diagram Ä‘Æ¡n giáº£n:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MÃ¡y cá»§a báº¡n                â”‚
â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  Agent   â”‚               â”‚
â”‚  â”‚          â”‚ spawn         â”‚
â”‚  â”‚    â†“     â”‚               â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”‚               â”‚
â”‚  â”‚ â”‚Serverâ”‚ â”‚               â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


### Code minh há»a:

```python
# Agent Tá»° Äá»˜NG spawn server process
server_params = StdioServerParameters(
    command="python",
    args=["my_tools.py"]  # File Python local
)

# Khi agent cháº¡y â†’ server tá»± khá»Ÿi Ä‘á»™ng
# Khi agent táº¯t â†’ server tá»± táº¯t
```


### Äáº·c Ä‘iá»ƒm:

| TiÃªu chÃ­ | GiÃ¡ trá»‹ |
| :-- | :-- |
| **CÃ³ cáº§n deploy khÃ´ng?** | âŒ KHÃ”NG - chá»‰ cáº§n file Python |
| **CÃ³ cáº§n server riÃªng khÃ´ng?** | âŒ KHÃ”NG - subprocess tá»± Ä‘á»™ng |
| **CÃ³ cáº§n worker pool khÃ´ng?** | âŒ KHÃ”NG - má»—i agent tá»± spawn |
| **Latency** | <1ms (nhanh nháº¥t)[^1][^2] |
| **Nhiá»u ngÆ°á»i dÃ¹ng Ä‘Æ°á»£c khÃ´ng?** | âŒ KHÃ”NG - má»—i ngÆ°á»i cháº¡y riÃªng |
| **Chi phÃ­** | \$0 (cháº¡y cÃ¹ng mÃ¡y agent) |

### Khi nÃ o dÃ¹ng?[^3]

- âœ… Development/testing
- âœ… Báº¡n code má»™t mÃ¬nh
- âœ… Tools cáº§n truy cáº­p file local (vÃ­ dá»¥: Ä‘á»c code trÃªn mÃ¡y)
- âœ… Desktop app (nhÆ° Claude Desktop)


### Æ¯u Ä‘iá»ƒm:

- Setup siÃªu nhanh (khÃ´ng cáº§n deploy gÃ¬)
- Nhanh nháº¥t (khÃ´ng qua network)
- Miá»…n phÃ­ hoÃ n toÃ n


### NhÆ°á»£c Ä‘iá»ƒm:

- Chá»‰ báº¡n dÃ¹ng Ä‘Æ°á»£c
- KhÃ´ng share tools vá»›i team
- Má»—i láº§n cháº¡y láº¡i pháº£i spawn láº¡i server

***

## Pattern 2: **Remote - Multi-tenant** (Remote + Shared)

### Server cháº¡y á»Ÿ Ä‘Ã¢u?

**Cháº¡y trÃªn server riÃªng (cloud/VPS)** - nhiá»u agents káº¿t ná»‘i Ä‘áº¿n

### Diagram Ä‘Æ¡n giáº£n:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent 1  â”‚â”€â”€â”€â”€â”€â”€â”    â”‚  Server riÃªng   â”‚
â”‚ (MÃ¡y A)  â”‚      â”‚    â”‚  (AWS/GCP)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚    â”‚                 â”‚
                  â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     HTTP  â”‚  â”‚ MCP Tools â”‚  â”‚
â”‚ Agent 2  â”‚â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â–¶â”‚  â”‚  Server   â”‚  â”‚
â”‚ (MÃ¡y B)  â”‚      â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚    â”‚                 â”‚
                  â”‚    â”‚  (Cháº¡y 24/7)    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Agent 3  â”‚â”€â”€â”€â”€â”€â”€â”˜
â”‚ (MÃ¡y C)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


### Code minh há»a:

```python
# Server: Deploy lÃªn AWS/GCP
# server.py cháº¡y trÃªn cloud
uvicorn server:app --host 0.0.0.0 --port 8080

# Agent: Connect Ä‘áº¿n remote URL
agent = Agent(
    mcps=["https://mcp-server.mycompany.com/mcp"]
)
```


### Äáº·c Ä‘iá»ƒm:

| TiÃªu chÃ­ | GiÃ¡ trá»‹ |
| :-- | :-- |
| **CÃ³ cáº§n deploy khÃ´ng?** | âœ… CÃ“ - cáº§n server riÃªng |
| **CÃ³ cáº§n server riÃªng khÃ´ng?** | âœ… CÃ“ - VPS/cloud |
| **CÃ³ cáº§n worker pool khÃ´ng?** | âš ï¸ TÃ™Y - náº¿u traffic cao thÃ¬ cáº§n nhiá»u workers |
| **Latency** | 10-50ms (cÃ³ network)[^1] |
| **Nhiá»u ngÆ°á»i dÃ¹ng Ä‘Æ°á»£c khÃ´ng?** | âœ… CÃ“ - nhiá»u ngÆ°á»i dÃ¹ng chung 1 server |
| **Chi phÃ­** | \$20-200/month[^3] |

### Khi nÃ o dÃ¹ng?[^3]

- âœ… Team 3+ ngÆ°á»i cáº§n dÃ¹ng chung tools
- âœ… Production app vá»›i nhiá»u users
- âœ… Tools cáº§n cháº¡y 24/7
- âœ… Cáº§n scale horizontally (thÃªm workers khi traffic tÄƒng)
- âœ… Cáº§n monitoring/logging táº­p trung


### Æ¯u Ä‘iá»ƒm:

- Team cÃ¹ng dÃ¹ng
- Update tools 1 láº§n â†’ má»i ngÆ°á»i cÃ³ ngay
- Dá»… monitor/logging
- Scale Ä‘Æ°á»£c khi traffic tÄƒng


### NhÆ°á»£c Ä‘iá»ƒm:

- Tá»‘n tiá»n server
- Cáº§n biáº¿t DevOps (Docker/K8s)
- Cháº­m hÆ¡n local (cÃ³ network latency)
- Pháº£i lo báº£o máº­t (authentication, rate limit)

***

## Pattern 3: **Remote - Single-tenant** (Remote + Isolated)

### Server cháº¡y á»Ÿ Ä‘Ã¢u?

**Má»—i user cÃ³ 1 container riÃªng trÃªn cloud**

### Diagram Ä‘Æ¡n giáº£n:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent 1  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Container riÃªng User 1  â”‚
â”‚ (User 1) â”‚   HTTP    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  â”‚ MCP Tools â”‚          â”‚
                       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent 2  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Container riÃªng User 2  â”‚
â”‚ (User 2) â”‚   HTTP    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  â”‚ MCP Tools â”‚          â”‚
                       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

              (Má»—i user = 1 container Ä‘á»™c láº­p)
```


### Code minh há»a:

```python
# Router nháº­n request â†’ spawn container cho user
@app.post("/mcp")
async def route_to_user_container(user_id: str):
    # Spawn container náº¿u chÆ°a cÃ³
    container = get_or_create_container(user_id)
    
    # Forward request Ä‘áº¿n container cá»§a user Ä‘Ã³
    return forward_to_container(container)
```


### Äáº·c Ä‘iá»ƒm:

| TiÃªu chÃ­ | GiÃ¡ trá»‹ |
| :-- | :-- |
| **CÃ³ cáº§n deploy khÃ´ng?** | âœ… CÃ“ - cáº§n orchestration platform |
| **CÃ³ cáº§n server riÃªng khÃ´ng?** | âœ… CÃ“ - nhiá»u containers |
| **CÃ³ cáº§n worker pool khÃ´ng?** | âœ… CÃ“ - má»—i user = 1 worker (container) |
| **Latency** | 10-50ms |
| **Nhiá»u ngÆ°á»i dÃ¹ng Ä‘Æ°á»£c khÃ´ng?** | âœ… CÃ“ - nhÆ°ng má»—i ngÆ°á»i container riÃªng |
| **Chi phÃ­** | \$100-1000/month (tÃ¹y users)[^3] |

### Khi nÃ o dÃ¹ng?[^4][^3]

- âœ… Cáº§n security cao (má»—i user isolated)
- âœ… Tools cÃ³ state riÃªng cho tá»«ng user (vÃ­ dá»¥: browser session)
- âœ… Compliance regulations (dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c share)
- âœ… Tools tá»‘n resource (GPU, heavy computation)


### Æ¯u Ä‘iá»ƒm:

- Báº£o máº­t tuyá»‡t Ä‘á»‘i (má»—i user isolated)
- Container khÃ´ng dÃ¹ng cÃ³ thá»ƒ táº¯t â†’ tiáº¿t kiá»‡m tiá»n
- Scale theo sá»‘ users


### NhÆ°á»£c Ä‘iá»ƒm:

- Phá»©c táº¡p nháº¥t (cáº§n K8s/orchestration)
- Chi phÃ­ cao nháº¥t
- Cáº§n DevOps skills máº¡nh

***

## So SÃ¡nh MECE 3 Patterns

| Pattern | NÆ¡i cháº¡y | Sá»‘ users | Deploy | Cost | Use case |
| :-- | :-- | :-- | :-- | :-- | :-- |
| **Workstation** | Local | 1 | âŒ KhÃ´ng | \$0 | Dev/testing |
| **Remote Multi-tenant** | Cloud | Nhiá»u (shared) | âœ… Cáº§n | \$20-200 | Team/startup |
| **Remote Single-tenant** | Cloud | Nhiá»u (isolated) | âœ… Cáº§n | \$100-1000 | Enterprise |


***

## Tráº£ Lá»i CÃ¢u Há»i Cá»¥ Thá»ƒ Cá»§a Báº¡n

### "Kho tool nÃ y mÃ¬nh cho cháº¡y luá»“ng worker riÃªng hay cáº§n deploy lÃªn server riÃªng?"

**TÃ¹y má»¥c Ä‘Ã­ch:**

### Náº¿u báº¡n Ä‘ang **development má»™t mÃ¬nh**:

```python
# âŒ KHÃ”NG cáº§n worker riÃªng
# âŒ KHÃ”NG cáº§n deploy lÃªn server
# âœ… Chá»‰ cáº§n file Python local

# Pattern: Workstation
agent = Agent(
    mcps=[MCPServerStdio(
        command="python",
        args=["tools.py"]  # File trÃªn mÃ¡y báº¡n
    )]
)
```


### Náº¿u **team 3-5 ngÆ°á»i cáº§n dÃ¹ng**:

```bash
# âœ… Cáº¦N deploy lÃªn server riÃªng
# âœ… Cáº¦N cháº¡y nhÆ° web service (FastAPI/uvicorn)

# Pattern: Remote Multi-tenant
# Deploy lÃªn Railway/Render (Ä‘Æ¡n giáº£n)
railway up
# hoáº·c Docker
docker run -p 8080:8080 mcp-server
```


### Náº¿u **production vá»›i 100+ users**:

```yaml
# âœ… Cáº¦N worker pool vá»›i load balancer
# âœ… Cáº¦N Kubernetes/ECS

# Pattern: Remote Multi-tenant vá»›i nhiá»u workers
apiVersion: apps/v1
kind: Deployment
spec:
  replicas: 5  # 5 workers
```


### Náº¿u **enterprise vá»›i báº£o máº­t cao**:

```python
# âœ… Cáº¦N container riÃªng cho má»—i user
# âœ… Cáº¦N orchestration platform (K8s)

# Pattern: Remote Single-tenant
# Má»—i user = 1 container Kubernetes pod
```


***

## Decision Tree ÄÆ¡n Giáº£n

```
Báº¡n Ä‘ang á»Ÿ giai Ä‘oáº¡n nÃ o?
â”‚
â”œâ”€ Development má»™t mÃ¬nh
â”‚  â””â”€ âœ… Workstation (stdio local)
â”‚     â””â”€ KhÃ´ng cáº§n deploy gÃ¬ cáº£
â”‚
â”œâ”€ Team nhá» (3-10 ngÆ°á»i)
â”‚  â””â”€ âœ… Remote Multi-tenant
â”‚     â””â”€ Deploy 1 server lÃªn Railway/Render
â”‚     â””â”€ Chi phÃ­: ~$20/month
â”‚
â”œâ”€ Production (100+ users)
â”‚  â””â”€ âœ… Remote Multi-tenant + Load Balancer
â”‚     â””â”€ Deploy Kubernetes vá»›i 3-5 workers
â”‚     â””â”€ Chi phÃ­: $200-500/month
â”‚
â””â”€ Enterprise (báº£o máº­t cao)
   â””â”€ âœ… Remote Single-tenant
      â””â”€ Má»—i user = 1 container
      â””â”€ Chi phÃ­: $1000+/month
```


***

## Khuyáº¿n Nghá»‹ Cho Báº¡n (FinTech Startup)

Dá»±a trÃªn profile báº¡n (AI Engineer, Ä‘ang build fintech startup):

### Phase 1: MVP (Hiá»‡n táº¡i - 1-2 tuáº§n Ä‘áº§u)

```python
# âœ… DÃ¹ng Workstation
# KhÃ´ng cáº§n deploy, khÃ´ng cáº§n worker, khÃ´ng cáº§n server
MCPServerStdio(command="python", args=["tools.py"])
```

**LÃ½ do**: Iterate nhanh, \$0 cost, focus vÃ o product

### Phase 2: Internal Testing (ThÃ¡ng 1-2)

```python
# âœ… Deploy 1 container lÃªn Railway
# URL: https://mcp-tools.railway.app/mcp
MCPServerHTTP(url="https://...")
```

**LÃ½ do**: Team test Ä‘Æ°á»£c, váº«n Ä‘Æ¡n giáº£n, ~\$10/month

### Phase 3: Beta Users (ThÃ¡ng 3-6)

```bash
# âœ… Docker Compose vá»›i 3 workers
docker-compose up --scale worker=3
```

**LÃ½ do**: Handle 50-100 users, ~\$50/month

### Phase 4: Scale (Sau product-market fit)

```yaml
# âœ… Kubernetes vá»›i autoscaling
replicas: 5-20 (tá»± Ä‘á»™ng)
```

**LÃ½ do**: Handle 1000+ users, monitoring Ä‘áº§y Ä‘á»§

***

## Key Takeaway

**"Worker riÃªng" vÃ  "Server riÃªng" lÃ  2 khÃ¡i niá»‡m khÃ¡c nhau:**

1. **Worker riÃªng** = Process xá»­ lÃ½ requests
    - Workstation: Agent tá»± spawn (khÃ´ng cáº§n setup)
    - Remote: Uvicorn workers hoáº·c K8s pods
2. **Server riÃªng** = MÃ¡y chá»§ cháº¡y Ä‘á»™c láº­p
    - Workstation: KHÃ”NG cáº§n (cháº¡y local)
    - Remote: Cáº¦N (VPS/cloud)

**Vá»›i MVP, báº¡n KHÃ”NG cáº§n cáº£ hai** - chá»‰ cáº§n file Python local.[^5][^6][^3]
<span style="display:none">[^10][^11][^7][^8][^9]</span>

<div align="center">â‚</div>

[^1]: https://mcpcat.io/guides/comparing-stdio-sse-streamablehttp/

[^2]: https://www.reddit.com/r/mcp/comments/1kssu2g/mcp_server_transports_inmemory_vs_httpsse_vs_stdio/

[^3]: https://mcpmanager.ai/blog/secure-mcp-server-deployment-at-scale-the-complete-guide/

[^4]: https://fly.io/docs/blueprints/remote-mcp-servers/

[^5]: https://modelcontextprotocol.io/docs/learn/architecture

[^6]: https://www.stainless.com/mcp/local-mcp-vs-remote-mcp

[^7]: https://milvus.io/ai-quick-reference/what-deployment-patterns-support-highavailability-in-model-context-protocol-mcp

[^8]: https://www.reddit.com/r/mcp/comments/1k9knt9/how_are_teams_deploying_mcp_servers_for/

[^9]: https://modelcontextprotocol-security.io/patterns/

[^10]: https://composio.dev/blog/mcp-server-step-by-step-guide-to-building-from-scrtch

[^11]: https://workos.com/blog/how-mcp-servers-work

