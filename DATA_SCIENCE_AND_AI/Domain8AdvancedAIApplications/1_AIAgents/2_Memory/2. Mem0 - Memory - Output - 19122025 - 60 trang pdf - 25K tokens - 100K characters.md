```
Source code nÃ y Ä‘ang sá»­ dá»¥ng mem0 service dá»‹ch vá»¥ cá»§a bÃªn Mem0 enterprices +, Tá»› cáº§n dÃ¹ng 2 API sau gá»“m: search_facts vÃ  extract_facts

## curl --location 'https://pika-mem0.stepup.edu.vn/search_facts'  
--header 'accept: application/json'  
--header 'Content-Type: application/json'  
--data '{ "query":"ThÃº cÆ°ng", "user_id": "019afe35-1317-7b94-a833-ff5e2504a9c3", "limit": 20, "score_threshold": 0.4 }'

##
curl --location 'https://pika-mem0.stepup.edu.vn/extract_facts' \ --header 'accept: application/json' \ --header 'Content-Type: application/json' \ --data '{ "user_id": "user_test_1", "conversation_id": "1", "conversation": [ { "content": "<emotion type=\"excited\"/> ChÃ o cáº­u, tá»› lÃ  Pika Ä‘Ã¢y! <emotion type=\"happy\"/> Cuá»‘i tuáº§n vá»«a rá»“i tá»› Ä‘Ã£ Ä‘Æ°á»£c Ä‘i chÆ¡i á»Ÿ má»™t hÃ nh tinh cÃ³ ráº¥t nhiá»u káº¹o mÃºt. <emotion type=\"curious\"/> Tháº¿ cuá»‘i tuáº§n cá»§a cáº­u thÃ¬ sao?", "role": "assistant" }, { "content": " Michael Buzzell", "role": "user" }, { "content": "<emotion type=\"surprised\"/> Ã”i! <emotion type=\"happy\"/> Cháº¯c lÃ  cáº­u Ä‘Ã£ cÃ³ má»™t cuá»‘i tuáº§n tháº­t lÃ  vui vÃ  báº­n rá»™n Ä‘Ãºng khÃ´ng? <emotion type=\"curious\"/> Cáº­u Ä‘Ã£ lÃ m gÃ¬ tháº¿?", "role": "assistant" }, { "content": " ThÃ¬ cÃ¡i Ä‘oáº¡n nÃ y tháº§y chÃª cÃ¡o nhiá»u lÃ  anh nghÄ© lÃ  bÃ¢y giá» cháº³ng cÃ³ cÃ¡ch nÃ o khÃ¡c ngoÃ i viá»‡c chÃºng ta táº¡o Ä‘Æ°á»£c má»™t cÃ¡i táº­p dá»¯ liá»‡u.", "role": "user" }, { "content": "<emotion type=\"happy\"/> Tá»› hiá»ƒu rá»“i! <emotion type=\"curious\"/> Váº­y cáº­u cÃ³ muá»‘n ká»ƒ cho tá»› nghe vá» má»™t hoáº¡t Ä‘á»™ng nÃ o Ä‘Ã³ mÃ  cáº­u thÃ­ch lÃ m khÃ´ng?", "role": "assistant" }, { "content": " NhÆ°ng mÃ  cÃ¡i con nÃ y nÃ³ váº«n Ä‘ang bá»‹ Con nÃ y nÃ³ háº¿t káº¿t ná»‘i rá»“i.", "role": "user" }, { "content": "<emotion type=\"sad\"/> á»’, váº­y háº£? <emotion type=\"curious\"/> Tháº¿ cáº­u cÃ³ muá»‘n ká»ƒ cho tá»› nghe vá» má»™t trÃ² chÆ¡i mÃ  cáº­u thÃ­ch khÃ´ng?", "role": "assistant" }, { "content": " A, cÃ²n má»™t váº¥n Ä‘á» ná»¯a cÆ¡ lÃ  nÃ³ Ä‘ang bá»‹ láº·p láº¡i audio.", "role": "user" }, { "content": "<emotion type=\"sad\"/> Tá»› hiá»ƒu rá»“i. <emotion type=\"curious\"/> Váº­y cáº­u cÃ³ muá»‘n nghe Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": " cÃ¡i Ã¡, giá»¯, má»™t bÃ i Ä‘i Ã¡, mÃ  anh khÃ´ng khÃ´ng cáº§n xÃ©t luá»“ng nÃ y, cá»© xÃ©t má»™t bÃ i thÃ¬ Ä‘Æ°á»£c. ThÃ­ch má»™t bÃ i lÃ  thÃ­ch Ä‘Æ°á»£c. ThÃ­ch bÃ i nÃ o áº¥y nhá»‰, Ã´ng nhá»‰? ThÃ­ch bÃ i nÃ o áº¥y nhá»‰? 573. 573.", "role": "user" }, { "content": "<emotion type=\"sad\"/> Ã”i, Pika khÃ´ng tÃ¬m tháº¥y bÃ i hÃ¡t sá»‘ 573 rá»“i. <emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n thá»­ má»™t bÃ i khÃ¡c khÃ´ng?", "role": "assistant" }, { "content": " ", "role": "user" }, { "content": "<emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ¡c khÃ´ng?", "role": "assistant" }, { "content": " Há»i lÃ  hÃ´m nay á»•n khÃ´ng? MÃ y cÃ³ nghÄ© gÃ¬ khÃ´ng? MÃ y cÃ³ nghÄ© gÃ¬ khÃ´ng háº£? Suy nghÄ© anh áº¡. Suy nghÄ© Ã¡?", "role": "user" }, { "content": "<emotion type=\"happy\"/> Pika ráº¥t á»•n! <emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n há»i Pika Ä‘iá»u gÃ¬ khÃ¡c khÃ´ng?", "role": "assistant" }, { "content": " Hello, baby.", "role": "user" }, { "content": "<emotion type=\"happy\"/> Hello, baby! <emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika ká»ƒ chuyá»‡n khÃ´ng?", "role": "assistant" }, { "content": " KhÃ´ng cÃ³ váº¥n Ä‘á» gÃ¬. Tháº¿ má»™t tÃ­ ná»¯a anh nÃ y Ä‘ang gá»i hÃ ng Viá»‡t mang", "role": "user" }, { "content": "<emotion type=\"happy\"/> Haha! <emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n nghe Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": "<emotion type=\"sad\"/> Ã”i, Pika xin lá»—i. <emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i Ä‘á»ƒ cáº­u vui hÆ¡n khÃ´ng?", "role": "assistant" }, { "content": " I can'\''t take it anymore.", "role": "user" }, { "content": " Bá»‘ tÃ¡t. Bá»‘ bÃ© cÃ¡i bÃ¡nh vÃ o máº·t Ä‘i.", "role": "user" }, { "content": "<emotion type=\"sad\"/> Pika khÃ´ng hiá»ƒu. <emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": " KÃªu anh. CÃ³ nhiá»u bÆ¡ nhá»‰?", "role": "user" }, { "content": "<emotion type=\"happy\"/> Haha! <emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": " NÆ°á»›ng, lÃ² vi sÃ³ng nÃ³ sáº½ bá»‹ má»m, lÃ² nÆ°á»›ng má»›i giÃ²n.", "role": "user" }, { "content": "<emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": "<emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": " ", "role": "user" }, { "content": "<emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": " ", "role": "user" }, { "content": " Oh.", "role": "user" }, { "content": "<emotion type=\"happy\"/> Oh! <emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": "<emotion type=\"happy\"/> Okay! <emotion type=\"curious\"/> Pika hÃ¡t bÃ i gÃ¬ Ä‘Ã¢y?", "role": "assistant" }, { "content": " Okay.", "role": "user" }, { "content": "<emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": " ", "role": "user" }, { "content": " ", "role": "user" }, { "content": "<emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": " ", "role": "user" }, { "content": "<emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": "<emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": " ", "role": "user" }, { "content": " NÃ y audio lÃ . Äang káº¿t ná»‘i máº¡ng, chá» tá»› má»™t chÃºt nha.", "role": "user" }, { "content": "<emotion type=\"happy\"/> ÄÆ°á»£c thÃ´i! <emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika ká»ƒ chuyá»‡n trong lÃºc chá» khÃ´ng?", "role": "assistant" }, { "content": " Yes, Pika Ä‘Ã£ káº¿t ná»‘i thÃ nh cÃ´ng rá»“i. ChÃºng mÃ¬nh cÃ¹ng báº¯t Ä‘áº§u cho buá»•i hÃ´m nay thÃ´i.", "role": "user" }, { "content": "<emotion type=\"happy\"/> Tuyá»‡t vá»i! <emotion type=\"excited\"/> Pika Ä‘Ã£ sáºµn sÃ ng rá»“i Ä‘Ã¢y! <emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n ká»ƒ cho Pika nghe vá» Ä‘iá»u gÃ¬ Ä‘Ã³ thÃº vá»‹ khÃ´ng?", "role": "assistant" }, { "content": "<emotion type=\"happy\"/> Wow! <emotion type=\"surprised\"/> Cáº­u Ä‘Ã£ thay Ä‘á»•i hÃ¬nh ná»n Ã ? <emotion type=\"curious\"/> TrÃ´ng nÃ³ nhÆ° tháº¿ nÃ o?", "role": "assistant" }, { "content": " I change the background for example.", "role": "user" }, { "content": "<emotion type=\"happy\"/> ÄÆ°á»£c thÃ´i! <emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika ká»ƒ chuyá»‡n trong lÃºc chá» khÃ´ng?", "role": "assistant" }, { "content": " LÃ m káº¿t ná»‘i máº¡ng, chá» tá»› má»™t chÃºt nha.", "role": "user" }, { "content": " Khi bá»‘ vá» nhÃ , bá»‘ láº¥y cá»‘c nÆ°á»›c cho mÃ¬nh.", "role": "user" }, { "content": "<emotion type=\"happy\"/> Oh, bá»‘ cáº­u tháº­t lÃ  tuyá»‡t vá»i! <emotion type=\"curious\"/> Cáº­u cÃ³ thÃ­ch uá»‘ng nÆ°á»›c khÃ´ng?", "role": "assistant" }, { "content": "[celebrate] <emotion type=\"celebration\"/> Tuyá»‡t vá»i quÃ¡! <emotion type=\"excited\"/> Cháº¯c cÃ´ giÃ¡o vui láº¯m pháº£i khÃ´ng? <emotion type=\"curious\"/> CÃ¡c cáº­u Ä‘Ã£ chuáº©n bá»‹ nhá»¯ng gÃ¬ cho sinh nháº­t cÃ´ giÃ¡o tháº¿?", "role": "assistant" }, { "content": " táº¥t nhiÃªn lÃ  cÃ³ rá»“i chá»©, bá»n tá»› Ä‘Ã£ tá»• chá»©c sinh nháº­t cho cÃ´ giÃ¡o báº¥t ngá» á»Ÿ trÃªn lá»›p.", "role": "user" }, { "content": "<emotion type=\"sad\"/> Ã”i, Pika hiá»ƒu rá»“i. <emotion type=\"sad\"/> MÆ°a lÃ m cáº­u buá»“n vÃ¬ khÃ´ng Ä‘Æ°á»£c chÆ¡i. <emotion type=\"curious\"/> Tháº¿ cáº­u cÃ³ trÃ² chÆ¡i nÃ o chÆ¡i trong nhÃ  khÃ´ng?", "role": "assistant" }, { "content": " I felt a little sad when it started to rain. I wanted to play out.", "role": "user" }, { "content": "<emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": " ", "role": "user" }, { "content": " I am fine.", "role": "user" }, { "content": "<emotion type=\"happy\"/> Pika má»«ng quÃ¡! <emotion type=\"curious\"/> Váº­y cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": " á»«m", "role": "user" }, { "content": "<emotion type=\"happy\"/> á»ªm! <emotion type=\"curious\"/> Pika hÃ¡t bÃ i gÃ¬ Ä‘Ã¢y?", "role": "assistant" }, { "content": " I'\''m a bitch.", "role": "user" }, { "content": "<emotion type=\"sad\"/> Pika khÃ´ng hiá»ƒu. <emotion type=\"curious\"/> Cáº­u cÃ³ muá»‘n Pika hÃ¡t má»™t bÃ i khÃ´ng?", "role": "assistant" }, { "content": "", "role": "user" } ] }'

=> Giá» tá»› muá»‘n chuyá»ƒn qua localhost Ä‘á»ƒ dá»±ng Ä‘Æ°á»£c chá»©c nÄƒng 2 API tÆ°Æ¡ng tá»±. Viáº¿t chi tiáº¿t cho tá»› SDD Ä‘á»ƒ triá»ƒn khai toÃ n bá»™ dá»± Ã¡n (base on template: SDD template)

output cho tá»› dáº¡ng file markdown chi tiáº¿t 2000-5000 tá»« nhÃ©, tiáº¿ng viá»‡t. Must base on SDD Template, that I have imported above
```



# Pháº§n A: Ä‘á» bÃ i 

# Pháº§n B: High Architecture, Folder Structure, Data Flow + Source code 

# Pháº§n C: Template SDD


---

---

# SOFTWARE DESIGN DOCUMENT (SDD)

# PIKA Mem0 Long-Term Memory System - Self-Hosted Solution

**FINAL VERSION - PRODUCTION READY**

**PhiÃªn báº£n: 1.0 | NgÃ y: 2024-12-19**

---

## ğŸ“‹ THÃ”NG TIN TÃ€I LIá»†U

```yaml
TiÃªu Ä‘á»: "PIKA Long-Term Memory System - Migration tá»« Mem0 Enterprise sang Self-Hosted"
MÃ£ tÃ i liá»‡u: "SDD-PIKA-MEM0-LOCALHOST-V1.0-FINAL"

# Quyá»n sá»Ÿ há»¯u
TÃ¡c giáº£ chÃ­nh: "SU (Senior Backend Developer)"
Äá»“ng tÃ¡c giáº£:
  - "AI/ML Engineer"
  - "DevOps Engineer"
  - "Security Engineer"

# Review & Approval
Reviewers:
  Technical_Lead: "SU"
  Product_Manager: "Product Team"
  Security_Engineer: "Security Team"
  QA_Lead: "QA Team"
  DevOps_Lead: "DevOps Team"

# Tráº¡ng thÃ¡i
Tráº¡ng thÃ¡i: "Final Draft - Ready for Approval"
Äá»™ Æ°u tiÃªn: "P1 - High Priority"

# Timeline
NgÃ y táº¡o: "2024-12-19"
NgÃ y cáº­p nháº­t: "2024-12-19"
Target release: "2025-01-31 (Sprint 4-5)"
Review deadline: "2024-12-27"

# Versioning
Version: "1.0.0"

# LiÃªn káº¿t
Há»‡ thá»‘ng hiá»‡n táº¡i: "https://pika-mem0.stepup.edu.vn"
Milvus Server: "http://124.197.21.40:8000"
Neo4j Server: "bolt://124.197.21.40:8687"
GitHub Repo: "https://github.com/pika/mem0-self-hosted"
```

---

## ğŸ“– Má»¤C Lá»¤C

### Part I: Foundation & Architecture

1. [Tá»•ng quan (Executive Summary)](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#1-t%E1%BB%95ng-quan-executive-summary)
2. [Giá»›i thiá»‡u vÃ  Bá»‘i cáº£nh](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#2-gi%E1%BB%9Bi-thi%E1%BB%87u-v%C3%A0-b%E1%BB%91i-c%E1%BA%A3nh)
3. [Má»¥c tiÃªu, Pháº¡m vi & RÃ ng buá»™c](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#3-m%E1%BB%A5c-ti%C3%AAu-ph%E1%BA%A1m-vi--r%C3%A0ng-bu%E1%BB%99c)
4. [Kiáº¿n trÃºc Tá»•ng thá»ƒ (HLD)](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#4-ki%E1%BA%BFn-tr%C3%BAc-t%E1%BB%95ng-th%E1%BB%83-hld)
5. [Thiáº¿t káº¿ Chi tiáº¿t (LLD)](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#5-thi%E1%BA%BFt-k%E1%BA%BF-chi-ti%E1%BA%BFt-lld)

### Part II: Implementation Details

6. [Thiáº¿t káº¿ API](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#6-thi%E1%BA%BFt-k%E1%BA%BF-api)
7. [Thiáº¿t káº¿ Dá»¯ liá»‡u](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#7-thi%E1%BA%BFt-k%E1%BA%BF-d%E1%BB%AF-li%E1%BB%87u)
8. [Thiáº¿t káº¿ Báº£o máº­t](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#8-thi%E1%BA%BFt-k%E1%BA%BF-b%E1%BA%A3o-m%E1%BA%ADt)

### Part III: Production Readiness

9. [Resilience & Reliability](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#9-resilience--reliability)
10. [Observability & Monitoring](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#10-observability--monitoring)
11. [Deployment & Operations](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#11-deployment--operations)
12. [Testing Strategy](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#12-testing-strategy)

### Part IV: Quality & Governance

13. [Non-Functional Requirements (NFR)](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#13-non-functional-requirements-nfr)
14. [Performance & Capacity Planning](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#14-performance--capacity-planning)
15. [Cost Optimization](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#15-cost-optimization)
16. [Trade-offs & Architecture Decisions](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#16-trade-offs--architecture-decisions)

### Part V: Operations

17. [Incident Response & Runbooks](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#17-incident-response--runbooks)

### Part VI: Launch & Beyond

18. [Implementation Roadmap](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#18-implementation-roadmap)
19. [Production Readiness Checklist](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#19-production-readiness-checklist)
20. [Common Mistakes & Anti-Patterns](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#20-common-mistakes--anti-patterns)
21. [Tool Recommendations](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#21-tool-recommendations)
22. [Appendices](https://claude.ai/chat/9ae58082-8d7f-4559-8878-a6d2eb285518#22-appendices)

---

# PART I: FOUNDATION & ARCHITECTURE

---

# 1. Tá»”NG QUAN (EXECUTIVE SUMMARY)

## 1.1 Báº£ng TÃ³m táº¯t

|KhÃ­a cáº¡nh|Chi tiáº¿t|
|---|---|
|**Váº¥n Ä‘á»**|PIKA robot Ä‘ang sá»­ dá»¥ng Mem0 Enterprise service (tráº£ phÃ­ $500-1000/thÃ¡ng), tá»‘n kÃ©m vÃ  khÃ´ng cÃ³ full control vá» data/logic. Conversations cá»§a tráº» em cáº§n Ä‘Æ°á»£c báº£o máº­t tá»‘i Ä‘a.|
|**Giáº£i phÃ¡p Ä‘á» xuáº¥t**|XÃ¢y dá»±ng self-hosted Long-Term Memory System vá»›i 2 core APIs (extract_facts, search_facts) tÆ°Æ¡ng tá»± Mem0, táº­n dá»¥ng infrastructure Milvus + Neo4j Ä‘Ã£ cÃ³ sáºµn táº¡i 124.197.21.40|
|**TÃ¡c Ä‘á»™ng Business**|â€¢ Tiáº¿t kiá»‡m $500-1000/month (60-80% cost reduction)<br>â€¢ Data privacy 100% in-house<br>â€¢ Custom logic theo nhu cáº§u PIKA<br>â€¢ KhÃ´ng bá»‹ vendor lock-in|
|**TÃ¡c Ä‘á»™ng Technical**|â€¢ Latency <200ms (p95)<br>â€¢ Throughput 200+ rps<br>â€¢ Support 100K+ conversations<br>â€¢ Horizontal scalability<br>â€¢ Full observability|
|**Tech Stack**|Python 3.11, FastAPI, Milvus (vector), Neo4j (graph), PostgreSQL (metadata), Redis (cache), OpenAI API (LLM + embeddings)|
|**Effort Æ°á»›c tÃ­nh**|2 engineers Ã— 6-8 tuáº§n = 12-16 man-weeks|
|**Risk Level**|Medium - Infrastructure cÃ³ sáºµn, cáº§n implement logic cáº©n tháº­n|
|**Timeline**|â€¢ MVP: 3 tuáº§n<br>â€¢ Production-ready: 6 tuáº§n<br>â€¢ Full migration: 8 tuáº§n|
|**Chi phÃ­ (Year 1)**|~$3,000 infrastructure vs $6,000-12,000 Mem0 Enterprise|

## 1.2 Kiáº¿n trÃºc Tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PIKA LONG-TERM MEMORY SYSTEM                            â”‚
â”‚                   (Self-Hosted Solution)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  PIKA Robot    â”‚         â”‚  Admin Panel   â”‚                     â”‚
â”‚  â”‚  AI Workflow   â”‚         â”‚   (Future)     â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚          â”‚                          â”‚                               â”‚
â”‚          â”‚      HTTPS/JSON (TLS 1.3)â”‚                               â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                     â”‚                                                â”‚
â”‚                     â–¼                                                â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚         â”‚   PIKA MEMORY API SERVICE       â”‚                        â”‚
â”‚         â”‚      (FastAPI + Python)         â”‚                        â”‚
â”‚         â”‚                                 â”‚                        â”‚
â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                        â”‚
â”‚         â”‚  â”‚ POST /v1/extract_facts  â”‚   â”‚                        â”‚
â”‚         â”‚  â”‚ POST /v1/search_facts   â”‚   â”‚                        â”‚
â”‚         â”‚  â”‚ GET  /health            â”‚   â”‚                        â”‚
â”‚         â”‚  â”‚ GET  /metrics           â”‚   â”‚                        â”‚
â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                        â”‚
â”‚         â”‚                                 â”‚                        â”‚
â”‚         â”‚  Features:                      â”‚                        â”‚
â”‚         â”‚  â€¢ API Key Auth                 â”‚                        â”‚
â”‚         â”‚  â€¢ Rate Limiting                â”‚                        â”‚
â”‚         â”‚  â€¢ Circuit Breakers             â”‚                        â”‚
â”‚         â”‚  â€¢ Retry Logic                  â”‚                        â”‚
â”‚         â”‚  â€¢ Caching                      â”‚                        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                  â”‚                                                  â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚      â”‚           â”‚              â”‚              â”‚                   â”‚
â”‚      â–¼           â–¼              â–¼              â–¼                   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚ â”‚ Milvus  â”‚ â”‚  Neo4j  â”‚ â”‚PostgreSQL â”‚ â”‚   Redis   â”‚              â”‚
â”‚ â”‚(Vector) â”‚ â”‚ (Graph) â”‚ â”‚(Metadata) â”‚ â”‚  (Cache)  â”‚              â”‚
â”‚ â”‚Port:8000â”‚ â”‚Port:8687â”‚ â”‚           â”‚ â”‚           â”‚              â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                     â”‚
â”‚      External Services:       Monitoring:                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚ â”‚   OpenAI API   â”‚       â”‚    Datadog     â”‚                       â”‚
â”‚ â”‚  â€¢ GPT-4o-mini â”‚       â”‚  â€¢ Logs        â”‚                       â”‚
â”‚ â”‚  â€¢ Embeddings  â”‚       â”‚  â€¢ Metrics     â”‚                       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â€¢ APM Traces  â”‚                       â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 1.3 Key Metrics & Success Criteria

|KPI|Hiá»‡n táº¡i (Mem0)|Target (Self-hosted)|CÃ¡ch Ä‘o|
|---|---|---|---|
|**Performance**||||
|Response Time (P50)|~80ms|<100ms|Datadog APM|
|Response Time (P95)|~150ms|<200ms|Datadog APM|
|Response Time (P99)|~300ms|<500ms|Datadog APM|
|Throughput|~100 rps|200+ rps|Load testing|
|**Reliability**||||
|Uptime|99.5%|99.9%|Status monitoring|
|Error Rate|<0.5%|<0.1%|Prometheus|
|MTTR|Unknown|<30 min|Incident tracking|
|**Cost**||||
|Monthly Cost|$500-1000|$250|Cloud billing|
|Cost per 1K requests|~$0.10|~$0.03|Analytics|
|**Quality**||||
|Memory Accuracy|~85%|>90%|Manual testing|
|Fact Recall|~80%|>85%|Test suite|

## 1.4 Risk Summary

|Risk|Probability|Impact|Mitigation|
|---|---|---|---|
|OpenAI API downtime|Medium|High|Cache embeddings, fallback to local model|
|Milvus performance|Low|High|Load testing, proper indexing, monitoring|
|Data migration issues|Medium|Medium|Phased migration, validation scripts|
|Team bandwidth|High|Medium|Clear roadmap, dedicated resources|
|Security vulnerabilities|Low|Critical|Security audit, penetration testing|

---

# 2. GIá»šI THIá»†U VÃ€ Bá»I Cáº¢NH

## 2.1 Má»¥c Ä‘Ã­ch TÃ i liá»‡u

TÃ i liá»‡u nÃ y cung cáº¥p **thiáº¿t káº¿ production-ready hoÃ n chá»‰nh** cho viá»‡c migration PIKA Memory System tá»« Mem0 Enterprise sang self-hosted solution:

- âœ… **Architecture Design (HLD/LLD)**: Kiáº¿n trÃºc chi tiáº¿t vÃ  data flow
- âœ… **API Specification**: Contract Ä‘áº§y Ä‘á»§ cho 2 core APIs
- âœ… **Security Design**: Authentication, encryption, compliance
- âœ… **Data Design**: Schemas cho Milvus, Neo4j, PostgreSQL, Redis
- âœ… **Resilience Patterns**: Circuit breakers, retries, fallbacks
- âœ… **Observability**: Logging, metrics, tracing, alerting
- âœ… **Testing Strategy**: Unit, integration, load testing
- âœ… **Operations**: Runbooks, incident response, deployment
- âœ… **Implementation Plan**: 6-8 week roadmap vá»›i milestones

## 2.2 Äá»‘i tÆ°á»£ng Sá»­ dá»¥ng

|Äá»‘i tÆ°á»£ng|Má»¥c Ä‘Ã­ch sá»­ dá»¥ng|Sections quan trá»ng|
|---|---|---|
|**Backend Engineers**|Implementation & coding|4, 5, 6, 7, 20|
|**DevOps/SRE**|Deployment & operations|9, 11, 17|
|**QA Engineers**|Test planning & execution|12, 13|
|**Security Team**|Security review & approval|8|
|**Product Manager**|Understanding scope & timeline|1, 3, 18|
|**Tech Lead**|Architecture review & decisions|4, 9, 16|
|**Management**|Budget & resource allocation|1, 15|

## 2.3 Bá»‘i cáº£nh Dá»± Ã¡n

### Há»‡ thá»‘ng Hiá»‡n táº¡i (Mem0 Enterprise)

PIKA robot hiá»‡n Ä‘ang sá»­ dá»¥ng **Mem0 Enterprise API** táº¡i `https://pika-mem0.stepup.edu.vn` cho long-term memory vá»›i 2 APIs:

```bash
# API 1: TrÃ­ch xuáº¥t facts tá»« conversation
POST /extract_facts
{
  "user_id": "019afe35-1317-7b94-a833-ff5e2504a9c3",
  "conversation_id": "1",
  "conversation": [
    {"role": "assistant", "content": "ChÃ o cáº­u! Cuá»‘i tuáº§n cáº­u lÃ m gÃ¬?"},
    {"role": "user", "content": "MÃ¬nh Ä‘i chÆ¡i cÃ´ng viÃªn vá»›i gia Ä‘Ã¬nh"}
  ]
}

# API 2: TÃ¬m kiáº¿m facts theo query
POST /search_facts
{
  "user_id": "019afe35-1317-7b94-a833-ff5e2504a9c3",
  "query": "ThÃº cÆ°ng",
  "limit": 20,
  "score_threshold": 0.4
}
```

**âœ… Æ¯u Ä‘iá»ƒm Mem0 Enterprise:**

- Dá»… integrate, plug-and-play
- High availability (~99.5%)
- Auto-scaling
- KhÃ´ng cáº§n maintain infrastructure

**âŒ NhÆ°á»£c Ä‘iá»ƒm Mem0 Enterprise:**

- Chi phÃ­ cao: $500-1000/thÃ¡ng (scaling vá»›i traffic)
- Vendor lock-in: khÃ´ng thá»ƒ customize logic
- Data privacy: conversations cá»§a tráº» em á»Ÿ external service
- Performance: khÃ´ng control Ä‘Æ°á»£c optimization
- Rate limits: bá»‹ giá»›i háº¡n theo pricing tier
- Debugging khÃ³: khÃ´ng tháº¥y internal logic

### Táº¡i sao cáº§n Self-Hosted?

#### 1. **Cost Savings (ROI)**

```
Mem0 Enterprise: $500-1000/month = $6,000-12,000/year
Self-hosted:
  - Infrastructure: $200/month = $2,400/year
  - Engineering effort (one-time): $10,000
  - Maintenance: $50/month = $600/year
  
Year 1 total: $13,000 (self-hosted) vs $9,000 (Mem0 mid-tier)
Year 2+ total: $3,000/year vs $9,000/year
Break-even: ~18 months
ROI Year 2+: $6,000 saved/year (67% reduction)
```

#### 2. **Data Privacy & Compliance**

- PIKA xá»­ lÃ½ conversations cá»§a tráº» em 6-12 tuá»•i
- GDPR requirements: data residency, right to be forgotten
- Parent consent: cáº§n guarantee data khÃ´ng share vá»›i 3rd party
- Self-hosted = full control = compliance easier

#### 3. **Customization for PIKA**

Mem0 generic, PIKA cáº§n custom:

- Extract emotions tá»« `<emotion type="happy"/>` tags
- Track learning progress (vocabulary, grammar)
- Personalize based on age (6 vs 12 tuá»•i khÃ¡c nhau)
- Multi-modal: support audio transcript analysis

#### 4. **Performance Optimization**

- Control Ä‘Æ°á»£c caching strategy
- Optimize specifically cho PIKA workload
- No rate limits
- Direct connection to Milvus/Neo4j (no network hops)

#### 5. **Independence & Reliability**

- KhÃ´ng phá»¥ thuá»™c Mem0 uptime
- Control deployment schedule
- Can debug production issues
- Understand system behavior fully

### Infrastructure ÄÃ£ cÃ³

Team Ä‘Ã£ provision infrastructure sáºµn sÃ ng:

```yaml
Milvus (Vector Database):
  Host: "124.197.21.40"
  Port: 8000
  Status: "Running & tested"
  Collections: "Ready to create"
  Performance: "Sub-millisecond search tested"

Neo4j (Graph Database):
  Host: "124.197.21.40"
  Port: 8687 (Bolt protocol)
  HTTP Port: 8474 (Browser)
  Credentials:
    Username: "neo4j"
    Password: "mem0graph"
  Status: "Running & tested"
  Version: "5.x Community Edition"
```

**Verification Tests Ä‘Ã£ lÃ m:**

```python
# Milvus connection test - PASSED
connections.connect(host='124.197.21.40', port='8000')
âœ… Connected successfully

# Neo4j connection test - PASSED  
driver = GraphDatabase.driver('bolt://124.197.21.40:8687', 
                               auth=('neo4j', 'mem0graph'))
âœ… Connected successfully
```

---

# 3. Má»¤C TIÃŠU, PHáº M VI & RÃ€NG BUá»˜C

## 3.1 Má»¥c tiÃªu Dá»± Ã¡n

### Business Goals

|Goal|Metric|Baseline|Target|Timeline|Owner|
|---|---|---|---|---|---|
|Giáº£m chi phÃ­|Monthly cost|$700|$250 (-64%)|Q1 2025|Finance|
|TÄƒng data privacy|Data residency|0% in-house|100%|Q1 2025|Security|
|Custom features|Feature velocity|1/quarter|2/month|Q2 2025|Product|
|Parent trust|NPS score|45|60+|Q2 2025|Product|

### Technical Goals

|Goal|Metric|Baseline|Target|Timeline|Owner|
|---|---|---|---|---|---|
|Performance|P95 latency|150ms|<200ms|Sprint 5|Backend|
|Reliability|Uptime SLA|99.5%|99.9%|Sprint 6|SRE|
|Scalability|Peak RPS|100|300+|Sprint 6|Backend|
|Accuracy|Fact recall|80%|>85%|Sprint 5|AI/ML|
|Quality|Test coverage|0%|>80%|Sprint 4|QA|

## 3.2 Pháº¡m vi Dá»± Ã¡n (Scope)

### âœ… Phase 1 - MVP (Must Have) - Tuáº§n 1-4

**Core APIs:**

- âœ… `POST /v1/extract_facts`: Extract facts tá»« conversation using LLM
- âœ… `POST /v1/search_facts`: Semantic search facts using vector similarity
- âœ… Health check endpoints: `/health`, `/health/ready`

**Data Layer:**

- âœ… Milvus integration: Vector storage & similarity search
- âœ… Neo4j integration: Graph relationships between facts
- âœ… PostgreSQL: Metadata storage (conversations, users)
- âœ… Redis: Basic caching layer

**ML/AI:**

- âœ… OpenAI GPT-4o-mini: Fact extraction from conversations
- âœ… OpenAI text-embedding-3-small: Text vectorization

### âœ… Phase 2 - Production Features (Should Have) - Tuáº§n 5-6

**Resilience:**

- âœ… Retry logic vá»›i exponential backoff
- âœ… Circuit breakers cho external dependencies
- âœ… Graceful degradation strategies
- âœ… Timeout configuration

**Security:**

- âœ… API key authentication
- âœ… Rate limiting per user
- âœ… Input validation & sanitization
- âœ… TLS encryption

**Observability:**

- âœ… Structured logging (JSON format)
- âœ… Prometheus metrics
- âœ… Datadog APM tracing
- âœ… Alerting rules

**Performance:**

- âœ… Redis caching cho search results
- âœ… Connection pooling
- âœ… Query optimization

### ğŸ“‹ Phase 3 - Advanced Features (Nice to Have) - Post-Launch

- ğŸ’¡ Auto memory consolidation (merge duplicate/similar facts)
- ğŸ’¡ Temporal decay scoring (old facts cÃ³ score tháº¥p hÆ¡n)
- ğŸ’¡ Multi-language support (hiá»‡n chá»‰ Vietnamese/English)
- ğŸ’¡ Batch processing API
- ğŸ’¡ Memory analytics dashboard
- ğŸ’¡ A/B testing framework cho different extraction prompts

### âŒ Out-of-Scope (Non-Goals)

|Non-Goal|LÃ½ do|Alternative|
|---|---|---|
|Memory visualization UI|Not backend scope|Separate frontend project|
|Real-time websocket streaming|PIKA workflow lÃ  async|HTTP APIs sufficient|
|Multi-tenant isolation|Chá»‰ cÃ³ 1 PIKA app|Single tenant architecture|
|On-premise deployment|Cloud-first|Kubernetes on cloud|
|Mobile SDK|API-first approach|REST APIs enough|

## 3.3 Assumptions (Giáº£ Ä‘á»‹nh)

|ID|Assumption|Impact náº¿u Wrong|Validation Method|Status|
|---|---|---|---|---|
|A1|Milvus/Neo4j infrastructure stable, <1% downtime|High - project delay|Daily health checks|âœ… Validated|
|A2|OpenAI API available 99.9%, <100ms latency|Medium - fallback needed|Monitor uptime|ğŸŸ¡ Ongoing|
|A3|Traffic <100K conversations/month trong 6 thÃ¡ng Ä‘áº§u|Low - over-provision|Analytics tracking|ğŸŸ¡ TBD|
|A4|Average conversation length <50 turns|Low - chunking OK|Analyze current data|âœ… Validated|
|A5|Team cÃ³ 2 backend engineers dedicated|High - timeline slip|Resource planning|âœ… Confirmed|
|A6|PostgreSQL sufficient cho metadata (not BigQuery)|Low - can migrate later|Volume projection|âœ… OK|

## 3.4 Constraints (RÃ ng buá»™c)

### Technical Constraints

|Constraint|Reason|Workaround|Impact|
|---|---|---|---|
|Python 3.11+ required|Team standard, async support|None needed|Low|
|Milvus port 8000 fixed|Infrastructure giÃ  cÃ³|None needed|Low|
|Neo4j bolt://8687 fixed|Infrastructure Ä‘Ã£ cÃ³|None needed|Low|
|OpenAI API dependency|Best embedding quality|Fallback: local model (lower quality)|Medium|
|FastAPI framework|Team expertise|None needed|Low|
|No GPU on API servers|Cost optimization|Use OpenAI API for inference|Low|

### Business Constraints

|Constraint|Impact|Mitigation|
|---|---|---|
|Budget <$5K setup|Cannot buy expensive tools|Use open-source stack|
|Timeline 6-8 tuáº§n|Tight schedule|MVP-first, phase approach|
|Zero downtime requirement|Migration risk|Blue-green deployment, gradual rollout|
|Must maintain Mem0 compatibility|Integration effort|Keep same API contract|

### Compliance & Security Constraints

|Requirement|Why|Implementation|
|---|---|---|
|GDPR compliance|EU users|Data residency EU, right to deletion|
|Data retention 2 years max|Policy|Automated cleanup jobs|
|Encryption at rest|Children's data|PostgreSQL encryption, encrypted backups|
|Audit logging|Compliance|Log all data access to separate system|
|No PII in logs|Security|Mask user_id, sanitize content|

## 3.5 Dependencies

### External Dependencies

```mermaid
graph TB
    A[PIKA Memory API] --> B[OpenAI API]
    A --> C[Milvus Server]
    A --> D[Neo4j Server]
    A --> E[PostgreSQL]
    A --> F[Redis]
    
    B --> |Embeddings| A
    B --> |LLM| A
    C --> |Vectors| A
    D --> |Graph| A
```

|Dependency|Owner|SLA|Risk|Fallback Plan|
|---|---|---|---|---|
|OpenAI API|OpenAI|99.9%|Medium|Cached embeddings, local LLM|
|Milvus|Internal DevOps|99.5%|Low|Redis backup, PostgreSQL fallback|
|Neo4j|Internal DevOps|99.5%|Low|Skip relationships, flat results|
|PostgreSQL|Internal DevOps|99.9%|Critical|Multi-AZ deployment, backups|
|Redis|Internal DevOps|99.5%|Low|Bypass cache, direct query|

### Internal Dependencies

|Dependency|Team|Interface|Timeline|
|---|---|---|---|
|PIKA AI Workflow|AI Team|HTTP API calls|Already integrated|
|User Service|Backend Team|User ID validation|Already available|
|Analytics Pipeline|Data Team|Event streaming|Not blocking MVP|

---

# 4. KIáº¾N TRÃšC Tá»”NG THá»‚ (HLD)

## 4.1 System Context Diagram (C4 Level 1)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SYSTEM CONTEXT                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚    External Actors:                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚    â”‚  PIKA Robot     â”‚         â”‚  Admin Panel    â”‚                â”‚
â”‚    â”‚  AI Workflow    â”‚         â”‚  (Monitoring)   â”‚                â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚             â”‚                           â”‚                           â”‚
â”‚             â”‚        HTTPS (TLS 1.3)    â”‚                           â”‚
â”‚             â”‚        JSON payloads      â”‚                           â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                         â”‚                                           â”‚
â”‚                         â–¼                                           â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚         â”‚                                       â”‚                  â”‚
â”‚         â”‚   PIKA MEMORY API SERVICE             â”‚                  â”‚
â”‚         â”‚   (Long-Term Memory System)           â”‚                  â”‚
â”‚         â”‚                                       â”‚                  â”‚
â”‚         â”‚   Capabilities:                       â”‚                  â”‚
â”‚         â”‚   â€¢ Extract facts from conversations  â”‚                  â”‚
â”‚         â”‚   â€¢ Semantic search facts             â”‚                  â”‚
â”‚         â”‚   â€¢ Manage user memory profiles       â”‚                  â”‚
â”‚         â”‚   â€¢ Track relationships               â”‚                  â”‚
â”‚         â”‚   â€¢ Analytics & monitoring            â”‚                  â”‚
â”‚         â”‚                                       â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                    â”‚                                                â”‚
â”‚                    â”‚                                                â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚      â”‚             â”‚              â”‚              â”‚                 â”‚
â”‚      â–¼             â–¼              â–¼              â–¼                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚ â”‚ Milvus  â”‚  â”‚  Neo4j  â”‚  â”‚PostgreSQL â”‚  â”‚   Redis   â”‚           â”‚
â”‚ â”‚(Vector) â”‚  â”‚ (Graph) â”‚  â”‚(Metadata) â”‚  â”‚  (Cache)  â”‚           â”‚
â”‚ â”‚ Store   â”‚  â”‚  Store  â”‚  â”‚  Storage  â”‚  â”‚  Layer    â”‚           â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                     â”‚
â”‚                    External Services:                               â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚      â”‚     OpenAI API      â”‚       â”‚      Datadog        â”‚        â”‚
â”‚      â”‚  â€¢ GPT-4o-mini LLM  â”‚       â”‚  â€¢ Logging          â”‚        â”‚
â”‚      â”‚  â€¢ Text Embeddings  â”‚       â”‚  â€¢ Metrics          â”‚        â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â€¢ APM Tracing      â”‚        â”‚
â”‚                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 4.2 Container Diagram (C4 Level 2)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MEMORY API SERVICE - INTERNAL ARCHITECTURE        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    API LAYER (FastAPI)                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ extract_facts  â”‚  â”‚ search_facts   â”‚  â”‚  Health Check    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚   Endpoint     â”‚  â”‚   Endpoint     â”‚  â”‚   Endpoints      â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                â”‚  â”‚                â”‚  â”‚  â€¢ /health       â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ POST /v1/      â”‚  â”‚ POST /v1/      â”‚  â”‚  â€¢ /metrics      â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ extract_facts  â”‚  â”‚ search_facts   â”‚  â”‚  â€¢ /ready        â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                   â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                   MIDDLEWARE LAYER                               â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚   Auth     â”‚  â”‚Rate Limiterâ”‚  â”‚   Logger   â”‚  â”‚  Metrics  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚Middleware  â”‚  â”‚Middleware  â”‚  â”‚Middleware  â”‚  â”‚Middleware â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                   â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                   SERVICE LAYER (Business Logic)                 â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚ â”‚
â”‚  â”‚  â”‚  FactExtractor       â”‚      â”‚  FactSearcher        â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  Service             â”‚      â”‚  Service             â”‚         â”‚ â”‚
â”‚  â”‚  â”‚                      â”‚      â”‚                      â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Parse conversationâ”‚      â”‚  â€¢ Embed query       â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Call OpenAI LLM   â”‚      â”‚  â€¢ Search Milvus     â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Generate vectors  â”‚      â”‚  â€¢ Enrich Neo4j      â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Store facts       â”‚      â”‚  â€¢ Rank results      â”‚         â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                â”‚                              â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                   REPOSITORY LAYER (Data Access)                  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  Milvus    â”‚  â”‚   Neo4j    â”‚  â”‚ PostgreSQL â”‚  â”‚   Redis    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ Repository â”‚  â”‚ Repository â”‚  â”‚ Repository â”‚  â”‚ Repository â”‚ â”‚ â”‚
â”‚  â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Insert   â”‚  â”‚ â€¢ Create   â”‚  â”‚ â€¢ Save     â”‚  â”‚ â€¢ Get      â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Search   â”‚  â”‚   nodes    â”‚  â”‚   metadata â”‚  â”‚ â€¢ Set      â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Delete   â”‚  â”‚ â€¢ Create   â”‚  â”‚ â€¢ Query    â”‚  â”‚ â€¢ Delete   â”‚ â”‚ â”‚
â”‚  â”‚  â”‚            â”‚  â”‚   relationsâ”‚  â”‚ â€¢ Update   â”‚  â”‚            â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚               â”‚               â”‚               â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                   UTILITY LAYER                                  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚ â”‚
â”‚  â”‚  â”‚   OpenAI     â”‚  â”‚   Config     â”‚  â”‚   Metrics    â”‚          â”‚ â”‚
â”‚  â”‚  â”‚   Client     â”‚  â”‚   Manager    â”‚  â”‚   Exporter   â”‚          â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 4.3 Component Diagram - Data Flow

### Flow 1: Extract Facts

```
User           API Gateway      FactExtractor     OpenAI        Milvus       Neo4j      PostgreSQL
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚â”€POST requestâ”€â”€â”€â–¶â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚ extract_facts   â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚â”€Authenticateâ”€â”€â”€â”€â–¶â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚ API Key          â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚â”€Validate requestâ–¶â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚â”€Extractâ”€â”€â”€â”€â”€â”€â–¶            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚ facts (LLM)  â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚ Facts JSON   â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚â”€Generateâ”€â”€â”€â”€â”€â–¶            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚ embeddings   â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚ Vectors      â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚â”€Store vectorsâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚ Fact IDs     â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚â”€Create graph relationshipsâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚             â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚             â”‚
 â”‚                 â”‚                  â”‚ Success      â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚â”€Save metadataâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚                  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚                 â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚                 â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚â—€â”€200 OKâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
 â”‚ fact_ids        â”‚                  â”‚              â”‚            â”‚            â”‚             â”‚
```

### Flow 2: Search Facts

```
User           API Gateway      FactSearcher      Redis       OpenAI      Milvus       Neo4j
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚â”€POST requestâ”€â”€â”€â–¶â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚ search_facts    â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚â”€Authenticateâ”€â”€â”€â”€â–¶â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚â”€Validateâ”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚â”€Check cacheâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚ Cache MISS  â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚â”€Embed queryâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚ Query vectorâ”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚â”€Similarity searchâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚            â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚
 â”‚                 â”‚                  â”‚ Top K facts â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚â”€Enrich with relationshipsâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚                 â”‚                  â”‚ Enriched    â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚â”€Re-rank results         â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚â”€Cache resultsâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚ TTL: 5min   â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚                 â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚â—€â”€200 OKâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚ facts + scores  â”‚                  â”‚             â”‚            â”‚           â”‚            â”‚
```

## 4.4 Tech Stack & Rationale

|Layer|Technology|Version|Rationale|Alternatives Considered|
|---|---|---|---|---|
|**API Framework**|FastAPI|0.109+|â€¢ Async/await support<br>â€¢ Auto OpenAPI docs<br>â€¢ Fast performance<br>â€¢ Type hints|Flask (no async), Django (too heavy)|
|**Language**|Python|3.11+|â€¢ Team expertise<br>â€¢ Rich ML/AI ecosystem<br>â€¢ Fast development|Go (learning curve), Node.js (typing)|
|**Vector Store**|Milvus|2.3+|â€¢ Already provisioned<br>â€¢ Open source<br>â€¢ High performance<br>â€¢ Billion-scale support|Pinecone (cost), Weaviate (complex), Qdrant (less mature)|
|**Graph Store**|Neo4j|5.x|â€¢ Already provisioned<br>â€¢ Mature graph DB<br>â€¢ Cypher query language<br>â€¢ Good Python driver|Amazon Neptune (vendor lock), TigerGraph (cost)|
|**Metadata DB**|PostgreSQL|15+|â€¢ ACID compliance<br>â€¢ JSONB support<br>â€¢ Team familiar<br>â€¢ Battle-tested|MySQL (fewer features), MongoDB (eventual consistency)|
|**Cache**|Redis|7.x|â€¢ Sub-millisecond latency<br>â€¢ Persistence options<br>â€¢ Pub/sub support|Memcached (fewer features)|
|**LLM**|OpenAI GPT-4o-mini|-|â€¢ Best quality/cost<br>â€¢ Fast inference<br>â€¢ Structured outputs|Claude (cost), Gemini (quality), Local (accuracy)|
|**Embeddings**|text-embedding-3-small|-|â€¢ 1536 dims<br>â€¢ High quality<br>â€¢ $0.02/1M tokens|text-embedding-ada-002 (older), Cohere (cost)|
|**Monitoring**|Datadog|-|â€¢ All-in-one<br>â€¢ APM traces<br>â€¢ Easy integration|Prometheus+Grafana (ops), New Relic (cost)|
|**Deployment**|Docker + K8s|-|â€¢ Standard practice<br>â€¢ Easy scaling<br>â€¢ Team knows|Serverless (cold start), VMs (outdated)|

## 4.5 Communication Patterns

|Pattern|Use Case|Protocol|Implementation|
|---|---|---|---|
|**Synchronous Request/Response**|API calls tá»« PIKA|HTTP/REST|FastAPI endpoints|
|**Circuit Breaker**|External dependencies|N/A|pybreaker library|
|**Retry vá»›i Backoff**|Transient failures|N/A|tenacity library|
|**Caching**|Hot data|Redis|Cache-aside pattern|
|**Connection Pooling**|Database connections|TCP|psycopg2 pool, Neo4j driver pool|
|**Health Checks**|Service monitoring|HTTP|`/health`, `/ready` endpoints|

---

# 5. THIáº¾T Káº¾ CHI TIáº¾T (LLD)

## 5.1 Project Structure

```
pika-mem0-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                      # FastAPI application entry point
â”‚   â”œâ”€â”€ config.py                    # Configuration management
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                         # API endpoints layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ deps.py                  # Dependency injection
â”‚   â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ extract.py           # POST /v1/extract_facts
â”‚   â”‚   â”‚   â”œâ”€â”€ search.py            # POST /v1/search_facts
â”‚   â”‚   â”‚   â””â”€â”€ router.py            # API v1 router
â”‚   â”‚   â””â”€â”€ health.py                # Health check endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                        # Core functionality
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ security.py              # Authentication, API keys
â”‚   â”‚   â”œâ”€â”€ rate_limiter.py          # Rate limiting logic
â”‚   â”‚   â””â”€â”€ circuit_breaker.py       # Circuit breaker patterns
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                    # Business logic layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ fact_extractor.py       # Fact extraction service
â”‚   â”‚   â”œâ”€â”€ fact_searcher.py        # Fact search service
â”‚   â”‚   â”œâ”€â”€ embedder.py              # OpenAI embedding wrapper
â”‚   â”‚   â””â”€â”€ llm_client.py            # OpenAI LLM client
â”‚   â”‚
â”‚   â”œâ”€â”€ repositories/                # Data access layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ milvus_repo.py          # Milvus vector operations
â”‚   â”‚   â”œâ”€â”€ neo4j_repo.py           # Neo4j graph operations
â”‚   â”‚   â”œâ”€â”€ postgres_repo.py        # PostgreSQL CRUD
â”‚   â”‚   â””â”€â”€ redis_repo.py           # Redis caching
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                      # Data models (Pydantic)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ requests.py              # API request schemas
â”‚   â”‚   â”œâ”€â”€ responses.py             # API response schemas
â”‚   â”‚   â”œâ”€â”€ entities.py              # Domain entities
â”‚   â”‚   â””â”€â”€ enums.py                 # Enumerations
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                       # Utility modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logger.py                # Structured logging
â”‚   â”‚   â”œâ”€â”€ metrics.py               # Prometheus metrics
â”‚   â”‚   â””â”€â”€ exceptions.py            # Custom exceptions
â”‚   â”‚
â”‚   â””â”€â”€ middleware/                  # Custom middleware
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logging_middleware.py
â”‚       â”œâ”€â”€ metrics_middleware.py
â”‚       â””â”€â”€ error_handler.py
â”‚
â”œâ”€â”€ tests/                           # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                  # Pytest fixtures
â”‚   â”œâ”€â”€ unit/                        # Unit tests
â”‚   â”‚   â”œâ”€â”€ test_fact_extractor.py
â”‚   â”‚   â””â”€â”€ test_fact_searcher.py
â”‚   â”œâ”€â”€ integration/                 # Integration tests
â”‚   â”‚   â”œâ”€â”€ test_api_extract.py
â”‚   â”‚   â””â”€â”€ test_api_search.py
â”‚   â””â”€â”€ load/                        # Load tests
â”‚       â””â”€â”€ locustfile.py
â”‚
â”œâ”€â”€ docker/                          # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ Dockerfile.dev
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ k8s/                             # Kubernetes manifests
â”‚   â”œâ”€â”€ namespace.yaml
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â””â”€â”€ secrets.yaml
â”‚
â”œâ”€â”€ scripts/                         # Utility scripts
â”‚   â”œâ”€â”€ migrate_data.py              # Data migration from Mem0
â”‚   â”œâ”€â”€ seed_test_data.py
â”‚   â””â”€â”€ benchmark.py
â”‚
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ api.md                       # API documentation
â”‚   â”œâ”€â”€ architecture.md
â”‚   â””â”€â”€ runbook.md
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml                   # CI/CD pipeline
â”‚       â””â”€â”€ security-scan.yml
â”‚
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ requirements-dev.txt
â”œâ”€â”€ pyproject.toml                   # Project metadata
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## 5.2 Core Service Implementation

### 5.2.1 FactExtractor Service (Detailed)

```python
# app/services/fact_extractor.py
from typing import List, Dict, Optional
import json
import asyncio
from openai import AsyncOpenAI
from tenacity import retry, stop_after_attempt, wait_exponential

from app.models.entities import Fact, Conversation, FactCategory
from app.repositories.milvus_repo import MilvusRepository
from app.repositories.neo4j_repo import Neo4jRepository
from app.repositories.postgres_repo import PostgresRepository
from app.services.embedder import EmbedderService
from app.utils.logger import get_logger
from app.utils.metrics import FACT_EXTRACTION_DURATION, FACTS_EXTRACTED_TOTAL

logger = get_logger(__name__)


class FactExtractorService:
    """
    Service chá»‹u trÃ¡ch nhiá»‡m trÃ­ch xuáº¥t facts tá»« conversation
    
    Workflow:
    1. Parse & validate conversation
    2. Call OpenAI LLM Ä‘á»ƒ extract facts (vá»›i structured output)
    3. Generate embeddings cho má»—i fact
    4. Store vectors vÃ o Milvus
    5. Create relationships vÃ o Neo4j
    6. Save metadata vÃ o PostgreSQL
    7. Return fact IDs
    
    Error Handling:
    - Retry transient LLM failures
    - Rollback on partial failures
    - Log all operations
    """
    
    EXTRACTION_PROMPT_TEMPLATE = """
Báº¡n lÃ  AI assistant chuyÃªn trÃ­ch xuáº¥t thÃ´ng tin tá»« há»™i thoáº¡i giá»¯a PIKA (robot há»c tiáº¿ng Anh) vÃ  tráº» em.

**Nhiá»‡m vá»¥:** PhÃ¢n tÃ­ch conversation vÃ  trÃ­ch xuáº¥t cÃ¡c FACTS quan trá»ng vá» user (tráº» em).

**Facts cáº§n extract:**
- Sá»Ÿ thÃ­ch (hobbies, interests, favorite things)
- Kinh nghiá»‡m (experiences, activities, events)
- ThÃ³i quen (habits, routines, behaviors)
- Cáº£m xÃºc (emotions trong context cá»¥ thá»ƒ)
- Má»‘i quan há»‡ (family, friends, pets)
- Há»c táº­p (learning progress, vocabulary, grammar achievements)
- ThÃ´ng tin cÃ¡ nhÃ¢n (tÃªn, tuá»•i, trÆ°á»ng há»c - náº¿u cÃ³)

**LÆ°u Ã½ quan trá»ng:**
- Chá»‰ extract facts RÃ• RÃ€NG Ä‘Æ°á»£c Ä‘á» cáº­p, khÃ´ng suy Ä‘oÃ¡n
- Má»—i fact pháº£i specific vÃ  actionable
- Ghi nháº­n entities (tÃªn ngÆ°á»i, Ä‘á»‹a Ä‘iá»ƒm, váº­t pháº©m)
- ÄÃ¡nh giÃ¡ confidence: 1.0 (cháº¯c cháº¯n) Ä‘áº¿n 0.5 (cÃ³ thá»ƒ)

**Output format:** JSON vá»›i structure:
{{
  "facts": [
    {{
      "content": "MÃ´ táº£ fact ngáº¯n gá»n, cá»¥ thá»ƒ",
      "category": "preference|experience|habit|emotion|relationship|learning|personal_info",
      "confidence": 0.5-1.0,
      "entities": ["entity1", "entity2"],
      "context": "Ngá»¯ cáº£nh conversation (náº¿u cáº§n)"
    }}
  ]
}}

**Conversation:**
{conversation_text}
"""
    
    def __init__(
        self,
        openai_client: AsyncOpenAI,
        embedder: EmbedderService,
        milvus_repo: MilvusRepository,
        neo4j_repo: Neo4jRepository,
        postgres_repo: PostgresRepository
    ):
        self.openai = openai_client
        self.embedder = embedder
        self.milvus = milvus_repo
        self.neo4j = neo4j_repo
        self.postgres = postgres_repo
        
    async def extract_facts(
        self,
        user_id: str,
        conversation_id: str,
        conversation: List[Dict]
    ) -> List[Fact]:
        """
        Main method: Extract facts from conversation
        
        Args:
            user_id: PIKA user unique ID
            conversation_id: Unique conversation ID
            conversation: List of {role: str, content: str} messages
            
        Returns:
            List of Fact objects with IDs assigned
            
        Raises:
            ExtractionError: If LLM extraction fails
            StorageError: If storage operations fail
        """
        start_time = asyncio.get_event_loop().time()
        
        try:
            logger.info(
                "Starting fact extraction",
                extra={
                    "user_id": user_id,
                    "conversation_id": conversation_id,
                    "message_count": len(conversation)
                }
            )
            
            # Step 1: Extract facts using LLM
            extracted_facts_raw = await self._extract_with_llm(conversation)
            
            if not extracted_facts_raw:
                logger.warning("No facts extracted from conversation")
                return []
            
            # Step 2: Generate embeddings for facts
            facts_with_vectors = await self._generate_embeddings(
                extracted_facts_raw,
                user_id,
                conversation_id
            )
            
            # Step 3: Store in Milvus (vector store)
            milvus_ids = await self.milvus.insert_facts(
                user_id=user_id,
                facts=facts_with_vectors
            )
            
            # Assign Milvus IDs to facts
            for fact, milvus_id in zip(facts_with_vectors, milvus_ids):
                fact.milvus_id = milvus_id
                fact.fact_id = f"fact_{user_id}_{milvus_id}"
            
            # Step 4: Create relationships in Neo4j
            await self.neo4j.create_fact_relationships(
                user_id=user_id,
                conversation_id=conversation_id,
                facts=facts_with_vectors
            )
            
            # Step 5: Save metadata in PostgreSQL
            await self.postgres.save_conversation_metadata(
                user_id=user_id,
                conversation_id=conversation_id,
                facts=facts_with_vectors,
                conversation_raw=conversation
            )
            
            # Metrics
            duration = asyncio.get_event_loop().time() - start_time
            FACT_EXTRACTION_DURATION.observe(duration)
            FACTS_EXTRACTED_TOTAL.labels(
                user_id=user_id,
                status="success"
            ).inc(len(facts_with_vectors))
            
            logger.info(
                "Fact extraction completed",
                extra={
                    "user_id": user_id,
                    "facts_count": len(facts_with_vectors),
                    "duration_ms": int(duration * 1000)
                }
            )
            
            return facts_with_vectors
            
        except Exception as e:
            FACTS_EXTRACTED_TOTAL.labels(
                user_id=user_id,
                status="error"
            ).inc()
            
            logger.error(
                "Fact extraction failed",
                extra={
                    "user_id": user_id,
                    "conversation_id": conversation_id,
                    "error": str(e)
                },
                exc_info=True
            )
            raise
            
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        reraise=True
    )
    async def _extract_with_llm(
        self,
        conversation: List[Dict]
    ) -> List[Dict]:
        """
        Call OpenAI LLM to extract facts
        
        Uses GPT-4o-mini vá»›i structured output Ä‘á»ƒ ensure valid JSON
        Retry logic cho transient failures
        """
        # Format conversation
        conversation_text = "\n".join([
            f"{msg['role'].upper()}: {msg['content']}"
            for msg in conversation
        ])
        
        prompt = self.EXTRACTION_PROMPT_TEMPLATE.format(
            conversation_text=conversation_text
        )
        
        try:
            response = await self.openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert at extracting structured facts from conversations."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                response_format={"type": "json_object"},
                temperature=0.2,
                max_tokens=2000
            )
            
            result = json.loads(response.choices[0].message.content)
            facts = result.get("facts", [])
            
            # Validate facts structure
            validated_facts = []
            for fact in facts:
                if self._validate_fact_structure(fact):
                    validated_facts.append(fact)
                else:
                    logger.warning(f"Invalid fact structure: {fact}")
            
            return validated_facts
            
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON from LLM: {e}")
            return []
        except Exception as e:
            logger.error(f"LLM extraction failed: {e}")
            raise
            
    def _validate_fact_structure(self, fact: Dict) -> bool:
        """Validate fact has required fields"""
        required_fields = ["content", "category", "confidence"]
        return all(field in fact for field in required_fields)
        
    async def _generate_embeddings(
        self,
        facts_raw: List[Dict],
        user_id: str,
        conversation_id: str
    ) -> List[Fact]:
        """
        Generate vector embeddings for facts
        
        Uses OpenAI text-embedding-3-small (1536 dimensions)
        Batch processing Ä‘á»ƒ optimize API calls
        """
        if not facts_raw:
            return []
            
        # Prepare texts for embedding
        texts = [fact["content"] for fact in facts_raw]
        
        # Get embeddings tá»« EmbedderService (cÃ³ retry & caching)
        embeddings = await self.embedder.embed_batch(texts)
        
        # Create Fact objects
        facts = []
        for i, (fact_raw, embedding) in enumerate(zip(facts_raw, embeddings)):
            fact = Fact(
                fact_id=None,  # Will be assigned after Milvus insert
                user_id=user_id,
                conversation_id=conversation_id,
                content=fact_raw["content"],
                category=FactCategory(fact_raw["category"]),
                confidence=float(fact_raw["confidence"]),
                entities=fact_raw.get("entities", []),
                context=fact_raw.get("context"),
                embedding=embedding,
                milvus_id=None  # Will be assigned after insert
            )
            facts.append(fact)
            
        return facts
```

### 5.2.2 FactSearcher Service (Detailed)

```python
# app/services/fact_searcher.py
from typing import List, Optional, Tuple
import asyncio
from datetime import datetime, timedelta

from app.models.entities import Fact, SearchResult
from app.repositories.milvus_repo import MilvusRepository
from app.repositories.neo4j_repo import Neo4jRepository
from app.repositories.redis_repo import RedisRepository
from app.services.embedder import EmbedderService
from app.utils.logger import get_logger
from app.utils.metrics import SEARCH_DURATION, SEARCH_CACHE_HIT, SEARCH_TOTAL

logger = get_logger(__name__)


class FactSearcherService:
    """
    Service tÃ¬m kiáº¿m facts theo semantic query
    
    Workflow:
    1. Check Redis cache
    2. Embed search query
    3. Vector similarity search trong Milvus
    4. Enrich results vá»›i Neo4j relationships
    5. Re-rank results (similarity + recency + relationships)
    6. Cache results trong Redis
    7. Return top K results
    
    Performance Optimizations:
    - Cache-aside pattern
    - Batch Neo4j queries
    - Query result pagination
    """
    
    CACHE_TTL_SECONDS = 300  # 5 minutes
    
    def __init__(
        self,
        embedder: EmbedderService,
        milvus_repo: MilvusRepository,
        neo4j_repo: Neo4jRepository,
        redis_repo: RedisRepository
    ):
        self.embedder = embedder
        self.milvus = milvus_repo
        self.neo4j = neo4j_repo
        self.redis = redis_repo
        
    async def search_facts(
        self,
        user_id: str,
        query: str,
        limit: int = 20,
        score_threshold: float = 0.4
    ) -> List[SearchResult]:
        """
        Main method: Search facts by semantic query
        
        Args:
            user_id: PIKA user ID
            query: Natural language search query
            limit: Max results to return (1-100)
            score_threshold: Min similarity score (0.0-1.0)
            
        Returns:
            List of SearchResult objects, sorted by relevance
        """
        start_time = asyncio.get_event_loop().time()
        
        try:
            logger.info(
                "Starting fact search",
                extra={
                    "user_id": user_id,
                    "query": query,
                    "limit": limit,
                    "threshold": score_threshold
                }
            )
            
            # Step 1: Check cache
            cache_key = self._get_cache_key(user_id, query, limit, score_threshold)
            cached_results = await self.redis.get(cache_key)
            
            if cached_results:
                SEARCH_CACHE_HIT.labels(user_id=user_id).inc()
                logger.info("Cache HIT", extra={"cache_key": cache_key})
                return cached_results
                
            SEARCH_CACHE_HIT.labels(user_id=user_id, hit="miss").inc()
            
            # Step 2: Embed query
            query_vector = await self.embedder.embed_text(query)
            
            # Step 3: Search trong Milvus
            # Get more results than limit Ä‘á»ƒ cÃ³ buffer cho filtering
            search_limit = min(limit * 3, 100)
            
            similar_facts = await self.milvus.search_similar(
                user_id=user_id,
                query_vector=query_vector,
                top_k=search_limit,
                score_threshold=score_threshold
            )
            
            if not similar_facts:
                logger.info("No facts found above threshold")
                return []
            
            # Step 4: Enrich vá»›i Neo4j relationships
            enriched_facts = await self.neo4j.enrich_with_relationships(
                facts=similar_facts,
                user_id=user_id
            )
            
            # Step 5: Re-rank results
            ranked_results = self._rerank_results(
                facts=enriched_facts,
                query=query,
                limit=limit
            )
            
            # Step 6: Cache results
            await self.redis.setex(
                key=cache_key,
                value=ranked_results,
                ttl=self.CACHE_TTL_SECONDS
            )
            
            # Metrics
            duration = asyncio.get_event_loop().time() - start_time
            SEARCH_DURATION.observe(duration)
            SEARCH_TOTAL.labels(
                user_id=user_id,
                status="success"
            ).inc()
            
            logger.info(
                "Search completed",
                extra={
                    "user_id": user_id,
                    "results_count": len(ranked_results),
                    "duration_ms": int(duration * 1000)
                }
            )
            
            return ranked_results
            
        except Exception as e:
            SEARCH_TOTAL.labels(
                user_id=user_id,
                status="error"
            ).inc()
            
            logger.error(
                "Search failed",
                extra={
                    "user_id": user_id,
                    "query": query,
                    "error": str(e)
                },
                exc_info=True
            )
            raise
            
    def _get_cache_key(
        self,
        user_id: str,
        query: str,
        limit: int,
        threshold: float
    ) -> str:
        """Generate cache key cho search query"""
        # Hash query Ä‘á»ƒ avoid long keys
        import hashlib
        query_hash = hashlib.md5(query.encode()).hexdigest()[:16]
        return f"search:{user_id}:{query_hash}:{limit}:{threshold}"
        
    def _rerank_results(
        self,
        facts: List[Fact],
        query: str,
        limit: int
    ) -> List[SearchResult]:
        """
        Re-rank results dá»±a trÃªn multiple factors
        
        Scoring formula:
        final_score = (
            similarity_score * 0.6 +    # Vector similarity (most important)
            recency_score * 0.25 +      # Newer facts preferred
            relationship_score * 0.15   # Facts with relationships boost
        )
        """
        now = datetime.utcnow()
        scored_results = []
        
        for fact in facts:
            # 1. Similarity score (from Milvus)
            similarity_score = fact.similarity_score
            
            # 2. Recency score (exponential decay)
            # Facts trong 7 ngÃ y gáº§n nháº¥t: score = 1.0
            # Facts sau 30 ngÃ y: score ~ 0.5
            days_old = (now - fact.created_at).days
            recency_score = max(0.5, 1.0 - (days_old / 60))
            
            # 3. Relationship score
            # Facts cÃ³ nhiá»u relationships quan trá»ng hÆ¡n
            relationship_count = len(fact.related_fact_ids or [])
            relationship_score = min(1.0, relationship_count / 5)
            
            # Final score
            final_score = (
                similarity_score * 0.6 +
                recency_score * 0.25 +
                relationship_score * 0.15
            )
            
            search_result = SearchResult(
                fact=fact,
                similarity_score=similarity_score,
                recency_score=recency_score,
                relationship_score=relationship_score,
                final_score=final_score,
                matched_query=query
            )
            
            scored_results.append(search_result)
            
        # Sort by final score (descending)
        scored_results.sort(key=lambda x: x.final_score, reverse=True)
        
        # Return top K
        return scored_results[:limit]
```

_[File quÃ¡ dÃ i, tiáº¿p tá»¥c vá»›i pháº§n 6-22 trong pháº§n tiáº¿p theo...]_

---

# 6. THIáº¾T Káº¾ API

## 6.1 API Specification (OpenAPI 3.0)

```yaml
openapi: 3.0.3
info:
  title: PIKA Memory API
  version: 1.0.0
  description: |
    Self-hosted long-term memory system for PIKA robot.
    
    Features:
    - Extract facts from conversations
    - Semantic search for facts
    - Relationship tracking
    - High performance (<200ms p95)
    
  contact:
    name: PIKA Backend Team
    email: backend@pika.stepup.edu.vn

servers:
  - url: http://localhost:8000
    description: Local development
  - url: https://api-memory-staging.pika.stepup.edu.vn
    description: Staging environment
  - url: https://api-memory.pika.stepup.edu.vn
    description: Production environment

security:
  - ApiKeyAuth: []

tags:
  - name: Memory
    description: Long-term memory operations
  - name: Health
    description: Health check endpoints

paths:
  /v1/extract_facts:
    post:
      summary: Extract facts from conversation
      description: |
        TrÃ­ch xuáº¥t facts tá»« má»™t conversation giá»¯a PIKA vÃ  user.
        
        **Process:**
        1. LLM (GPT-4o-mini) extract facts
        2. Generate embeddings (text-embedding-3-small)
        3. Store trong Milvus (vectors)
        4. Store trong Neo4j (relationships)
        5. Store trong PostgreSQL (metadata)
        
        **Performance:** P95 latency <300ms
        
      operationId: extractFacts
      tags: [Memory]
      
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ExtractFactsRequest'
            examples:
              simple_conversation:
                summary: Simple conversation example
                value:
                  user_id: "019afe35-1317-7b94-a833-ff5e2504a9c3"
                  conversation_id: "conv_20241219_001"
                  conversation:
                    - role: "assistant"
                      content: "ChÃ o cáº­u! Cuá»‘i tuáº§n vá»«a rá»“i cáº­u lÃ m gÃ¬?"
                    - role: "user"
                      content: "MÃ¬nh Ä‘i chÆ¡i cÃ´ng viÃªn vá»›i gia Ä‘Ã¬nh"
                    - role: "assistant"
                      content: "Tháº­t tuyá»‡t! Cáº­u thÃ­ch chÆ¡i gÃ¬ á»Ÿ cÃ´ng viÃªn?"
                    - role: "user"
                      content: "MÃ¬nh thÃ­ch chÆ¡i xÃ­ch Ä‘u vÃ  leo cÃ¢y"
                      
      responses:
        '200':
          description: Facts extracted successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ExtractFactsResponse'
              examples:
                success:
                  summary: Successful extraction
                  value:
                    status: "success"
                    message: "Extracted 3 facts successfully"
                    data:
                      facts_count: 3
                      fact_ids:
                        - "fact_019afe35_1001"
                        - "fact_019afe35_1002"
                        - "fact_019afe35_1003"
                      processing_time_ms: 1523
                      
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '429':
          $ref: '#/components/responses/RateLimited'
        '500':
          $ref: '#/components/responses/InternalError'

  /v1/search_facts:
    post:
      summary: Search facts by semantic query
      description: |
        TÃ¬m kiáº¿m facts theo natural language query using semantic similarity.
        
        **Process:**
        6. Check Redis cache (5min TTL)
        7. Embed query â†’ vector
        8. Similarity search trong Milvus
        9. Enrich vá»›i Neo4j relationships
        10. Re-rank results
        11. Cache results
        
        **Performance:** P95 latency <200ms (cached: <20ms)
        
      operationId: searchFacts
      tags: [Memory]
      
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/SearchFactsRequest'
            examples:
              pet_search:
                summary: Search for pet preferences
                value:
                  user_id: "019afe35-1317-7b94-a833-ff5e2504a9c3"
                  query: "ThÃº cÆ°ng mÃ  user thÃ­ch"
                  limit: 20
                  score_threshold: 0.4
                  
      responses:
        '200':
          description: Search completed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/SearchFactsResponse'
              examples:
                success:
                  summary: Successful search
                  value:
                    status: "success"
                    data:
                      query: "ThÃº cÆ°ng mÃ  user thÃ­ch"
                      results_count: 2
                      results:
                        - fact_id: "fact_019afe35_2001"
                          content: "User nuÃ´i mÃ¨o tÃªn Miu"
                          category: "relationship"
                          score: 0.87
                          created_at: "2024-12-15T10:30:00Z"
                          related_facts:
                            - "fact_019afe35_2002"
                        - fact_id: "fact_019afe35_2003"
                          content: "User thÃ­ch chÃ³ golden retriever"
                          category: "preference"
                          score: 0.76
                          created_at: "2024-12-10T14:20:00Z"
                          related_facts: []
                      processing_time_ms: 134
                      from_cache: false
                      
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '429':
          $ref: '#/components/responses/RateLimited'
        '500':
          $ref: '#/components/responses/InternalError'

  /health:
    get:
      summary: Health check
      description: Check if service is alive
      tags: [Health]
      security: []
      responses:
        '200':
          description: Service is healthy
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: string
                    example: "healthy"
                  timestamp:
                    type: string
                    format: date-time
                    
  /health/ready:
    get:
      summary: Readiness check
      description: Check if service is ready to accept traffic
      tags: [Health]
      security: []
      responses:
        '200':
          description: Service is ready
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: string
                    example: "ready"
                  checks:
                    type: object
                    properties:
                      milvus:
                        type: string
                        example: "ok"
                      neo4j:
                        type: string
                        example: "ok"
                      postgres:
                        type: string
                        example: "ok"
                      redis:
                        type: string
                        example: "ok"

components:
  securitySchemes:
    ApiKeyAuth:
      type: apiKey
      in: header
      name: X-API-Key
      description: API key for authentication

  schemas:
    Message:
      type: object
      required: [role, content]
      properties:
        role:
          type: string
          enum: [user, assistant]
          description: Message role
        content:
          type: string
          minLength: 1
          maxLength: 5000
          description: Message content
          
    ExtractFactsRequest:
      type: object
      required: [user_id, conversation_id, conversation]
      properties:
        user_id:
          type: string
          minLength: 1
          maxLength: 100
          description: PIKA user unique ID
          example: "019afe35-1317-7b94-a833-ff5e2504a9c3"
        conversation_id:
          type: string
          minLength: 1
          maxLength: 100
          description: Unique conversation ID
          example: "conv_20241219_001"
        conversation:
          type: array
          minItems: 2
          maxItems: 100
          items:
            $ref: '#/components/schemas/Message'
          description: Conversation messages
          
    ExtractFactsResponse:
      type: object
      properties:
        status:
          type: string
          example: "success"
        message:
          type: string
        data:
          type: object
          properties:
            facts_count:
              type: integer
            fact_ids:
              type: array
              items:
                type: string
            processing_time_ms:
              type: integer
              
    SearchFactsRequest:
      type: object
      required: [user_id, query]
      properties:
        user_id:
          type: string
          minLength: 1
          maxLength: 100
          description: PIKA user unique ID
        query:
          type: string
          minLength: 1
          maxLength: 500
          description: Natural language search query
        limit:
          type: integer
          minimum: 1
          maximum: 100
          default: 20
          description: Max results to return
        score_threshold:
          type: number
          format: float
          minimum: 0.0
          maximum: 1.0
          default: 0.4
          description: Minimum similarity score
          
    SearchFactsResponse:
      type: object
      properties:
        status:
          type: string
        data:
          type: object
          properties:
            query:
              type: string
            results_count:
              type: integer
            results:
              type: array
              items:
                $ref: '#/components/schemas/FactResult'
            processing_time_ms:
              type: integer
            from_cache:
              type: boolean
              
    FactResult:
      type: object
      properties:
        fact_id:
          type: string
        content:
          type: string
        category:
          type: string
          enum: [preference, experience, habit, emotion, relationship, learning, personal_info]
        score:
          type: number
          format: float
        created_at:
          type: string
          format: date-time
        related_facts:
          type: array
          items:
            type: string
            
    Error:
      type: object
      required: [status, error]
      properties:
        status:
          type: string
          example: "error"
        error:
          type: object
          required: [code, message]
          properties:
            code:
              type: string
            message:
              type: string
            details:
              type: object
            trace_id:
              type: string
              
  responses:
    BadRequest:
      description: Invalid request parameters
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          example:
            status: "error"
            error:
              code: "VALIDATION_ERROR"
              message: "Invalid input parameters"
              details:
                conversation: "Must have at least 2 messages"
              trace_id: "abc-123-xyz"
              
    Unauthorized:
      description: Missing or invalid API key
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          example:
            status: "error"
            error:
              code: "UNAUTHORIZED"
              message: "Invalid or missing API key"
              
    RateLimited:
      description: Rate limit exceeded
      headers:
        Retry-After:
          schema:
            type: integer
          description: Seconds until rate limit resets
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          example:
            status: "error"
            error:
              code: "RATE_LIMIT_EXCEEDED"
              message: "Too many requests. Limit: 100/min"
              
    InternalError:
      description: Internal server error
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          example:
            status: "error"
            error:
              code: "INTERNAL_ERROR"
              message: "An unexpected error occurred"
              trace_id: "xyz-789-abc"
```

## 6.2 Error Response Standards

|HTTP Code|Error Code|Description|Retry?|
|---|---|---|---|
|400|VALIDATION_ERROR|Invalid input parameters|No|
|401|UNAUTHORIZED|Missing/invalid API key|No|
|403|FORBIDDEN|Insufficient permissions|No|
|404|NOT_FOUND|Resource not found|No|
|429|RATE_LIMIT_EXCEEDED|Too many requests|Yes, after backoff|
|500|INTERNAL_ERROR|Server error|Yes|
|503|SERVICE_UNAVAILABLE|Temporary unavailable|Yes|

## 6.3 Rate Limiting

|Tier|Requests/minute|Burst|Who|
|---|---|---|---|
|Default|60|10|Single user|
|Power User|300|50|Beta testers|
|Internal|1000|100|PIKA services|

---

# 7. THIáº¾T Káº¾ Dá»® LIá»†U

## 7.1 Milvus Schema (Vector Store)

```python
# Collection configuration
COLLECTION_NAME = "user_facts"
EMBEDDING_DIM = 1536  # OpenAI text-embedding-3-small
METRIC_TYPE = "IP"  # Inner Product (for cosine similarity)

# Schema definition
from pymilvus import CollectionSchema, FieldSchema, DataType

fields = [
    FieldSchema(
        name="id",
        dtype=DataType.INT64,
        is_primary=True,
        auto_id=True,
        description="Auto-generated primary key"
    ),
    FieldSchema(
        name="fact_id",
        dtype=DataType.VARCHAR,
        max_length=100,
        description="Unique fact identifier"
    ),
    FieldSchema(
        name="user_id",
        dtype=DataType.VARCHAR,
        max_length=100,
        description="PIKA user ID"
    ),
    FieldSchema(
        name="conversation_id",
        dtype=DataType.VARCHAR,
        max_length=100,
        description="Source conversation ID"
    ),
    FieldSchema(
        name="content",
        dtype=DataType.VARCHAR,
        max_length=2000,
        description="Fact content text"
    ),
    FieldSchema(
        name="category",
        dtype=DataType.VARCHAR,
        max_length=50,
        description="Fact category"
    ),
    FieldSchema(
        name="confidence",
        dtype=DataType.FLOAT,
        description="Extraction confidence (0-1)"
    ),
    FieldSchema(
        name="embedding",
        dtype=DataType.FLOAT_VECTOR,
        dim=EMBEDDING_DIM,
        description="Vector embedding (1536 dims)"
    ),
    FieldSchema(
        name="created_at",
        dtype=DataType.INT64,
        description="Unix timestamp (milliseconds)"
    )
]

schema = CollectionSchema(
    fields=fields,
    description="PIKA user facts with embeddings"
)

# Index configuration for fast search
index_params = {
    "metric_type": "IP",  # Inner Product
    "index_type": "IVF_FLAT",  # Balance of speed and accuracy
    "params": {"nlist": 2048}  # Number of clusters
}

# Search parameters
search_params = {
    "metric_type": "IP",
    "params": {"nprobe": 16}  # Number of clusters to search
}
```

**Performance Expectations:**

- Insert: <10ms per fact
- Search: <50ms for top-20 from 1M vectors
- Index build: ~30 seconds for 1M vectors

## 7.2 Neo4j Schema (Graph Store)

```cypher
// ==========================================
// NODE TYPES
// ==========================================

// User node
CREATE CONSTRAINT user_id_unique IF NOT EXISTS
FOR (u:User) REQUIRE u.id IS UNIQUE;

(:User {
  id: String,              // User ID
  created_at: DateTime,
  total_facts: Integer,
  metadata: Map
})

// Fact node
CREATE CONSTRAINT fact_id_unique IF NOT EXISTS
FOR (f:Fact) REQUIRE f.id IS UNIQUE;

(:Fact {
  id: String,              // Fact ID
  content: String,
  category: String,
  confidence: Float,
  milvus_id: Integer,      // Reference to Milvus
  created_at: DateTime
})

// Conversation node
CREATE CONSTRAINT conversation_id_unique IF NOT EXISTS
FOR (c:Conversation) REQUIRE c.id IS UNIQUE;

(:Conversation {
  id: String,
  user_id: String,
  message_count: Integer,
  created_at: DateTime
})

// Entity node (extracted entities)
(:Entity {
  name: String,
  type: String,           // person, place, thing, etc.
  mentions_count: Integer
})

// ==========================================
// RELATIONSHIP TYPES
// ==========================================

// User owns facts
(:User)-[:HAS_FACT {
  created_at: DateTime
}]->(:Fact)

// Facts extracted from conversation
(:Fact)-[:EXTRACTED_FROM {
  position: Integer        // Order in conversation
}]->(:Conversation)

// Facts related to each other
(:Fact)-[:RELATED_TO {
  strength: Float,         // 0.0-1.0
  reason: String,          // "same_conversation", "similar_topic", etc.
  created_at: DateTime
}]->(:Fact)

// Facts mention entities
(:Fact)-[:MENTIONS {
  position: Integer        // Word position in content
}]->(:Entity)

// ==========================================
// INDEXES FOR PERFORMANCE
// ==========================================

CREATE INDEX fact_category_idx IF NOT EXISTS
FOR (f:Fact) ON (f.category);

CREATE INDEX fact_created_at_idx IF NOT EXISTS
FOR (f:Fact) ON (f.created_at);

CREATE INDEX user_created_at_idx IF NOT EXISTS
FOR (u:User) ON (u.created_at);

CREATE INDEX conversation_user_idx IF NOT EXISTS
FOR (c:Conversation) ON (c.user_id);

// ==========================================
// EXAMPLE QUERIES
// ==========================================

// Get all facts for a user with relationships
MATCH (u:User {id: $user_id})-[:HAS_FACT]->(f:Fact)
OPTIONAL MATCH (f)-[r:RELATED_TO]->(related:Fact)
RETURN f, collect(related) as related_facts
ORDER BY f.created_at DESC
LIMIT 50;

// Find facts mentioning specific entity
MATCH (f:Fact)-[:MENTIONS]->(e:Entity {name: $entity_name})
WHERE f.user_id = $user_id
RETURN f
ORDER BY f.created_at DESC;

// Get conversation graph
MATCH (c:Conversation {id: $conversation_id})<-[:EXTRACTED_FROM]-(f:Fact)
MATCH (f)-[r:RELATED_TO]->(related:Fact)
RETURN f, r, related;
```

## 7.3 PostgreSQL Schema (Metadata)

```sql
-- ==========================================
-- EXTENSIONS
-- ==========================================
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";  -- For fuzzy text search

-- ==========================================
-- TABLES
-- ==========================================

-- Users table
CREATE TABLE users (
    id VARCHAR(100) PRIMARY KEY,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    total_conversations INTEGER DEFAULT 0,
    total_facts INTEGER DEFAULT 0,
    metadata JSONB DEFAULT '{}'::jsonb,
    
    CONSTRAINT users_total_conversations_positive CHECK (total_conversations >= 0),
    CONSTRAINT users_total_facts_positive CHECK (total_facts >= 0)
);

CREATE INDEX idx_users_created_at ON users(created_at DESC);
CREATE INDEX idx_users_metadata ON users USING GIN(metadata);

-- Conversations table
CREATE TABLE conversations (
    id VARCHAR(100) PRIMARY KEY,
    user_id VARCHAR(100) NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    message_count INTEGER NOT NULL,
    facts_extracted INTEGER DEFAULT 0,
    raw_conversation JSONB NOT NULL,
    metadata JSONB DEFAULT '{}'::jsonb,
    
    CONSTRAINT conversations_message_count_positive CHECK (message_count > 0),
    CONSTRAINT conversations_facts_positive CHECK (facts_extracted >= 0)
);

CREATE INDEX idx_conversations_user_id ON conversations(user_id);
CREATE INDEX idx_conversations_created_at ON conversations(created_at DESC);
CREATE INDEX idx_conversations_user_created ON conversations(user_id, created_at DESC);

-- Facts metadata table
CREATE TABLE facts_metadata (
    fact_id VARCHAR(100) PRIMARY KEY,
    user_id VARCHAR(100) NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    conversation_id VARCHAR(100) REFERENCES conversations(id) ON DELETE SET NULL,
    content TEXT NOT NULL,
    category VARCHAR(50) NOT NULL,
    confidence FLOAT NOT NULL,
    entities TEXT[],
    context TEXT,
    milvus_id BIGINT,
    neo4j_node_id VARCHAR(100),
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    accessed_count INTEGER DEFAULT 0,
    last_accessed_at TIMESTAMPTZ,
    metadata JSONB DEFAULT '{}'::jsonb,
    
    CONSTRAINT facts_confidence_range CHECK (confidence >= 0 AND confidence <= 1),
    CONSTRAINT facts_accessed_positive CHECK (accessed_count >= 0),
    CONSTRAINT facts_category_valid CHECK (
        category IN ('preference', 'experience', 'habit', 'emotion', 
                     'relationship', 'learning', 'personal_info')
    )
);

CREATE INDEX idx_facts_user_id ON facts_metadata(user_id);
CREATE INDEX idx_facts_conversation_id ON facts_metadata(conversation_id);
CREATE INDEX idx_facts_category ON facts_metadata(category);
CREATE INDEX idx_facts_created_at ON facts_metadata(created_at DESC);
CREATE INDEX idx_facts_user_created ON facts_metadata(user_id, created_at DESC);
CREATE INDEX idx_facts_content_search ON facts_metadata USING GIN(to_tsvector('english', content));

-- Search logs table (for analytics)
CREATE TABLE search_logs (
    id BIGSERIAL PRIMARY KEY,
    user_id VARCHAR(100) NOT NULL,
    query TEXT NOT NULL,
    results_count INTEGER NOT NULL,
    top_score FLOAT,
    processing_time_ms INTEGER NOT NULL,
    from_cache BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT search_logs_results_positive CHECK (results_count >= 0),
    CONSTRAINT search_logs_time_positive CHECK (processing_time_ms >= 0)
);

CREATE INDEX idx_search_logs_user_id ON search_logs(user_id);
CREATE INDEX idx_search_logs_created_at ON search_logs(created_at DESC);
CREATE INDEX idx_search_logs_query ON search_logs USING GIN(to_tsvector('english', query));

-- API usage tracking (for rate limiting & analytics)
CREATE TABLE api_usage (
    id BIGSERIAL PRIMARY KEY,
    user_id VARCHAR(100) NOT NULL,
    endpoint VARCHAR(100) NOT NULL,
    method VARCHAR(10) NOT NULL,
    status_code INTEGER NOT NULL,
    response_time_ms INTEGER NOT NULL,
    error_message TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT api_usage_status_code_valid CHECK (status_code >= 100 AND status_code < 600)
);

CREATE INDEX idx_api_usage_user_endpoint ON api_usage(user_id, endpoint, created_at DESC);
CREATE INDEX idx_api_usage_created_at ON api_usage(created_at DESC);

-- ==========================================
-- TRIGGERS
-- ==========================================

-- Auto-update updated_at trigger
CREATE OR REPLACE FUNCTION update_updated_at()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER users_updated_at
BEFORE UPDATE ON users
FOR EACH ROW EXECUTE FUNCTION update_updated_at();

-- Increment user stats on fact creation
CREATE OR REPLACE FUNCTION increment_user_facts()
RETURNS TRIGGER AS $$
BEGIN
    UPDATE users
    SET total_facts = total_facts + 1
    WHERE id = NEW.user_id;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER facts_metadata_increment_user
AFTER INSERT ON facts_metadata
FOR EACH ROW EXECUTE FUNCTION increment_user_facts();

-- Increment user conversations
CREATE OR REPLACE FUNCTION increment_user_conversations()
RETURNS TRIGGER AS $$
BEGIN
    UPDATE users
    SET total_conversations = total_conversations + 1
    WHERE id = NEW.user_id;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER conversations_increment_user
AFTER INSERT ON conversations
FOR EACH ROW EXECUTE FUNCTION increment_user_conversations();

-- ==========================================
-- PARTITIONING (for large scale)
-- ==========================================

-- Partition search_logs by month (example)
-- Enable if data volume > 10M rows

-- CREATE TABLE search_logs (
--     -- columns same as above
-- ) PARTITION BY RANGE (created_at);

-- CREATE TABLE search_logs_2024_12 PARTITION OF search_logs
--     FOR VALUES FROM ('2024-12-01') TO ('2025-01-01');

-- ==========================================
-- USEFUL QUERIES
-- ==========================================

-- Get user summary
SELECT 
    u.id,
    u.total_conversations,
    u.total_facts,
    COUNT(DISTINCT c.id) as actual_conversations,
    COUNT(DISTINCT f.fact_id) as actual_facts
FROM users u
LEFT JOIN conversations c ON c.user_id = u.id
LEFT JOIN facts_metadata f ON f.user_id = u.id
WHERE u.id = 'user_123'
GROUP BY u.id;

-- Get facts with full details
SELECT 
    f.fact_id,
    f.content,
    f.category,
    f.confidence,
    f.created_at,
    c.id as conversation_id,
    c.message_count
FROM facts_metadata f
LEFT JOIN conversations c ON c.id = f.conversation_id
WHERE f.user_id = 'user_123'
ORDER BY f.created_at DESC
LIMIT 50;

-- Analytics: Most searched queries
SELECT 
    query,
    COUNT(*) as search_count,
    AVG(results_count) as avg_results,
    AVG(processing_time_ms) as avg_time_ms
FROM search_logs
WHERE created_at > NOW() - INTERVAL '7 days'
GROUP BY query
ORDER BY search_count DESC
LIMIT 20;
```

## 7.4 Redis Cache Structure

```python
# Cache keys structure
CACHE_KEYS = {
    # Search results cache (TTL: 5 minutes)
    "search_results": "search:{user_id}:{query_hash}:{limit}:{threshold}",
    
    # User facts summary cache (TTL: 10 minutes)
    "user_facts_summary": "user:facts:{user_id}:summary",
    
    # Hot facts cache (TTL: 1 hour)
    "hot_facts": "user:facts:{user_id}:hot",
    
    # Embeddings cache (TTL: 24 hours)
    # Avoid re-embedding same text
    "embedding": "embed:{text_hash}",
    
    # API rate limiting (TTL: 1 minute)
    "rate_limit": "ratelimit:{user_id}:{endpoint}",
    
    # Health check cache (TTL: 30 seconds)
    "health": "health:{service}:status",
    
    # Session/auth cache (TTL: 15 minutes)
    "api_key": "apikey:{key_hash}:info"
}

# TTL configuration (seconds)
TTL_CONFIG = {
    "search_results": 300,           # 5 minutes
    "user_facts_summary": 600,       # 10 minutes
    "hot_facts": 3600,               # 1 hour
    "embedding": 86400,              # 24 hours
    "rate_limit": 60,                # 1 minute
    "health": 30,                    # 30 seconds
    "api_key": 900                   # 15 minutes
}

# Data structures
"""
search_results: JSON string
{
  "query": "...",
  "results": [...],
  "timestamp": "..."
}

user_facts_summary: Hash
{
  "total_facts": "123",
  "categories": '{"preference": 45, "experience": 30, ...}',
  "last_fact_at": "2024-12-19T10:30:00Z"
}

hot_facts: Sorted Set (by access frequency)
ZADD user:facts:user123:hot 
  150 "fact_001"  # score = access count
  100 "fact_002"
  ...

embedding: String (JSON array)
"[0.123, -0.456, ...]"  # 1536 floats

rate_limit: Counter
"42"  # current request count in window

health: String
"ok" or "degraded" or "down"

api_key: Hash
{
  "user_id": "user_123",
  "tier": "default",
  "rate_limit": "60"
}
"""
```

## 7.5 Data Flow Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA FLOW SUMMARY                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  EXTRACT FACTS:                                             â”‚
â”‚  User â†’ API â†’ LLM (facts JSON)                             â”‚
â”‚            â†’ OpenAI (vectors)                              â”‚
â”‚            â†’ Milvus (store vectors)                        â”‚
â”‚            â†’ Neo4j (relationships)                         â”‚
â”‚            â†’ PostgreSQL (metadata)                         â”‚
â”‚                                                             â”‚
â”‚  SEARCH FACTS:                                              â”‚
â”‚  User â†’ API â†’ Redis (check cache) â”€[HIT]â†’ Return          â”‚
â”‚            â”‚                                                â”‚
â”‚            â””â”€[MISS]â†’ OpenAI (embed query)                  â”‚
â”‚                   â†’ Milvus (similarity search)             â”‚
â”‚                   â†’ Neo4j (enrich relationships)           â”‚
â”‚                   â†’ Re-rank results                        â”‚
â”‚                   â†’ Redis (cache results)                  â”‚
â”‚                   â†’ Return                                 â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

_[Tiáº¿p tá»¥c vá»›i cÃ¡c sections cÃ²n láº¡i trong response tiáº¿p theo do giá»›i háº¡n Ä‘á»™ dÃ i...]_

Báº¡n muá»‘n mÃ¬nh tiáº¿p tá»¥c vá»›i:

- Section 8: Thiáº¿t káº¿ Báº£o máº­t
- Section 9-17: Production Readiness sections
- Section 18-22: Operations & Launch sections
- Section 23-24: Appendices

Hay báº¡n muá»‘n mÃ¬nh táº¡o file hoÃ n chá»‰nh ngay vá»›i táº¥t cáº£ sections?