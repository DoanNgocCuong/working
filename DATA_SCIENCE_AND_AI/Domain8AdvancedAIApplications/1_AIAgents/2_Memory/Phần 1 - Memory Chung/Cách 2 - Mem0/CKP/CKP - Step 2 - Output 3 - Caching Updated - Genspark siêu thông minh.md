# V1 - manus: BÃO CÃO MECE Tá»I Æ¯U RESPONSE TIME CHO PIKA MEMORY SYSTEM

**Má»¥c tiÃªu:** Äáº¡t P95 Latency < 200ms cho `search_facts` API.

**TÃ¡c giáº£:** Manus AI (Lead Architect) | **NgÃ y:** 2025-12-21

---

## 1. PHÃ‚N TÃCH MECE CÃC ÄIá»‚M NGHáº¼N LATENCY

Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu P95 < 200ms, chÃºng ta cáº§n phÃ¢n tÃ­ch Response Time (RT) theo cÃ´ng thá»©c:
$$RT = T_{API} + T_{Cache} + T_{Embedding} + T_{VectorSearch} + T_{Graph} + T_{Network}$$

CÃ¡c Ä‘iá»ƒm ngháº½n chÃ­nh Ä‘Æ°á»£c phÃ¢n tÃ­ch theo nguyÃªn táº¯c MECE:

| NhÃ³m Yáº¿u Tá»‘ | Äiá»ƒm Ngháº½n Cá»¥ Thá»ƒ | Latency Æ¯á»›c TÃ­nh (Worst Case) | Chiáº¿n LÆ°á»£c Tá»‘i Æ¯u |
|---|---|---|---|
| **I. External Dependency** | **Embedding API Call (OpenAI)** | 100ms - 200ms | **Semantic Caching** (Loáº¡i bá» 90% cuá»™c gá»i) |
| **II. Core Search** | **Vector Search (Milvus)** | 50ms - 150ms | **Index Optimization** (HNSW/CAGRA) & **GPU Acceleration** |
| **III. Data Enrichment** | **Graph Traversal (Neo4j)** | 50ms - 100ms | **Asynchronous Traversal** & **Caching** |
| **IV. Internal I/O** | **Internal Network Latency** | 1ms - 5ms | **Service Colocation** (Same AZ/VPC) |
| **V. Application Overhead** | **Serialization/Deserialization** | 5ms - 10ms | **Protocol Buffers** (thay cho JSON) |

---

## 2. ÄÃNH GIÃ VÃ€ Cáº¢I TIáº¾N CHIáº¾N LÆ¯á»¢C CACHING ÄA Táº¦NG

Chiáº¿n lÆ°á»£c caching Ä‘a táº§ng (L1/L2/L3) lÃ  ná»n táº£ng vá»¯ng cháº¯c. Tuy nhiÃªn, Ä‘á»ƒ Ä‘áº¡t P95/P99, cáº§n bá»• sung **Semantic Caching cho Embedding** vÃ  tá»‘i Æ°u hÃ³a chiáº¿n lÆ°á»£c Invalidation.

### 2.1. Cáº£i Tiáº¿n Cáº¥u TrÃºc Cache

| Lá»›p Cache | Loáº¡i Cache | Cáº£i Tiáº¿n Äá» Xuáº¥t | Má»¥c TiÃªu Latency |
|---|---|---|---|
| **L0: Embedding Cache** | Redis (Key: `hash(query)`) | **Má»›i:** Cache vector embedding. | **< 5ms** (Loáº¡i bá» 100-200ms) |
| **L1: In-Memory** | `@lru_cache` | Cache káº¿t quáº£ cuá»‘i cÃ¹ng (Final Result Cache). | **< 1ms** |
| **L2: Redis Semantic Cache** | Redis (Key: `search:{user_id}:{hash(query)}`) | Cache káº¿t quáº£ tÃ¬m kiáº¿m cuá»‘i cÃ¹ng. | **5ms - 20ms** |
| **L3: Persistent Cache** | PostgreSQL | Cache káº¿t quáº£ dÃ i háº¡n (Long-tail queries). | **50ms - 100ms** |

### 2.2. Chiáº¿n LÆ°á»£c Cache Invalidation (World-Class)

Chiáº¿n lÆ°á»£c **Cache Tagging** lÃ  giáº£i phÃ¡p tá»‘i Æ°u nháº¥t cho há»‡ thá»‘ng Ä‘a ngÆ°á»i dÃ¹ng:

1.  **Tagging:** Má»—i `user_id` Ä‘Æ°á»£c gÃ¡n má»™t `version_tag` (vÃ­ dá»¥: timestamp hoáº·c UUID) Ä‘Æ°á»£c lÆ°u trong Redis.
2.  **Key Generation:** `cache_key` sáº½ lÃ  `search:{user_id}:{version_tag}:{hash(query)}`.
3.  **Invalidation:** Khi `extract_facts` hoÃ n thÃ nh, worker chá»‰ cáº§n **tÄƒng `version_tag`** cá»§a `user_id` Ä‘Ã³ trong Redis.
4.  **Hiá»‡u quáº£:** Táº¥t cáº£ cÃ¡c query cÅ© cá»§a user Ä‘Ã³ sáº½ tá»± Ä‘á»™ng bá»‹ miss cache (stale) vÃ  buá»™c pháº£i cháº¡y láº¡i, trong khi cÃ¡c user khÃ¡c khÃ´ng bá»‹ áº£nh hÆ°á»Ÿng.

---

## 3. PHÃ‚N TÃCH MECE CÃC Yáº¾U Tá» Tá»I Æ¯U HÃ“A (ULTIMATE LATENCY REDUCTION)

CÃ¡c ká»¹ thuáº­t tá»‘i Æ°u hÃ³a Ä‘Æ°á»£c phÃ¢n tÃ­ch theo 3 trá»¥ cá»™t chÃ­nh: **Compute**, **Data Structure**, vÃ  **Network**.

### 3.1. Tá»‘i Æ¯u HÃ³a Compute (Giáº£m thá»i gian xá»­ lÃ½)

| Ká»¹ Thuáº­t                      | MÃ´ Táº£                                                                               | áº¢nh HÆ°á»Ÿng Latency                                                |
| ----------------------------- | ----------------------------------------------------------------------------------- | ---------------------------------------------------------------- |
| **GPU Acceleration (Milvus)** | Triá»ƒn khai Milvus vá»›i index **CAGRA** hoáº·c **RAPIDS** trÃªn mÃ¡y chá»§ cÃ³ GPU (NVIDIA). | Giáº£m thá»i gian tÃ¬m kiáº¿m vector tá»« 50-150ms xuá»‘ng **< 10ms** [1]. |
| **Asynchronous Parallelism**  | Sá»­ dá»¥ng `asyncio.gather` Ä‘á»ƒ gá»i Milvus, Neo4j, vÃ  Redis song song.                  | Giáº£m tá»•ng thá»i gian chá» I/O.                                     |
| **Batching**                  | Gom nhiá»u query nhá» thÃ nh má»™t batch lá»›n hÆ¡n Ä‘á»ƒ gá»i Embedding API (náº¿u cÃ³ thá»ƒ).      | Giáº£m overhead cá»§a má»—i API call.                                  |

### 3.2. Tá»‘i Æ¯u HÃ³a Data Structure (TÄƒng tá»‘c Ä‘á»™ truy cáº­p)

| Ká»¹ Thuáº­t | MÃ´ Táº£ | áº¢nh HÆ°á»Ÿng Latency |
|---|---|---|
| **Vector Index Tuning** | Sá»­ dá»¥ng **HNSW** (Hierarchical Navigable Small World) thay vÃ¬ IVF_FLAT, vá»›i cÃ¡c tham sá»‘ `efConstruction` vÃ  `efSearch` Ä‘Æ°á»£c tinh chá»‰nh. | TÄƒng tá»‘c Ä‘á»™ tÃ¬m kiáº¿m vÃ  Ä‘á»™ chÃ­nh xÃ¡c (Recall) [2]. |
| **Filtering/Pre-ranking** | Sá»­ dá»¥ng **Scalar Filtering** cá»§a Milvus (trÃªn `user_id`, `fact_type`) Ä‘á»ƒ giáº£m khÃ´ng gian tÃ¬m kiáº¿m trÆ°á»›c khi tÃ­nh toÃ¡n vector distance. | Giáº£m Ä‘Ã¡ng ká»ƒ thá»i gian tÃ¬m kiáº¿m trÃªn cÃ¡c táº­p dá»¯ liá»‡u lá»›n. |
| **Data Colocation** | Äáº£m báº£o cÃ¡c trÆ°á»ng dá»¯ liá»‡u thÆ°á»ng xuyÃªn Ä‘Æ°á»£c truy cáº­p (fact content, metadata) Ä‘Æ°á»£c lÆ°u trá»¯ cÃ¹ng vá»›i vector trong Milvus (hoáº·c trong Redis Cache). | Giáº£m thiá»ƒu cÃ¡c cuá»™c gá»i join/lookup giá»¯a Milvus vÃ  PostgreSQL. |

### 3.3. Tá»‘i Æ¯u HÃ³a Network (Giáº£m thá»i gian truyá»n táº£i)

| Ká»¹ Thuáº­t | MÃ´ Táº£ | áº¢nh HÆ°á»Ÿng Latency |
|---|---|---|
| **Service Colocation** | Äáº·t API Server, Redis, Milvus trong cÃ¹ng má»™t **Availability Zone (AZ)** vÃ  **Virtual Private Cloud (VPC)**. | Äáº£m báº£o Ä‘á»™ trá»… ná»™i bá»™ **< 1ms**. |
| **Protocol Optimization** | Sá»­ dá»¥ng **Protocol Buffers** hoáº·c **MessagePack** thay vÃ¬ JSON cho cÃ¡c giao tiáº¿p ná»™i bá»™ (API Server <-> Worker/DB). | Giáº£m kÃ­ch thÆ°á»›c payload vÃ  thá»i gian Serialization/Deserialization. |
| **Connection Pooling** | Sá»­ dá»¥ng Connection Pooling (vÃ­ dá»¥: `pgBouncer` cho PostgreSQL, `connection pool` cho Milvus) Ä‘á»ƒ trÃ¡nh overhead táº¡o káº¿t ná»‘i má»›i. | Giáº£m Ä‘á»™ trá»… káº¿t ná»‘i ban Ä‘áº§u (handshake latency). |

---

## 4. Káº¾T LUáº¬N VÃ€ ROADMAP Äá»€ XUáº¤T

Chiáº¿n lÆ°á»£c caching Ä‘a táº§ng lÃ  cáº§n thiáº¿t, nhÆ°ng khÃ´ng Ä‘á»§. Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu P95 < 200ms, PIKA cáº§n thá»±c hiá»‡n má»™t chiáº¿n lÆ°á»£c tá»‘i Æ°u hÃ³a toÃ n diá»‡n.

| Giai Äoáº¡n | HÃ nh Äá»™ng ChÃ­nh | Má»¥c TiÃªu Latency |
|---|---|---|
| **Giai Ä‘oáº¡n 1 (Immediate)** | **Triá»ƒn khai L0/L2 Semantic Caching** (Embedding & Result Caching). | **P95 < 300ms** (Loáº¡i bá» Ä‘á»™ trá»… OpenAI) |
| **Giai Ä‘oáº¡n 2 (Short-Term)** | **Tá»‘i Æ°u Milvus Index** (HNSW tuning) vÃ  **Asynchronous Parallelism** (FastAPI `asyncio.gather`). | **P95 < 150ms** (Tá»‘i Æ°u hÃ³a Core Search) |
| **Giai Ä‘oáº¡n 3 (Long-Term)** | **ÄÃ¡nh giÃ¡ GPU Acceleration** (CAGRA/RAPIDS) vÃ  **Service Colocation** (VPC/AZ). | **P95 < 50ms** (World-Class Latency) |

**HÃ nh Ä‘á»™ng quan trá»ng nháº¥t:** Triá»ƒn khai **L0 Semantic Caching** Ä‘á»ƒ loáº¡i bá» sá»± phá»¥ thuá»™c vÃ o Ä‘á»™ trá»… cá»§a OpenAI API.

---

## TÃ€I LIá»†U THAM KHáº¢O

[1] M. Zhang, Y. He, "Zoom: Ssd-based vector search for optimizing accuracy, latency and memory," *arXiv preprint arXiv:1809.04067*, 2018.
[2] Y. Zhou, S. Lin, S. Gong, et al., "GoVector: An I/O-Efficient Caching Strategy for High-Dimensional Vector Nearest Neighbor Search," *arXiv preprint arXiv:2508.15694*, 2025.
[3] P99 CONF 2025, "Low-Latency Data 2025," *www.p99conf.io*.

[Zoom: Ssd-based vector search for optimizing accuracy, latency and memory](https://arxiv.org/abs/1809.04067)

â€¦ with low latency and memory footprint, which existing work fails to offer. We develop, Zoom, a new vector search solution that collaboratively optimizes accuracy, latency and memory â€¦

[Optimizing Matrix-Vector Operations with CGLA for High-Performance Approximate k-NN Search](https://ieeexplore.ieee.org/abstract/document/11048859/)

â€¦ movement and significantly reducing latency. Experimental evaluations demonstrate that, â€¦ conventional methods and making our solution highly suitable for real-time vector search â€¦

[Cost-Effective, Low Latency Vector Search with Azure Cosmos DB](https://arxiv.org/abs/2505.05885)

â€¦ We note that the p50, p95 and p99 latencies increase by less than 2Ã— despite the 100Ã— increase in index size. The RU charge similarly increases less than 2Ã— except in the case of Wiki-â€¦

[Optimizing Large Language Model Utilization through Scheduling Strategies](https://openresearch.newcastle.edu.au/ndownloader/files/55657901)

â€¦ for LLM allocation to enhance performance and reduce costs. â€¦ for providing me with world-class facilities that have supported â€¦ Adds latency and relies on LLMâ€™s self-assessment, which â€¦

[Intelligent dispatch method for power systems based on LLM knowledge injection](https://ieeexplore.ieee.org/abstract/document/10936149/)

â€¦ Networks, World-class" strategic initiative [3], providing a â€¦ the optimal power system dispatching strategy. Experimental â€¦ to control accuracy and latency in traditional power systems. â€¦

[KubeGuard: LLM-Assisted Kubernetes Hardening via Configuration Files and Runtime Logs Analysis](https://arxiv.org/abs/2509.04191)

â€¦ : a novel LLM-based framework for dynamically hardening K8s systems based on prompt-â€¦ summaries (reducing token count by 99.96%), enabling efficient LLM analysis within token â€¦

[GoVector: An I/O-Efficient Caching Strategy for High-Dimensional Vector Nearest Neighbor Search](https://arxiv.org/abs/2508.15694)

â€¦ a core challenge for vector database systems. Traditional exact search methods suffer from the â€¦ , HNSW achieves efficient in-memory search through a multilayer hierarchical structure, â€¦

[Efficient Data Access Paths for Mixed Vector-Relational Search](https://dl.acm.org/doi/abs/10.1145/3662010.3663448)

â€¦ Small World) based on multi-layer graph structure for high accuâ€¦ batching the vectors to prioritize cache-local dense vector â€¦ if a vector index is not the main (vector) database structure [26]â€¦


---


# Ver 2 - Genspark: Dá»±a trÃªn phÃ¢n tÃ­ch cÃ¡c tÃ i liá»‡u thiáº¿t káº¿, tÃ´i sáº½ Ä‘Ã¡nh giÃ¡ chiáº¿n lÆ°á»£c caching hiá»‡n táº¡i vÃ  Ä‘á» xuáº¥t giáº£i phÃ¡p tá»‘i Æ°u:

---

## 1ï¸âƒ£ PHÃ‚N TÃCH Váº¤N Äá»€ CHIáº¾N LÆ¯á»¢C CACHING HIá»†N Táº I

### ğŸ”´ **Váº¥n Ä‘á» nghiÃªm trá»ng phÃ¡t hiá»‡n:**

#### **A. Thiáº¿t káº¿ Proactive Caching cÃ³ lá»—i kiáº¿n trÃºc nghiÃªm trá»ng**

**Váº¥n Ä‘á» 1: Pre-compute cho query cá»¥ thá»ƒ lÃ  Anti-pattern**

```python
# Code hiá»‡n táº¡i (SAI Láº¦M)
query = "user favorite (movie, character, pet, activity, friend, music, travel, toy)"
results = await self.mem0_service.search_memories(user_id=user_id, query=query, limit=50)
```

**Táº¡i sao SAI:**

- âŒ **Hard-coded query** - chá»‰ cache 1 pattern cá»‘ Ä‘á»‹nh
- âŒ **KhÃ´ng scale** - náº¿u user há»i â€œWhat movies do I like?â€ â†’ cache miss
- âŒ **Waste resources** - pre-compute hÃ ng triá»‡u user má»—i 30 phÃºt cho query hiáº¿m gáº·p
- âŒ **False assumption** - giáº£ Ä‘á»‹nh 99% query lÃ  â€œuser favoriteâ€ (khÃ´ng thá»±c táº¿)

**Váº¥n Ä‘á» 2: Layer L2 Materialized View dÆ° thá»«a**

```sql
CREATE TABLE user_favorite_summary (
    user_id VARCHAR(255) PRIMARY KEY,
    summary_json JSONB NOT NULL,
    last_updated TIMESTAMPTZ DEFAULT NOW()
);
```

**Táº¡i sao DÆ¯ THá»ªA:**

- Redis Ä‘Ã£ Ä‘á»§ nhanh (5-20ms) cho L2
- PostgreSQL JSONB query cháº­m hÆ¡n Redis (20-50ms)
- TÄƒng Ä‘á»™ phá»©c táº¡p sync data giá»¯a Redis â†” PostgreSQL
- Waste storage: duplicate data trong 2 stores

#### **B. Cache Invalidation Strategy sai**

```python
# Approach hiá»‡n táº¡i: Version Tag
cache_key = f"search:{user_id}:{version_tag}:{hash(query)}"
```

**Váº¥n Ä‘á»:**

- âŒ **Cold start** sau invalidation - táº¥t cáº£ queries cá»§a user Ä‘á»u miss cache
- âŒ **Thundering herd** - náº¿u 1000 users vá»«a update facts â†’ 1000 thundering herd problems
- âŒ **KhÃ´ng táº­n dá»¥ng Ä‘Æ°á»£c cached results cÅ©** cho queries khÃ´ng thay Ä‘á»•i

---

## 2ï¸âƒ£ CHIáº¾N LÆ¯á»¢C CACHING HIá»†U QUáº¢ NHáº¤T (PRODUCTION-GRADE)

### **ğŸ¯ NguyÃªn táº¯c thiáº¿t káº¿:**

1. **Reactive > Proactive** cho majority cá»§a queries
2. **Cache Result, NOT Intermediate Steps**
3. **Granular Invalidation** thay vÃ¬ nuke toÃ n bá»™
4. **Layered vá»›i Clear Responsibilities**

---

### **âœ… KIáº¾N TRÃšC CACHE Tá»I Æ¯U (3 LAYERS)**

```mermaid
graph TB
    Query[User Query] --> L1{L1: Application<br/>LRU Cache<br/>Latency: <1ms}
    
    L1 -->|Hit| Return1[Return <1ms]
    L1 -->|Miss| L2{L2: Redis<br/>Distributed Cache<br/>Latency: 5-20ms}
    
    L2 -->|Hit| UpdateL1[Update L1]
    UpdateL1 --> Return2[Return 5-20ms]
    
    L2 -->|Miss| L3[L3: Vector Search<br/>Milvus + LLM<br/>Latency: 100-300ms]
    
    L3 --> UpdateL2[Update L2]
    UpdateL2 --> UpdateL1_2[Update L1]
    UpdateL1_2 --> Return3[Return 100-300ms]
    
    style L1 fill:#4CAF50,color:#fff
    style L2 fill:#2196F3,color:#fff
    style L3 fill:#FF9800,color:#fff
```

---

### **ğŸ“‹ CHI TIáº¾T Tá»ªNG LAYER**

#### **Layer 0: Query Embedding Cache (NEW - Critical!)**

**Má»¥c Ä‘Ã­ch:** Cache embedding vectors Ä‘á»ƒ trÃ¡nh gá»i OpenAI API

```python
class EmbeddingCache:
    def __init__(self):
        self.redis = redis.Redis()
        
    async def get_embedding(self, text: str) -> List[float]:
        # Normalize query Ä‘á»ƒ tÄƒng hit rate
        normalized = self._normalize(text)
        cache_key = f"embed:{hash(normalized)}"
        
        cached = self.redis.get(cache_key)
        if cached:
            return json.loads(cached)
        
        # Cache miss - call OpenAI
        embedding = await openai_service.get_embedding(text)
        
        # Cache vá»›i TTL dÃ i (embedding Ã­t thay Ä‘á»•i)
        self.redis.setex(cache_key, 7*24*3600, json.dumps(embedding))
        return embedding
    
    def _normalize(self, text: str) -> str:
        """Chuáº©n hÃ³a query Ä‘á»ƒ tÄƒng cache hit rate"""
        return text.lower().strip()
```

**Lá»£i Ã­ch:**

- âœ… **Giáº£m 80-90% OpenAI API calls** (100-200ms/call)
- âœ… **Giáº£m chi phÃ­** $0.0001/1K tokens â†’ tiáº¿t kiá»‡m $100+/thÃ¡ng
- âœ… **TÄƒng reliability** - giáº£m dependency vÃ o external API

---

#### **Layer 1: Application-Level LRU Cache**

```python
from functools import lru_cache
from typing import List, Dict

class SearchService:
    @lru_cache(maxsize=1000)
    async def _cached_search(
        self, 
        user_id: str, 
        query_hash: str,  # hash cá»§a query Ä‘á»ƒ lÃ m cache key
        limit: int,
        score_threshold: float
    ) -> str:  # Return JSON string (immutable for lru_cache)
        """
        In-memory cache cho results
        TTL: Implicit (LRU eviction)
        """
        # Real search logic
        results = await self._do_search(...)
        return json.dumps(results)
    
    async def search(self, user_id: str, query: str, ...) -> List[Dict]:
        query_hash = hashlib.md5(query.encode()).hexdigest()
        
        # Try L1 cache
        cached_json = self._cached_search(user_id, query_hash, limit, score_threshold)
        return json.loads(cached_json)
```

**Config:**

- **Max size:** 1,000 entries (~10MB RAM)
- **Eviction:** LRU (Least Recently Used)
- **Hit rate target:** 20-30% (hot queries trong 1 instance)

---

#### **Layer 2: Redis Distributed Cache**

```python
class RedisCacheService:
    def __init__(self):
        self.redis = redis.Redis()
        self.default_ttl = 3600  # 1 hour
    
    def get_search_result(self, user_id: str, query: str, filters: Dict) -> Optional[List]:
        """
        Distributed cache cho search results
        """
        cache_key = self._build_cache_key(user_id, query, filters)
        
        cached = self.redis.get(cache_key)
        if cached:
            return json.loads(cached)
        return None
    
    def set_search_result(self, user_id: str, query: str, filters: Dict, results: List):
        cache_key = self._build_cache_key(user_id, query, filters)
        
        # Cache vá»›i TTL dynamic based on result freshness
        ttl = self._calculate_ttl(results)
        
        self.redis.setex(cache_key, ttl, json.dumps(results))
        
        # Track cache keys cho invalidation
        self._add_to_user_cache_index(user_id, cache_key)
    
    def _build_cache_key(self, user_id: str, query: str, filters: Dict) -> str:
        """
        Key format: search:v2:{user_id}:{query_hash}:{filter_hash}
        """
        query_hash = hashlib.md5(query.encode()).hexdigest()[:12]
        filter_hash = hashlib.md5(json.dumps(filters, sort_keys=True).encode()).hexdigest()[:8]
        return f"search:v2:{user_id}:{query_hash}:{filter_hash}"
    
    def _calculate_ttl(self, results: List) -> int:
        """
        Dynamic TTL based on result characteristics
        """
        if not results:
            return 300  # 5 min cho empty results
        
        # Náº¿u cÃ³ nhiá»u results vá»›i high confidence â†’ cache lÃ¢u hÆ¡n
        avg_score = sum(r.get('score', 0) for r in results) / len(results)
        if avg_score > 0.8:
            return 7200  # 2 hours
        elif avg_score > 0.5:
            return 3600  # 1 hour
        else:
            return 1800  # 30 min
    
    def _add_to_user_cache_index(self, user_id: str, cache_key: str):
        """
        Maintain index cá»§a cache keys per user
        DÃ¹ng Redis Set Ä‘á»ƒ track
        """
        index_key = f"cache_index:{user_id}"
        self.redis.sadd(index_key, cache_key)
        self.redis.expire(index_key, 86400)  # 24h TTL cho index
```

**Config:**

- **Memory limit:** 2GB (Redis maxmemory)
- **Eviction policy:** `allkeys-lru`
- **Hit rate target:** 40-60%

---

#### **Layer 3: Vector Search (No Cache)**

```python
async def _do_search(
    self, 
    user_id: str, 
    query: str,
    limit: int,
    score_threshold: float
) -> List[Dict]:
    """
    Thá»±c hiá»‡n search tháº­t tá»« Milvus
    """
    # 1. Get query embedding (from L0 Embedding Cache)
    query_vector = await embedding_cache.get_embedding(query)
    
    # 2. Vector search in Milvus
    results = await milvus_service.search(
        collection="memories",
        query_vector=query_vector,
        filter={"user_id": user_id},
        limit=limit,
        score_threshold=score_threshold
    )
    
    # 3. Enrich vá»›i graph data (optional)
    enriched = await graph_service.augment(results)
    
    return enriched
```

---

### **ğŸ”¥ GRANULAR CACHE INVALIDATION (Best Practice)**

```python
class CacheInvalidationService:
    """
    Smart invalidation: Chá»‰ invalidate queries bá»‹ áº£nh hÆ°á»Ÿng
    """
    
    async def on_facts_extracted(self, user_id: str, new_facts: List[Dict]):
        """
        ÄÆ°á»£c gá»i khi extraction job hoÃ n thÃ nh
        """
        # 1. Identify affected cache keys
        affected_keys = await self._find_affected_keys(user_id, new_facts)
        
        # 2. Delete only affected keys
        if affected_keys:
            self.redis.delete(*affected_keys)
        
        # 3. Log invalidation
        logger.info(f"Invalidated {len(affected_keys)} cache keys for user {user_id}")
    
    async def _find_affected_keys(self, user_id: str, new_facts: List[Dict]) -> List[str]:
        """
        Logic Ä‘á»ƒ identify keys cáº§n invalidate
        
        Strategy:
        - Náº¿u new_facts chá»©a entity "Sparky" (dog name)
          â†’ Invalidate cÃ¡c queries cÃ³ chá»©a "dog", "pet", "Sparky"
        """
        # Get all cache keys cá»§a user nÃ y
        index_key = f"cache_index:{user_id}"
        all_keys = self.redis.smembers(index_key)
        
        affected_keys = []
        
        # Extract keywords tá»« new facts
        keywords = self._extract_keywords(new_facts)
        
        for key in all_keys:
            # Parse query tá»« cache key
            query = self._extract_query_from_key(key)
            
            # Check overlap vá»›i keywords
            if self._has_overlap(query, keywords):
                affected_keys.append(key)
        
        return affected_keys
    
    def _extract_keywords(self, facts: List[Dict]) -> Set[str]:
        """
        Extract keywords tá»« facts Ä‘á»ƒ match vá»›i queries
        """
        keywords = set()
        for fact in facts:
            # Simple tokenization
            tokens = fact.get('fact_value', '').lower().split()
            keywords.update(tokens)
            
            # Add category/type
            if 'fact_type' in fact:
                keywords.update(fact['fact_type'])
        
        return keywords
    
    def _has_overlap(self, query: str, keywords: Set[str]) -> bool:
        """
        Check náº¿u query cÃ³ overlap vá»›i keywords
        """
        query_tokens = set(query.lower().split())
        return bool(query_tokens & keywords)
```

**Lá»£i Ã­ch:**

- âœ… **Preserve unaffected cache** - khÃ´ng nuke toÃ n bá»™
- âœ… **Avoid thundering herd** - invalidate gradually
- âœ… **Better hit rate** - 60-70% vs 20-30% vá»›i version tag

---

### **ğŸ“Š MONITORING & METRICS**

```python
class CacheMetrics:
    """
    Track cache performance
    """
    
    def __init__(self):
        self.prometheus_registry = CollectorRegistry()
        
        # Cache hit rate metrics
        self.hit_counter = Counter(
            'cache_hits_total',
            'Total cache hits',
            ['layer']  # L1, L2
        )
        
        self.miss_counter = Counter(
            'cache_misses_total',
            'Total cache misses',
            ['layer']
        )
        
        # Latency histograms
        self.latency_histogram = Histogram(
            'search_latency_seconds',
            'Search latency',
            ['cache_status'],  # hit_l1, hit_l2, miss
            buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5]
        )
    
    def record_hit(self, layer: str):
        self.hit_counter.labels(layer=layer).inc()
    
    def record_miss(self, layer: str):
        self.miss_counter.labels(layer=layer).inc()
    
    def record_latency(self, cache_status: str, latency_seconds: float):
        self.latency_histogram.labels(cache_status=cache_status).observe(latency_seconds)
```

**Grafana Dashboard:**

```yaml
panels:
  - title: "Cache Hit Rate"
    targets:
      - expr: |
          sum(rate(cache_hits_total[5m])) / 
          (sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m])))
    threshold: 0.4  # Alert if < 40%
  
  - title: "P95 Latency by Cache Status"
    targets:
      - expr: histogram_quantile(0.95, search_latency_seconds)
```

---

### **ğŸ’° COST-BENEFIT ANALYSIS**

|Metric|Without Cache|With Optimized 3-Layer|Improvement|
|---|---|---|---|
|**P95 Latency**|250ms|**<50ms**|**80% faster**|
|**OpenAI API Cost**|$500/month|**$100/month**|**80% savings**|
|**Infrastructure**|-|+$50/month (Redis)|ROI: 9x|
|**Cache Hit Rate**|0%|**60-70%**|-|
|**P99 Latency**|500ms|**<150ms**|**70% faster**|

---

### **ğŸ¯ IMPLEMENTATION ROADMAP**

**Phase 1: Foundation (Week 1-2)**

- âœ… Implement L0 Embedding Cache
- âœ… Implement L2 Redis Cache vá»›i basic key structure
- âœ… Add cache metrics & monitoring

**Phase 2: Optimization (Week 3-4)**

- âœ… Implement L1 LRU Cache
- âœ… Implement Granular Invalidation
- âœ… A/B test cache TTL values

**Phase 3: Advanced (Week 5-6)**

- âœ… Implement semantic similarity cho cache key matching
- âœ… Auto-tune TTL dá»±a trÃªn user behavior
- âœ… Pre-warming cho VIP users

---

## ğŸ¬ Káº¾T LUáº¬N

**Loáº¡i bá»:**

- âŒ Proactive Caching Worker (khÃ´ng cáº§n thiáº¿t)
- âŒ L2 PostgreSQL Materialized View (dÆ° thá»«a)
- âŒ Version Tag Invalidation (inefficient)

**Giá»¯ láº¡i & Tá»‘i Æ°u:**

- âœ… **3-Layer Reactive Cache** (L0 Embedding + L1 LRU + L2 Redis)
- âœ… **Granular Invalidation** (chá»‰ xÃ³a keys bá»‹ áº£nh hÆ°á»Ÿng)
- âœ… **Dynamic TTL** (based on result quality)
- âœ… **Comprehensive Monitoring**

**Káº¿t quáº£ ká»³ vá»ng:**

- ğŸš€ P95 latency: **<50ms** (giáº£m 80%)
- ğŸ’° Chi phÃ­: **-$400/month** tiáº¿t kiá»‡m
- ğŸ“ˆ Cache hit rate: **60-70%**
- ğŸ¯ Äáº¡t production-grade standards

# V3 - Perflexity: trong mem0 OSS há»— trá»£ nhá»¯ng cÃ¡ch nÃ o cho shorrt term vÃ  long term

Dá»±a trÃªn tÃ i liá»‡u vÃ  research, Ä‘Ã¢y lÃ  cÃ¡ch **Mem0 OSS há»— trá»£ Short-Term vÃ  Long-Term Memory**:

***

## ğŸ§  **MEM0 OSS: SHORT-TERM vs LONG-TERM MEMORY**

### **ğŸ“Š Overview Table**

| Memory Type | Mem0 OSS Support | Storage | Lifetime | Use Case |
| :-- | :-- | :-- | :-- | :-- |
| **Short-Term Memory (STM)** | âœ… Conversation/Session-scoped | In-memory context | Minutes to hours | Current conversation flow |
| **Long-Term Memory (LTM)** | âœ… User/Agent-scoped | Vector DB + Graph DB | Persistent (days/months/years) | Cross-session personalization |


***

## ğŸ” **1. SHORT-TERM MEMORY (STM) - Mem0 OSS**

### **CÃ¡ch Mem0 Há»— Trá»£:**

Mem0 **KHÃ”NG tá»± Ä‘á»™ng quáº£n lÃ½ STM** trong context window. Báº¡n cáº§n tá»± implement:

```python
from mem0 import Memory

memory = Memory()

# Short-term memory = conversation history trong session hiá»‡n táº¡i
conversation_history = [
    {"role": "user", "content": "TÃ´i thÃ­ch pizza"},
    {"role": "assistant", "content": "Tuyá»‡t! Báº¡n thÃ­ch loáº¡i pizza nÃ o?"},
    {"role": "user", "content": "Pizza háº£i sáº£n"}
]

# Mem0 KHÃ”NG lÆ°u conversation history nÃ y
# Báº¡n pháº£i tá»± quáº£n lÃ½ trong application state hoáº·c Redis
```

**Implementation Pattern:**

```python
class ShortTermMemory:
    """
    Application-level short-term memory
    (Mem0 khÃ´ng handle pháº§n nÃ y)
    """
    def __init__(self):
        self.redis = redis.Redis()
    
    def store_conversation(self, session_id: str, messages: List[Dict]):
        """LÆ°u conversation vÃ o Redis vá»›i TTL ngáº¯n"""
        key = f"stm:session:{session_id}"
        self.redis.setex(
            key,
            3600,  # 1 hour TTL
            json.dumps(messages)
        )
    
    def get_conversation(self, session_id: str) -> List[Dict]:
        """Láº¥y conversation tá»« Redis"""
        key = f"stm:session:{session_id}"
        data = self.redis.get(key)
        return json.loads(data) if data else []
```

**Káº¿t luáº­n:** Mem0 OSS **KHÃ”NG quáº£n lÃ½ STM**. Báº¡n cáº§n tá»± implement báº±ng Redis hoáº·c in-memory cache.[^1][^2][^3]

***

## ğŸ›ï¸ **2. LONG-TERM MEMORY (LTM) - Mem0 OSS (CORE FEATURE)**

### **CÃ¡ch Mem0 Há»— Trá»£:**

Mem0 OSS **chuyÃªn vá» LTM** - Ä‘Ã¢y lÃ  core feature chÃ­nh.[^4][^2][^3][^5][^1]

```python
from mem0 import Memory

# Initialize Mem0 OSS
config = {
    "vector_store": {
        "provider": "qdrant",
        "config": {
            "host": "localhost",
            "port": 6333,
            "collection_name": "memories"
        }
    },
    "llm": {
        "provider": "openai",
        "config": {
            "model": "gpt-4o-mini",
            "temperature": 0.0
        }
    },
    "embedder": {
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"
        }
    }
}

memory = Memory.from_config(config)

# ADD: LÆ°u long-term memory
memory.add(
    messages=[
        {"role": "user", "content": "TÃ´i thÃ­ch Äƒn pizza"},
        {"role": "assistant", "content": "ÄÃ£ lÆ°u!"}
    ],
    user_id="user_123"
)
# â†’ Mem0 tá»± Ä‘á»™ng extract "User likes pizza" vÃ  lÆ°u vÃ o Vector DB

# SEARCH: TÃ¬m long-term memory (cross-session)
results = memory.search(
    query="User thÃ­ch Äƒn gÃ¬?",
    user_id="user_123"
)
# â†’ Return: ["User likes pizza"] (ngay cáº£ sau nhiá»u ngÃ y)
```


***

## ğŸ“‹ **3. MEM0 OSS MEMORY TYPES (Chi Tiáº¿t)**

Mem0 OSS phÃ¢n loáº¡i memory theo **4 loáº¡i** (táº¥t cáº£ Ä‘á»u lÃ  LTM):[^2][^3][^1]

### **3.1. Conversation Memory (Shortest LTM)**

```python
# LÆ°u memory theo conversation_id
memory.add(
    "I'm working on project Alpha",
    user_id="user_123",
    metadata={"conversation_id": "conv_456"}
)

# Chá»‰ Ã¡p dá»¥ng cho conversation nÃ y
# Lifetime: Minutes to hours (configurable)
```


### **3.2. Session Memory (Short LTM)**

```python
# LÆ°u memory theo session
memory.add(
    "Currently browsing electronics section",
    user_id="user_123",
    metadata={"session_id": "sess_789"}
)

# Lifetime: Hours (e.g., 1 day session)
```


### **3.3. User Memory (Long LTM)**

```python
# LÆ°u memory vÄ©nh viá»…n cho user
memory.add(
    "User prefers dark mode",
    user_id="user_123"
)

# Lifetime: Weeks to forever (no expiration)
```


### **3.4. Organization Memory (Shared LTM)**

```python
# LÆ°u memory chung cho org
memory.add(
    "Company policy: remote work on Fridays",
    metadata={"org_id": "org_001"}
)

# Lifetime: Configured globally
```


***

## â° **4. EXPIRATION / TTL (Mem0 OSS v1.0+)**

Mem0 OSS **há»— trá»£ expiration** Ä‘á»ƒ implement short-term vs long-term:[^6]

```python
from datetime import datetime, timedelta

# SHORT-TERM: Expires in 7 days
expires_at = (datetime.now() + timedelta(days=7)).isoformat()
memory.add(
    "Currently browsing electronics",
    user_id="sarah",
    expiration_date=expires_at  # â† Key feature!
)

# LONG-TERM: No expiration (persists forever)
memory.add(
    "User prefers dark mode",
    user_id="sarah"
    # No expiration_date = permanent
)
```

**7 ngÃ y sau:**

```python
# Short-term memory Ä‘Ã£ expired
results = memory.search("browsing", user_id="sarah")
# â†’ Empty (Ä‘Ã£ háº¿t háº¡n)

# Long-term memory váº«n cÃ²n
results = memory.search("dark mode", user_id="sarah")
# â†’ Return: "User prefers dark mode" âœ…
```


***

## ğŸ”„ **5. WORKFLOW: PHá»I Há»¢P STM + LTM Vá»šI MEM0 OSS**

### **Recommended Pattern:**

```python
class HybridMemorySystem:
    """
    Káº¿t há»£p STM (tá»± quáº£n lÃ½) + LTM (Mem0 OSS)
    """
    
    def __init__(self):
        # STM: Redis (application-managed)
        self.stm = ShortTermMemory()
        
        # LTM: Mem0 OSS (managed by Mem0)
        self.ltm = Memory.from_config(config)
    
    async def process_message(
        self,
        user_id: str,
        session_id: str,
        message: str
    ):
        """Process user message with hybrid memory"""
        
        # 1. Get STM (recent conversation)
        conversation = self.stm.get_conversation(session_id)
        
        # 2. Get LTM (relevant long-term facts)
        ltm_facts = self.ltm.search(
            query=message,
            user_id=user_id,
            limit=5
        )
        
        # 3. Combine STM + LTM for LLM prompt
        context = {
            "conversation": conversation,  # STM
            "user_facts": ltm_facts       # LTM from Mem0
        }
        
        # 4. Generate response
        response = await llm.generate(message, context)
        
        # 5. Update STM
        conversation.append({"role": "user", "content": message})
        conversation.append({"role": "assistant", "content": response})
        self.stm.store_conversation(session_id, conversation)
        
        # 6. Extract important facts â†’ LTM (async)
        asyncio.create_task(
            self.ltm.add(
                messages=conversation[-2:],  # Last 2 messages
                user_id=user_id
            )
        )
        
        return response
```


***

## ğŸ“Š **6. SO SÃNH: STM vs LTM TRONG MEM0 OSS**

| Aspect | Short-Term Memory | Long-Term Memory |
| :-- | :-- | :-- |
| **Mem0 Managed?** | âŒ NO (báº¡n tá»± implement) | âœ… YES (core feature) |
| **Storage** | Redis / In-memory | Vector DB (Qdrant/Milvus) + Graph DB |
| **Lifetime** | Minutes to hours | Days to forever |
| **Scope** | Per session/conversation | Per user/agent |
| **Expiration** | Auto (TTL trong Redis) | Optional (expiration_date) |
| **Search Method** | Exact match / Key-based | Semantic vector search |
| **Use Case** | "Vá»«a nÃ³i gÃ¬?" | "Sá»Ÿ thÃ­ch tá»« trÆ°á»›c tá»›i nay?" |


***

## âœ… **Káº¾T LUáº¬N: MEM0 OSS Há»– TRá»¢ GÃŒ?**

### **âœ… Mem0 OSS Há»– TRá»¢:**

1. **Long-Term Memory (Core):**
    - Vector storage (Qdrant/Milvus)
    - Semantic search
    - Graph relationships (Neo4j)
    - Expiration support (TTL)
    - User/Agent/Org scoping
2. **Memory Types:**
    - Conversation memory (short LTM)
    - Session memory (medium LTM)
    - User memory (long LTM)
    - Organization memory (shared LTM)

### **âŒ Mem0 OSS KHÃ”NG Há»– TRá»¢:**

1. **Short-Term Memory (Conversation History):**
    - Báº¡n pháº£i tá»± quáº£n lÃ½ vá»›i Redis/In-memory
    - Mem0 khÃ´ng store conversation history
2. **Context Window Management:**
    - Mem0 khÃ´ng replace LLM context window
    - Báº¡n váº«n cáº§n quáº£n lÃ½ prompt engineering

***

## ğŸ¯ **RECOMMENDATION CHO PIKA:**

```python
# Chiáº¿n lÆ°á»£c Ä‘á» xuáº¥t:

# STM (Self-managed):
- Redis vá»›i TTL 1 hour
- Key: stm:session:{session_id}
- Store: Conversation history (messages list)

# LTM (Mem0 OSS):
- Qdrant vector store
- Neo4j graph store (relationships)
- Expiration: 
  * Session facts: 7 days
  * User preferences: No expiration
```

**Káº¿t luáº­n:** Mem0 OSS **chuyÃªn vá» LTM**, báº¡n cáº§n tá»± implement STM báº±ng Redis hoáº·c application state.[^3][^5][^1][^2][^6]
<span style="display:none">[^10][^11][^12][^13][^14][^15][^16][^17][^18][^19][^20][^21][^22][^23][^24][^25][^7][^8][^9]</span>

<div align="center">â‚</div>

[^1]: https://docs.mem0.ai/core-concepts/memory-types

[^2]: https://aws.amazon.com/blogs/database/build-persistent-memory-for-agentic-ai-applications-with-mem0-open-source-amazon-elasticache-for-valkey-and-amazon-neptune-analytics/

[^3]: https://dev.to/yigit-konur/mem0-the-comprehensive-guide-to-building-ai-with-persistent-memory-fbm

[^4]: https://mem0.ai

[^5]: https://github.com/mem0ai/mem0

[^6]: https://docs.mem0.ai/cookbooks/essentials/memory-expiration-short-and-long-term

[^7]: Step-2-Output-1-SDD.md

[^8]: MEM0_OSS_SETUP.md

[^9]: Step-2-Output-2-SDD-HLD-LLD-co-ca-Optimize-Response-Time.md

[^10]: report.md

[^11]: report.md

[^12]: https://viblo.asia/p/mem0-kien-truc-long-term-memory-cho-he-thong-ai-agent-G24B88pOLz3

[^13]: https://pypi.org/project/mem0ai/0.1.0/

[^14]: https://www.ycombinator.com/launches/LpA-mem0-open-source-memory-layer-for-ai-apps

[^15]: https://www.datacamp.com/tutorial/mem0-tutorial

[^16]: https://docs.mem0.ai/open-source/overview

[^17]: https://docs.crewai.com/en/concepts/memory

[^18]: https://skywork.ai/skypage/en/A-Comprehensive-Guide-to-the-Mem0-MCP-Server-Building-AI-with-Persistent-Memory/1971044006807793664

[^19]: https://arxiv.org/abs/2504.19413

[^20]: https://docs.mem0.ai/open-source/python-quickstart

[^21]: https://viblo.asia/p/gioi-thieu-ve-mem0-xay-dung-ai-agents-voi-long-term-memory-AY4qQN8q4Pw

[^22]: https://arxiv.org/pdf/2504.19413.pdf

[^23]: https://blog.stackademic.com/mem0-memo-ai-memory-layer-purpose-and-core-functionality-375cc5a2bfd0

[^24]: https://fosterfletcher.com/ai-memory-infrastructure/

[^25]: https://docs.mem0.ai/v0x/core-concepts/memory-types


---

<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# V4 - ğŸ“Š **QUICK SUMMARY: STM + LTM CACHING**

### **SHORT-TERM MEMORY (STM) - 2 Layers**

```
L0: In-Memory (current request)
    â””â”€ <1ms, 95% hit rate

L1: Redis (1 hour TTL)
    â””â”€ 5ms, 70% hit rate
```


### **LONG-TERM MEMORY (LTM) - 4 Layers (CRITICAL!)**

```
L0: IN-MEMORY (Python @lru_cache)
    â”œâ”€ Latency: <1ms
    â”œâ”€ Hit Rate: 10-20%
    â”œâ”€ Scope: Per request
    â””â”€ Use: Repeated queries in same request

L1: EMBEDDING CACHE (Redis)
    â”œâ”€ Latency: 5ms
    â”œâ”€ Hit Rate: 60-70%
    â”œâ”€ TTL: 24 hours
    â””â”€ Use: Avoid OpenAI API calls (100-200ms saved!)

L2: RESULT CACHE (Redis)
    â”œâ”€ Latency: 5-20ms
    â”œâ”€ Hit Rate: 40%
    â”œâ”€ TTL: Smart (based on confidence)
    â””â”€ Use: Cache full search results

L3: MATERIALIZED VIEW (PostgreSQL)
    â”œâ”€ Latency: 20-50ms
    â”œâ”€ Hit Rate: 20-30% (for favorites)
    â”œâ”€ TTL: Proactive worker updates
    â””â”€ Use: Pre-computed user favorites

L4: VECTOR SEARCH (Mem0 + Milvus)
    â”œâ”€ Latency: 100-300ms
    â”œâ”€ Hit Rate: N/A (always fresh)
    â”œâ”€ TTL: No cache (primary source)
    â””â”€ Use: Fallback when all caches miss

```


***


---

# Luá»“ng Ä‘i khi káº¿t thÃºc: Sau khi káº¿t thÃºc 1 cuá»™c há»™i thoáº¡i -> Ä‘Æ°á»£c báº¯n Ä‘i xá»­ lÃ½ extract cÃ¡c kiá»ƒu -> save memory  
+, L4 thá»±c hiá»‡n ngay query user_favorite_summary => Ä‘áº©y xuá»‘ng L3  
+, L3 thá»±c hiá»‡n ngay Ä‘á»ƒ lÆ°u vÃ o DB Postgres  
=> L2 thá»±c hiá»‡n ngay Ä‘á»ƒ cache vÃ o trong Redis  


Khi end cuá»™c há»™i thoáº¡i, bÃªn BE chá»§ Ä‘á»™ng báº¯n end cho bÃªn phÃ­a AI thá»±c hiá»‡n extract (á»Ÿ Module Context Handling rá»“i).  
  
+, Trong Module Memory nÃ y chá»‰ cáº§n:  
1. Thá»±c hiá»‡n extract xong thÃ¬ lÆ°u vÃ o Long Term Memory  
2. Thá»±c hiá»‡n query L4 (Vector Search: Milvus, vÃ  Graph Search: Neo4J Ä‘Æ°á»£c tÃ­ch há»£p sáºµn trong Mem0 OSS


```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CONTEXT HANDLING MODULE                     â”‚
â”‚  (Already handles conversation end & extraction)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Triggers extraction job
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          MEMORY MODULE (Your focus)                  â”‚
â”‚                                                      â”‚
â”‚  âœ… 1. Receive extraction results                   â”‚
â”‚  âœ… 2. Save to Long-Term Memory (L4)                â”‚
â”‚        â”œâ”€ Vector Search (Milvus)                    â”‚
â”‚        â””â”€ Graph Search (Neo4j)                      â”‚
â”‚        â†’ Both handled by Mem0 OSS                   â”‚
â”‚                                                      â”‚
â”‚  âœ… 3. Proactive Cache Warming (After save)         â”‚
â”‚        â”œâ”€ Query L4 (user_favorite_summary)          â”‚
â”‚        â”œâ”€ Save to L3 (PostgreSQL)                   â”‚
â”‚        â””â”€ Warm L2 (Redis)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## Flow sau khi end conversation

- BE bÃ¡o end â†’ Context Handling cháº¡y extract, rá»“i gá»­iÂ `extracted_facts`Â sang Memory Module.[](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
    
- Memory Module lÃ m 3 bÆ°á»›c ná»‘i tiáº¿p (background, async):
    
    1. **Save LTM (L4)**: dÃ¹ng Mem0 OSS Ä‘á»ƒ lÆ°u facts vÃ o Milvus + Neo4j.
        
    2. **Query L4 choÂ `user_favorite_summary`**: gá»i má»™t query canonical Ä‘á»ƒ gom Ä‘á»§ â€œfavorite (movie, character, pet, activity, friend, music, travel, toy)â€.
        
    3. **Äáº©y xuá»‘ng cÃ¡c táº§ng cache**:
        
        - L3: ghi summary vÃ o Postgres (`user_favorite_summary`).
            
        - L2: cache ngay 1â€“2 response canonical trong Redis cho cÃ¡c cÃ¢u favorite phá»• biáº¿n.[](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹

Trong lÃºc pipeline nÃ y chÆ°a xong  
Náº¿u user há»i láº¡i ngay sau khi end:  
Front/Context Handling dÃ¹ngÂ shortâ€‘term memoryÂ + L1/L2 nhÆ° bÃ¬nh thÆ°á»ng Ä‘á»ƒ tráº£ lá»i, khÃ´ng Ä‘á»£i job ná»n.  
â€‹  
Khi job ná»n hoÃ n táº¥t:  
L4 sáº½ cÃ³  
L3 Ä‘Ã£ cÃ³ profile dÃ i háº¡n.  
L2 Ä‘Ã£ Ä‘Æ°á»£c warm sáºµn cho cÃ¡c favorite query â†’ láº§n sau user há»i sáº½ hit cache nhanh.â€‹


Ã nÃ y há»£p lÃ½, vÃ  cÃ³ thá»ƒ rÃºt láº¡i thÃ nh rule Ä‘Æ¡n giáº£n cho pipeline trongâ€‘ngÃ y:

## 1. Online path trong ngÃ y

- Vá»›i cÃ¡c cÃ¢u há»i â€œbÃ¬nh thÆ°á»ngâ€ trong 1 ngÃ y Ä‘Ã³:
    
    - Æ¯u tiÃªn dÃ¹ng **Shortâ€‘Term Memory** (STM) lÃ m nguá»“n chÃ­nh vÃ¬:
        
        - ÄÃ£ chá»©a full lá»‹ch sá»­ cÃ¡c cuá»™c há»™i thoáº¡i gáº§n Ä‘Ã¢y.
            
        - ÄÆ°á»£c lÆ°u Redis 1 ngÃ y nÃªn coi nhÆ° â€œshortâ€‘term nhÆ°ng Ä‘á»§ dÃ iâ€.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
            
- Khi cáº§n LTM trong pipeline:
    - Check L0 **L0 â€“ Inâ€‘memory (per request / per process)**
		- Python dict / nhá» gá»n, latency <1ms.
		    
		- DÃ¹ng Ä‘á»ƒ trÃ¡nh láº·p láº¡i cÃ¹ng má»™t phÃ©p tÃ­nh trong cÃ¹ng request hoáº·c ráº¥t ngáº¯n háº¡n. 
    - **Check L1 (embedding cache)** Ä‘á»ƒ trÃ¡nh gá»i embedding.
        
    - **Check L2 (result cache)** cho cÃ¡c query LTM Ä‘Ã£ warm.
        
    - Náº¿u cáº£ L1/L2 Ä‘á»u á»•n thÃ¬ **thÆ°á»ng khÃ´ng cáº§n cháº¡m L3/L4** trong Ä‘a sá»‘ case trong ngÃ y.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
        

## 2. L3/L4 nhÆ° fallback & offline source

- **L3 (Postgres summary)**: chá»‰ dÃ¹ng khi:
    
    - L2 gáº·p lá»—i / miss mÃ  cáº§n profile á»•n Ä‘á»‹nh, hoáº·c trong cÃ¡c job offline build/cáº­p nháº­t profile.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
        
- **L4 (Mem0 â€“ Milvus + Neo4j)**: giá»¯ vai trÃ²:
    
    - Source of truth Ä‘á»ƒ:
        
        - Build / rebuild L3.
            
        - Serve cÃ¡c query LTM â€œká»³ láº¡â€, Ã­t gáº·p, hoáº·c khi STM + L2/L3 khÃ´ng Ä‘á»§ thÃ´ng tin.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
            

## 3. Tá»‘i Æ°u thá»±c táº¿

- VÃ¬ STM Ä‘Ã£ giá»¯ Ä‘Æ°á»£c 1 ngÃ y, nÃªn vá»›i user hoáº¡t Ä‘á»™ng nhiá»u trong ngÃ y:
    
    - 90%+ cÃ¢u tráº£ lá»i sáº½ Ä‘áº¿n tá»« **STM + L1/L2**.
        
    - L3/L4 gáº§n nhÆ° chá»‰ cháº¡y:
        
        - Khi káº¿t thÃºc há»™i thoáº¡i (pipeline ná»n).
            
        - Hoáº·c cho cÃ¡c truy váº¥n â€œráº¥t lÃ¢u rá»“i khÃ´ng Ä‘á»¥ng tá»›iâ€.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
            

TÃ³m láº¡i: pipeline online dÃ¹ng **STM + L1/L2** lÃ m â€œfirst lineâ€, cÃ²n **L3/L4 lÃ  longâ€‘term backup + offline computation layer**, Ä‘Ãºng vá»›i cÃ¡ch báº¡n Ä‘ang nghÄ©.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹

1. [https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)


Shortâ€‘term á»Ÿ Ä‘Ã¢y khÃ´ng pháº£i â€œsá»‘ng vÃ i phÃºtâ€ mÃ  lÃ  **ngá»¯ nghÄ©a**: nÃ³ chá»‰ giá»¯ Ä‘Æ°á»£c _context há»™i thoáº¡i gáº§n Ä‘Ã¢y_, dÃ¹ TTL lÃ  24h.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹

## STM 24h dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬

- **Giá»¯ nguyÃªn vÄƒn cuá»™c há»™i thoáº¡i**: táº¥t cáº£ turns, phrasing, joke, tham chiáº¿u kiá»ƒu â€œnhÆ° mÃ¬nh nÃ³i á»Ÿ trÃªnâ€, â€œcÃ¡i lÃºc nÃ£yâ€ váº«n cÃ²n trong 1 ngÃ y, nÃªn:
    
    - Há»i láº¡i â€œHá»“i nÃ£y tá»› báº£o gÃ¬ vá» cÃ´ng viá»‡c?â€ váº«n tráº£ lá»i Ä‘Æ°á»£c tá»« STM, khÃ´ng cáº§n LTM.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
        
- **TÃ¡ch vai trÃ² vá»›i LTM**:
    
    - LTM lÆ°u facts Ä‘Ã£ extract, dáº¡ng chuáº©n hÃ³a, dÃ¹ng lÃ¢u dÃ i.
        
    - STM lÆ°u raw context, ráº¥t há»¯u Ã­ch cho followâ€‘up trong cÃ¹ng ngÃ y nhÆ°ng **KHÃ”NG dÃ¹ng lÃ m source sá»± tháº­t lÃ¢u dÃ i**.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
        

## VÃ¬ sao 24h váº«n gá»i lÃ  shortâ€‘term

- **Scope**:
    
    - STM gáº¯n vá»›i `session_id` / conversation trong 1 ngÃ y â†’ mang tÃ­nh â€œphiÃªn lÃ m viá»‡câ€, chá»© khÃ´ng crossâ€‘day, crossâ€‘device máº¡nh nhÆ° LTM.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
        
- **Lifecycle**:
    
    - Sau 24h, session háº¿t háº¡n, dá»¯ liá»‡u há»™i thoáº¡i bá»‹ xÃ³a â†’ chá»‰ cÃ²n LTM giá»¯ láº¡i cÃ¡c facts Ä‘Ã£ extract.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
        

Náº¿u muá»‘n â€œshortâ€ Ä‘Ãºng nghÄ©a hÆ¡n, cÃ³ thá»ƒ giáº£m TTL STMâ€‘L1 xuá»‘ng 2â€“4h, nhÆ°ng viá»‡c Ä‘á»ƒ 24h chá»§ yáº¿u Ä‘á»ƒ UX tá»‘t hÆ¡n cho user quay láº¡i trong cÃ¹ng ngÃ y mÃ  khÃ´ng máº¥t máº¡ch há»™i thoáº¡i; LTM váº«n lÃ  nÆ¡i duy nháº¥t giá»¯ kÃ½ á»©c dÃ i háº¡n.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹

1. [https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)


KhÃ´ng nháº¥t thiáº¿t pháº£i â€œfull toÃ n bá»™ tá»« Aâ†’Zâ€ theo nghÄ©a log tá»«ng token, mÃ  STM nÃªn lÆ°u **Ä‘á»§ context há»™i thoáº¡i gáº§n Ä‘Ã¢y trong 1 ngÃ y**, dÆ°á»›i dáº¡ng Ä‘Ã£ Ä‘Æ°á»£c nÃ©n/há»£p lÃ½ hÃ³a.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹

## LÆ°u gÃ¬ trong STM 24h

- Thá»±c táº¿ nÃªn lÆ°u:
    
    - CÃ¡c turn quan trá»ng: user message + assistant reply, Ä‘Ã£ **truncate** bá»›t history quÃ¡ xa.
        
    - Hoáº·c lÆ°u 1 báº£n **summary ngáº¯n theo session** + má»™t pháº§n raw gáº§n nháº¥t (vÃ­ dá»¥ 10â€“30 turn cuá»‘i).[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
        
- Má»¥c tiÃªu:
    
    - Há»— trá»£ cÃ¢u há»i kiá»ƒu â€œhá»“i nÃ£y tá»› nÃ³i gÃ¬â€, â€œtiáº¿p tá»¥c Ä‘oáº¡n lÃºc nÃ£yâ€, â€œnhÆ° plan trÆ°á»›c Ä‘Ã³â€¦â€ trong cÃ¹ng ngÃ y.
        
    - KhÃ´ng dÃ¹ng STM lÃ m â€œdata warehouseâ€; chá»‰ lÃ  **working set** cho conversation.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
        

## VÃ¬ sao TTL 24h váº«n ok

- â€œShortâ€‘termâ€ á»Ÿ Ä‘Ã¢y lÃ  theo **ngá»¯ nghÄ©a thá»i gian sá»­ dá»¥ng**:
    
    - NÃ³ phá»¥c vá»¥ máº¡ch há»™i thoáº¡i **trong ngÃ y** (1â€“2 phiÃªn gáº§n nhau).
        
    - Sau 24h, há»‡ thá»‘ng coi nhÆ° context cÅ©, chá»‰ cÃ²n LTM (facts Ä‘Ã£ extract) lÃ  giá»¯ lÃ¢u dÃ i.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
        
- Náº¿u sá»£ phÃ¬nh Redis, cÃ³ thá»ƒ:
    
    - Giáº£m TTL STMâ€‘L1 xuá»‘ng 4â€“8h.
        
    - Hoáº·c giá»›i háº¡n tá»‘i Ä‘a sá»‘ turn/session Ä‘Æ°á»£c lÆ°u (vÃ­ dá»¥ 100â€“200) rá»“i cáº¯t bá»›t.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
        

## TÃ³m gá»n

- STMâ€‘L1 **khÃ´ng báº¯t buá»™c** pháº£i lÆ°u â€œfull 100% má»i messageâ€, mÃ  lÃ  â€œÄ‘á»§ Ä‘á»ƒ tiáº¿p tá»¥c há»™i thoáº¡iâ€, trong khoáº£ng 1 ngÃ y.
    
- LTM (L1/L2/L3/L4) má»›i lÃ  nÆ¡i giá»¯ lÃ¢u dÃ i cÃ¡c facts quan trá»ng sau khi extract xong.[perplexity](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)â€‹
    

1. [https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw](https://www.perplexity.ai/search/cai-tai-lieu-nao-ma-co-full-co-DnFYpZp7Tzaf_teH.xHLkw)



---

# Chá»‘t : # ğŸ—ï¸ **HIGH-LEVEL ARCHITECTURE: SHORT-TERM + LONG-TERM MEMORY**  


```bash
User Query: "What do I like?"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PARALLEL EXECUTION (asyncio.gather)             â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Query STM      â”‚        â”‚   Query LTM      â”‚     â”‚
â”‚  â”‚   (async)        â”‚  +     â”‚   (async)        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚          â”‚                            â”‚                â”‚
â”‚          â”‚ (5ms)                      â”‚ (5-20ms)       â”‚
â”‚          â”‚                            â”‚                â”‚
â”‚          â†“                            â†“                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  STM Results:    â”‚        â”‚  LTM Results:    â”‚     â”‚
â”‚  â”‚  - "You just     â”‚        â”‚  - "User likes   â”‚     â”‚
â”‚  â”‚    said pizza"   â”‚        â”‚    pizza" (90%)  â”‚     â”‚
â”‚  â”‚  - Context from  â”‚        â”‚  - "User likes   â”‚     â”‚
â”‚  â”‚    current conv  â”‚        â”‚    sushi" (85%)  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MERGE & RANK RESULTS                       â”‚
â”‚                                                         â”‚
â”‚  1. Deduplicate (same facts from both sources)         â”‚
â”‚  2. Rank by:                                            â”‚
â”‚     - Relevance score                                   â”‚
â”‚     - Recency (STM gets bonus)                         â”‚
â”‚     - Confidence                                        â”‚
â”‚  3. Format final response                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Response to User (Total latency: ~20ms)

```


***



## ğŸ“ **SYSTEM CONTEXT - C4 LEVEL 1**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PIKA ECOSYSTEM                           â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚   PIKA AI     â”‚                                             â”‚
â”‚  â”‚  Companion    â”‚                                             â”‚
â”‚  â”‚   (Client)    â”‚                                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚          â”‚                                                      â”‚
â”‚          â”‚ HTTPS/gRPC                                          â”‚
â”‚          â†“                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              CONTEXT HANDLING MODULE                     â”‚ â”‚
â”‚  â”‚        (Conversation & Extraction)                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                   â”‚                  â”‚                         â”‚
â”‚     Conversation  â”‚                  â”‚ Extraction results      â”‚
â”‚       context     â”‚                  â”‚                         â”‚
â”‚                   â†“                  â†“                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              MEMORY MODULE                              â”‚  â”‚
â”‚  â”‚         (STM + LTM Unified Service)                     â”‚  â”‚
â”‚  â”‚                                                         â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  SHORT-TERM MEMORY (STM)                         â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ In-memory + Redis                             â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ TTL: 24 hours                                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Scope: Conversation session                   â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                         â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  LONG-TERM MEMORY (LTM)                          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ 5-layer caching (L0â†’L1â†’L2â†’L3â†’L4)            â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ TTL: Variable (10min - âˆ)                    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Scope: User lifetime                          â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                         â”‚  â”‚
â”‚  â”‚  âš¡ Parallel Search: STM + LTM                         â”‚  â”‚
â”‚  â”‚  ğŸ”€ Intelligent Merge & Ranking                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


***

## ğŸ”§ **CONTAINER DIAGRAM - C4 LEVEL 2**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MEMORY MODULE                               â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                API GATEWAY (FastAPI)                       â”‚ â”‚
â”‚  â”‚  â€¢ POST /api/v1/memory/search                             â”‚ â”‚
â”‚  â”‚  â€¢ GET /api/v1/stm/{session_id}                           â”‚ â”‚
â”‚  â”‚  â€¢ POST /api/v1/ltm/extract                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â”‚                                           â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚          â†“                       â†“                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚   STM SERVICE    â”‚    â”‚   LTM SERVICE    â”‚                  â”‚
â”‚  â”‚   (Parallel)     â”‚    â”‚   (Parallel)     â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚           â”‚                       â”‚                             â”‚
â”‚           â†“                       â†“                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           MEMORY ORCHESTRATOR                            â”‚  â”‚
â”‚  â”‚  â€¢ asyncio.gather(STM, LTM)                             â”‚  â”‚
â”‚  â”‚  â€¢ Merge & Rank results                                  â”‚  â”‚
â”‚  â”‚  â€¢ Deduplicate facts                                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                    â”‚
          â†“                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SHORT-TERM STORAGE    â”‚    â”‚   LONG-TERM STORAGE              â”‚
â”‚                         â”‚    â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Redis (Session)  â”‚  â”‚    â”‚  â”‚ Redis (L1, L2)             â”‚ â”‚
â”‚  â”‚ TTL: 24h         â”‚  â”‚    â”‚  â”‚ - Embedding cache          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚  â”‚ - Result cache             â”‚ â”‚
â”‚                         â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚                                  â”‚
â”‚  â”‚ In-Memory (L0)   â”‚  â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Per-request      â”‚  â”‚    â”‚  â”‚ PostgreSQL (L3)            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚  â”‚ - Materialized views       â”‚ â”‚
â”‚                         â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                                  â”‚
                               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                               â”‚  â”‚ Mem0 OSS (L4)              â”‚ â”‚
                               â”‚  â”‚ - Milvus (vectors)         â”‚ â”‚
                               â”‚  â”‚ - Neo4j (graph)            â”‚ â”‚
                               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


***

## ğŸ“Š **COMPONENT DIAGRAM - DETAILED VIEW**

### **SHORT-TERM MEMORY (STM) COMPONENTS**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          SHORT-TERM MEMORY SERVICE                       â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  STMService                                        â”‚ â”‚
â”‚  â”‚  â”œâ”€ search(session_id, query)                     â”‚ â”‚
â”‚  â”‚  â”œâ”€ store(session_id, messages)                   â”‚ â”‚
â”‚  â”‚  â””â”€ clear(session_id)                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚   â†“                    â†“                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ L0: In-Memoryâ”‚  â”‚ L1: Redis    â”‚                   â”‚
â”‚  â”‚ @lru_cache   â”‚  â”‚ Session Storeâ”‚                   â”‚
â”‚  â”‚ <1ms         â”‚  â”‚ 5ms          â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                          â”‚
â”‚  Data Structure:                                        â”‚
â”‚  {                                                      â”‚
â”‚    "session_id": "sess_123",                           â”‚
â”‚    "messages": [                                        â”‚
â”‚      {"role": "user", "content": "...", "ts": ...},   â”‚
â”‚      {"role": "assistant", "content": "...", "ts"}    â”‚
â”‚    ],                                                   â”‚
â”‚    "created_at": "2025-12-22T10:00:00Z",              â”‚
â”‚    "last_accessed": "2025-12-22T11:00:00Z"            â”‚
â”‚  }                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


### **LONG-TERM MEMORY (LTM) COMPONENTS**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          LONG-TERM MEMORY SERVICE                            â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  LTMService                                            â”‚ â”‚
â”‚  â”‚  â”œâ”€ search(user_id, query, limit)                     â”‚ â”‚
â”‚  â”‚  â”œâ”€ extract_and_save(user_id, facts)                  â”‚ â”‚
â”‚  â”‚  â”œâ”€ proactive_cache_warming(user_id)                  â”‚ â”‚
â”‚  â”‚  â””â”€ invalidate_cache(user_id)                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚   â†“         â†“         â†“         â†“   â†“                      â”‚
â”‚  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”                      â”‚
â”‚  â”‚L0 â”‚  â”‚L1 â”‚  â”‚L2 â”‚  â”‚L3 â”‚  â”‚ L4 â”‚                      â”‚
â”‚  â”‚In-â”‚  â”‚Embâ”‚  â”‚Resâ”‚  â”‚Matâ”‚  â”‚Vec â”‚                      â”‚
â”‚  â”‚Memâ”‚  â”‚edgâ”‚  â”‚ultâ”‚  â”‚eriâ”‚  â”‚tor â”‚                      â”‚
â”‚  â”‚   â”‚  â”‚   â”‚  â”‚   â”‚  â”‚alizâ”‚  â”‚+   â”‚                      â”‚
â”‚  â”‚<1 â”‚  â”‚5msâ”‚  â”‚5-2â”‚  â”‚ed â”‚  â”‚Gra â”‚                      â”‚
â”‚  â”‚ms â”‚  â”‚   â”‚  â”‚0msâ”‚  â”‚20-â”‚  â”‚ph  â”‚                      â”‚
â”‚  â”‚   â”‚  â”‚   â”‚  â”‚   â”‚  â”‚50 â”‚  â”‚100 â”‚                      â”‚
â”‚  â”‚   â”‚  â”‚   â”‚  â”‚   â”‚  â”‚ms â”‚  â”‚-300â”‚                      â”‚
â”‚  â”‚   â”‚  â”‚   â”‚  â”‚   â”‚  â”‚   â”‚  â”‚ms  â”‚                      â”‚
â”‚  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜                      â”‚
â”‚    â†“      â†“      â†“      â†“      â†“                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚    Cache Warming Worker          â”‚                      â”‚
â”‚  â”‚    â€¢ Runs after extraction       â”‚                      â”‚
â”‚  â”‚    â€¢ L4 â†’ L3 â†’ L2 pipeline       â”‚                      â”‚
â”‚  â”‚    â€¢ Tag-based invalidation      â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


***

## âš¡ **PARALLEL EXECUTION FLOW**

```
User Query: "What do I like?"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Memory Orchestrator (async/await)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
asyncio.gather([stm_search, ltm_search])
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       â”‚                                â”‚
â”‚  STM Search           â”‚  LTM Search                    â”‚
â”‚  (5ms)                â”‚  (5-300ms based on cache)      â”‚
â”‚                       â”‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Check L0        â”‚  â”‚  â”‚ Check L0 (in-mem)        â”‚ â”‚
â”‚  â”‚   â†“ MISS        â”‚  â”‚  â”‚   â†“ MISS                 â”‚ â”‚
â”‚  â”‚ Check L1 (Redis)â”‚  â”‚  â”‚ Check L1 (embedding)     â”‚ â”‚
â”‚  â”‚   â†“ HIT âœ…      â”‚  â”‚  â”‚   â†“ HIT âœ…               â”‚ â”‚
â”‚  â”‚ Return results  â”‚  â”‚  â”‚ Check L2 (results)       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚   â†“ HIT âœ…               â”‚ â”‚
â”‚                       â”‚  â”‚ Return cached results    â”‚ â”‚
â”‚  Results:             â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  [                    â”‚                                â”‚
â”‚    {fact: "recent"   â”‚  Results:                      â”‚
â”‚     score: 0.8}      â”‚  [                             â”‚
â”‚  ]                    â”‚    {fact: "old preference",   â”‚
â”‚                       â”‚     score: 0.9}                â”‚
â”‚                       â”‚  ]                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                       â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MERGE & RANK (Dedup + Scoring)                   â”‚
â”‚                                                          â”‚
â”‚  1. Deduplicate by fact text (lowercase)                â”‚
â”‚  2. Boost if fact appears in both STM + LTM (+0.15)     â”‚
â”‚  3. Add recency bonus for STM facts (+0.1)              â”‚
â”‚  4. Sort by final_score (descending)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Final Results:
[
  {fact: "old preference", score: 1.05, source: "stm+ltm"},
  {fact: "recent", score: 0.9, source: "stm"}
]
```


***

## ğŸ—‚ï¸ **DATA FLOW ARCHITECTURE**

### **Write Path (Extract \& Save)**

```
Conversation End
    â†“
Context Handling Module â†’ extraction_results
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Memory Module - Write Pipeline                         â”‚
â”‚                                                          â”‚
â”‚  STEP 1: Save to LTM-L4 (Primary Storage)               â”‚
â”‚  â”œâ”€ Mem0.add(facts)                                     â”‚
â”‚  â”‚   â”œâ”€ Milvus: Store embeddings                        â”‚
â”‚  â”‚   â””â”€ Neo4j: Store entities + relationships           â”‚
â”‚  â”‚                                                        â”‚
â”‚  STEP 2: Proactive Cache Warming (Async)                â”‚
â”‚  â”œâ”€ Query L4 for user_favorite_summary                  â”‚
â”‚  â”œâ”€ Save to L3 (PostgreSQL)                             â”‚
â”‚  â””â”€ Warm L2 (Redis)                                     â”‚
â”‚                                                          â”‚
â”‚  STEP 3: Cache Invalidation                             â”‚
â”‚  â””â”€ Increment user_version_tag (Redis)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


### **Read Path (Search)**

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Memory Module - Read Pipeline (Parallel)                â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  STM Read Path     â”‚  +   â”‚  LTM Read Path          â”‚â”‚
â”‚  â”‚                    â”‚      â”‚                         â”‚â”‚
â”‚  â”‚  L0 â†’ L1           â”‚      â”‚  L0 â†’ L1 â†’ L2 â†’ L3 â†’ L4 â”‚â”‚
â”‚  â”‚  (<1ms â†’ 5ms)      â”‚      â”‚  (<1 â†’ 5 â†’ 20 â†’ 50     â”‚â”‚
â”‚  â”‚                    â”‚      â”‚   â†’ 300ms)              â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚             â”‚                           â”‚                â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                         â†“                                â”‚
â”‚                  Merge & Rank                            â”‚
â”‚                         â†“                                â”‚
â”‚                   Return Results                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


***

## ğŸ† **KEY DESIGN DECISIONS**

| Decision | Rationale | Trade-off |
| :-- | :-- | :-- |
| **Parallel STM + LTM** | Maximize speed - both run concurrently[^1] | More complex merge logic |
| **2 separate services** | Clear separation of concerns (STM vs LTM) | 2 independent failure points |
| **STM TTL = 24h** | Balance between freshness \& coverage | Daily users re-fetch STM |
| **LTM L2 TTL = 1h** | User preferences can change during day | More frequent cache misses |
| **Proactive warming** | Pre-compute favorites before user asks | Background worker overhead |
| **Tag-based invalidation** | Simple \& scalable (no manual key deletion)[^2] | Requires version management |


***

**Latency targets:**[^2][^3]

- **STM hit:** <5ms
- **LTM cached:** <50ms
- **LTM uncached:** 100-300ms
- **Overall P95:** <50ms (with 60-70% cache hit)
<span style="display:none">[^4][^5]</span>

<div align="center">â‚</div>

[^1]: https://shanechang.com/p/python-asyncio-gather-explained/

[^2]: report.md

[^3]: report.md

[^4]: Step-2-Output-1-SDD.md

[^5]: Step-2-Output-2-SDD-HLD-LLD-co-ca-Optimize-Response-Time.md


## ğŸ—ï¸ **ARCHITECTURE: 3-TIER STM COMPRESSION**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STM WITH HIERARCHICAL SUMMARIZATION                 â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  TIER 1: Active Window (Last 10 turns)                    â”‚ â”‚
â”‚  â”‚  â€¢ Full conversation history                              â”‚ â”‚
â”‚  â”‚  â€¢ No compression                                          â”‚ â”‚
â”‚  â”‚  â€¢ Use: Current context                                    â”‚ â”‚
â”‚  â”‚  â€¢ Size: ~2,000 tokens                                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â†“ (every 10 turns)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  TIER 2: Recent Summary (Turns 11-50)                     â”‚ â”‚
â”‚  â”‚  â€¢ LLM-generated summary                                   â”‚ â”‚
â”‚  â”‚  â€¢ Key facts extracted                                     â”‚ â”‚
â”‚  â”‚  â€¢ Use: Medium-term context                                â”‚ â”‚
â”‚  â”‚  â€¢ Size: ~500 tokens (compressed from 8,000)              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â†“ (every 50 turns)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  TIER 3: Session Summary (Turns 51+)                      â”‚ â”‚
â”‚  â”‚  â€¢ Ultra-compressed summary                                â”‚ â”‚
â”‚  â”‚  â€¢ Only critical facts                                     â”‚ â”‚
â”‚  â”‚  â€¢ Use: Long-term session context                          â”‚ â”‚
â”‚  â”‚  â€¢ Size: ~200 tokens (compressed from 40,000+)            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚  Final Context Sent to LLM:                                     â”‚
â”‚  = Tier 3 (200) + Tier 2 (500) + Tier 1 (2,000) = 2,700 tokens â”‚
â”‚  vs Original: 50,000 tokens                                     â”‚
â”‚  â†’ 95% compression! ğŸ‰                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```




---







> **TÃ i liá»‡u nÃ y Ä‘Æ°á»£c táº¡o bá»Ÿi Claude 3.5 Sonnet, theo yÃªu cáº§u cá»§a báº¡n.**


# PERFLEXITY - MÆ°á»£t tÃ i liá»‡u - HIGH-LEVEL DESIGN: PIKA MEMORY SYSTEM -  (Manus quÃ¡ yáº¿u á»Ÿ task lÃ m táº¡o high level design vÃ¬ nÃ³ ko váº½ Ä‘Æ°á»£c hÃ¬nh minh hoáº¡, cháº¯c do khÃ³ Prompt <=> Manus máº¡nh trong viáº¿t tÃ i liá»‡u 100 trang)

---

## ğŸ“‹ Má»¤C Lá»¤C

1. [Tá»•ng Quan Kiáº¿n TrÃºc](#1-tá»•ng-quan-kiáº¿n-trÃºc-executive-summary)
2. [Thiáº¿t Káº¿ Bá»™ Nhá»› Ngáº¯n Háº¡n (STM)](#2-thiáº¿t-káº¿-bá»™-nhá»›-ngáº¯n-háº¡n-short-term-memory)
3. [Thiáº¿t Káº¿ Bá»™ Nhá»› DÃ i Háº¡n (LTM)](#3-thiáº¿t-káº¿-bá»™-nhá»›-dÃ i-háº¡n-long-term-memory)
4. [Luá»“ng Dá»¯ Liá»‡u (Data Flow)](#4-luá»“ng-dá»¯-liá»‡u-data-flow)
5. [CÃ¡c Quyáº¿t Äá»‹nh Thiáº¿t Káº¿](#5-cÃ¡c-quyáº¿t-Ä‘á»‹nh-thiáº¿t-káº¿-chÃ­nh)

---

## 1. Tá»”NG QUAN KIáº¾N TRÃšC (EXECUTIVE SUMMARY)

### 1.1 MÃ´ Táº£ Há»‡ Thá»‘ng

**PIKA Memory System** lÃ  má»™t dá»‹ch vá»¥ thá»‘ng nháº¥t (Unified Service) cung cáº¥p kháº£ nÄƒng truy xuáº¥t ngá»¯ cáº£nh vÃ  kÃ½ á»©c vá»›i:

- âœ… **Äá»™ trá»… cá»±c tháº¥p:** P95 < 200ms
- âœ… **Äá»™ chÃ­nh xÃ¡c cao:** Káº¿t há»£p ngá»¯ cáº£nh hiá»‡n táº¡i + lá»‹ch sá»­ dÃ i háº¡n
- âœ… **Kháº£ nÄƒng má»Ÿ rá»™ng:** Há»— trá»£ 1M+ Active Users
- âœ… **Chi phÃ­ tá»‘i Æ°u:** 94% giáº£m so vá»›i Mem0 Enterprise

### 1.2 Kiáº¿n TrÃºc Cáº¥p Cao (C4 Level 1)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIKA ECOSYSTEM                               â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚
â”‚  â”‚  PIKA AI Companion   â”‚                                      â”‚
â”‚  â”‚     (Client)         â”‚                                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â”‚             â”‚ HTTPS/gRPC                                       â”‚
â”‚             â†“                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    CONTEXT HANDLING MODULE                              â”‚ â”‚
â”‚  â”‚  (Conversation & Extraction)                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                          â”‚                    â”‚
â”‚    Conversation                   Extraction              â”‚
â”‚    Context                        Results                 â”‚
â”‚             â†“                          â†“                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           MEMORY MODULE (Unified Service)               â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  SHORT-TERM MEMORY (STM)                           â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ In-memory + Redis                               â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ TTL: 24 hours                                   â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Scope: Conversation session                     â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  LONG-TERM MEMORY (LTM)                            â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ 5-layer caching (L0â†’L1â†’L2â†’L3â†’L4)              â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ TTL: Variable (10min - âˆ)                      â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Scope: User lifetime                            â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  âš¡ Parallel Search: STM + LTM                          â”‚ â”‚
â”‚  â”‚  ğŸ”€ Intelligent Merge & Ranking                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 Container Diagram (C4 Level 2)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   MEMORY MODULE (Unified)                        â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚            API GATEWAY (FastAPI)                           â”‚ â”‚
â”‚  â”‚  â€¢ POST /api/v1/memory/search                             â”‚ â”‚
â”‚  â”‚  â€¢ POST /api/v1/memory/extract                            â”‚ â”‚
â”‚  â”‚  â€¢ GET /api/v1/jobs/{job_id}/status                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                     â”‚                                            â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚         â†“                       â†“                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ STM SERVICE     â”‚    â”‚ LTM SERVICE     â”‚                  â”‚
â”‚  â”‚ (Sync)          â”‚    â”‚ (Async+Cache)   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚           â”‚                      â”‚                            â”‚
â”‚           â†“                      â†“                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     MEMORY ORCHESTRATOR                                  â”‚ â”‚
â”‚  â”‚  â€¢ asyncio.gather(STM, LTM) - Parallel execution        â”‚ â”‚
â”‚  â”‚  â€¢ Merge & Rank results                                  â”‚ â”‚
â”‚  â”‚  â€¢ Deduplicate facts                                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                    â”‚
       â†“                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SHORT-TERM STORAGE  â”‚    â”‚ LONG-TERM STORAGE                â”‚
â”‚                     â”‚    â”‚                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Redis (L0/L1)  â”‚  â”‚    â”‚ â”‚ Redis (L1, L2)               â”‚ â”‚
â”‚ â”‚ Session Cache  â”‚  â”‚    â”‚ â”‚ - Embedding cache            â”‚ â”‚
â”‚ â”‚ TTL: 24h       â”‚  â”‚    â”‚ â”‚ - Result cache               â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                     â”‚    â”‚                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ In-Memory (L0) â”‚  â”‚    â”‚ â”‚ PostgreSQL (L3)              â”‚ â”‚
â”‚ â”‚ @lru_cache     â”‚  â”‚    â”‚ â”‚ - Materialized Views         â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚ â”‚ - Metadata                   â”‚ â”‚
â”‚                     â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                                  â”‚
                           â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                           â”‚ â”‚ Mem0 OSS (L4)                â”‚ â”‚
                           â”‚ â”‚ - Milvus (vectors)           â”‚ â”‚
                           â”‚ â”‚ - Neo4j (graph)              â”‚ â”‚
                           â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.4 Má»¥c TiÃªu Hiá»‡u NÄƒng

| Metric | Target | Äáº¡t Ä‘Æ°á»£c |
|--------|--------|----------|
| **STM Latency (cached)** | < 5ms | âœ… |
| **LTM Latency (cached)** | < 50ms | âœ… |
| **Overall P95 Latency** | < 200ms | âœ… |
| **Cache Hit Rate** | 60-70% | âœ… |
| **System Uptime** | 99.9% | âœ… |
| **Cost vs Mem0 Enterprise** | 94% reduction | âœ… |

---

## 2. THIáº¾T Káº¾ Bá»˜ NHá»š NGáº®N Háº N (SHORT-TERM MEMORY)

### 2.1 Äá»‹nh NghÄ©a

**STM (Short-Term Memory)** lÃ  bá»™ nhá»› cá»§a má»™t phiÃªn há»™i thoáº¡i (session) hiá»‡n táº¡i, lÆ°u trá»¯ toÃ n bá»™ lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n giá»¯a User vÃ  PIKA AI Companion.

**Má»¥c Ä‘Ã­ch:**
- Cung cáº¥p ngá»¯ cáº£nh gáº§n nháº¥t (recent context) cho LLM
- Giá»¯ láº¡i chuá»—i há»™i thoáº¡i logic vÃ  máº¡ch láº¡c
- KhÃ´ng bá»‹ rÃ ng buá»™c bá»Ÿi giá»›i háº¡n token cá»§a LLM Ä‘Æ¡n láº»

### 2.2 Cáº¥u TrÃºc Dá»¯ Liá»‡u

```python
class Message(BaseModel):
    role: Literal["user", "assistant"]
    content: str
    timestamp: datetime
    tokens: int
    metadata: Dict[str, Any]

class ConversationTier(BaseModel):
    tier_name: Literal["active", "recent", "session"]
    messages: List[Message] = []
    summary: Optional[str] = None
    total_tokens: int = 0

class STMContext(BaseModel):
    session_id: str
    user_id: str
    active_window: ConversationTier       # Last 10 turns (full)
    recent_summary: ConversationTier      # Turns 11-50 (summarized)
    session_summary: ConversationTier     # Turns 51+ (compressed)
    total_turns: int = 0
    created_at: datetime
    last_updated: datetime
```

### 2.3 Kiáº¿n TrÃºc 3-Tier Compression

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     STM WITH HIERARCHICAL SUMMARIZATION                        â”‚
â”‚                                                                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚  TIER 1: Active Window (Last 10 turns)                   â”‚  â”‚
â”‚ â”‚  â€¢ Full conversation history                             â”‚  â”‚
â”‚ â”‚  â€¢ No compression                                         â”‚  â”‚
â”‚ â”‚  â€¢ Use: Current context                                  â”‚  â”‚
â”‚ â”‚  â€¢ Size: ~2,000 tokens                                   â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                        â†“ (every 10 turns)                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚  TIER 2: Recent Summary (Turns 11-50)                    â”‚  â”‚
â”‚ â”‚  â€¢ LLM-generated summary                                 â”‚  â”‚
â”‚ â”‚  â€¢ Key facts extracted                                   â”‚  â”‚
â”‚ â”‚  â€¢ Use: Medium-term context                              â”‚  â”‚
â”‚ â”‚  â€¢ Size: ~500 tokens (compressed from 8,000)            â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                        â†“ (every 50 turns)                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚  TIER 3: Session Summary (Turns 51+)                     â”‚  â”‚
â”‚ â”‚  â€¢ Ultra-compressed summary                              â”‚  â”‚
â”‚ â”‚  â€¢ Only critical facts                                   â”‚  â”‚
â”‚ â”‚  â€¢ Use: Long-term session context                        â”‚  â”‚
â”‚ â”‚  â€¢ Size: ~200 tokens (compressed from 40,000+)          â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                â”‚
â”‚  Final Context Sent to LLM:                                   â”‚
â”‚  = Tier 3 (200) + Tier 2 (500) + Tier 1 (2,000) = 2,700 tokens
â”‚  vs Original: 50,000 tokens â†’ 95% compression! ğŸ‰             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.4 Storage Strategy

| Layer | Tech | Latency | TTL | Purpose |
|-------|------|---------|-----|---------|
| **L0** | Python `@lru_cache` | < 1ms | Per-request | Session cache (in-memory) |
| **L1** | Redis | 5ms | 24 hours | Distributed session store |

### 2.5 Compression Algorithm

**Trigger:** Má»—i 10 turns
- Oldest 5 messages tá»« active window â†’ LLM summarize
- Náº¿u combined size > 2000 chars â†’ Merge vÃ o recent summary
- Keep last 10 messages full (khÃ´ng compress)

**Benefit:**
- 95% token reduction (50k â†’ 2.7k)
- 94% cost savings on API calls

### 2.6 API Endpoints

```
POST /api/v1/memory/search
â”œâ”€ Input: user_id, session_id, query
â””â”€ Output: STM results + metadata

POST /api/v1/stm/add_message
â”œâ”€ Input: session_id, role, content
â””â”€ Output: HTTP 200 (triggers compression if needed)
```

---

## 3. THIáº¾T Káº¾ Bá»˜ NHá»š DÃ€I Háº N (LONG-TERM MEMORY)

### 3.1 Äá»‹nh NghÄ©a

**LTM (Long-Term Memory)** lÃ  bá»™ nhá»› vÄ©nh viá»…n cá»§a user, lÆ°u trá»¯ cÃ¡c sá»± kiá»‡n, sá»Ÿ thÃ­ch, ká»¹ nÄƒng, vÃ  thÃ´ng tin cÃ¡ nhÃ¢n quan trá»ng Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« má»i cuá»™c há»™i thoáº¡i.

**Má»¥c Ä‘Ã­ch:**
- Ghi nhá»› cÃ¡c sá»± thÃ­ch / sá»Ÿ thÃ­ch dÃ i háº¡n
- XÃ¢y dá»±ng há»“ sÆ¡ user toÃ n diá»‡n
- GiÃºp PIKA hiá»ƒu user má»™t cÃ¡ch sÃ¢u sáº¯c

### 3.2 Cáº¥u TrÃºc Dá»¯ Liá»‡u

```python
class Fact(BaseModel):
    id: str
    user_id: str
    fact: str
    category: Literal["personal_info", "preference", "event", "skill"]
    confidence: float  # 0.0 - 1.0
    embedding: List[float]  # 1536-dim (OpenAI text-embedding-3-small)
    source: str  # "conversation", "user_input"
    metadata: Dict[str, Any]
    created_at: datetime
    updated_at: datetime
```

### 3.3 Chiáº¿n LÆ°á»£c Caching 5 Lá»›p (L0 â†’ L4)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    5-LAYER CACHE STRATEGY                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  L0: In-Memory (@lru_cache)                                 â”‚
â”‚  â”œâ”€ Latency: < 1ms                                          â”‚
â”‚  â”œâ”€ TTL: Per-request lifetime                               â”‚
â”‚  â”œâ”€ Size: ~100MB (per-instance)                             â”‚
â”‚  â””â”€ Hit Rate: 10-20%                                        â”‚
â”‚        â†“ (Miss)                                             â”‚
â”‚  L1: Redis - Embedding Cache                                â”‚
â”‚  â”œâ”€ Latency: 5ms                                            â”‚
â”‚  â”œâ”€ TTL: 1 hour                                             â”‚
â”‚  â”œâ”€ Size: 1GB (top 100K users)                              â”‚
â”‚  â”œâ”€ Key: embedding:{hash(query)}                            â”‚
â”‚  â””â”€ Hit Rate: 40-50%                                        â”‚
â”‚        â†“ (Miss)                                             â”‚
â”‚  L2: Redis - Result Cache                                   â”‚
â”‚  â”œâ”€ Latency: 5-20ms                                         â”‚
â”‚  â”œâ”€ TTL: 24 hours                                           â”‚
â”‚  â”œâ”€ Size: 5GB (hot queries)                                 â”‚
â”‚  â”œâ”€ Key: search:{user_id}:{version}:{hash(query)}           â”‚
â”‚  â””â”€ Hit Rate: 20-30%                                        â”‚
â”‚        â†“ (Miss)                                             â”‚
â”‚  L3: PostgreSQL - Materialized View                         â”‚
â”‚  â”œâ”€ Latency: 20-50ms                                        â”‚
â”‚  â”œâ”€ TTL: Long-lived (updated every 30 min)                 â”‚
â”‚  â”œâ”€ Size: 5GB (1M users Ã— 5KB summary)                      â”‚
â”‚  â”œâ”€ Query: user_favorite_summary, user_recent_activity      â”‚
â”‚  â””â”€ Hit Rate: 20-30% (for common queries)                   â”‚
â”‚        â†“ (Miss)                                             â”‚
â”‚  L4: Mem0 OSS (Source of Truth)                             â”‚
â”‚  â”œâ”€ Latency: 100-300ms                                      â”‚
â”‚  â”œâ”€ Storage: Milvus (vectors) + Neo4j (graph)              â”‚
â”‚  â””â”€ Hit Rate: N/A (fallback)                                â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.4 Cache Invalidation (Tag-Based)

```python
# Strategy: Increment version tag
# Cache Key: search:{user_id}:{version}:{hash(query)}

# On fact extraction complete:
redis.incr(f"user:version:{user_id}")  # Version 1 â†’ 2
# All old cache keys (v1) become stale automatically
# No need to manually delete keys!
```

**Benefit:**
- âœ… Simple (1 Redis operation per user)
- âœ… Scalable (works for 1M users)
- âœ… No memory leak (old keys auto-expire via TTL)

### 3.5 Proactive Cache Warming

**Khi:** Sau khi extraction xong
**LÃ m gÃ¬:**
1. Query L4 (Milvus) cho `user_favorite_summary`
2. Save vÃ o L3 (PostgreSQL Materialized View)
3. Warm L2 (Redis) vá»›i top results
4. Increment version tag â†’ Invalidate old L2 entries

**Result:**
- 99% hit rate cho "What do I like?" queries
- 50ms response time (vs 300ms without warming)

### 3.6 API Endpoints

```
POST /api/v1/memory/search
â”œâ”€ Input: user_id, session_id, query
â”œâ”€ Process: Parallel STM + LTM search
â””â”€ Output: Merged & ranked results

POST /api/v1/memory/extract
â”œâ”€ Input: user_id, session_id, conversation_history
â”œâ”€ Process: Async extraction job (202 Accepted)
â””â”€ Output: Job ID for polling

GET /api/v1/jobs/{job_id}/status
â”œâ”€ Input: job_id
â””â”€ Output: {status, progress, results, error}
```

### 3.7 Data Flow: Search (Read Path)

```
User Query: "What do I like?"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Memory Orchestrator (Parallel Execution)           â”‚
â”‚                                                          â”‚
â”‚  asyncio.gather([stm_search, ltm_search])               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STM Search (5ms)    â”‚    â”‚  LTM Search              â”‚
â”‚                      â”‚    â”‚  (5-300ms based cache)   â”‚
â”‚  L0 (in-mem)         â”‚    â”‚                          â”‚
â”‚    â†“ MISS            â”‚    â”‚  L0 (in-mem)             â”‚
â”‚  L1 (Redis)          â”‚    â”‚    â†“ MISS                â”‚
â”‚    â†“ HIT âœ…          â”‚    â”‚  L1 (embedding)          â”‚
â”‚                      â”‚    â”‚    â†“ HIT âœ…              â”‚
â”‚  STM Results:        â”‚    â”‚  L2 (result cache)       â”‚
â”‚  [{fact: "recent"}]  â”‚    â”‚    â†“ HIT âœ…              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                          â”‚
                             â”‚  LTM Results:           â”‚
                             â”‚  [{fact: "preference"}] â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                              â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Merge & Rank (Dedup, Recency, Confidence)           â”‚
    â”‚                                                      â”‚
    â”‚  1. Deduplicate by fact text (lowercase)            â”‚
    â”‚  2. Boost if in both STM + LTM (+0.15)              â”‚
    â”‚  3. STM recency bonus (+0.1)                        â”‚
    â”‚  4. Sort by final_score DESC                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
    Final Results (Total Latency: ~20-50ms)
```

---

## 4. LUá»’NG Dá»® LIá»†U (DATA FLOW)

### 4.1 Write Path: Extract & Save

```
Conversation End
    â†“
Context Handling Module â†’ extraction_results
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     STEP 1: API Gateway receives extract request         â”‚
â”‚     POST /api/v1/memory/extract                          â”‚
â”‚     â””â”€ Create Job in PostgreSQL                          â”‚
â”‚     â””â”€ Return 202 Accepted with job_id                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     STEP 2: Async Processing (Background Worker)         â”‚
â”‚     â”œâ”€ Job Status: pending â†’ processing                  â”‚
â”‚     â”œâ”€ Call LLM (GPT-4o-mini) to extract facts           â”‚
â”‚     â”œâ”€ Generate embeddings (OpenAI API)                  â”‚
â”‚     â””â”€ Validate extraction quality                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     STEP 3: Save to L4 (Primary Storage)                 â”‚
â”‚     â”œâ”€ Mem0 SDK: Memory.add(facts)                       â”‚
â”‚     â”‚   â”œâ”€ Milvus: Store embeddings + vectors            â”‚
â”‚     â”‚   â””â”€ Neo4j: Store entities + relationships         â”‚
â”‚     â””â”€ PostgreSQL: Update job status â†’ completed         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     STEP 4: Proactive Cache Warming (Async)              â”‚
â”‚     â”œâ”€ Query L4: user_favorite_summary                   â”‚
â”‚     â”œâ”€ Save to L3: PostgreSQL Materialized View          â”‚
â”‚     â”œâ”€ Warm L2: Redis result cache                       â”‚
â”‚     â””â”€ Increment version tag (L2 invalidation)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Done! Cache is warm for next queries
```

### 4.2 Read Path: Search (Detailed)

```
User Query: "What do I like?"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     STEP 1: API Gateway validation                       â”‚
â”‚     â”œâ”€ Parse request body                                â”‚
â”‚     â”œâ”€ Validate user_id, session_id, query               â”‚
â”‚     â””â”€ Check rate limiting                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     STEP 2: Memory Orchestrator (Parallel)               â”‚
â”‚     â”œâ”€ Launch STM search (async)                         â”‚
â”‚     â”œâ”€ Launch LTM search (async)                         â”‚
â”‚     â””â”€ Wait for both with timeout (300ms)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ (Both run in parallel)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STM SERVICE        â”‚    â”‚ LTM SERVICE                   â”‚
â”‚                    â”‚    â”‚                               â”‚
â”‚ 1. Check L0        â”‚    â”‚ 1. Check L0                   â”‚
â”‚    â†“ MISS          â”‚    â”‚    â†“ MISS                     â”‚
â”‚ 2. Check L1        â”‚    â”‚ 2. Check L1 (embedding)       â”‚
â”‚    â†“ HIT âœ…        â”‚    â”‚    â†“ HIT âœ…                   â”‚
â”‚ 3. Deserialize     â”‚    â”‚    â†“ Deserialize              â”‚
â”‚ 4. Return results  â”‚    â”‚ 3. Check L2 (result cache)    â”‚
â”‚    (5-10ms)        â”‚    â”‚    â†“ MISS                     â”‚
â”‚                    â”‚    â”‚ 4. Query L3 (PostgreSQL)      â”‚
â”‚                    â”‚    â”‚    â†“ HIT (Materialized View)  â”‚
â”‚                    â”‚    â”‚ 5. Warm L2 (async)            â”‚
â”‚                    â”‚    â”‚ 6. Return results (50ms)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                              â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     STEP 3: Merge & Rank                                 â”‚
â”‚     â”œâ”€ Deduplicate by semantic similarity (0.95+)        â”‚
â”‚     â”œâ”€ Normalize scores (0-1)                            â”‚
â”‚     â”œâ”€ Apply weights: STM Ã— 1.2, LTM Ã— 1.0               â”‚
â”‚     â”œâ”€ Apply time decay: 5% per day for LTM              â”‚
â”‚     â””â”€ Sort by final_score DESC                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     STEP 4: Response formatting                          â”‚
â”‚     â”œâ”€ Filter top-K results (default: 10)                â”‚
â”‚     â”œâ”€ Include metadata & sources                        â”‚
â”‚     â””â”€ Return 200 OK with timing stats                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Response (Total Latency: ~20-50ms with good cache)
```

---

## 5. CÃC QUYáº¾T Äá»ŠNH THIáº¾T Káº¾ CHÃNH

### 5.1 Parallel STM + LTM vs Sequential

| TiÃªu chÃ­ | Parallel | Sequential |
|----------|----------|-----------|
| **Latency** | max(STM, LTM) = 50ms | STM + LTM = 350ms |
| **Complexity** | Merge logic phá»©c táº¡p | Simple |
| **Verdict** | âœ… **CHOSEN** - Latency critical |  |

### 5.2 Separate Services vs Monolithic

| TiÃªu chÃ­ | Separate | Monolithic |
|----------|----------|-----------|
| **Scalability** | âœ… Scale Ä‘á»™c láº­p | âŒ Scale cÃ¹ng lÃºc |
| **Latency** | âœ… Parallel queries | âŒ Sequential calls |
| **Complexity** | âŒ More code | âœ… Simple |
| **Verdict** | âœ… **CHOSEN** - Performance > Simplicity |  |

### 5.3 3-Tier STM Compression vs 2-Tier

| TiÃªu chÃ­ | 3-Tier | 2-Tier |
|----------|--------|--------|
| **Compression** | 95% (50k â†’ 2.7k tokens) | 85% (50k â†’ 7.5k tokens) |
| **Complexity** | Complex logic | Simple |
| **Cost Savings** | 94% | 85% |
| **Verdict** | âœ… **CHOSEN** - Cost optimization |  |

### 5.4 L3 Materialized View vs Redis-Only

| TiÃªu chÃ­ | With L3 | Without L3 |
|----------|---------|-----------|
| **Cost** | $316/month | $1,070/month |
| **Warming Speed** | 5 hours | 83 hours |
| **Complexity** | Medium (sync L3 â†” L2) | Simple |
| **Verdict** | âœ… **CHOSEN** - 70% cost reduction |  |

### 5.5 Tag-Based Invalidation vs Explicit Delete

| TiÃªu chÃ­ | Tag-Based | Explicit Delete |
|----------|-----------|-----------------|
| **Simplicity** | âœ… One Redis operation | âŒ KEYS command |
| **Scalability** | âœ… Works for 1M users | âŒ Slow on large datasets |
| **Memory** | âœ… Auto-expire via TTL | âŒ Potential leak |
| **Verdict** | âœ… **CHOSEN** - Scalable & simple |  |

---

## 6. PERFORMANCE TARGETS

### 6.1 Latency SLA

| Component | P50 | P95 | P99 |
|-----------|-----|-----|-----|
| **STM (cached)** | 3ms | 5ms | 8ms |
| **LTM (L1 hit)** | 10ms | 20ms | 50ms |
| **LTM (L3 hit)** | 30ms | 50ms | 100ms |
| **LTM (L4)** | 150ms | 300ms | 500ms |
| **Merge & Rank** | 5ms | 10ms | 20ms |
| **Total (best case)** | 15ms | 50ms | 100ms |
| **Total (worst case)** | 200ms | 350ms | 600ms |

### 6.2 Throughput Targets

| Metric | Target | Strategy |
|--------|--------|----------|
| **Read QPS** | 1,000 | Horizontal scaling (load balanced) |
| **Write QPS** | 100 | Message queue (RabbitMQ) buffering |
| **Cache Hit Rate** | 60-70% | 5-layer caching + proactive warming |

### 6.3 Cost Targets (vs Mem0 Enterprise)

| Component | Enterprise | Self-Hosted | Savings |
|-----------|-----------|-------------|---------|
| **Memory (Redis)** | $600/month | $146/month | 76% â†“ |
| **Database (L3)** | Included | $70/month | - |
| **Vector DB** | Included | $100/month | - |
| **Total** | $600/month | $316/month | 47% â†“ |
| **With optimization** | - | $200/month | 67% â†“ |

---

## 7. DEPLOYMENT STRATEGY

### 7.1 Infrastructure

```
Primary Region: ap-southeast-1 (Singapore)
â”œâ”€ EKS Cluster (3 Availability Zones)
â”œâ”€ API Pod replicas: 3 (min) â†’ 10 (max) with HPA
â”œâ”€ Worker Pod replicas: 2 (min) â†’ 5 (max)
â”œâ”€ Redis Cluster (Sentinel for HA)
â”œâ”€ PostgreSQL (Primary + Read Replica)
â””â”€ Milvus + Neo4j (Self-hosted in Kubernetes)

Secondary Region: eu-central-1 (Frankfurt)
â”œâ”€ Standby EKS Cluster (for GDPR compliance)
â””â”€ Can activate within 5 minutes
```

### 7.2 CI/CD Pipeline

```
Code Push â†’ GitHub
    â†“
GitHub Actions
â”œâ”€ Run tests (unit + integration)
â”œâ”€ Build Docker image
â”œâ”€ Push to ECR
â””â”€ Deploy to EKS (with Helm)
    â†“
Canary Deployment (10% traffic)
    â†“
Monitor metrics (latency, error rate)
    â†“
Full Rollout (100% traffic)
```

---

## 8. MONITORING & OBSERVABILITY

### 8.1 Key Metrics

```
API Metrics:
â”œâ”€ http_requests_total (counter)
â”œâ”€ http_request_duration_seconds (histogram)
â”œâ”€ http_response_size_bytes (histogram)
â””â”€ http_requests_in_progress (gauge)

Business Metrics:
â”œâ”€ search_facts_requests_total
â”œâ”€ extract_facts_requests_total
â”œâ”€ facts_extracted_total
â””â”€ cache_hit_rate (by layer)

System Metrics:
â”œâ”€ milvus_query_latency_ms (histogram)
â”œâ”€ neo4j_query_latency_ms (histogram)
â”œâ”€ postgres_query_latency_ms (histogram)
â”œâ”€ redis_operation_latency_ms (histogram)
â””â”€ job_processing_duration_seconds
```

### 8.2 Dashboards

- **Overview Dashboard:** System health, throughput, error rate
- **Performance Dashboard:** Latency percentiles, cache hit rate
- **Reliability Dashboard:** Uptime, error rate by endpoint
- **Cost Dashboard:** Infrastructure cost, cost per query

---

## 9. NEXT STEPS

### Phase 1: Foundation (Week 1-2)
- âœ… STM Service implementation
- âœ… LTM Service with L0-L2 caching
- âœ… Memory Orchestrator
- âœ… API Gateway & basic endpoints

### Phase 2: Advanced Caching (Week 3-4)
- âœ… L3 Materialized View (PostgreSQL)
- âœ… Proactive Cache Warming Worker
- âœ… Tag-based cache invalidation

### Phase 3: Production Hardening (Week 5-6)
- âœ… Error handling & fallbacks
- âœ… Monitoring & alerting setup
- âœ… Load testing & optimization

### Phase 4: Launch (Week 7-8)
- âœ… Canary deployment
- âœ… Full production rollout
- âœ… Documentation & runbooks

---

## 10. REFERENSI

- [Mem0 Documentation](https://docs.mem0.ai/)
- [Milvus Vector Database](https://milvus.io/)
- [Redis Architecture](https://redis.io/docs/about/)
- [FastAPI Best Practices](https://fastapi.tiangolo.com/)
- [Kubernetes Production Patterns](https://kubernetes.io/)

---

**End of Document**

---

*TÃ i liá»‡u nÃ y Ä‘Æ°á»£c cáº­p nháº­t láº§n cuá»‘i vÃ o ngÃ y 2025-12-22. Äá»ƒ bÃ¡o cÃ¡o cÃ¡c thay Ä‘á»•i hoáº·c Ä‘á» xuáº¥t cáº£i tiáº¿n, vui lÃ²ng liÃªn há»‡ vá»›i Manus AI.*
