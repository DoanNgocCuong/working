

# PHáº¦N A: Latency Optimization Research Summary

1. Milvus Vector Search Optimization Techniques

Indexing Strategies

- HNSW (Hierarchical Navigable Small World): Logarithmic search complexity, ideal for low-latency scenarios
- IVF (Inverted File Index): Partitions dataset into clusters, reduces search space
- Product Quantization (PQ): Compresses vectors into smaller codes, 4x memory reduction while maintaining accuracy
- CAGRA (GPU-accelerated): 50x performance improvement vs CPU-only

Hardware Optimization

- GPU Acceleration: Reduces query times from milliseconds to microseconds
- SIMD Instructions: AVX-512 can process 16 float32 values in parallel
- In-memory Storage: Avoid disk I/O delays
- CPU/GPU Collaborative Filtering: Hybrid approach for billion-scale search

Parameter Tuning

- HNSW Parameters:
    - M=32 (default)
    - efConstruction=200
    - efSearch: 64-256 (tune based on P95 latency and recall)
- IVF Parameters:
    - nprobe: Number of clusters to scan (balance between speed and accuracy)

2. Semantic Caching Techniques (Redis LangCache)

10 Optimization Techniques

1. Remove semantic noise: Filter common/boilerplate phrases
2. Domain-specific embeddings: Fine-tune models for your domain
3. Summarization: Use small LLM to distill long contexts
4. Similarity threshold tuning: Start high (0.88), lower gradually
5. LLM-based reranking: Validate and reorder top candidates
6. Metadata filtering: Add custom attributes for context-aware retrieval
7. Adaptive TTLs: Dynamic expiration based on data volatility
8. Smart eviction: LRU/LFU policies with per-entry TTLs
9. Pre-warming: Preload common queries
10. Continuous observability: Monitor cache hit rates, latency

Cache Hit Rate Impact

- Cost reduction: Up to 86% reduction in LLM inference costs
- Latency improvement: Up to 70% reduction
- Throughput stabilization: More consistent response times

3. Multi-Layer Caching Strategy

Layer Architecture

- L1 (In-memory): Application-level cache for hot data
- L2 (Distributed): Redis/Memcached for shared cache
- L3 (Persistent): Database-level caching

Performance Gains

- Hybrid caching with Redis can improve inference speeds by up to 4x
- Multi-layer approach handles varying workloads elastically

4. Query Optimization Techniques

Batch Processing

- Combine multiple queries into single batch
- Trade-off: Individual request speed vs overall system efficiency
- Beneficial for high-throughput scenarios

Pre-computation

- Pre-compute and cache results for common queries
- Dramatically speeds up pipeline
- Anticipate future queries based on usage patterns

Hybrid Search

- Combine vector search with keyword/BM25 search
- Re-ranking layer for precision improvement
- OpenSearch 3.1: 3.8x faster hybrid query throughput

5. Vector Database Benchmarks

Sub-second Performance Targets

- P50 latency: <50ms
- P95 latency: <100-200ms (achievable with optimization)
- P99 latency: <300ms (with proper tuning)

Achievable with Current Tech

- HNSW: Single-digit millisecond latency at millions of vectors
- Sub-30ms P95 at millions of vectors
- Qdrant/Pgvector: Sub-100ms P95/P99 at 99% recall

6. Pika's Current SDD Assessment

Latency Targets in SDD

- P95 latency: <200ms (stated in SDD)
- Load test targets: P95 <200ms, sustained 200 rps

Gap Analysis

- Extract Facts API:
    - LLM call: ~500-1000ms (OpenAI)
    - Embedding generation: ~100-200ms
    - Milvus storage: ~50-100ms
    - Neo4j relationships: ~50-100ms
    - PostgreSQL metadata: ~50-100ms
    - Total: ~800-1500ms (NOT meeting <1s target for P95)
- Search Facts API:
    - Query embedding: ~100-200ms
    - Milvus search: ~50-100ms (with optimization)
    - Redis cache check: <10ms
    - Neo4j enrichment: ~50-100ms
    - Redis cache write: <10ms
    - Total: ~250-420ms (CAN meet <1s target, but P99 might exceed)

7. Critical Gaps in Current SDD

8. No mention of semantic caching strategy
9. No GPU acceleration plan for Milvus
10. No pre-computation/pre-warming strategy
11. No batch processing optimization
12. No query decomposition or hybrid search
13. Limited discussion on embedding model selection
14. No adaptive TTL/eviction policy details
15. Insufficient latency breakdown analysis
16. No fallback/degradation strategies
17. Missing P99 latency targets (only P95 mentioned)

18. Recommended Additions to SDD

For Extract Facts API

- Implement async job processing with 202 Accepted response
- Use RabbitMQ for async fact extraction
- Add LLM caching layer to reduce repeated extractions
- Implement batch processing for multiple conversations

For Search Facts API

- Add semantic caching layer (Redis LangCache)
- Implement GPU-accelerated Milvus search
- Add query pre-computation for common searches
- Implement hybrid search (vector + keyword)
- Add LLM-based reranking layer
- Implement adaptive TTLs based on query patterns

Infrastructure Improvements

- Enable GPU acceleration on Milvus (CAGRA)
- Optimize Milvus index parameters (HNSW tuning)
- Add Redis semantic cache layer
- Implement multi-layer caching (L1, L2, L3)
- Add query decomposition service
- Implement pre-warming strategy

Monitoring & Observability

- Track P50, P95, P99 latencies separately
- Monitor cache hit rates
- Track embedding quality metrics
- Monitor GPU utilization
- Set up alerts for latency SLA breaches
# PHáº¦N B: MECE Analysis: Caching & Optimization Solutions for Pika Memory System

## Executive Summary

Pika's current SDD targets P95 latency of <200ms for search operations and does not explicitly address P99 latency requirements. The extract_facts API is designed as synchronous, which creates a bottleneck for long-running LLM operations (500-1000ms). To achieve the desired <1s P95/P99 latency targets for both APIs, a comprehensive multi-layered optimization strategy is required.

This analysis provides a MECE (Mutually Exclusive, Collectively Exhaustive) breakdown of all viable caching and optimization solutions currently used by world-class AI systems.

---

## Part 1: Latency Breakdown Analysis

### Current Architecture Latency (SDD Design)

#### Extract Facts API (Synchronous)
- OpenAI LLM call: 500-1000ms (dominant factor)
- Embedding generation: 100-200ms
- Milvus vector storage: 50-100ms
- Neo4j relationship creation: 50-100ms
- PostgreSQL metadata save: 50-100ms
- **Total: 750-1500ms** âŒ EXCEEDS <1s target

#### Search Facts API (Current SDD)
- Redis cache check: <10ms
- Query embedding: 100-200ms
- Milvus similarity search: 50-100ms (without optimization)
- Neo4j relationship enrichment: 50-100ms
- Redis cache write: <10ms
- **Total: 250-420ms** âœ… MEETS <1s target (but P99 at risk)

### Critical Issues
1. **Extract Facts is synchronous**: LLM latency (500-1000ms) dominates, making it impossible to meet <1s P99 target
2. **Search Facts lacks semantic caching**: No hit rate optimization for repeated queries
3. **No GPU acceleration**: Milvus search could be 10-50x faster with GPU
4. **No query pre-computation**: Common searches not pre-warmed
5. **Single-layer caching**: Only Redis, no L1 in-memory or L3 persistent caching

---

## Part 2: MECE Breakdown of Caching Solutions

### Category 1: Caching Layers (By Storage Location)

#### 1.1 L1: In-Memory Application Cache
**Characteristics**: Fastest, single-process, volatile
- **Technique**: Local Python dict/cache with TTL
- **Hit latency**: <1ms
- **Capacity**: Limited by single process memory (~100MB-1GB)
- **Use case**: Extremely hot queries (top 1-5%)
- **Trade-off**: No cross-process sharing, data loss on restart

**Implementation for Pika**:
```python
# Application-level cache for top queries
@lru_cache(maxsize=1000)
def cached_search(query_hash: str) -> List[Fact]:
    pass
```

#### 1.2 L2: Distributed Cache (Redis/Memcached)
**Characteristics**: Fast, shared across processes, persistent
- **Technique**: Redis with semantic caching
- **Hit latency**: 5-20ms
- **Capacity**: Limited by Redis memory (typically 10-100GB)
- **Use case**: Hot queries across all users
- **Trade-off**: Network latency, requires serialization

**Implementation for Pika**:
```python
# Redis semantic cache
cache_key = f"search:{user_id}:{query_hash}:{limit}"
cached_result = await redis.get(cache_key)
if cached_result:
    return cached_result  # 5-20ms latency
```

#### 1.3 L3: Persistent Cache (Database)
**Characteristics**: Slow, durable, unlimited capacity
- **Technique**: PostgreSQL materialized views or query result tables
- **Hit latency**: 50-200ms
- **Capacity**: Unlimited (disk-based)
- **Use case**: Historical queries, audit trail
- **Trade-off**: Slower than L2, requires cache invalidation strategy

**Implementation for Pika**:
```sql
-- Materialized view for common searches
CREATE MATERIALIZED VIEW popular_searches AS
SELECT user_id, query, results, created_at
FROM query_cache
WHERE created_at > NOW() - INTERVAL '7 days'
AND hit_count > 10;
```

---

### Category 2: Semantic Caching Strategies (By Query Matching)

#### 2.1 Exact Match Caching
**Characteristics**: Simple, high precision, low recall
- **Hit rate**: 5-15% for typical workloads
- **Latency**: <10ms on hit
- **Implementation**: Hash-based lookup
- **Use case**: Identical repeated queries
- **Trade-off**: Misses paraphrased queries

**Example**: Query "ThÃº cÆ°ng" exactly matches previous query â†’ cache hit

#### 2.2 Semantic Similarity Caching
**Characteristics**: Complex, moderate precision, higher recall
- **Hit rate**: 30-60% for typical workloads
- **Latency**: 20-50ms on hit (embedding + similarity search)
- **Implementation**: Vector similarity with threshold tuning
- **Use case**: Paraphrased queries with same intent
- **Trade-off**: Requires embedding model, similarity threshold tuning

**Example**: Query "ThÃº cÆ°ng mÃ  user thÃ­ch" matches cached "Sá»Ÿ thÃ­ch vá» thÃº cÆ°ng" â†’ semantic hit

#### 2.3 Hybrid Caching (Exact + Semantic)
**Characteristics**: Balanced, best of both worlds
- **Hit rate**: 40-70% for typical workloads
- **Latency**: <10ms (exact) or 20-50ms (semantic)
- **Implementation**: Try exact first, fallback to semantic
- **Use case**: Production systems requiring high hit rates
- **Trade-off**: More complex implementation

**Implementation for Pika**:
```python
# Hybrid caching strategy
cache_key_exact = hash(query)
result = await redis.get(cache_key_exact)  # Try exact match
if not result:
    query_vector = await embed(query)
    similar_queries = await milvus.search_similar(query_vector)
    if similar_queries:
        result = await redis.get(similar_queries[0].cache_key)  # Semantic match
```

---

### Category 3: Cache Invalidation Strategies (By Freshness Policy)

#### 3.1 Time-Based Invalidation (TTL)
**Characteristics**: Simple, predictable, may serve stale data
- **TTL range**: 5 minutes to 7 days
- **Staleness risk**: Medium
- **Implementation complexity**: Low
- **Use case**: Stable data (facts don't change frequently)

**For Pika**: 5-minute TTL for search results, 24-hour TTL for facts

#### 3.2 Event-Based Invalidation
**Characteristics**: Precise, complex, requires event infrastructure
- **Staleness risk**: Low
- **Implementation complexity**: High
- **Use case**: Data changes frequently, need immediate consistency
- **Trade-off**: Requires pub/sub system (Redis Streams, RabbitMQ)

**For Pika**: Invalidate search cache when new facts extracted for user

#### 3.3 Adaptive TTL (Hybrid)
**Characteristics**: Balanced, learns from usage patterns
- **Staleness risk**: Low
- **Implementation complexity**: Medium-High
- **Use case**: Production systems with varying data volatility
- **Trade-off**: Requires ML/heuristics

**For Pika**: 
- Frequently accessed facts: 24-hour TTL
- Rarely accessed facts: 1-hour TTL
- Recently extracted facts: 5-minute TTL

#### 3.4 LRU/LFU Eviction (Capacity-Based)
**Characteristics**: Automatic, memory-efficient
- **Eviction policy**: Least Recently/Frequently Used
- **Implementation complexity**: Medium
- **Use case**: Fixed cache size, need to maximize hit rate
- **Trade-off**: May evict important data

**For Pika**: Redis LRU with 10GB memory limit

---

### Category 4: Query Optimization (By Processing Approach)

#### 4.1 Pre-Computation (Offline)
**Characteristics**: Fastest, requires prediction, one-time cost
- **Latency on hit**: <1ms (lookup only)
- **Preparation time**: Hours/days offline
- **Use case**: Known, predictable queries
- **Trade-off**: Requires accurate prediction of user queries

**For Pika**:
```python
# Pre-compute results for top 100 queries
top_queries = [
    "Sá»Ÿ thÃ­ch cá»§a tÃ´i",
    "Gia Ä‘Ã¬nh cá»§a tÃ´i",
    "TrÆ°á»ng há»c cá»§a tÃ´i",
    # ... 97 more
]
for query in top_queries:
    result = await search_facts(query)
    await redis.set(f"precomputed:{query}", result, ttl=86400)
```

#### 4.2 Batch Processing (Async)
**Characteristics**: Moderate latency, high throughput
- **Latency**: 100-500ms (depends on batch size)
- **Throughput**: 10-100x higher than single queries
- **Use case**: Non-real-time workloads, bulk operations
- **Trade-off**: Requires async infrastructure (RabbitMQ)

**For Pika**: Batch extract_facts for multiple conversations

#### 4.3 Query Decomposition
**Characteristics**: Complex, improves cache hit rate
- **Hit rate improvement**: 20-40%
- **Implementation complexity**: High
- **Use case**: Complex queries that can be split
- **Trade-off**: Requires NLP/LLM to decompose

**Example**: "ThÃº cÆ°ng mÃ  user thÃ­ch vÃ  gia Ä‘Ã¬nh cá»§a user" â†’ Split into:
1. "ThÃº cÆ°ng mÃ  user thÃ­ch" (cached)
2. "Gia Ä‘Ã¬nh cá»§a user" (cached)
3. Merge results

#### 4.4 Approximate/Degraded Responses
**Characteristics**: Fastest, reduced accuracy
- **Latency**: 10-50ms
- **Accuracy**: 70-90%
- **Use case**: When exact answer not available
- **Trade-off**: User experience impact

**For Pika**: Return top-3 results from cache even if P99 latency exceeded

---

### Category 5: Hardware Acceleration (By Compute Resource)

#### 5.1 GPU Acceleration (Milvus CAGRA)
**Characteristics**: Dramatic speedup, capital cost
- **Speedup**: 10-50x faster vector search
- **Latency**: 5-20ms (vs 50-100ms CPU)
- **Cost**: $500-5000/month for GPU instance
- **Use case**: High-throughput search workloads
- **Trade-off**: Requires GPU hardware, power consumption

**For Pika**: Deploy GPU-accelerated Milvus for search_facts

#### 5.2 CPU Optimization (SIMD, Multi-core)
**Characteristics**: Moderate speedup, no capital cost
- **Speedup**: 2-4x faster
- **Implementation**: Use SIMD instructions (AVX-512)
- **Cost**: No additional cost
- **Use case**: CPU-only environments
- **Trade-off**: Limited speedup vs GPU

#### 5.3 Network Optimization (Locality)
**Characteristics**: Reduces network latency
- **Speedup**: 2-5x faster
- **Implementation**: Co-locate services (same datacenter)
- **Use case**: Distributed systems
- **Trade-off**: Requires infrastructure changes

---

### Category 6: LLM Optimization (For Extract Facts)

#### 6.1 Synchronous LLM Calls (Current SDD)
**Characteristics**: Simple, blocks response
- **Latency**: 500-1000ms per call
- **Throughput**: Limited by LLM API rate limits
- **Use case**: Low-volume workloads
- **Trade-off**: Cannot meet <1s target for P99

#### 6.2 Asynchronous LLM Calls (202 Accepted)
**Characteristics**: Non-blocking, returns immediately
- **API response latency**: <100ms (202 Accepted)
- **Processing latency**: 500-1000ms (async)
- **Throughput**: 10-100x higher
- **Use case**: Production systems, high-volume workloads
- **Trade-off**: Requires polling/webhook for results

**Implementation for Pika**:
```python
# Extract facts API returns 202 Accepted immediately
@app.post("/v1/extract_facts")
async def extract_facts(request: ExtractFactsRequest):
    job_id = str(uuid.uuid4())
    # Push to RabbitMQ queue
    await rabbitmq.publish("extract_facts_queue", {
        "job_id": job_id,
        "user_id": request.user_id,
        "conversation": request.conversation
    })
    # Return immediately
    return {
        "status": "accepted",
        "job_id": job_id,
        "status_url": f"/v1/extract_facts/{job_id}/status"
    }

# Client polls for results
@app.get("/v1/extract_facts/{job_id}/status")
async def get_extract_status(job_id: str):
    result = await postgres.get_job_result(job_id)
    if result.status == "completed":
        return {
            "status": "completed",
            "data": result.data
        }
    elif result.status == "processing":
        return {
            "status": "processing",
            "progress": result.progress
        }
```

#### 6.3 LLM Result Caching
**Characteristics**: Reduces repeated LLM calls
- **Hit rate**: 10-30% for typical conversations
- **Savings**: $0.01-0.10 per hit (OpenAI API cost)
- **Implementation**: Cache LLM responses by conversation hash
- **Use case**: Repeated conversations or similar patterns
- **Trade-off**: Requires cache invalidation strategy

#### 6.4 Smaller/Faster LLM Models
**Characteristics**: Faster, less accurate
- **Latency**: 100-300ms (vs 500-1000ms for GPT-4)
- **Cost**: $0.001-0.005 per call (vs $0.01-0.03)
- **Accuracy**: 70-85% (vs 90%+ for GPT-4)
- **Use case**: When speed matters more than accuracy
- **Trade-off**: Reduced quality

**For Pika**: Use GPT-4o-mini (current) or gpt-3.5-turbo for faster extraction

---

## Part 3: MECE Breakdown by API Endpoint

### Extract Facts API Optimization Strategy

#### Current State (SDD)
- **Design**: Synchronous
- **Latency**: 750-1500ms (FAILS <1s target)
- **Bottleneck**: OpenAI LLM call (500-1000ms)

#### Recommended Solution: Async + Caching

| Component | Current | Optimized | Latency Reduction |
|-----------|---------|-----------|-------------------|
| API Response | Sync (750-1500ms) | 202 Accepted (<100ms) | 87-93% |
| LLM Caching | None | Semantic cache (Redis) | 50-70% hit rate |
| Embedding | Sequential | Batch + GPU | 30-50% |
| Storage | Sequential | Parallel (Milvus + Neo4j + PG) | 20-30% |
| **Total P95** | **~1200ms** | **~150-200ms** | **85-90%** |

#### Implementation Roadmap
1. **Phase 1**: Add 202 Accepted response + RabbitMQ queue
2. **Phase 2**: Add semantic LLM result caching
3. **Phase 3**: Implement batch embedding + GPU acceleration
4. **Phase 4**: Parallel storage operations

---

### Search Facts API Optimization Strategy

#### Current State (SDD)
- **Design**: Synchronous with Redis cache
- **Latency**: 250-420ms (MEETS <1s target, but P99 at risk)
- **Bottleneck**: Query embedding (100-200ms)

#### Recommended Solution: Multi-Layer Caching + GPU

| Component | Current | Optimized | Latency Reduction |
|-----------|---------|-----------|-------------------|
| Cache Check (L1) | None | In-memory LRU | 90% hit rate |
| Cache Check (L2) | Redis | Redis semantic cache | 40-60% hit rate |
| Query Embedding | CPU (100-200ms) | GPU (5-10ms) | 90-95% |
| Milvus Search | CPU (50-100ms) | GPU CAGRA (5-20ms) | 75-90% |
| Neo4j Enrichment | Sequential (50-100ms) | Cached (5-10ms) | 80-90% |
| **Total P95** | **~250ms** | **~30-50ms** | **80-90%** |
| **Total P99** | **~400ms** | **~50-80ms** | **80-90%** |

#### Implementation Roadmap
1. **Phase 1**: Add L1 in-memory cache (LRU)
2. **Phase 2**: Upgrade to semantic caching (similarity threshold tuning)
3. **Phase 3**: GPU acceleration for Milvus (CAGRA)
4. **Phase 4**: Pre-computation of top 100 queries

---

## Part 4: Complete MECE Matrix

### All Possible Optimization Combinations

```
EXTRACT FACTS API OPTIMIZATION MATRIX
=====================================

Async Strategy:
â”œâ”€ Synchronous (Current SDD) âŒ
â”œâ”€ 202 Accepted + RabbitMQ âœ…
â””â”€ Webhook callbacks

LLM Optimization:
â”œâ”€ No caching (Current)
â”œâ”€ Semantic LLM cache âœ…
â”œâ”€ Smaller models (gpt-3.5)
â””â”€ Local LLM (Llama 2)

Embedding Strategy:
â”œâ”€ Sequential (Current)
â”œâ”€ Batch processing âœ…
â”œâ”€ GPU acceleration âœ…
â””â”€ Local embeddings

Storage Strategy:
â”œâ”€ Sequential writes (Current)
â”œâ”€ Parallel writes âœ…
â””â”€ Async writes + queue

---

SEARCH FACTS API OPTIMIZATION MATRIX
====================================

Caching Layers:
â”œâ”€ Single layer (Current Redis)
â”œâ”€ L1 + L2 (In-memory + Redis) âœ…
â”œâ”€ L1 + L2 + L3 (Full stack) âœ…
â””â”€ No caching

Query Matching:
â”œâ”€ Exact match only
â”œâ”€ Semantic similarity âœ…
â”œâ”€ Hybrid (Exact + Semantic) âœ…
â””â”€ Query decomposition

Hardware:
â”œâ”€ CPU only (Current)
â”œâ”€ GPU acceleration âœ…
â”œâ”€ CPU + GPU hybrid
â””â”€ TPU (not available)

Pre-computation:
â”œâ”€ None (Current)
â”œâ”€ Top 100 queries âœ…
â”œâ”€ Top 1000 queries
â””â”€ Predictive pre-warming

Cache Invalidation:
â”œâ”€ TTL-based âœ…
â”œâ”€ Event-based
â”œâ”€ Adaptive TTL âœ…
â””â”€ LRU/LFU eviction âœ…
```

---

## Part 5: Recommended Architecture (Best Practices)

### Extract Facts API (Async Pattern)

```
Client Request
    â†“
FastAPI Endpoint (extract_facts)
    â†“
Validation + Request ID generation
    â†“
Push to RabbitMQ queue
    â†“
Return 202 Accepted immediately (<100ms) âœ…
    â†“
[Async Worker Process]
    â”œâ”€ Check LLM cache (Redis)
    â”œâ”€ If miss: Call OpenAI (500-1000ms)
    â”œâ”€ Cache LLM result (5-minute TTL)
    â”œâ”€ Generate embeddings (batch)
    â”œâ”€ Store in Milvus (parallel)
    â”œâ”€ Create Neo4j relationships (parallel)
    â”œâ”€ Save PostgreSQL metadata (parallel)
    â””â”€ Store job result (status = completed)
    â†“
Client polls /status endpoint
    â”œâ”€ If processing: Return 200 + progress
    â””â”€ If completed: Return 200 + results
```

### Search Facts API (Multi-Layer Caching)

```
Client Request
    â†“
FastAPI Endpoint (search_facts)
    â†“
Check L1 Cache (In-memory LRU) â†’ Hit? Return (<1ms) âœ…
    â†“
Check L2 Cache (Redis) â†’ Hit? Return (<20ms) âœ…
    â†“
Embed query (GPU) â†’ 5-10ms âœ…
    â†“
Milvus search (GPU CAGRA) â†’ 5-20ms âœ…
    â†“
Enrich with Neo4j (cached) â†’ 5-10ms âœ…
    â†“
Re-rank results (LLM-based) â†’ 50-100ms (optional)
    â†“
Store in L1 + L2 cache
    â†“
Return results (P95: 30-50ms, P99: 50-80ms) âœ…
```

---

## Part 6: Implementation Priority Matrix

| Solution                          | Complexity | Impact                           | Time    | Priority |
| --------------------------------- | ---------- | -------------------------------- | ------- | -------- |
| Add 202 Accepted to extract_facts | Low        | High (87% latency reduction)     | 1 week  | **P0**   |
| Semantic LLM caching              | Medium     | High (50-70% cost reduction)     | 2 weeks | **P0**   |
| L1 in-memory cache (search)       | Low        | Medium (90% hit rate)            | 3 days  | **P1**   |
| GPU acceleration (Milvus CAGRA)   | High       | High (90% latency reduction)     | 3 weeks | **P1**   |
| Semantic similarity caching       | Medium     | High (40-60% hit rate)           | 2 weeks | **P1**   |
| Query pre-computation             | Low        | Medium (5-15% latency reduction) | 1 week  | **P2**   |
| LLM-based re-ranking              | High       | Low (5-10% accuracy improvement) | 3 weeks | **P3**   |
| Adaptive TTL policies             | Medium     | Low (5% cost reduction)          | 2 weeks | **P3**   |

---

## Conclusion

The current SDD has significant gaps in latency optimization:

1. **Extract Facts API**: Synchronous design makes <1s P99 target impossible. Must implement 202 Accepted + async processing.
2. **Search Facts API**: Current design meets <1s target but P99 is at risk. Multi-layer caching + GPU acceleration recommended.
3. **No semantic caching**: Missing 40-60% potential cache hit rate improvement.
4. **No GPU acceleration**: Missing 90% latency reduction opportunity.
5. **No pre-computation**: Missing 5-15% latency reduction for common queries.

**Recommended next steps**: Implement P0 items (async extract_facts, LLM caching) immediately, then P1 items (GPU, semantic caching) in parallel.


# PHáº¦N C: ÄÃ¡nh giÃ¡ SDD vÃ  Äá» xuáº¥t Tá»‘i Æ°u HoÃ¡ cho Pika Memory System

**PhiÃªn báº£n: 1.0 | NgÃ y: 2025-12-20 | TÃ¡c giáº£: Manus AI**

---

## 1. Tá»”NG QUAN (EXECUTIVE SUMMARY)

TÃ i liá»‡u nÃ y cung cáº¥p má»™t báº£n Ä‘Ã¡nh giÃ¡ chi tiáº¿t vá» tÃ i liá»‡u thiáº¿t káº¿ pháº§n má»m (SDD) cho há»‡ thá»‘ng Pika Long-Term Memory, Ä‘á»“ng thá»i Ä‘á» xuáº¥t má»™t kiáº¿n trÃºc tá»‘i Æ°u theo chuáº©n má»±c tháº¿ giá»›i Ä‘á»ƒ Ä‘Ã¡p á»©ng cÃ¡c yÃªu cáº§u kháº¯t khe vá» hiá»‡u nÄƒng, Ä‘áº·c biá»‡t lÃ  má»¥c tiÃªu Ä‘á»™ trá»… P95/P99 dÆ°á»›i 1 giÃ¢y.

**ÄÃ¡nh giÃ¡ chung:**

- **Äiá»ƒm máº¡nh:** SDD hiá»‡n táº¡i Ä‘Ã£ cÃ³ má»™t ná»n táº£ng tá»‘t, xÃ¡c Ä‘á»‹nh rÃµ rÃ ng hai API chÃ­nh (`extract_facts` vÃ  `search_facts`) vÃ  sá»­ dá»¥ng má»™t tech stack hiá»‡n Ä‘áº¡i (Milvus, Neo4j, Redis). Kiáº¿n trÃºc cÆ¡ báº£n lÃ  há»£p lÃ½.
- **Lá»— há»•ng nghiÃªm trá»ng:** Thiáº¿t káº¿ hiá»‡n táº¡i **KHÃ”NG** thá»ƒ Ä‘Ã¡p á»©ng Ä‘Æ°á»£c yÃªu cáº§u Ä‘á»™ trá»… <1s cho táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p. Cá»¥ thá»ƒ:
    - **`extract_facts` API:** ÄÆ°á»£c thiáº¿t káº¿ Ä‘á»“ng bá»™ (synchronous), vá»›i Ä‘á»™ trá»… Æ°á»›c tÃ­nh **750-1500ms**, hoÃ n toÃ n tháº¥t báº¡i trong viá»‡c Ä‘Ã¡p á»©ng má»¥c tiÃªu <1s do phá»¥ thuá»™c vÃ o thá»i gian xá»­ lÃ½ cá»§a LLM.
    - **`search_facts` API:** Máº·c dÃ¹ Ä‘á»™ trá»… P95 Æ°á»›c tÃ­nh (~250-420ms) cÃ³ thá»ƒ Ä‘áº¡t yÃªu cáº§u, nhÆ°ng thiáº¿t káº¿ cÃ²n sÆ¡ sÃ i, thiáº¿u cÃ¡c lá»›p caching nÃ¢ng cao vÃ  tá»‘i Æ°u hoÃ¡ pháº§n cá»©ng, khiáº¿n Ä‘á»™ trá»… P99 cÃ³ nguy cÆ¡ cao vÆ°á»£t ngÆ°á»¡ng vÃ  khÃ´ng Ä‘áº£m báº£o hiá»‡u nÄƒng á»•n Ä‘á»‹nh dÆ°á»›i táº£i cao.

**Äá» xuáº¥t chÃ­nh:**

Äá»ƒ xÃ¢y dá»±ng má»™t há»‡ thá»‘ng táº§m cá»¡ tháº¿ giá»›i, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t cuá»™c tÃ¡i kiáº¿n trÃºc táº­p trung vÃ o hai trá»¥ cá»™t chÃ­nh:

1.  **Chuyá»ƒn Ä‘á»•i `extract_facts` sang mÃ´ hÃ¬nh báº¥t Ä‘á»“ng bá»™ (Asynchronous):** Sá»­ dá»¥ng pattern `202 Accepted` vá»›i message queue (RabbitMQ) Ä‘á»ƒ tÃ¡ch rá»i cÃ¡c tÃ¡c vá»¥ tá»‘n thá»i gian (LLM processing) ra khá»i luá»“ng request chÃ­nh, Ä‘áº£m báº£o API response ngay láº­p tá»©c (<100ms).
2.  **Triá»ƒn khai kiáº¿n trÃºc Caching Ä‘a táº§ng vÃ  tÄƒng tá»‘c pháº§n cá»©ng cho `search_facts`:** Ãp dá»¥ng má»™t chiáº¿n lÆ°á»£c caching 3 lá»›p (In-Memory, Distributed, Persistent) káº¿t há»£p vá»›i Semantic Caching vÃ  tÄƒng tá»‘c GPU cho Milvus Ä‘á»ƒ giáº£m Ä‘á»™ trá»… P99 xuá»‘ng dÆ°á»›i 100ms.

TÃ i liá»‡u nÃ y sáº½ phÃ¢n tÃ­ch MECE (Mutually Exclusive, Collectively Exhaustive) toÃ n bá»™ cÃ¡c giáº£i phÃ¡p vÃ  cung cáº¥p má»™t lá»™ trÃ¬nh triá»ƒn khai chi tiáº¿t Ä‘á»ƒ Pika Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u nÄƒng vÆ°á»£t trá»™i, kháº£ nÄƒng má»Ÿ rá»™ng vÃ  tiáº¿t kiá»‡m chi phÃ­ váº­n hÃ nh.

---

## 2. PHÃ‚N TÃCH CHI TIáº¾T VÃ€ XÃC Äá»ŠNH Lá»– Há»”NG TRONG SDD

### 2.1. PhÃ¢n tÃ­ch YÃªu cáº§u API

SDD Ä‘Ã£ xÃ¡c Ä‘á»‹nh Ä‘Ãºng vÃ  Ä‘á»§ 2 API theo yÃªu cáº§u cá»§a báº¡n:

- `POST /v1/extract_facts`: Nháº­n vÃ o má»™t cuá»™c há»™i thoáº¡i vÃ  trÃ­ch xuáº¥t cÃ¡c "facts".
- `POST /v1/search_facts`: Nháº­n vÃ o má»™t cÃ¢u truy váº¥n vÃ  tÃ¬m kiáº¿m cÃ¡c "facts" liÃªn quan.

=> **Káº¿t luáº­n:** YÃªu cáº§u vá» API Ä‘Æ°á»£c Ä‘Ã¡p á»©ng. âœ…

### 2.2. PhÃ¢n tÃ­ch YÃªu cáº§u vá» Äá»™ trá»… (Latency)

ÄÃ¢y lÃ  Ä‘iá»ƒm yáº¿u chÃ­ máº¡ng cá»§a SDD hiá»‡n táº¡i.

#### **PhÃ¢n tÃ­ch `extract_facts` API:**

Luá»“ng xá»­ lÃ½ Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»“ng bá»™, client pháº£i chá» toÃ n bá»™ quÃ¡ trÃ¬nh hoÃ n táº¥t:

| BÆ°á»›c | Äá»™ trá»… Æ°á»›c tÃ­nh (ms) | Ghi chÃº |
| :--- | :--- | :--- |
| 1. Gá»i OpenAI LLM | 500 - 1000+ | **NÃºt tháº¯t cá»• chai chÃ­nh** |
| 2. Táº¡o Embeddings | 100 - 200 | Phá»¥ thuá»™c vÃ o sá»‘ lÆ°á»£ng facts |
| 3. LÆ°u vÃ o Milvus | 50 - 100 | |
| 4. LÆ°u vÃ o Neo4j | 50 - 100 | |
| 5. LÆ°u vÃ o PostgreSQL | 50 - 100 | |
| **Tá»•ng cá»™ng** | **750 - 1500+** | **Tháº¥t báº¡i** âŒ |

=> **Káº¿t luáº­n:** Vá»›i thiáº¿t káº¿ nÃ y, viá»‡c Ä‘áº¡t Ä‘Æ°á»£c P95/P99 < 1s lÃ  **báº¥t kháº£ thi**. Báº¥t ká»³ sá»± cháº­m trá»… nÃ o tá»« phÃ­a API cá»§a OpenAI cÅ©ng sáº½ áº£nh hÆ°á»Ÿng trá»±c tiáº¿p Ä‘áº¿n ngÆ°á»i dÃ¹ng cuá»‘i.

#### **PhÃ¢n tÃ­ch `search_facts` API:**

Luá»“ng xá»­ lÃ½ cÃ³ sá»­ dá»¥ng Redis cache, nhÆ°ng chá»‰ lÃ  caching á»Ÿ má»©c cÆ¡ báº£n (exact match).

| BÆ°á»›c | Äá»™ trá»… Æ°á»›c tÃ­nh (ms) | Ghi chÃº |
| :--- | :--- | :--- |
| 1. Kiá»ƒm tra Redis Cache | < 10 | Cache hit (náº¿u cÃ³) |
| 2. Táº¡o Query Embedding | 100 - 200 | Cache miss |
| 3. TÃ¬m kiáº¿m trÃªn Milvus (CPU) | 50 - 100 | Cache miss |
| 4. Láº¥y dá»¯ liá»‡u tá»« Neo4j/Postgres | 50 - 100 | Cache miss |
| 5. Ghi vÃ o Redis Cache | < 10 | Cache miss |
| **Tá»•ng cá»™ng (Cache Miss)** | **210 - 420** | **Äáº¡t P95, P99 rá»§i ro** âš ï¸ |

=> **Káº¿t luáº­n:** Máº·c dÃ¹ P95 cÃ³ thá»ƒ Ä‘áº¡t <1s, nhÆ°ng P99 ráº¥t dá»… bá»‹ vÆ°á»£t ngÆ°á»¡ng khi táº£i tÄƒng cao hoáº·c cÃ³ sá»± biáº¿n Ä‘á»™ng tá»« cÃ¡c thÃ nh pháº§n phá»¥ thuá»™c. Thiáº¿t káº¿ nÃ y thiáº¿u cÃ¡c ká»¹ thuáº­t tá»‘i Æ°u hiá»‡u nÄƒng Ä‘á»‰nh cao nhÆ° Semantic Caching, GPU acceleration, vÃ  pre-computation.

### 2.3. Báº£ng tá»•ng há»£p cÃ¡c lá»— há»•ng (Gap Analysis)

| Háº¡ng má»¥c | Váº¥n Ä‘á» trong SDD | TÃ¡c Ä‘á»™ng | Má»©c Ä‘á»™ nghiÃªm trá»ng |
| :--- | :--- | :--- | :--- |
| **Kiáº¿n trÃºc API** | `extract_facts` lÃ  synchronous | Block luá»“ng request, latency > 1s | **NghiÃªm trá»ng (P0)** |
| **Caching Strategy** | Chá»‰ cÃ³ L2 cache cÆ¡ báº£n, thiáº¿u Semantic Caching | Tá»· lá»‡ cache hit tháº¥p, lÃ£ng phÃ­ tÃ i nguyÃªn tÃ­nh toÃ¡n | **NghiÃªm trá»ng (P0)** |
| **Tá»‘i Æ°u Vector DB** | KhÃ´ng cÃ³ káº¿ hoáº¡ch tÄƒng tá»‘c GPU cho Milvus | Latency tÃ¬m kiáº¿m vector cao hÆ¡n 10-50 láº§n so vá»›i tá»‘i Æ°u | **Cao (P1)** |
| **Tá»‘i Æ°u truy váº¥n** | KhÃ´ng cÃ³ chiáº¿n lÆ°á»£c pre-computation hay query decomposition | Bá» lá»¡ cÆ¡ há»™i giáº£m latency cho cÃ¡c truy váº¥n phá»• biáº¿n | **Trung bÃ¬nh (P2)** |
| **Má»¥c tiÃªu hiá»‡u nÄƒng** | Chá»‰ Ä‘á»‹nh nghÄ©a P95, bá» qua P99 | KhÃ´ng cÃ³ cam káº¿t cho tráº£i nghiá»‡m cá»§a nhÃ³m ngÆ°á»i dÃ¹ng tá»‡ nháº¥t | **Trung bÃ¬nh (P2)** |
| **Kháº£ nÄƒng phá»¥c há»“i** | KhÃ´ng cÃ³ chiáº¿n lÆ°á»£c fallback khi cÃ¡c dá»‹ch vá»¥ (LLM, DB) cháº­m | Há»‡ thá»‘ng dá»… bá»‹ sá»¥p Ä‘á»• dÃ¢y chuyá»n | **Cao (P1)** |

---

## 3. PHÃ‚N TÃCH MECE CÃC GIáº¢I PHÃP Tá»I Æ¯U Táº¦M Cá»  THáº¾ GIá»šI

Dá»±a trÃªn cÃ¡c nghiÃªn cá»©u sÃ¢u rá»™ng vá» cÃ¡c há»‡ thá»‘ng AI/ML hiá»‡u nÄƒng cao táº¡i Google, Meta, Netflix vÃ  cÃ¡c cÃ´ng ty hÃ ng Ä‘áº§u khÃ¡c, chÃºng tÃ´i Ä‘Ã£ tá»•ng há»£p má»™t danh sÃ¡ch MECE cÃ¡c giáº£i phÃ¡p Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c lá»— há»•ng trÃªn.

### 3.1. Giáº£i phÃ¡p cho `extract_facts` API: MÃ´ hÃ¬nh báº¥t Ä‘á»“ng bá»™

**NguyÃªn táº¯c:** KhÃ´ng bao giá» Ä‘á»ƒ ngÆ°á»i dÃ¹ng chá» má»™t tÃ¡c vá»¥ khÃ´ng xÃ¡c Ä‘á»‹nh vá» thá»i gian. TÃ¡ch biá»‡t viá»‡c tiáº¿p nháº­n yÃªu cáº§u vÃ  viá»‡c xá»­ lÃ½ yÃªu cáº§u.

| Giáº£i phÃ¡p | MÃ´ táº£ | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm | PhÃ¹ há»£p cho Pika? |
| :--- | :--- | :--- | :--- | :--- |
| **1. Async Request-Reply (202 Accepted)** | API tráº£ vá» `202 Accepted` ngay láº­p tá»©c cÃ¹ng má»™t `job_id`. Client dÃ¹ng `job_id` Ä‘á»ƒ polling láº¥y káº¿t quáº£. | **Pháº£n há»“i tá»©c thÃ¬ (<100ms)**, chuáº©n RESTful, dá»… triá»ƒn khai. | Client cáº§n logic Ä‘á»ƒ polling. | **Ráº¥t phÃ¹ há»£p (Äá» xuáº¥t)** âœ… |
| **2. Webhooks** | API nháº­n request vÃ  gá»i láº¡i má»™t URL cá»§a client khi xá»­ lÃ½ xong. | KhÃ´ng cáº§n polling, real-time. | YÃªu cáº§u client pháº£i cÃ³ má»™t endpoint public, phá»©c táº¡p hÆ¡n. | Ãt phÃ¹ há»£p hÆ¡n. |
| **3. WebSockets** | Duy trÃ¬ má»™t káº¿t ná»‘i má»Ÿ Ä‘á»ƒ Ä‘áº©y káº¿t quáº£ vá» cho client. | Real-time nháº¥t. | Tá»‘n tÃ i nguyÃªn server, overkill cho tÃ¡c vá»¥ nÃ y. | KhÃ´ng phÃ¹ há»£p. |

### 3.2. Giáº£i phÃ¡p cho `search_facts` API: Caching Ä‘a táº§ng & Tá»‘i Æ°u hoÃ¡

#### **A. Caching Layers**

| Lá»›p                 | Ká»¹ thuáº­t                     | Äá»™ trá»… Hit | DÃ nh cho                                               | Äá» xuáº¥t cho Pika       |
| :------------------ | :--------------------------- | :--------- | :----------------------------------------------------- | :--------------------- |
| **L1: In-Memory**   | `lru_cache` trong Python     | < 1ms      | CÃ¡c truy váº¥n cá»±c nÃ³ng (top 1%) trong cÃ¹ng má»™t process. | **NÃªn cÃ³** âœ…           |
| **L2: Distributed** | Redis / KeyDB                | 5-20ms     | CÃ¡c truy váº¥n nÃ³ng trÃªn toÃ n há»‡ thá»‘ng.                  | **Báº¯t buá»™c (ÄÃ£ cÃ³)** âœ… |
| **L3: Persistent**  | Materialized View (Postgres) | 50-200ms   | CÃ¡c truy váº¥n phá»• biáº¿n, cÃ³ thá»ƒ tÃ­nh toÃ¡n trÆ°á»›c.         | CÃ³ thá»ƒ xem xÃ©t sau.    |

#### **B. Semantic Caching**

| Ká»¹ thuáº­t | Tá»· lá»‡ Hit Rate | MÃ´ táº£ | Äá» xuáº¥t cho Pika |
| :--- | :--- | :--- | :--- |
| **Exact Match** | 5-15% | Hash cá»§a cÃ¢u query. (Hiá»‡n táº¡i SDD Ä‘ang dÃ¹ng) | **Giá»¯ láº¡i** âœ… |
| **Semantic Similarity** | 30-60% | TÃ¬m vector cá»§a query trong cache. Náº¿u tÆ°Æ¡ng Ä‘á»“ng > ngÆ°á»¡ng (e.g., 0.9) thÃ¬ lÃ  cache hit. | **Báº¯t buá»™c pháº£i thÃªm** âœ… |
| **Hybrid (Exact + Semantic)** | 40-70% | Thá»­ exact match trÆ°á»›c, náº¿u miss thÃ¬ thá»­ semantic match. | **Kiáº¿n trÃºc tá»‘t nháº¥t** âœ… |

#### **C. Tá»‘i Æ°u Vector Database (Milvus)**

| Ká»¹ thuáº­t                | Má»©c Ä‘á»™ giáº£m Latency | MÃ´ táº£                                                                                                 | Äá» xuáº¥t cho Pika                  |
| :---------------------- | :------------------ | :---------------------------------------------------------------------------------------------------- | :-------------------------------- |
| **GPU Acceleration**    | **10x - 50x**       | Sá»­ dá»¥ng index há»— trá»£ GPU (e.g., CAGRA, IVF_GPU) Ä‘á»ƒ tÄƒng tá»‘c tÃ¬m kiáº¿m.                                 | **Báº¯t buá»™c Ä‘á»ƒ Ä‘áº¡t P99 < 100ms** âœ… |
| **Tuning Index Params** | 2x - 5x             | Tinh chá»‰nh cÃ¡c tham sá»‘ `efSearch` (HNSW) hoáº·c `nprobe` (IVF) Ä‘á»ƒ cÃ¢n báº±ng giá»¯a tá»‘c Ä‘á»™ vÃ  Ä‘á»™ chÃ­nh xÃ¡c. | **Báº¯t buá»™c** âœ…                    |
| **Quantization**        | 2x - 4x (Memory)    | NÃ©n vector (e.g., PQ, SQ) Ä‘á»ƒ giáº£m bá»™ nhá»› vÃ  tÄƒng tá»‘c Ä‘á»™ tÃ­nh toÃ¡n khoáº£ng cÃ¡ch.                        | **NÃªn cÃ³** âœ…                      |

#### **D. Tá»‘i Æ°u Truy váº¥n**

| Ká»¹ thuáº­t | Má»¥c Ä‘Ã­ch | MÃ´ táº£ | Äá» xuáº¥t cho Pika |
| :--- | :--- | :--- | :--- |
| **Pre-computation** | Giáº£m latency cho query phá»• biáº¿n | Cháº¡y trÆ°á»›c cÃ¡c truy váº¥n thÆ°á»ng gáº·p (e.g., "sá»Ÿ thÃ­ch cá»§a tÃ´i") vÃ  lÆ°u káº¿t quáº£ vÃ o cache. | **NÃªn cÃ³** âœ… |
| **Query Decomposition** | TÄƒng cache hit rate | DÃ¹ng LLM Ä‘á»ƒ chia má»™t query phá»©c táº¡p thÃ nh cÃ¡c query con Ä‘Ã£ Ä‘Æ°á»£c cache. | NÃ¢ng cao, xem xÃ©t sau. |
| **Hybrid Search** | TÄƒng Ä‘á»™ chÃ­nh xÃ¡c | Káº¿t há»£p tÃ¬m kiáº¿m vector vÃ  tÃ¬m kiáº¿m keyword (BM25) Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t nháº¥t. | **NÃªn cÃ³** âœ… |

---

## 4. Äá»€ XUáº¤T KIáº¾N TRÃšC Tá»I Æ¯U (BEST PRACTICES)

### 4.1. Kiáº¿n trÃºc cho `extract_facts` (Async Pattern)

```mermaid
sequenceDiagram
    participant Client
    participant API_Gateway as API Gateway
    participant Extract_Service as Extract Service (FastAPI)
    participant Message_Queue as RabbitMQ
    participant Worker

    Client->>API_Gateway: POST /v1/extract_facts (payload)
    API_Gateway->>Extract_Service: (forward request)
    Extract_Service-->>Client: HTTP 202 Accepted (job_id, status_url)
    Extract_Service->>Message_Queue: Publish job (payload, job_id)

    Note right of Worker: Long-running process
    Message_Queue->>Worker: Consume job
    Worker->>OpenAI: Call LLM to extract
    Worker->>Milvus/Neo4j: Store facts & vectors
    Worker->>PostgreSQL: Update job status = 'completed'

    Client->>API_Gateway: GET /v1/jobs/{job_id}/status (polling)
    API_Gateway->>Extract_Service: (forward request)
    Extract_Service->>PostgreSQL: Get job status
    PostgreSQL-->>Extract_Service: 'completed', results
    Extract_Service-->>Client: HTTP 200 OK (results)
```

**Lá»£i Ã­ch:**
- **API Response Time:** < 100ms.
- **Kháº£ nÄƒng chá»‹u lá»—i:** Náº¿u worker tháº¥t báº¡i, job cÃ³ thá»ƒ Ä‘Æ°á»£c retry tá»« message queue.
- **Kháº£ nÄƒng má»Ÿ rá»™ng:** CÃ³ thá»ƒ tÄƒng sá»‘ lÆ°á»£ng worker má»™t cÃ¡ch Ä‘á»™c láº­p Ä‘á»ƒ xá»­ lÃ½ nhiá»u job song song.

### 4.2. Kiáº¿n trÃºc cho `search_facts` (Multi-Layer Caching & GPU)

```mermaid
sequenceDiagram
    participant Client
    participant Search_Service as Search Service (FastAPI)
    participant L1_Cache as L1 Cache (In-Memory)
    participant L2_Cache as L2 Cache (Redis)
    participant Milvus_GPU as Milvus (GPU-Accelerated)

    Client->>Search_Service: POST /v1/search_facts (query)

    Search_Service->>L1_Cache: Check exact match (hash)
    alt L1 Hit
        L1_Cache-->>Search_Service: Return cached result
        Search_Service-->>Client: HTTP 200 OK (<1ms)
    end

    Search_Service->>L2_Cache: Check semantic match (vector)
    alt L2 Hit
        L2_Cache-->>Search_Service: Return cached result
        Search_Service-->>Client: HTTP 200 OK (<20ms)
    end

    Note right of Search_Service: Cache Miss - Full Flow
    Search_Service->>OpenAI: Embed query
    Search_Service->>Milvus_GPU: Similarity Search
    Milvus_GPU-->>Search_Service: Top K results
    Search_Service->>Neo4j/Postgres: Enrich data
    Search_Service->>L1_Cache: Store result
    Search_Service->>L2_Cache: Store result
    Search_Service-->>Client: HTTP 200 OK (P99 < 100ms)
```

**Lá»£i Ã­ch:**
- **P99 Latency:** < 100ms, vÆ°á»£t xa má»¥c tiÃªu 1s.
- **Hiá»‡u quáº£ chi phÃ­:** Tá»· lá»‡ cache hit cao (40-70%) giÃºp giáº£m Ä‘Ã¡ng ká»ƒ sá»‘ lÆ°á»£ng cuá»™c gá»i Ä‘áº¿n cÃ¡c thÃ nh pháº§n tá»‘n kÃ©m (Embedding, Milvus).
- **Tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng vÆ°á»£t trá»™i:** Pháº£n há»“i gáº§n nhÆ° tá»©c thÃ¬ cho pháº§n lá»›n cÃ¡c truy váº¥n.

---

## 5. Lá»˜ TRÃŒNH TRIá»‚N KHAI Äá»€ XUáº¤T

ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t lá»™ trÃ¬nh gá»“m 3 giai Ä‘oáº¡n Ä‘á»ƒ triá»ƒn khai cÃ¡c cáº£i tiáº¿n nÃ y.

| Giai Ä‘oáº¡n | Æ¯u tiÃªn | Háº¡ng má»¥c | Thá»i gian Æ°á»›c tÃ­nh | Má»¥c tiÃªu |
| :--- | :--- | :--- | :--- | :--- |
| **Giai Ä‘oáº¡n 1: Ná»n táº£ng** | **P0** | 1. Chuyá»ƒn `extract_facts` sang async (202 Accepted + RabbitMQ).<br>2. ThÃªm L1 in-memory cache cho `search_facts`. | 2-3 tuáº§n | Äáº£m báº£o khÃ´ng block request, giáº£m latency cÆ¡ báº£n. |
| **Giai Ä‘oáº¡n 2: TÄƒng tá»‘c** | **P1** | 1. Triá»ƒn khai Semantic Caching cho `search_facts`.<br>2. NÃ¢ng cáº¥p Milvus Ä‘á»ƒ sá»­ dá»¥ng GPU acceleration. | 3-4 tuáº§n | Äáº¡t P99 < 200ms, tÄƒng cache hit rate lÃªn >40%. |
| **Giai Ä‘oáº¡n 3: Tinh chá»‰nh** | **P2** | 1. Triá»ƒn khai pre-computation cho cÃ¡c query phá»• biáº¿n.<br>2. Tinh chá»‰nh cÃ¡c tham sá»‘ cá»§a Milvus vÃ  ngÆ°á»¡ng similarity.<br>3. ThÃªm Hybrid Search (káº¿t há»£p keyword). | 2 tuáº§n | Äáº¡t P99 < 100ms, tá»‘i Æ°u Ä‘á»™ chÃ­nh xÃ¡c. |

---

## 6. Káº¾T LUáº¬N VÃ€ BÆ¯á»šC TIáº¾P THEO

SDD hiá»‡n táº¡i lÃ  má»™t khá»Ÿi Ä‘áº§u tá»‘t nhÆ°ng chÆ°a Ä‘á»§ Ä‘á»ƒ xÃ¢y dá»±ng má»™t há»‡ thá»‘ng Memory Ä‘áº³ng cáº¥p tháº¿ giá»›i vá»›i yÃªu cáº§u hiá»‡u nÄƒng kháº¯t khe. CÃ¡c lá»— há»•ng vá» kiáº¿n trÃºc, Ä‘áº·c biá»‡t lÃ  á»Ÿ `extract_facts` API vÃ  chiáº¿n lÆ°á»£c caching, cáº§n Ä‘Æ°á»£c kháº¯c phá»¥c ngay láº­p tá»©c.

Báº±ng cÃ¡ch Ã¡p dá»¥ng cÃ¡c Ä‘á» xuáº¥t trong tÃ i liá»‡u nÃ yâ€”chuyá»ƒn sang mÃ´ hÃ¬nh báº¥t Ä‘á»“ng bá»™, triá»ƒn khai caching Ä‘a táº§ng, vÃ  táº­n dá»¥ng tÄƒng tá»‘c pháº§n cá»©ngâ€”Pika khÃ´ng chá»‰ Ä‘Ã¡p á»©ng mÃ  cÃ²n cÃ³ thá»ƒ vÆ°á»£t xa má»¥c tiÃªu P95/P99 < 1s, táº¡o ra má»™t tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng mÆ°á»£t mÃ , Ä‘á»“ng thá»i xÃ¢y dá»±ng má»™t ná»n táº£ng vá»¯ng cháº¯c, hiá»‡u quáº£ vÃ  dá»… dÃ ng má»Ÿ rá»™ng trong tÆ°Æ¡ng lai.

**BÆ°á»›c tiáº¿p theo Ä‘Æ°á»£c Ä‘á» xuáº¥t:**

1.  **Review vÃ  phÃª duyá»‡t** cÃ¡c thay Ä‘á»•i kiáº¿n trÃºc Ä‘Æ°á»£c Ä‘á» xuáº¥t trong tÃ i liá»‡u nÃ y.
2.  **Cáº­p nháº­t SDD** Ä‘á»ƒ pháº£n Ã¡nh kiáº¿n trÃºc má»›i.
3.  **Báº¯t Ä‘áº§u triá»ƒn khai Giai Ä‘oáº¡n 1** theo lá»™ trÃ¬nh Ä‘Ã£ váº¡ch ra.



# PHáº¦N D: FOLDER STRUCTURE 

```

your_project/

â”‚

â”œâ”€â”€ ğŸ“¦ app/                                    # Main Application

â”‚   â”œâ”€â”€ __init__.py

â”‚   â”œâ”€â”€ main.py                               # FastAPI app creation, lifespan events

â”‚   â”‚

â”‚   â”œâ”€â”€ ğŸ”Œ api/                               # PRESENTATION LAYER (HTTP/REST/GraphQL)

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ dependencies.py                   # Shared dependency injection (Depends)

â”‚   â”‚   â”œâ”€â”€ middleware/                       # HTTP middleware

â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”œâ”€â”€ error_handler.py              # Global error handling (try/except wrapper)

â”‚   â”‚   â”‚   â”œâ”€â”€ request_logger.py             # Request/response logging with structlog

â”‚   â”‚   â”‚   â”œâ”€â”€ correlation_id.py             # Distributed tracing (trace_id, span_id)

â”‚   â”‚   â”‚   â”œâ”€â”€ auth_middleware.py            # JWT validation, user context injection

â”‚   â”‚   â”‚   â””â”€â”€ performance_monitor.py        # Request latency tracking

â”‚   â”‚   â”‚

â”‚   â”‚   â””â”€â”€ v1/                               # API versioning (v1, v2 in future)

â”‚   â”‚       â”œâ”€â”€ __init__.py

â”‚   â”‚       â”œâ”€â”€ router.py                     # Main router aggregator

â”‚   â”‚       â”‚                                 # APIRouter("/v1").include_router(auth_router)...

â”‚   â”‚       â”‚

â”‚   â”‚       â”œâ”€â”€ endpoints/                    # Feature-specific endpoint groups

â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚       â”‚   â”œâ”€â”€ auth.py                   # POST /login, /refresh, /logout

â”‚   â”‚       â”‚   â”œâ”€â”€ users.py                  # GET /users, POST /users, PATCH /users/{id}

â”‚   â”‚       â”‚   â”œâ”€â”€ products.py               # GET /products, POST /products (search, filter)

â”‚   â”‚       â”‚   â”œâ”€â”€ orders.py                 # POST /orders, GET /orders/{id}, PATCH /orders/{id}/status

â”‚   â”‚       â”‚   â”œâ”€â”€ payments.py               # POST /payments/webhook, GET /payments/{id}

â”‚   â”‚       â”‚   â””â”€â”€ health.py                 # GET /health (Kubernetes readiness/liveness)

â”‚   â”‚       â”‚

â”‚   â”‚       â””â”€â”€ schemas/                      # Request/Response Pydantic models (per endpoint)

â”‚   â”‚           â”œâ”€â”€ __init__.py

â”‚   â”‚           â”œâ”€â”€ auth.py                   # LoginRequest, LoginResponse, TokenPayload

â”‚   â”‚           â”œâ”€â”€ user.py                   # UserCreate, UserUpdate, UserResponse

â”‚   â”‚           â”œâ”€â”€ product.py                # ProductCreate, ProductResponse

â”‚   â”‚           â””â”€â”€ order.py                  # OrderCreate, OrderResponse

â”‚   â”‚

â”‚   â”œâ”€â”€ âš™ï¸ core/                              # CONFIGURATION & CROSS-CUTTING CONCERNS

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ config.py                         # Pydantic BaseSettings + environment vars

â”‚   â”‚   â”‚                                     # class Settings: db_url, redis_url, jwt_secret, etc.

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ constants.py                      # App-wide constants, enums

â”‚   â”‚   â”‚                                     # enum UserRole: ADMIN, USER, GUEST

â”‚   â”‚   â”‚                                     # MAX_PAGE_SIZE = 100

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ exceptions.py                     # Custom exceptions (domain-agnostic)

â”‚   â”‚   â”‚                                     # class AppException(Exception): ...

â”‚   â”‚   â”‚                                     # class ValidationError: ...

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ security.py                       # Security utilities

â”‚   â”‚   â”‚   â”œâ”€â”€ jwt_handler.py                # create_token(), verify_token()

â”‚   â”‚   â”‚   â”œâ”€â”€ password.py                   # hash_password(), verify_password()

â”‚   â”‚   â”‚   â””â”€â”€ cors.py                       # CORS configuration

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ logging.py                        # Structured logging setup

â”‚   â”‚   â”‚                                     # logger = setup_logging() â†’ JSON format for ELK

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ telemetry.py                      # OpenTelemetry setup

â”‚   â”‚   â”‚                                     # trace_provider, metric_provider setup

â”‚   â”‚   â”‚

â”‚   â”‚   â””â”€â”€ enums.py                          # Reusable enums

â”‚   â”‚                                         # class OrderStatus: PENDING, PAID, SHIPPED

â”‚   â”‚

â”‚   â”œâ”€â”€ ğŸ¢ domains/                           # DOMAIN LAYER (DDD BOUNDED CONTEXTS)

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ users/                            # ===== USER MANAGEMENT BOUNDED CONTEXT =====

â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ domain/                       # DOMAIN LOGIC (Entities, Value Objects, Events)

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ entities.py               # User entity: email, password_hash, status

â”‚   â”‚   â”‚   â”‚   â”‚                             # class User: aggregate root

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ value_objects.py          # Email, PhoneNumber, PasswordHash

â”‚   â”‚   â”‚   â”‚   â”‚                             # class Email: validate_email(), __eq__()

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ events.py                 # UserCreated, UserUpdated, UserDeleted

â”‚   â”‚   â”‚   â”‚   â”‚                             # class UserCreatedEvent: user_id, email, timestamp

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ exceptions.py             # UserNotFound, EmailAlreadyExists

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ application/                  # APPLICATION LOGIC (Use Cases, Orchestration)

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ services/

â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ user_service.py       # UserService: create_user(), get_user(), update_user()

â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ auth_service.py       # AuthService: login(), logout(), refresh_token()

â”‚   â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ usecases/                 # (Optional, if using full CQRS)

â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ create_user.py

â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ get_user.py

â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ update_user.py

â”‚   â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ repositories/             # ABSTRACT REPOSITORY INTERFACES

â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base.py               # BaseRepository[T]

â”‚   â”‚   â”‚   â”‚   â”‚   â”‚                         # async def get(id: UUID) -> T

â”‚   â”‚   â”‚   â”‚   â”‚   â”‚                         # async def save(entity: T) -> T

â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ user_repository.py    # IUserRepository: find_by_email(), find_by_id()

â”‚   â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ dto/                      # Data Transfer Objects (if using CQRS)

â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ user_dto.py

â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ auth_dto.py

â”‚   â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ commands.py               # (Optional) Command objects for CQRS

â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ create_user_cmd.py

â”‚   â”‚   â”‚   â”‚       â””â”€â”€ update_user_cmd.py

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â””â”€â”€ infrastructure/               # INFRASTRUCTURE (Concrete Implementations)

â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚       â”œâ”€â”€ models.py                 # SQLAlchemy ORM model: User

â”‚   â”‚   â”‚       â”œâ”€â”€ schemas.py                # Pydantic schemas: UserCreate, UserResponse

â”‚   â”‚   â”‚       â”œâ”€â”€ repositories/

â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚       â”‚   â””â”€â”€ user_repository_impl.py  # Concrete UserRepository implementation

â”‚   â”‚   â”‚       â”‚

â”‚   â”‚   â”‚       â”œâ”€â”€ mappers.py                # Map ORM â†” Domain Entity

â”‚   â”‚   â”‚       â”‚                             # class UserMapper: orm_to_entity(), entity_to_orm()

â”‚   â”‚   â”‚       â”‚

â”‚   â”‚   â”‚       â””â”€â”€ event_handlers.py         # Event subscribers for UserCreated, UserDeleted

â”‚   â”‚   â”‚                                     # send welcome email, update analytics

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ products/                         # ===== PRODUCT CATALOG BOUNDED CONTEXT =====

â”‚   â”‚   â”‚   â”œâ”€â”€ domain/

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ entities.py

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ value_objects.py          # Money, Sku, Category

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ events.py                 # ProductCreated, InventoryUpdated

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ exceptions.py

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ application/

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ services/

â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ product_service.py

â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ inventory_service.py

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ repositories/

â”‚   â”‚   â”‚   â”‚       â””â”€â”€ product_repository.py

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â””â”€â”€ infrastructure/

â”‚   â”‚   â”‚       â”œâ”€â”€ models.py                 # Product, Inventory ORM

â”‚   â”‚   â”‚       â”œâ”€â”€ repositories/

â”‚   â”‚   â”‚       â”‚   â””â”€â”€ product_repository_impl.py

â”‚   â”‚   â”‚       â””â”€â”€ event_handlers.py         # Handle product events

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ orders/                           # ===== ORDER MANAGEMENT BOUNDED CONTEXT =====

â”‚   â”‚   â”‚   â”œâ”€â”€ domain/

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ entities.py               # Order (aggregate root), OrderItem

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ value_objects.py          # OrderStatus, Address, Currency

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ events.py                 # OrderCreated, PaymentProcessed, OrderShipped

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ exceptions.py             # OrderNotFound, InvalidOrderStatus

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ application/

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ services/

â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ order_service.py      # Create, update, cancel order

â”‚   â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ repositories/

â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ order_repository.py   # Abstract

â”‚   â”‚   â”‚   â”‚       â””â”€â”€ order_item_repository.py

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â””â”€â”€ infrastructure/

â”‚   â”‚   â”‚       â”œâ”€â”€ models.py                 # Order, OrderItem ORM

â”‚   â”‚   â”‚       â”œâ”€â”€ repositories/

â”‚   â”‚   â”‚       â”‚   â””â”€â”€ order_repository_impl.py

â”‚   â”‚   â”‚       â”‚

â”‚   â”‚   â”‚       â””â”€â”€ event_handlers.py         # OrderCreated â†’ trigger payment service

â”‚   â”‚   â”‚                                     # PaymentSuccess â†’ update order status

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ payments/                         # ===== PAYMENT PROCESSING BOUNDED CONTEXT =====

â”‚   â”‚   â”‚   â”œâ”€â”€ domain/

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ entities.py               # Payment (aggregate root)

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ value_objects.py          # PaymentStatus, Money, TransactionId

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ events.py                 # PaymentInitiated, PaymentSuccess, PaymentFailed

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ exceptions.py

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ application/

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ services/

â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ payment_service.py    # Process payment, handle webhooks

â”‚   â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ repositories/

â”‚   â”‚   â”‚   â”‚       â””â”€â”€ payment_repository.py

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â””â”€â”€ infrastructure/

â”‚   â”‚   â”‚       â”œâ”€â”€ models.py

â”‚   â”‚   â”‚       â”œâ”€â”€ repositories/

â”‚   â”‚   â”‚       â”‚   â””â”€â”€ payment_repository_impl.py

â”‚   â”‚   â”‚       â”‚

â”‚   â”‚   â”‚       â””â”€â”€ stripe_adapter.py         # Stripe API integration

â”‚   â”‚   â”‚

â”‚   â”‚   â””â”€â”€ shared/                           # ===== SHARED DOMAIN LOGIC =====

â”‚   â”‚       â”œâ”€â”€ __init__.py

â”‚   â”‚       â”œâ”€â”€ events.py                     # Base Event class, EventPublisher

â”‚   â”‚       â”‚                                 # class Event: domain, event_type, timestamp, data

â”‚   â”‚       â”‚

â”‚   â”‚       â”œâ”€â”€ specifications.py             # Query specifications (DDD)

â”‚   â”‚       â”‚                                 # class Specification: to_predicate()

â”‚   â”‚       â”‚

â”‚   â”‚       â””â”€â”€ value_objects.py              # Shared VO: Id, AuditFields

â”‚   â”‚                                         # class EntityId(ValueObject): id, created_at, updated_by

â”‚   â”‚

â”‚   â”œâ”€â”€ ğŸ”Œ infrastructure/                    # INFRASTRUCTURE LAYER (Technical Details)

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ db/                               # DATABASE

â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”œâ”€â”€ session.py                    # SQLAlchemy session factory + context manager

â”‚   â”‚   â”‚   â”‚                                 # async def get_session() â†’ AsyncSession

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ base.py                       # Base model with common fields

â”‚   â”‚   â”‚   â”‚                                 # class BaseModel: id, created_at, updated_at, deleted_at

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ connection.py                 # DB connection pool setup

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â””â”€â”€ transactions.py               # Transaction management

â”‚   â”‚   â”‚                                     # async with transaction(): ...

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ cache/                            # CACHING (Redis)

â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”œâ”€â”€ client.py                     # Redis client wrapper

â”‚   â”‚   â”‚   â”‚                                 # async def get(key), async def set(key, value, ttl)

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ keys.py                       # Cache key generation constants

â”‚   â”‚   â”‚   â”‚                                 # USER_CACHE_KEY = "user:{user_id}"

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ ttl.py                        # TTL constants by entity

â”‚   â”‚   â”‚   â”‚                                 # USER_TTL = 3600, PRODUCT_TTL = 7200

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â””â”€â”€ decorators.py                 # @cache_result(ttl=3600)

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ messaging/                        # MESSAGE QUEUE & EVENTS (Kafka/RabbitMQ)

â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”œâ”€â”€ broker.py                     # Kafka/RabbitMQ client setup

â”‚   â”‚   â”‚   â”‚                                 # class MessageBroker: publish(), consume()

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ celery_app.py                 # Celery configuration

â”‚   â”‚   â”‚   â”‚                                 # @app.task async def send_email(user_id)

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ publishers/                   # Event publishers per domain

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ user_events.py

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ order_events.py

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ payment_events.py

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ consumers/                    # Event subscribers

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ order_consumer.py         # Handle OrderCreated â†’ trigger payment

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ payment_consumer.py       # Handle PaymentSuccess â†’ update order status

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ user_consumer.py          # Handle UserCreated â†’ send welcome email

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â””â”€â”€ schemas.py                    # Kafka message schemas (JSON serialization)

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ storage/                          # FILE STORAGE (S3, GCS, Local)

â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”œâ”€â”€ base.py                       # Abstract storage interface

â”‚   â”‚   â”‚   â”‚                                 # class StorageProvider: upload(), download(), delete()

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ s3_client.py                  # AWS S3 implementation

â”‚   â”‚   â”‚   â”‚                                 # class S3Storage(StorageProvider): ...

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ local_storage.py              # Local filesystem (dev/test)

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â””â”€â”€ gcs_client.py                 # Google Cloud Storage (optional)

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ external/                         # EXTERNAL API CLIENTS (3rd Party)

â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”œâ”€â”€ base_client.py                # Base HTTP client with retry, circuit breaker

â”‚   â”‚   â”‚   â”‚                                 # class BaseApiClient: _request(), _retry_with_backoff()

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ stripe_client.py              # Stripe payment processor

â”‚   â”‚   â”‚   â”‚                                 # class StripeClient: create_payment(), refund()

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ email_client.py               # SendGrid email service

â”‚   â”‚   â”‚   â”‚                                 # class EmailClient: send_email(), send_batch()

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â”œâ”€â”€ llm_client.py                 # OpenAI / LLM API

â”‚   â”‚   â”‚   â”‚                                 # class LLMClient: generate_summary(), classify()

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â””â”€â”€ analytics_client.py           # Analytics (Google Analytics, Mixpanel)

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ search/                           # SEARCH & ANALYTICS

â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”œâ”€â”€ elasticsearch.py              # Elasticsearch client

â”‚   â”‚   â”‚   â”‚                                 # async def index_product(), async def search()

â”‚   â”‚   â”‚   â”‚

â”‚   â”‚   â”‚   â””â”€â”€ milvus_client.py              # Vector search (embeddings)

â”‚   â”‚   â”‚                                     # For AI/ML features

â”‚   â”‚   â”‚

â”‚   â”‚   â””â”€â”€ repositories/                     # CONCRETE REPOSITORY IMPLEMENTATIONS

â”‚   â”‚       â”œâ”€â”€ __init__.py

â”‚   â”‚       â”œâ”€â”€ base_repository.py            # Generic CRUD: get(), create(), update(), delete()

â”‚   â”‚       â”‚

â”‚   â”‚       â”œâ”€â”€ user_repository.py            # Extends BaseRepository, implements IUserRepository

â”‚   â”‚       â”œâ”€â”€ product_repository.py         # Extends BaseRepository

â”‚   â”‚       â”œâ”€â”€ order_repository.py           # Extends BaseRepository

â”‚   â”‚       â””â”€â”€ payment_repository.py         # Extends BaseRepository

â”‚   â”‚

â”‚   â”œâ”€â”€ ğŸ›¡ï¸ middleware/                        # HTTP MIDDLEWARE (Cross-cutting)

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ error_handler.py                  # Global exception handling

â”‚   â”‚   â”‚                                     # @app.exception_handler(Exception)

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ request_logger.py                 # Log all requests/responses

â”‚   â”‚   â”‚                                     # Structured JSON logging

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ correlation_id.py                 # Distributed tracing

â”‚   â”‚   â”‚                                     # x-request-id, x-trace-id headers

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ auth.py                           # JWT authentication

â”‚   â”‚   â”‚                                     # async def verify_token(token: str)

â”‚   â”‚   â”‚

â”‚   â”‚   â””â”€â”€ rate_limiter.py                   # Rate limiting (per user, per endpoint)

â”‚   â”‚

â”‚   â”œâ”€â”€ ğŸ”’ security/                          # SECURITY UTILITIES

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ jwt_handler.py                    # JWT create/verify

â”‚   â”‚   â”‚                                     # encode_token(), decode_token()

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ password.py                       # Password hashing

â”‚   â”‚   â”‚                                     # hash_password() â†’ bcrypt, verify_password()

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ cors.py                           # CORS configuration

â”‚   â”‚   â”‚                                     # CORSMiddleware setup

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ permissions.py                    # RBAC (Role-Based Access Control)

â”‚   â”‚   â”‚                                     # async def check_permission(user, resource, action)

â”‚   â”‚   â”‚

â”‚   â”‚   â””â”€â”€ encryption.py                     # Encryption at rest

â”‚   â”‚                                         # encrypt_field(), decrypt_field()

â”‚   â”‚

â”‚   â”œâ”€â”€ ğŸ›¡ï¸ resilience/                        # RESILIENCE PATTERNS

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ circuit_breaker.py                # Circuit breaker (prevent cascading failures)

â”‚   â”‚   â”‚                                     # @circuit_breaker(failure_threshold=5)

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ retry.py                          # Retry logic with exponential backoff

â”‚   â”‚   â”‚                                     # @retry(max_attempts=3, backoff=2)

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ timeout.py                        # Timeout management

â”‚   â”‚   â”‚                                     # @with_timeout(seconds=5)

â”‚   â”‚   â”‚

â”‚   â”‚   â””â”€â”€ bulkhead.py                       # Resource isolation

â”‚   â”‚                                         # Limit concurrent requests per resource

â”‚   â”‚

â”‚   â””â”€â”€ ğŸ› ï¸ utils/                             # UTILITIES & HELPERS

â”‚       â”œâ”€â”€ __init__.py

â”‚       â”œâ”€â”€ date_utils.py                     # Date/time helpers

â”‚       â”‚                                     # to_utc(), parse_iso8601(), age_from_dob()

â”‚       â”‚

â”‚       â”œâ”€â”€ string_utils.py                   # String manipulation

â”‚       â”‚                                     # slugify(), camel_to_snake(), truncate()

â”‚       â”‚

â”‚       â”œâ”€â”€ pagination.py                     # Pagination logic

â”‚       â”‚                                     # class PaginationParams: limit, offset

â”‚       â”‚

â”‚       â”œâ”€â”€ validators.py                     # Custom validators

â”‚       â”‚                                     # validate_email(), validate_phone()

â”‚       â”‚

â”‚       â”œâ”€â”€ decorators.py                     # Reusable decorators

â”‚       â”‚                                     # @retry, @cache, @log_time, @require_auth

â”‚       â”‚

â”‚       â”œâ”€â”€ converters.py                     # Type converters

â”‚       â”‚                                     # str_to_uuid(), dict_to_model()

â”‚       â”‚

â”‚       â””â”€â”€ file_utils.py                     # File operations

â”‚                                             # generate_unique_filename(), safe_path()

â”‚

â”œâ”€â”€ ğŸ§ª tests/                                 # TEST SUITE (Mirror domain structure)

â”‚   â”œâ”€â”€ __init__.py

â”‚   â”œâ”€â”€ conftest.py                           # Pytest fixtures + setup

â”‚   â”‚                                         # @pytest.fixture: async_client, db_session, redis

â”‚   â”‚

â”‚   â”œâ”€â”€ factories/                            # Factory Boy for test data generation

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ user_factory.py

â”‚   â”‚   â”œâ”€â”€ product_factory.py

â”‚   â”‚   â”œâ”€â”€ order_factory.py

â”‚   â”‚   â””â”€â”€ payment_factory.py

â”‚   â”‚

â”‚   â”œâ”€â”€ fixtures/                             # Reusable test fixtures

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ auth_fixtures.py                  # JWT tokens, auth contexts

â”‚   â”‚   â”œâ”€â”€ db_fixtures.py                    # Database setup/teardown

â”‚   â”‚   â””â”€â”€ mocking_fixtures.py               # Mock external services

â”‚   â”‚

â”‚   â”œâ”€â”€ unit/                                 # UNIT TESTS (Business logic in isolation)

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ domains/

â”‚   â”‚   â”‚   â”œâ”€â”€ test_user_service.py          # Test UserService.create_user()

â”‚   â”‚   â”‚   â”œâ”€â”€ test_order_service.py         # Test OrderService.create_order()

â”‚   â”‚   â”‚   â”œâ”€â”€ test_payment_service.py       # Test PaymentService.process_payment()

â”‚   â”‚   â”‚   â””â”€â”€ test_product_service.py

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ utils/

â”‚   â”‚   â”‚   â”œâ”€â”€ test_validators.py

â”‚   â”‚   â”‚   â”œâ”€â”€ test_pagination.py

â”‚   â”‚   â”‚   â””â”€â”€ test_date_utils.py

â”‚   â”‚   â”‚

â”‚   â”‚   â””â”€â”€ security/

â”‚   â”‚       â”œâ”€â”€ test_jwt.py

â”‚   â”‚       â””â”€â”€ test_password.py

â”‚   â”‚

â”‚   â”œâ”€â”€ integration/                          # INTEGRATION TESTS (Service + Repository + DB)

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ test_user_creation.py             # UserService â†’ UserRepository â†’ PostgreSQL

â”‚   â”‚   â”œâ”€â”€ test_order_flow.py                # OrderService â†’ OrderRepository, PaymentService

â”‚   â”‚   â”œâ”€â”€ test_payment_processing.py        # PaymentService â†’ Stripe API (mocked)

â”‚   â”‚   â””â”€â”€ test_product_search.py            # ProductService â†’ Elasticsearch

â”‚   â”‚

â”‚   â”œâ”€â”€ api/                                  # API ENDPOINT TESTS (HTTP contract)

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ test_auth.py                      # POST /v1/auth/login, POST /v1/auth/refresh

â”‚   â”‚   â”œâ”€â”€ test_users.py                     # GET /v1/users, POST /v1/users, PATCH /v1/users/{id}

â”‚   â”‚   â”œâ”€â”€ test_products.py                  # GET /v1/products, POST /v1/products

â”‚   â”‚   â”œâ”€â”€ test_orders.py                    # POST /v1/orders, GET /v1/orders/{id}

â”‚   â”‚   â””â”€â”€ test_payments.py                  # POST /v1/payments/webhook

â”‚   â”‚

â”‚   â”œâ”€â”€ e2e/                                  # END-TO-END TESTS (Full user journeys)

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ test_user_signup.py               # Sign up â†’ Login â†’ Create order

â”‚   â”‚   â”œâ”€â”€ test_complete_checkout.py         # Browse â†’ Add to cart â†’ Checkout â†’ Payment

â”‚   â”‚   â””â”€â”€ test_payment_webhook.py           # Webhook handling, event processing

â”‚   â”‚

â”‚   â””â”€â”€ load/                                 # LOAD & PERFORMANCE TESTS

â”‚       â”œâ”€â”€ __init__.py

â”‚       â”œâ”€â”€ locustfile.py                     # Locust load test scenarios

â”‚       â””â”€â”€ k6_scenarios.js                   # K6 performance test scripts

â”‚

â”œâ”€â”€ ğŸ“š docs/                                  # DOCUMENTATION

â”‚   â”œâ”€â”€ __init__.py

â”‚   â”œâ”€â”€ README.md                             # Project overview, quick start

â”‚   â”‚

â”‚   â”œâ”€â”€ ARCHITECTURE.md                       # HLD (High-Level Design)

â”‚   â”‚                                         # Chapter 5 from your SDD template

â”‚   â”‚                                         # System overview, C4 diagrams, tech stack

â”‚   â”‚

â”‚   â”œâ”€â”€ DEVELOPMENT.md                        # Local development setup

â”‚   â”‚                                         # Prerequisites, env setup, running locally

â”‚   â”‚

â”‚   â”œâ”€â”€ API.md                                # API documentation

â”‚   â”‚                                         # Link to Swagger UI, authentication

â”‚   â”‚

â”‚   â”œâ”€â”€ DEPLOYMENT.md                         # Production deployment guide

â”‚   â”‚                                         # K8s setup, monitoring, scaling

â”‚   â”‚

â”‚   â”œâ”€â”€ RUNBOOK.md                            # Operational runbook

â”‚   â”‚                                         # Incident response, common issues

â”‚   â”‚

â”‚   â”œâ”€â”€ ADR/                                  # Architecture Decision Records

â”‚   â”‚   â”œâ”€â”€ ADR-001-db-choice.md              # Why PostgreSQL vs MongoDB

â”‚   â”‚   â”œâ”€â”€ ADR-002-event-driven.md           # Why Kafka/RabbitMQ for async

â”‚   â”‚   â”œâ”€â”€ ADR-003-ddd-structure.md          # Why DDD bounded contexts

â”‚   â”‚   â””â”€â”€ ADR-004-api-versioning.md         # API versioning strategy

â”‚   â”‚

â”‚   â”œâ”€â”€ CONTRIBUTING.md                       # How to contribute

â”‚   â”‚                                         # Code style, PR process, testing requirements

â”‚   â”‚

â”‚   â”œâ”€â”€ CHANGELOG.md                          # Version history

â”‚   â”‚                                         # v1.0.0 released, breaking changes, new features

â”‚   â”‚

â”‚   â”œâ”€â”€ SECURITY.md                           # Security guidelines

â”‚   â”‚                                         # Vulnerability disclosure, best practices

â”‚   â”‚

â”‚   â””â”€â”€ GLOSSARY.md                           # Domain terminology

â”‚                                             # User, Order, Payment, Product definitions

â”‚

â”œâ”€â”€ ğŸ“Š migrations/                            # DATABASE MIGRATIONS (Alembic)

â”‚   â”œâ”€â”€ __init__.py

â”‚   â”œâ”€â”€ env.py                                # Alembic environment setup

â”‚   â”œâ”€â”€ script.py.mako                        # Migration template

â”‚   â”‚

â”‚   â””â”€â”€ versions/                             # Migration history

â”‚       â”œâ”€â”€ 001_initial_schema.py             # create users, products, orders tables

â”‚       â”œâ”€â”€ 002_add_audit_fields.py           # add created_at, updated_at, deleted_at

â”‚       â”œâ”€â”€ 003_add_payment_table.py

â”‚       â””â”€â”€ ...

â”‚

â”œâ”€â”€ ğŸ³ docker/                                # DOCKER & CONTAINERIZATION

â”‚   â”œâ”€â”€ Dockerfile                            # Production image

â”‚   â”‚                                         # Multi-stage build: builder â†’ runtime

â”‚   â”‚

â”‚   â”œâ”€â”€ Dockerfile.dev                        # Development image

â”‚   â”‚                                         # Includes dev tools, debugger

â”‚   â”‚

â”‚   â”œâ”€â”€ docker-compose.yml                    # Local dev environment

â”‚   â”‚                                         # app, postgres, redis, rabbitmq, elasticsearch

â”‚   â”‚

â”‚   â”œâ”€â”€ docker-compose.prod.yml               # Production-like environment

â”‚   â”‚

â”‚   â””â”€â”€ .dockerignore                         # Exclude files from build context

â”‚

â”œâ”€â”€ ğŸŒ infrastructure/                        # INFRASTRUCTURE AS CODE

â”‚   â”œâ”€â”€ terraform/                            # Terraform configuration

â”‚   â”‚   â”œâ”€â”€ main.tf                           # Main resources

â”‚   â”‚   â”œâ”€â”€ variables.tf                      # Input variables

â”‚   â”‚   â”œâ”€â”€ outputs.tf                        # Output values

â”‚   â”‚   â”œâ”€â”€ provider.tf                       # AWS/GCP provider config

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ networking/

â”‚   â”‚   â”‚   â”œâ”€â”€ vpc.tf                        # Virtual Private Cloud

â”‚   â”‚   â”‚   â””â”€â”€ security_groups.tf            # Firewall rules

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ database/

â”‚   â”‚   â”‚   â”œâ”€â”€ rds.tf                        # PostgreSQL RDS

â”‚   â”‚   â”‚   â””â”€â”€ backup.tf                     # Backup policy

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ cache/

â”‚   â”‚   â”‚   â””â”€â”€ elasticache.tf                # Redis cluster

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ compute/

â”‚   â”‚   â”‚   â”œâ”€â”€ eks.tf                        # Kubernetes (EKS)

â”‚   â”‚   â”‚   â””â”€â”€ ec2.tf                        # EC2 instances

â”‚   â”‚   â”‚

â”‚   â”‚   â”œâ”€â”€ storage/

â”‚   â”‚   â”‚   â”œâ”€â”€ s3.tf                         # S3 buckets

â”‚   â”‚   â”‚   â””â”€â”€ efs.tf                        # Shared storage

â”‚   â”‚   â”‚

â”‚   â”‚   â””â”€â”€ monitoring/

â”‚   â”‚       â”œâ”€â”€ cloudwatch.tf                 # AWS CloudWatch

â”‚   â”‚       â””â”€â”€ alarms.tf                     # Alarms & notifications

â”‚   â”‚

â”‚   â””â”€â”€ helm/                                 # Kubernetes Helm charts

â”‚       â”œâ”€â”€ Chart.yaml                        # Chart metadata

â”‚       â”œâ”€â”€ values.yaml                       # Default values

â”‚       â”œâ”€â”€ values-prod.yaml                  # Production overrides

â”‚       â”œâ”€â”€ values-staging.yaml               # Staging overrides

â”‚       â”‚

â”‚       â””â”€â”€ templates/

â”‚           â”œâ”€â”€ deployment.yaml               # K8s Deployment

â”‚           â”œâ”€â”€ service.yaml                  # K8s Service

â”‚           â”œâ”€â”€ configmap.yaml                # Configuration

â”‚           â”œâ”€â”€ secrets.yaml                  # Secrets (mounted from external source)

â”‚           â”œâ”€â”€ hpa.yaml                      # Horizontal Pod Autoscaler

â”‚           â”œâ”€â”€ pdb.yaml                      # Pod Disruption Budget

â”‚           â”œâ”€â”€ ingress.yaml                  # Ingress controller

â”‚           â””â”€â”€ networkpolicy.yaml            # Network policies

â”‚

â”œâ”€â”€ ğŸ”§ .github/                               # CI/CD WORKFLOWS (GitHub Actions)

â”‚   â””â”€â”€ workflows/

â”‚       â”œâ”€â”€ test.yml                          # Run tests on PR

â”‚       â”‚                                     # Unit, integration, E2E tests

â”‚       â”‚

â”‚       â”œâ”€â”€ lint.yml                          # Code quality checks

â”‚       â”‚                                     # Black, isort, mypy, flake8, pylint

â”‚       â”‚

â”‚       â”œâ”€â”€ security.yml                      # Security scanning

â”‚       â”‚                                     # Bandit, Safety, Snyk, SAST

â”‚       â”‚

â”‚       â”œâ”€â”€ build.yml                         # Build & push Docker image

â”‚       â”‚                                     # ECR, Docker Hub

â”‚       â”‚

â”‚       â””â”€â”€ deploy.yml                        # Deploy to K8s

â”‚                                             # Staging â†’ Production with canary

â”‚

â”œâ”€â”€ ğŸ“‹ scripts/                               # UTILITY SCRIPTS

â”‚   â”œâ”€â”€ __init__.py

â”‚   â”œâ”€â”€ seed_data.py                          # Load initial/test data

â”‚   â”‚                                         # python scripts/seed_data.py

â”‚   â”‚

â”‚   â”œâ”€â”€ cleanup.py                            # Cleanup old data

â”‚   â”‚                                         # python scripts/cleanup.py

â”‚   â”‚

â”‚   â”œâ”€â”€ user_migration.py                     # Data migration scripts

â”‚   â”‚                                         # from_old_db_to_new_db()

â”‚   â”‚

â”‚   â”œâ”€â”€ performance_audit.py                  # Profiling & optimization

â”‚   â”‚                                         # python -m cProfile

â”‚   â”‚

â”‚   â”œâ”€â”€ generate_test_data.py                 # Generate load test data

â”‚   â”‚

â”‚   â””â”€â”€ db_backup.sh                          # Database backup script

â”‚

â”œâ”€â”€ ğŸ“„ Configuration Files (Root)

â”‚   â”œâ”€â”€ pyproject.toml                        # Modern Python project metadata

â”‚   â”‚                                         # [project], [tool.poetry], [tool.black], etc.

â”‚   â”‚

â”‚   â”œâ”€â”€ setup.py                              # Setup script (can be minimal)

â”‚   â”œâ”€â”€ setup.cfg                             # Setup configuration

â”‚   â”‚

â”‚   â”œâ”€â”€ requirements.txt                      # Production dependencies (pinned)

â”‚   â”œâ”€â”€ requirements-dev.txt                  # Development dependencies

â”‚   â”œâ”€â”€ requirements-test.txt                 # Test dependencies

â”‚   â”‚

â”‚   â”œâ”€â”€ .env.example                          # Environment template

â”‚   â”œâ”€â”€ .env.test                             # Test environment

â”‚   â”‚

â”‚   â”œâ”€â”€ .gitignore                            # Git ignore patterns

â”‚   â”œâ”€â”€ .pre-commit-config.yaml               # Pre-commit hooks

â”‚   â”‚

â”‚   â”œâ”€â”€ pytest.ini                            # Pytest configuration

â”‚   â”œâ”€â”€ mypy.ini                              # Type checking config

â”‚   â”œâ”€â”€ .flake8                               # Flake8 linting rules

â”‚   â”œâ”€â”€ .pylintrc                             # Pylint configuration

â”‚   â”œâ”€â”€ .bandit                               # Security scanning config

â”‚   â”‚

â”‚   â”œâ”€â”€ Makefile                              # Common commands

â”‚   â”‚                                         # make test, make lint, make run, make docker-build

â”‚   â”‚

â”‚   â””â”€â”€ docker.env                            # Docker environment variables

â”‚

â””â”€â”€ ğŸ“„ Root Documentation

    â”œâ”€â”€ README.md                             # Quick start + project overview

    â”œâ”€â”€ ROADMAP.md                            # Product & tech roadmap (12-24 months)

    â”œâ”€â”€ CONTRIBUTING.md                       # Contribution guidelines

    â”œâ”€â”€ LICENSE                               # License file

    â””â”€â”€ CODE_OF_CONDUCT.md                    # Community guidelines


```