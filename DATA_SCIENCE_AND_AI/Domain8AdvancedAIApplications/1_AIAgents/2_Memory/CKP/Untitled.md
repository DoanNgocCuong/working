CÃ¡ch lÃ m hiá»‡n táº¡i cá»§a mÃ¬nh. 
1. LÃ  Ä‘á»ƒ Ä‘Ã¡h giÃ¡ káº¿t quáº£ extract memories thÃ¬ lÃ m nhÆ° nÃ o ? 
MÃ¬nh Ä‘Ã£ cho tá»«ng dÃ²ng káº¿t quáº£ extract Ä‘Ã³ Ä‘i qua LLMs Ä‘á»ƒ nÃ³ Ä‘Ã¡nh giÃ¡ káº¿t quáº£ cá»§a user 

```
# PROMPT ÄÃNH GIÃ CHáº¤T LÆ¯á»¢NG MEMORY EXTRACTION

## NGá»® Cáº¢NH
Báº¡n lÃ  má»™t AI Evaluator chuyÃªn nghiá»‡p, nhiá»‡m vá»¥ cá»§a báº¡n lÃ  Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cá»§a má»™t há»‡ thá»‘ng trÃ­ch xuáº¥t "memories" (kÃ½ á»©c) tá»« cÃ¡c Ä‘oáº¡n há»™i thoáº¡i (conversation logs). Má»¥c tiÃªu cá»§a há»‡ thá»‘ng memory lÃ  Ä‘á»ƒ cÃ¡ nhÃ¢n hÃ³a (personalization) cÃ¡c tÆ°Æ¡ng tÃ¡c trong tÆ°Æ¡ng lai.

## INPUT
- **Conversation Log**: ToÃ n bá»™ cuá»™c trÃ² chuyá»‡n giá»¯a `user` vÃ  `assistant`.
- **Extracted Memories**: Danh sÃ¡ch cÃ¡c memories mÃ  há»‡ thá»‘ng Ä‘Ã£ trÃ­ch xuáº¥t Ä‘Æ°á»£c tá»« cuá»™c trÃ² chuyá»‡n Ä‘Ã³ (Ä‘á»‹nh dáº¡ng JSON).

## QUY TRÃŒNH ÄÃNH GIÃ
1. **PhÃ¢n tÃ­ch Conversation Log**: Äá»c ká»¹ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xem cÃ³ thÃ´ng tin nÃ o quan trá»ng Ä‘Ã¡ng Ä‘á»ƒ trÃ­ch xuáº¥t khÃ´ng (dá»±a vÃ o danh sÃ¡ch "CÃ¡c loáº¡i thÃ´ng tin quan trá»ng").
2. **Äá»‘i chiáº¿u vá»›i Extracted Memories**: So sÃ¡nh nhá»¯ng gÃ¬ *nÃªn* Ä‘Æ°á»£c trÃ­ch xuáº¥t vá»›i nhá»¯ng gÃ¬ *Ä‘Ã£* Ä‘Æ°á»£c trÃ­ch xuáº¥t.
3. **Ãp dá»¥ng Logic TÃ­nh Ä‘iá»ƒm**: Cháº¥m Ä‘iá»ƒm dá»±a trÃªn logic vÃ  cÃ´ng thá»©c Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a cháº·t cháº½ bÃªn dÆ°á»›i.
4. **Viáº¿t Feedback**: Cung cáº¥p pháº£n há»“i chi tiáº¿t, mang tÃ­nh xÃ¢y dá»±ng theo Ä‘á»‹nh dáº¡ng output Ä‘Æ°á»£c yÃªu cáº§u.

---

## LOGIC TÃNH ÄIá»‚M (QUAN TRá»ŒNG)

Báº¡n **PHáº¢I** tuÃ¢n theo logic nÃ y Ä‘á»ƒ Ä‘áº£m báº£o Ä‘iá»ƒm sá»‘ pháº£n Ã¡nh Ä‘Ãºng cháº¥t lÆ°á»£ng.

### TrÆ°á»ng há»£p 1: `Extracted Memories` Bá»Š Rá»–NG (`num_memories: 0`)

1. **Kiá»ƒm tra `Conversation Log`**: CÃ³ thÃ´ng tin nÃ o quan trá»ng bá»‹ bá» lá»¡ khÃ´ng (`missing_insights`)?
* **A) Rá»–NG NHÆ¯NG SAI (CÃ³ `missing_insights`)**: Há»‡ thá»‘ng Ä‘Ã£ bá» lá»¡ thÃ´ng tin quan trá»ng.
* `completeness_score`: **0** (ÄÃ¢y lÃ  lá»—i nghiÃªm trá»ng nháº¥t)
* `accuracy_score`, `relevance_score`, `clarity_score`: **0** (KhÃ´ng cÃ³ gÃ¬ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c tiÃªu chÃ­ nÃ y)
* `no_hallucination_score`: **10** (VÃ¬ khÃ´ng cÃ³ memory nÃ o Ä‘Æ°á»£c táº¡o ra)
* `overall_score`: **0** (Pháº£n Ã¡nh lá»—i nghiÃªm trá»ng cá»§a viá»‡c bá» sÃ³t)

* **B) Rá»–NG VÃ€ ÄÃšNG (KhÃ´ng cÃ³ `missing_insights`)**: Cuá»™c há»™i thoáº¡i khÃ´ng cÃ³ gÃ¬ Ä‘Ã¡ng Ä‘á»ƒ lÆ°u.
* `completeness_score`: **10**
* `accuracy_score`, `relevance_score`, `clarity_score`: **10** (VÃ¬ khÃ´ng cÃ³ lá»—i nÃ o)
* `no_hallucination_score`: **10**
* `overall_score`: **10** (Káº¿t quáº£ hoÃ n háº£o)

### TrÆ°á»ng há»£p 2: `Extracted Memories` KHÃ”NG Bá»Š Rá»–NG (`num_memories > 0`)

Cháº¥m Ä‘iá»ƒm tá»«ng tiÃªu chÃ­ (Accuracy, Completeness, Relevance, Clarity, No Hallucination) theo thang 0-10. Sau Ä‘Ã³, tÃ­nh `overall_score` báº±ng **cÃ´ng thá»©c trung bÃ¬nh cÃ³ trá»ng sá»‘** sau:

`overall_score = (0.35 * completeness_score) + (0.35 * accuracy_score) + (0.1 * relevance_score) + (0.1 * clarity_score) + (0.1 * no_hallucination_score)`

**LÃ½ do**: `Completeness` (khÃ´ng bá» sÃ³t) vÃ  `Accuracy` (khÃ´ng sai) lÃ  hai yáº¿u tá»‘ quan trá»ng nháº¥t.

---

## CÃC LOáº I THÃ”NG TIN QUAN TRá»ŒNG Cáº¦N TRÃCH XUáº¤T

Danh sÃ¡ch nÃ y Ä‘Æ°á»£c chia thÃ nh hai pháº§n: tá»« **User** vÃ  tá»« **Assistant**. HÃ£y kiá»ƒm tra cáº©n tháº­n cáº£ hai phÃ­a.

### Tá»« User:
- **ThÃ´ng tin cÃ¡ nhÃ¢n (User Profile)**: TÃªn, tuá»•i, sá»Ÿ thÃ­ch, tÃ­nh cÃ¡ch, nhá»¯ng Ä‘iá»u khÃ´ng thÃ­ch.
- **Tráº¡ng thÃ¡i & Cáº£m xÃºc (User State & Emotions)**: Cáº£m xÃºc hiá»‡n táº¡i (vui, buá»“n, má»‡t má»i), tráº¡ng thÃ¡i nÄƒng lÆ°á»£ng, Ã½ Ä‘á»‹nh (muá»‘n Ä‘i ngá»§, muá»‘n chÆ¡i tiáº¿p).
- **Kiáº¿n thá»©c & Sá»± kiá»‡n (Facts & Events)**: CÃ¡c sá»± tháº­t, sá»± kiá»‡n Ä‘Ã£ xáº£y ra, hoáº·c kiáº¿n thá»©c mÃ  user chia sáº».
- **Sá»Ÿ thÃ­ch & Lá»±a chá»n (Preferences & Choices)**: Lá»±a chá»n giá»¯a cÃ¡c phÆ°Æ¡ng Ã¡n (thÃ­ch váº½ hÆ¡n hÃ¡t), sá»Ÿ thÃ­ch vá» Ä‘á»“ Äƒn, hoáº¡t Ä‘á»™ng.
- **SÃ¡ng táº¡o & TÆ°á»Ÿng tÆ°á»£ng (Creative Inputs)**: CÃ¡c cÃ¢u chuyá»‡n, nhÃ¢n váº­t, Ã½ tÆ°á»Ÿng do user sÃ¡ng táº¡o ra.
- **HÃ nh Ä‘á»™ng & YÃªu cáº§u (Actions & Requests)**: CÃ¡c yÃªu cáº§u user Ä‘Æ°a ra cho assistant.

### Tá»« Assistant:
- **Má»‘i quan há»‡ (Relationships)**: ThÃ´ng tin vá» má»‘i quan há»‡ giá»¯a user vÃ  assistant (vÃ­ dá»¥: láº§n Ä‘áº§u gáº·p, Ä‘Ã£ biáº¿t nhau bao lÃ¢u).
- **ThÃ´ng tin vá» Assistant**: TÃªn, vai trÃ², nguá»“n gá»‘c, má»¥c Ä‘Ã­ch cá»§a assistant.
- **HÃ nh Ä‘á»™ng & Äá» xuáº¥t (Actions & Proposals)**: CÃ¡c Ä‘á» xuáº¥t, yÃªu cáº§u, hoáº·c hÃ nh Ä‘á»™ng mÃ  assistant Ä‘Æ°a ra (vÃ­ dá»¥: "chÃºng ta cÃ¹ng chá»¥p áº£nh nhÃ©", "báº¡n nhá» bá»‘ máº¹ giÃºp Ä‘Æ°á»£c khÃ´ng").
- **ThÃ´ng tin vá» User (inferred)**: Nhá»¯ng gÃ¬ assistant suy luáº­n hoáº·c nháº­n xÃ©t vá» user (vÃ­ dá»¥: "cáº­u thÃ­ch váº½", "cáº­u ráº¥t thÃ´ng minh").

---

## TIÃŠU CHÃ ÄÃNH GIÃ CHI TIáº¾T (Thang Ä‘iá»ƒm 0-10)

### 1. Accuracy (Äá»™ chÃ­nh xÃ¡c)
- **Äá»‹nh nghÄ©a**: Memory cÃ³ pháº£n Ã¡nh chÃ­nh xÃ¡c 100% thÃ´ng tin trong há»™i thoáº¡i khÃ´ng?
- **Checklist**:
- Má»—i chi tiáº¿t trong memory cÃ³ khá»›p vá»›i lá»i nÃ³i gá»‘c khÃ´ng?
- CÃ³ sai lá»‡ch vá» fact, con sá»‘, tÃªn riÃªng, hay hÃ nh Ä‘á»™ng khÃ´ng?

### 2. Completeness (Äá»™ Ä‘áº§y Ä‘á»§)
- **Äá»‹nh nghÄ©a**: Há»‡ thá»‘ng cÃ³ bá» sÃ³t thÃ´ng tin quan trá»ng nÃ o khÃ´ng?
- **Checklist**:
- Kiá»ƒm tra danh sÃ¡ch "CÃ¡c loáº¡i thÃ´ng tin quan trá»ng" á»Ÿ trÃªn.
- CÃ³ thÃ´ng tin nÃ o vá» sá»Ÿ thÃ­ch, tráº¡ng thÃ¡i, má»‘i quan há»‡ bá»‹ bá» lá»¡ khÃ´ng?
- **Äáº·c biá»‡t**: Kiá»ƒm tra cáº£ thÃ´ng tin tá»« assistant, khÃ´ng chá»‰ tá»« user.

### 3. Relevance (Äá»™ liÃªn quan)
- **Äá»‹nh nghÄ©a**: Memory cÃ³ thá»±c sá»± há»¯u Ã­ch cho viá»‡c cÃ¡ nhÃ¢n hÃ³a trong tÆ°Æ¡ng lai khÃ´ng?
- **Checklist**:
- Memory nÃ y cÃ³ giÃºp assistant Ä‘Æ°a ra cÃ¢u tráº£ lá»i tá»‘t hÆ¡n trong tÆ°Æ¡ng lai khÃ´ng?
- NÃ³ cÃ³ pháº£i lÃ  má»™t chi tiáº¿t "Ä‘áº¯t giÃ¡" vá» user hoáº·c má»‘i quan há»‡, hay chá»‰ lÃ  má»™t cÃ¢u nÃ³i thÃ´ng thÆ°á»ng, vÃ´ nghÄ©a?

### 4. Clarity (Äá»™ rÃµ rÃ ng)
- **Äá»‹nh nghÄ©a**: Memory cÃ³ Ä‘Æ°á»£c viáº¿t má»™t cÃ¡ch rÃµ rÃ ng, Ä‘á»™c láº­p vÃ  dá»… hiá»ƒu khÃ´ng?
- **Checklist**:
- Memory cÃ³ Ä‘áº§y Ä‘á»§ chá»§ ngá»¯, vá»‹ ngá»¯ khÃ´ng?
- CÃ³ chá»©a cÃ¡c Ä‘áº¡i tá»« mÆ¡ há»“ nhÆ° "nÃ³", "cÃ¡i Ä‘Ã³", "viá»‡c nÃ y" khÃ´ng?

### 5. No Hallucination (KhÃ´ng bá»‹a Ä‘áº·t)
- **Äá»‹nh nghÄ©a**: Memory cÃ³ chá»©a thÃ´ng tin nÃ o hoÃ n toÃ n khÃ´ng cÃ³ trong há»™i thoáº¡i khÃ´ng?
- **Checklist**:
- Má»i thÃ´ng tin trong memory pháº£i cÃ³ nguá»“n gá»‘c rÃµ rÃ ng tá»« `Conversation Log`.
- Cáº£nh giÃ¡c vá»›i nhá»¯ng suy diá»…n quÃ¡ xa.

---

## Äá»ŠNH Dáº NG OUTPUT (JSON)

Vui lÃ²ng cung cáº¥p Ä‘Ã¡nh giÃ¡ cá»§a báº¡n theo Ä‘Ãºng Ä‘á»‹nh dáº¡ng JSON dÆ°á»›i Ä‘Ã¢y.

```json
{
"num_memories": <sá»‘ lÆ°á»£ng memories Ä‘Æ°á»£c trÃ­ch xuáº¥t>,
"accuracy_score": <Ä‘iá»ƒm 0-10>,
"completeness_score": <Ä‘iá»ƒm 0-10>,
"relevance_score": <Ä‘iá»ƒm 0-10>,
"clarity_score": <Ä‘iá»ƒm 0-10>,
"no_hallucination_score": <Ä‘iá»ƒm 0-10>,
"overall_score": <tÃ­nh theo logic vÃ  cÃ´ng thá»©c Ä‘Ã£ cho>,
"good_points": [
"âœ“ [Äiá»ƒm máº¡nh 1]"
],
"issues": [
"âœ— [Váº¥n Ä‘á» 1]: [Giáº£i thÃ­ch ngáº¯n gá»n]"
],
"missing_insights": [
"â€¢ [ThÃ´ng tin quan trá»ng bá»‹ bá» lá»¡ 1]"
],
"hallucination_examples": [
"ğŸš¨ [Memory bá»‹a Ä‘áº·t]: [Giáº£i thÃ­ch]"
],
"recommendations": [
"â†’ [Äá» xuáº¥t cáº£i thiá»‡n 1]"
]
}
```
```

Báº¡n nghÄ© sao vá» cÃ¡ch lÃ m nÃ y


```

---


<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

## ÄÃ¡nh giÃ¡ cÃ¡ch lÃ m cá»§a báº¡n

CÃ¡ch tiáº¿p cáº­n sá»­ dá»¥ng LLM-as-a-Judge cá»§a báº¡n vá» cÆ¡ báº£n lÃ  **há»£p lÃ½ vÃ  Ä‘Ãºng hÆ°á»›ng**, nhÆ°ng cáº§n bá»• sung thÃªm cÃ¡c cÆ¡ cháº¿ kiá»ƒm soÃ¡t Ä‘á»ƒ Ä‘áº£m báº£o reliability. DÆ°á»›i Ä‘Ã¢y lÃ  phÃ¢n tÃ­ch chi tiáº¿t:[^1]

## Äiá»ƒm máº¡nh cá»§a prompt hiá»‡n táº¡i

### Cáº¥u trÃºc Ä‘Ã¡nh giÃ¡ rÃµ rÃ ng

Prompt cá»§a báº¡n cÃ³ evaluation criteria ráº¥t chi tiáº¿t vá»›i 5 dimensions (Accuracy, Completeness, Relevance, Clarity, No Hallucination), Ä‘iá»u nÃ y ráº¥t quan trá»ng vÃ¬ nghiÃªn cá»©u cho tháº¥y **evaluation criteria lÃ  yáº¿u tá»‘ quyáº¿t Ä‘á»‹nh Ä‘á»™ tin cáº­y** cá»§a LLM-as-a-Judge.[^2]

### Logic scoring Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a cháº·t cháº½

Viá»‡c báº¡n phÃ¢n biá»‡t rÃµ trÆ°á»ng há»£p "rá»—ng Ä‘Ãºng" vs "rá»—ng sai" vÃ  cÃ³ cÃ´ng thá»©c weighted average cá»¥ thá»ƒ lÃ  Ä‘iá»ƒm máº¡nh. CÃ´ng thá»©c `(0.35 * completeness + 0.35 * accuracy + ...)` pháº£n Ã¡nh Ä‘Ãºng táº§m quan trá»ng cá»§a tá»«ng metric.[^3]

### Danh sÃ¡ch thÃ´ng tin quan trá»ng Ä‘áº§y Ä‘á»§

Báº¡n Ä‘Ã£ liá»‡t kÃª chi tiáº¿t cÃ¡c loáº¡i thÃ´ng tin tá»« cáº£ User vÃ  Assistant, giÃºp LLM cÃ³ checklist cá»¥ thá»ƒ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ completeness.[^1]

## Váº¥n Ä‘á» cáº§n cáº£i thiá»‡n

### 1. Thiáº¿u cÆ¡ cháº¿ kiá»ƒm soÃ¡t reliability

**Váº¥n Ä‘á»**: LLM-as-a-Judge cÃ³ thá»ƒ bá»‹ inconsistency vÃ  bias. Báº¡n cáº§n bá»• sung:[^4]

- **Multi-judge ensemble**: Thay vÃ¬ 1 LLM, dÃ¹ng 2-3 LLM judges khÃ¡c nhau vÃ  vote hoáº·c average scores[^5][^3]
- **Pairwise comparison**: NgoÃ i absolute scoring, thÃªm pairwise ranking giá»¯a 2 extracted memories Ä‘á»ƒ tÄƒng reliability[^5]
- **Temperature > 0**: NghiÃªn cá»©u gáº§n Ä‘Ã¢y cho tháº¥y **non-deterministic sampling (temperature > 0) cáº£i thiá»‡n alignment vá»›i human judgment** hÆ¡n lÃ  deterministic (temperature=0)[^2]


### 2. Thiáº¿u human calibration

**Khuyáº¿n nghá»‹**: Báº¡n cáº§n táº¡o **golden dataset** gá»“m 50-100 conversation logs vá»›i ground-truth annotations do con ngÆ°á»i Ä‘Ã¡nh giÃ¡. Sau Ä‘Ã³:[^4][^3]

- Äo inter-rater agreement giá»¯a LLM judge vÃ  human annotators
- TÃ­nh correlation (Kendall's tau hoáº·c Spearman) giá»¯a LLM scores vÃ  human scores
- Äiá»u chá»‰nh prompt hoáº·c weights dá»±a trÃªn káº¿t quáº£


### 3. KhÃ´ng cÃ³ cÆ¡ cháº¿ detect prompt sensitivity

**Váº¥n Ä‘á»**: LLM judges cÃ³ thá»ƒ bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi:

- Thá»© tá»± cá»§a memories trong list[^4]
- CÃ¡ch diá»…n Ä‘áº¡t trong conversation log
- Length bias (thiÃªn vá»‹ memories dÃ i hÆ¡n)[^6]

**Giáº£i phÃ¡p**:

- Random shuffle thá»© tá»± memories vÃ  test consistency
- Cháº¡y evaluation nhiá»u láº§n vá»›i cÃ¡c seed khÃ¡c nhau
- Monitor xem LLM cÃ³ xu hÆ°á»›ng cho Ä‘iá»ƒm cao hÆ¡n vá»›i memories dÃ i khÃ´ng


### 4. Thiáº¿u evaluation cho chÃ­nh LLM judge

Báº¡n Ä‘ang dÃ¹ng LLM Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ extraction system, nhÆ°ng **ai Ä‘Ã¡nh giÃ¡ LLM judge?**. Cáº§n thÃªm:[^6]

- **Calibration metrics**: Äo Ä‘á»™ chÃ­nh xÃ¡c cá»§a judge trÃªn golden dataset
- **Version control**: Track prompt version vÃ  LLM model version[^5]
- **Drift detection**: Monitor xem judge cÃ³ thay Ä‘á»•i behavior theo thá»i gian khÃ´ng


## Recommendations cá»¥ thá»ƒ

### Bá»• sung vÃ o pipeline hiá»‡n táº¡i

```python
# 1. Multi-judge voting
judges = ["gpt-4", "claude-3", "gemini-pro"]
scores = [judge(conversation, memories) for judge in judges]
final_score = np.mean([s['overall_score'] for s in scores])
agreement = calculate_inter_judge_agreement(scores)

# 2. Consistency check vá»›i temperature > 0
runs = [judge(conv, mem, temperature=0.7) for _ in range(3)]
std_dev = np.std([r['overall_score'] for r in runs])
if std_dev > threshold:
    flag_inconsistent_case()

# 3. Human calibration periodic
if sample_count % 50 == 0:
    human_score = get_human_annotation(conversation, memories)
    correlation = calculate_correlation(llm_scores, human_scores)
    update_calibration_report(correlation)
```


### Cáº£i thiá»‡n prompt

ThÃªm vÃ o prompt cá»§a báº¡n:

```
## IMPORTANT GUIDELINES FOR JUDGES
1. **Be consistent**: Apply the same standards across all evaluations
2. **Avoid length bias**: A short, precise memory can be better than a long, verbose one
3. **Focus on facts**: Base your judgment only on what's explicitly in the conversation
4. **Check order independence**: Your score should not depend on the order of memories
```


### Hybrid approach

Káº¿t há»£p LLM-as-a-Judge vá»›i **programmatic checks**:[^3]

- **Automated checks**: DÃ¹ng regex/NLP Ä‘á»ƒ detect hallucination (tÃ¬m entities trong memory nhÆ°ng khÃ´ng cÃ³ trong conversation)
- **Fact verification**: DÃ¹ng NER + entity linking Ä‘á»ƒ verify accuracy
- **Redundancy detection**: DÃ¹ng similarity scores Ä‘á»ƒ detect duplicate memories


## Best practices tá»« industry

Theo cÃ¡c há»‡ thá»‘ng RAG evaluation hiá»‡n Ä‘áº¡i:[^7][^3]

1. **Offline + Online**: Evaluation offline trÃªn test set, nhÆ°ng cÅ©ng monitor production data
2. **CI/CD gates**: TÃ­ch há»£p evaluation vÃ o pipeline, chá»‰ deploy khi scores > threshold
3. **Observability**: Log táº¥t cáº£ judgments Ä‘á»ƒ phÃ¢n tÃ­ch sau
4. **A/B testing**: So sÃ¡nh extraction systems khÃ¡c nhau vá»›i controlled experiments

## Káº¿t luáº­n

Prompt cá»§a báº¡n Ä‘Ã£ **ráº¥t tá»‘t vá» máº·t cáº¥u trÃºc vÃ  logic**, nhÆ°ng Ä‘á»ƒ deploy vÃ o production cáº§n bá»• sung cÃ¡c lá»›p kiá»ƒm soÃ¡t vá» reliability: multi-judge ensemble, human calibration, consistency checking, vÃ  hybrid approach vá»›i programmatic validation. ÄÃ¢y lÃ  best practices mÃ  cÃ¡c cÃ´ng ty nhÆ° Meta, Microsoft, vÃ  DataRobot Ä‘ang Ã¡p dá»¥ng cho LLM evaluation systems.[^1][^3][^6][^5]
<span style="display:none">[^10][^8][^9]</span>

<div align="center">â‚</div>

[^1]: https://arxiv.org/abs/2411.15594

[^2]: https://arxiv.org/abs/2506.13639

[^3]: https://www.getmaxim.ai/articles/rag-evaluation-a-complete-guide-for-2025/

[^4]: https://toloka.ai/blog/llm-as-a-judge-can-ai-systems-evaluate-model-outputs/

[^5]: https://www.statsig.com/perspectives/ai-judge-reliability

[^6]: https://www.datarobot.com/blog/llm-judges/

[^7]: https://orq.ai/blog/rag-evaluation

[^8]: https://www.evidentlyai.com/llm-guide/llm-as-a-judge

[^9]: https://ciir.cs.umass.edu/pubfiles/eval.pdf

[^10]: https://ai.meta.com/research/publications/automatic-rule-extraction-from-long-short-term-memory-networks/

