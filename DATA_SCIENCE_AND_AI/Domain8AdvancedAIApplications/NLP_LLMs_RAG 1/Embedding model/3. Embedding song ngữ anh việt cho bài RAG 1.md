
---
```bash
T·ª•i em ƒë√£ b√≥c t√°ch ph·∫ßn API Search c·ªßa Mem0  
Call song song:  
+, Vector Search: Embedding + Search Mivlus + T√≠nh rerank (code g·ªëc c√≤n ƒëang call l·∫ßn l∆∞·ª£t t·ª´ng ·ª©ng vi√™n ƒë·ªÉ t√≠nh rerank)  
+, Graph Search: (ƒë√£ t·∫Øt)  
  
---  
Hi·ªán em ƒëang log th√¨  
- Embedding OpenAI : 1s => D·ª± ki·∫øn ƒë·ªïi sang embedding kh√°c s·∫Ω nhanh h∆°n  
_ Search Milvus : 70-200ms  
_ T√≠nh reranks: 500ms * s·ªë ·ª©ng vi√™n (do code g·ªëc ƒëang ƒë·ªÉ tu·∫ßn t·ª±) => D·ª± ki·∫øn s·∫Ω b·ªè reranks  
  
=> K·ª≥ v·ªçng: embedding + search <500ms
```


```bash
Anh @ƒêinh H√πng ∆°i, c√≥ model embedding n√†o ti·∫øng vi·ªát nhanh, ƒë·ªô ch√≠nh x√°c ·ªïn ƒë·ªãnh kh√¥ng ·∫°.  
--  
T·ª•i em c√≥ d·ª±ng OSS Mem0 l√™n th√¨ b√™n ƒë√≥ ƒëang d√πng embedding small-3 c·ªßa openAI (1s) + search Milvus (50-200ms) anh ·∫°. => T·ª•i em ƒëang t√≠nh thay small-3 sang 1 con embedding kh√°c ·∫°.
```

```
```bash
DEEP RESEARCH model embedding n√†o song ng·ªØ ti·∫øng anh ti·∫øng vi·ªát nhanh, ƒë·ªô ch√≠nh x√°c ·ªïn ƒë·ªãnh kh√¥ng ·∫°.  
--  
T·ª•i em c√≥ d·ª±ng OSS Mem0 l√™n th√¨ b√™n ƒë√≥ ƒëang d√πng embedding small-3 c·ªßa openAI (1s) + search Milvus (50-200ms) anh ·∫°. => T·ª•i em ƒëang t√≠nh thay small-3 c·ªßa openAI sang 1 con embedding kh√°c ·∫°: si√™u nhanh, ƒë·ªô ch√≠nh x√°c si√™u cao (SOTA embedding anh v√† vi·ªát).
```
```
DEEP RESEARCH model embedding n√†o song ng·ªØ ti·∫øng anh ti·∫øng vi·ªát nhanh, ƒë·ªô ch√≠nh x√°c ·ªïn ƒë·ªãnh kh√¥ng ·∫°.  
--  
T·ª•i em c√≥ d·ª±ng OSS Mem0 l√™n th√¨ b√™n ƒë√≥ ƒëang d√πng embedding small-3 c·ªßa openAI (1s) + search Milvus (50-200ms) anh ·∫°. => T·ª•i em ƒëang t√≠nh thay small-3 c·ªßa openAI sang 1 con embedding kh√°c ·∫°: si√™u nhanh, ƒë·ªô ch√≠nh x√°c si√™u cao (SOTA embedding anh v√† vi·ªát).
```


```1. You are MASTER DEEP RESEARCH about embedding small model, v√† master technical writer embedding model  
1. Your tasks, goals: ƒë√£ m√¥ t·∫£ b√™n tr√™n 
2. Instructions: 
- Deep research ƒë·ªÉ t√¨m model sota 
- B·∫£ng t·ªïng h·ª£p v√† so s√°nh c√°c model 
4. Output 
+, Output format 
- Markdown g·ªìm nhi·ªÅu b·∫£ng so s√°nh 
- M·ªói ph·∫ßn ƒë·ªÅu c·∫ßn c√°c link d·∫´n ch·ª©ng chi ti·∫øt ƒë·ªÉ ng∆∞·ªùi ƒë·ªçc d·ªÖ d√†ng check
+, Ti√™u ch√≠ th√†nh c√¥ng 
- MECE: Benchmark so s√°nh benchmark t·∫•t c·∫£ embedidng ti·∫øng anh vi·ªát t·ªët nh·∫•t thu·ªôc top 5-10 
- T√¨m best practices cho b√†i embedding ti·∫øng anh vi·ªát v√† ƒë·∫°t t·ªëc ƒë·ªô v√† ƒë·ªôc ch√≠nh x√°c si√™u cao v√† si√™u ch√≠nh x√°c

```

# PERFLEXITY: ƒê√ÅNH GI√Å Cho t·ªõ 1 b·∫£n final benchmark to√†n b·ªô c√°c model embedding ƒë√£ ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn trong ƒë√¢y

ƒê√¢y l√† b·∫£n **Final Benchmark Report** to√†n di·ªán nh·∫•t, t·ªïng h·ª£p d·ªØ li·ªáu t·ª´ c√°c b√°o c√°o tr∆∞·ªõc ƒë√≥ v√† ƒë·ªëi chi·∫øu v·ªõi c√°c th√¥ng s·ªë k·ªπ thu·∫≠t m·ªõi nh·∫•t (State-of-the-Art) nƒÉm 2024-2025.

B·∫£ng n√†y so s√°nh tr·ª±c di·ªán **7 model embedding** ƒë√£ ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn trong cu·ªôc th·∫£o lu·∫≠n c·ªßa team b·∫°n, chia th√†nh 3 nh√≥m: **Nh√≥m T·ªëc ƒë·ªô (Speed)**, **Nh√≥m Chuy√™n bi·ªát (Specialist)**, v√† **Nh√≥m SOTA (Next-Gen)**.

***

### üìä 1. B·∫£ng T·ªïng S·∫Øp Benchmark (The Ultimate Cheat Sheet)

| Model Name                                |   NƒÉm    |   Size   |   Dims    | Max Tokens | Latency (GPU T4)  | Latency (CPU) |    VN Performance     |  Milvus Speed  |
| :---------------------------------------- | :------: | :------: | :-------: | :--------: | :---------------: | :-----------: | :-------------------: | :------------: |
| **Nh√≥m 1: The Speedsters (Si√™u T·ªëc)**     |          |          |           |            |                   |               |                       |                |
| `multilingual-e5-small`                   |   2023   | **118M** |  **384**  |    512     |     **~6ms**      |   **~16ms**   |    Kh√° (Top 2023)     |     ‚ö°‚ö°‚ö°‚ö°‚ö°      |
| `MiniLM-L12-v2`                           |   2021   | **118M** |  **384**  |    512     |     **~5ms**      |   **~15ms**   |      Trung b√¨nh       |     ‚ö°‚ö°‚ö°‚ö°‚ö°      |
| **Nh√≥m 2: The Specialists (Chuy√™n Vi·ªát)** |          |          |           |            |                   |               |                       |                |
| `dangvantuan/vietnamese`                  |   2024   |   135M   |    768    |    512     |       ~10ms       |     ~40ms     | **Xu·∫•t s·∫Øc (VN-STS)** |      ‚ö°‚ö°‚ö°       |
| `bge-vi-base` (Fine-tuned)                |   2024   |  ~200M   |    768    |    512     |       ~15ms       |     ~50ms     |        R·∫•t t·ªët        |      ‚ö°‚ö°‚ö°       |
| **Nh√≥m 3: The SOTA (Ch·∫•t l∆∞·ª£ng cao)**     |          |          |           |            |                   |               |                       |                |
| **`jina-embeddings-v3`**                  | **2024** |   570M   | **1024*** |  **8192**  |       ~25ms       |    ~150ms     |    **SOTA (MTEB)**    |   ‚ö°‚ö°‚ö°‚ö° (MRL)   |
| `BAAI/bge-m3`                             |   2024   |   568M   |   1024    |  **8192**  |       ~30ms       |    ~200ms     |   SOTA (Retrieval)    | ‚ö°‚ö°‚ö°‚ö°‚ö° (Binary) |
| **Tham chi·∫øu (Baseline)**                 |          |          |           |            |                   |               |                       |                |
| `OpenAI text-emb-3-small`                 |   2024   |   N/A    |   1536    |    8191    | **1000ms+** (API) |      N/A      |     T·ªët (General)     |   ‚ö°‚ö° (N·∫∑ng)    |

> ***Ghi ch√∫:**
> *   **Dims:** S·ªë chi·ªÅu vector. C√†ng nh·ªè th√¨ Milvus search c√†ng nhanh v√† t·ªën √≠t RAM.
> *   **Milvus Speed:** D·ª±a tr√™n k√≠ch th∆∞·ªõc vector. 384 dims nhanh g·∫•p 4 l·∫ßn 1536 dims.
> *   **MRL:** Jina v3 h·ªó tr·ª£ Matryoshka, c√≥ th·ªÉ c·∫Øt xu·ªëng 128 dims (nhanh h∆°n c·∫£ e5-small).

***

### üîç 2. Ph√¢n T√≠ch Chi Ti·∫øt T·ª´ng ·ª®ng Vi√™n

#### üöÄ Nh√≥m 1: T·ªëi ∆∞u T·ªëc ƒë·ªô (Speed Priority)

D√†nh cho h·ªá th·ªëng t√†i nguy√™n th·∫•p (CPU Only) ho·∫∑c y√™u c·∫ßu ƒë·ªô tr·ªÖ c·ª±c th·∫•p (<20ms).

* **`intfloat/multilingual-e5-small`** [Link](https://huggingface.co/intfloat/multilingual-e5-small)
    * **∆Øu ƒëi·ªÉm:** C√¢n b·∫±ng t·ªët nh·∫•t gi·ªØa T·ªëc ƒë·ªô v√† Ch·∫•t l∆∞·ª£ng cho m√°y c·∫•u h√¨nh y·∫øu. Support ƒëa ng·ªØ t·ªët h∆°n MiniLM.
    * **Nh∆∞·ª£c ƒëi·ªÉm:** Context window qu√° ng·∫Øn (512 tokens) khi·∫øn n√≥ kh√¥ng ph√π h·ª£p ƒë·ªÉ embed c√°c vƒÉn b·∫£n ph√°p l√Ω d√†i hay l·ªãch s·ª≠ chat d√†i trong Mem0.
    * **K·∫øt lu·∫≠n:** Ch·ªçn n·∫øu **ch·ªâ c√≥ CPU**.
* **`paraphrase-multilingual-MiniLM-L12-v2`** [Link](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2)
    * **∆Øu ƒëi·ªÉm:** Model "huy·ªÅn tho·∫°i" v·ªÅ t·ªëc ƒë·ªô. Nh·ªè, nh·∫π, ch·∫°y ƒë∆∞·ª£c c·∫£ tr√™n Edge devices.
    * **Nh∆∞·ª£c ƒëi·ªÉm:** ƒê√£ l·ªói th·ªùi (2021). ƒê·ªô ch√≠nh x√°c ng·ªØ nghƒ©a (Semantic Accuracy) thua xa c√°c model 2024, ƒë·∫∑c bi·ªát v·ªõi c√°c c√¢u ti·∫øng Vi·ªát ph·ª©c t·∫°p.
    * **K·∫øt lu·∫≠n:** ‚ùå Kh√¥ng khuy·∫øn ngh·ªã cho d·ª± √°n m·ªõi nƒÉm 2025.


#### üáªüá≥ Nh√≥m 2: T·ªëi ∆∞u Ti·∫øng Vi·ªát (Vietnamese Priority)

D√†nh cho h·ªá th·ªëng **thu·∫ßn ti·∫øng Vi·ªát** (User ch·ªâ h·ªèi ti·∫øng Vi·ªát, Data ch·ªâ c√≥ ti·∫øng Vi·ªát).

* **`dangvantuan/vietnamese-embedding`** [Link](https://huggingface.co/dangvantuan/vietnamese-embedding)
    * **Core:** D·ª±a tr√™n **PhoBERT** (State-of-the-art cho NLP ti·∫øng Vi·ªát).
    * **∆Øu ƒëi·ªÉm:** Hi·ªÉu s√¢u s·∫Øc ti·∫øng l√≥ng, t·ª´ gh√©p, ng·ªØ ph√°p Vi·ªát Nam. ƒêi·ªÉm benchmark VN-STS (ƒë·ªô t∆∞∆°ng ƒë·ªìng c√¢u) c·ª±c cao (~88.33).
    * **Nh∆∞·ª£c ƒëi·ªÉm:**
        * Vector 768 dims (N·∫∑ng g·∫•p ƒë√¥i e5-small).
        * Kh·∫£ nƒÉng ti·∫øng Anh h·∫°n ch·∫ø. N·∫øu User h·ªèi "What is the policy?" (ti·∫øng Anh) t√¨m trong data ti·∫øng Vi·ªát, model n√†y s·∫Ω l√†m kh√¥ng t·ªët b·∫±ng Jina/E5.
    * **K·∫øt lu·∫≠n:** Ch·ªçn n·∫øu **99% Input/Output l√† Ti·∫øng Vi·ªát**.


#### üß† Nh√≥m 3: SOTA - Th·∫ø h·ªá m·ªõi (Performance Priority)

D√†nh cho h·ªá th·ªëng Production c·∫ßn ch·∫•t l∆∞·ª£ng ngang/h∆°n OpenAI nh∆∞ng ch·∫°y Local.

* **`jina-embeddings-v3` (üèÜ Winner)** [Link](https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/)
    * **C√¥ng ngh·ªá:** S·ª≠ d·ª•ng **LoRA Adapters** ƒë·ªÉ t·ªëi ∆∞u ri√™ng cho t·ª´ng task (Retrieval vs Separation).
    * **Killer Feature:** **Matryoshka Representation Learning**. B·∫°n c√≥ th·ªÉ c·∫•u h√¨nh model output ra vector 128 chi·ªÅu (thay v√¨ 1024).
        * L√∫c n√†y: **Nhanh h∆°n e5-small (128 vs 384 dims) nh∆∞ng Th√¥ng minh h∆°n (Context 8192 vs 512).**
    * **K·∫øt lu·∫≠n:** **BEST CHOICE** n·∫øu b·∫°n c√≥ 1 con GPU nh·ªè (T4/A10).
* **`BAAI/bge-m3`** [Link](https://github.com/FlagOpen/FlagEmbedding)
    * **∆Øu ƒëi·ªÉm:** H·ªó tr·ª£ **Sparse Retrieval** (t√¨m ki·∫øm t·ª´ kh√≥a hi·∫øm - gi·ªëng ElasticSearch) t√≠ch h·ª£p trong c√πng 1 model.
    * **K·∫øt lu·∫≠n:** Ch·ªçn n·∫øu Mem0 c·ªßa b·∫°n c·∫ßn t√¨m ki·∫øm ch√≠nh x√°c c√°c m√£ s·ªë, t√™n ri√™ng l·∫° (Hybrid Search).

***

### üí° 3. Ma tr·∫≠n Ra Quy·∫øt ƒê·ªãnh (Final Recommendation)

D·ª±a tr√™n h·∫° t·∫ßng v√† y√™u c·∫ßu c·ªßa team b·∫°n, ƒë√¢y l√† l·ªùi khuy√™n cu·ªëi c√πng:


| H·∫° t·∫ßng c·ªßa b·∫°n | Y√™u c·∫ßu nghi·ªáp v·ª• | **Model n√™n ch·ªçn** | C·∫•u h√¨nh t·ªëi ∆∞u |
| :-- | :-- | :-- | :-- |
| **Server c√≥ GPU (T4/A10)** | Song ng·ªØ Anh-Vi·ªát, C·∫ßn ch√≠nh x√°c cao | **`jina-embeddings-v3`** | `dim=512` (Matryoshka), `fp16` |
| **Server ch·ªâ c√≥ CPU** | C·∫ßn nhanh, T√†i nguy√™n √≠t | **`multilingual-e5-small`** | `quantization=int8` (ONNX) |
| **Server ch·ªâ c√≥ CPU** | Thu·∫ßn Ti·∫øng Vi·ªát, VƒÉn b·∫£n ng·∫Øn | **`dangvantuan/vietnamese`** | `batch_size=32` |
| **C·∫ßn t√¨m t·ª´ kh√≥a d·ªã** | Search m√£ h·ª£p ƒë·ªìng, m√£ s·ªë thu·∫ø | **`BAAI/bge-m3`** | D√πng Sparse Vector c·ªßa M3 |

**üëâ L·ªùi khuy√™n cho Mem0:**
H√£y d√πng **`jina-embeddings-v3`** v·ªõi c·∫•u h√¨nh **Matryoshka (512 dims)**.

* N√≥ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ ƒë·ªô tr·ªÖ 1s (xu·ªëng c√≤n ~30ms).
* N√≥ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ Milvus ch·∫≠m (vector 512 nh·∫π h∆°n 1536 c·ªßa OpenAI 3 l·∫ßn).
* N√≥ x·ª≠ l√Ω ƒë∆∞·ª£c vƒÉn b·∫£n d√†i (8192 tokens) cho b·ªô nh·ªõ d√†i h·∫°n c·ªßa AI.
<span style="display:none">[^1][^10][^11][^12][^13][^14][^15][^16][^17][^18][^19][^2][^20][^21][^3][^4][^5][^6][^7][^8][^9]</span>

<div align="center">‚ÅÇ</div>

[^1]: paste.txt

[^2]: https://www.facebook.com/groups/vietaicommunity/posts/500908625841511/

[^3]: https://huggingface.co/dangvantuan/vietnamese-embedding

[^4]: https://arxiv.org/html/2507.21500v1

[^5]: https://www.studocu.vn/vn/document/dai-hoc-khoa-hoc-xa-hoi-va-nhan-van-dai-hoc-quoc-gia-thanh-pho-ho-chi-minh/toan-cao-cap/danh-gia-chat-luong-he-thong-rag-cac-chi-so-va-phuong-phap-thuattoan/139108950

[^6]: https://dataloop.ai/library/model/dangvantuan_vietnamese-embedding/

[^7]: https://agentset.ai/embeddings/compare/jina-embeddings-v3-vs-baaibge-m3

[^8]: https://jina.ai/models/jina-embeddings-v3/

[^9]: https://dataloop.ai/library/model/dangvantuan_vietnamese-document-embedding/

[^10]: https://huggingface.co/dangvantuan/vietnamese-document-embedding

[^11]: https://leaderboard.nexgencompany.ai/mteb

[^12]: https://research.aimultiple.com/open-source-embedding-models/

[^13]: https://aclanthology.org/2023.findings-emnlp.925.pdf

[^14]: https://arxiv.org/html/2503.07470

[^15]: https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/

[^16]: https://huggingface.co/BAAI/bge-m3

[^17]: https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

[^18]: https://www.facebook.com/protonxai/posts/benchmark-c√°c-embedding-ti·∫øng-vi·ªát-cho-b√†i-truy-xu·∫•t-th√¥ng-tin/933366875259120/

[^19]: https://www.facebook.com/groups/machinelearningcoban/posts/1970098033447594/

[^20]: https://elephas.app/blog/best-embedding-models

[^21]: https://sentic.net/sea-bed.pdf

