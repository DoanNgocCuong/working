# ğŸ¯ ÄÃšC Káº¾T CUá»I CÃ™NG: KHI NÃ€O TÄ‚NG WORKERS

Dá»±a trÃªn phÃ¢n tÃ­ch chi tiáº¿t vÃ  test thá»±c táº¿ vá»›i mem0-server, Ä‘Ã¢y lÃ  káº¿t luáº­n vá» **khi nÃ o nÃªn tÄƒng workers**:

---

## âš¡ QUY Táº®C VÃ€NG (Golden Rules)

### ğŸŸ¢ **DEFAULT: Báº¯t Ä‘áº§u vá»›i 1 WORKER**

Ãp dá»¥ng cho **Táº¤T Cáº¢** async I/O-bound applications:

- âœ… FastAPI/Flask/Django async
- âœ… Web APIs gá»i database/cache/external services
- âœ… Microservices vá»›i async HTTP clients
- âœ… Workload >70% I/O time

**LÃ½ do:**

- 1 worker + async event loop xá»­ lÃ½ Ä‘Æ°á»£c **hÃ ng nghÃ¬n concurrent connections**
- CPU idle tháº¥p nháº¥t (20-30%)
- Memory tiáº¿t kiá»‡m nháº¥t
- Debug Ä‘Æ¡n giáº£n nháº¥t

---

### ğŸ”´ **CHá»ˆ TÄ‚NG WORKERS KHI:**

Thá»a mÃ£n **ÃT NHáº¤T 1** trong cÃ¡c Ä‘iá»u kiá»‡n sau:

#### 1ï¸âƒ£ **CPU-bound Operations â‰¥30% Total Time**

```python
# âŒ Cáº§n workers: Heavy CPU computation
@app.post("/predict")
async def ml_inference(data):
    # 500ms CPU blocking
    result = model.predict(data)  # Sync blocking!
    return result

# Total: 500ms CPU (100% CPU-bound)
# â†’ Cáº§n 2-4 workers Ä‘á»ƒ táº­n dá»¥ng multi-core
```

**Dáº¥u hiá»‡u:**

- ML inference, image/video processing
- Data transformation (pandas, numpy)
- Cryptography operations
- CPU time â‰¥30% total response time

**Giáº£i phÃ¡p:**

```yaml
# Option 1: Scale workers
command: uvicorn main:app --workers 4

# Option 2: Offload to ProcessPoolExecutor (KHUYáº¾N NGHá»Š)
cpu_pool = ProcessPoolExecutor(max_workers=4)
result = await loop.run_in_executor(cpu_pool, heavy_compute)
```

---

#### 2ï¸âƒ£ **Legacy Blocking Code KhÃ´ng Thá»ƒ Refactor**

```python
# âŒ Cáº§n workers: Blocking sync library
import requests  # Not async!

@app.get("/external")
async def call_api():
    # Sync blocking worker!
    response = requests.get("https://api.example.com")
    return response.json()
```

**Giáº£i phÃ¡p tá»‘t:**

```python
# âœ… Migrate to async (KHUYáº¾N NGHá»Š)
import httpx

@app.get("/external")
async def call_api():
    async with httpx.AsyncClient() as client:
        response = await client.get("https://api.example.com")
    return response.json()
```

**Giáº£i phÃ¡p táº¡m:**

```yaml
# Náº¿u KHÃ”NG THá»‚ refactor â†’ dÃ¹ng workers
command: uvicorn main:app --workers 2
```

---

#### 3ï¸âƒ£ **High Traffic â‰¥10,000 Requests/Second**

**Load test chá»©ng minh bottleneck:**

```bash
# Test vá»›i 1 worker
wrk -t12 -c1000 -d30s http://localhost:8000/api

Results:
  Requests/sec:   8,500
  Latency p99:    800ms  âŒ (quÃ¡ cao)
  CPU usage:      95%    âŒ (saturated)
  
# Test vá»›i 4 workers
Results:
  Requests/sec:   15,000  âœ… (+76%)
  Latency p99:    250ms   âœ… (-69%)
  CPU usage:      85%     âœ… (balanced)
```

**Quy táº¯c:**

- 1 worker async thÆ°á»ng handle: **5K-10K reqs/s**
- Náº¿u traffic >10K reqs/s â†’ cáº§n 2-4 workers

---

#### 4ï¸âƒ£ **Load Test Cáº£i Thiá»‡n â‰¥30%**

**Decision matrix:**

|Workers|Req/s|Lat p99|CPU%|Memory|Verdict|
|---|---|---|---|---|---|
|1|8,500|800ms|95%|400MB|âš ï¸ Bottleneck|
|2|12,000|500ms|85%|700MB|âœ… Cáº£i thiá»‡n 41%|
|4|15,000|250ms|80%|1.3GB|âœ… Cáº£i thiá»‡n 76%|

**Quy táº¯c:** Scale náº¿u:

- Throughput tÄƒng â‰¥30%
- Latency p99 giáº£m â‰¥30%
- CPU < 90% under load
- Memory Ä‘á»§ (cÃ³ â‰¥2GB available)

---

## ğŸš« **KHÃ”NG TÄ‚NG WORKERS KHI:**

### âŒ Anti-patterns (trÃ¡nh)

#### 1. Code 100% Async + I/O-bound

```python
# âœ… Giá»¯ 1 worker: Pure async I/O
@app.get("/users")
async def get_users():
    users = await db.query()     # Async
    cache = await redis.get()    # Async
    result = await api.call()    # Async
    return users

# Total: 350ms
# CPU: 10ms (3%)
# I/O: 340ms (97%)
# â†’ 1 worker Äá»¦
```

#### 2. CPU Idle Cao (>50%)

```bash
# 4 workers: CPU idle 116% â†’ Overhead cao
# 1 worker:  CPU idle  54% â†’ Tá»‘i Æ°u
```

#### 3. ChÆ°a Fix Root Cause

```python
# âŒ SAI: Scale workers trÆ°á»›c khi fix N+1 queries
# N+1 query problem
for user in users:
    posts = await db.get_posts(user.id)  # N queries!

# âœ… ÄÃšNG: Fix N+1 trÆ°á»›c
post_map = await db.get_all_posts(user_ids)  # 1 query
```

#### 4. Memory Háº¡n Cháº¿

```
1 worker:  400MB
2 workers: 700MB
4 workers: 1.3GB

â†’ Náº¿u container limit 1GB â†’ chá»‰ dÃ¹ng 1-2 workers
```

---

## ğŸ“Š CASE STUDY: mem0-server

### Káº¿t quáº£ test thá»±c táº¿ cá»§a Báº N:

|Metric|4 Workers|2 Workers|1 Worker|
|---|---|---|---|
|**CPU Idle**|116.21% âš ï¸|54.96-61.55%|**53.70%** âœ…|
|**CPU Peak**|415.16% âŒ|130-415%|407-408% âš ï¸|
|**Memory**|819MB|622MB|**386MB** âœ…|
|**PIDS**|3,610|3,498|~2,500 âœ…|
|**30 CCU**|Treo|Treo|Treo (408% CPU) âŒ|
|**50 CCU**|Treo|?|Treo (407% CPU) âŒ|

### PhÃ¢n tÃ­ch workload:

```python
# mem0-server flow:
async def search(query):
    chunks = chunk_text(query)          # 50ms - CPU
    vectors = await embed(chunks)        # 200ms - I/O
    results = await milvus.search()      # 100ms - I/O
    summary = await llm.generate()       # 100ms - I/O
    await milvus.insert()                # 50ms - I/O
    return results

# Total: 500ms
# CPU: 50ms (10%)
# I/O: 450ms (90%)
# â†’ I/O-bound workload âœ…
```

### âœ… Káº¾T LUáº¬N: GIá»® 1 WORKER

**LÃ½ do:**

1. âœ… Code 100% async (FastAPI + async clients)
2. âœ… Workload 90% I/O-bound
3. âœ… CPU idle tháº¥p nháº¥t (53.70% vs 116%)
4. âœ… Memory tiáº¿t kiá»‡m 38-54%
5. âœ… Traffic vá»«a pháº£i (<5K reqs/s)

**ğŸ”´ Váº¥n Ä‘á» thá»±c sá»±:**

KhÃ´ng pháº£i sá»‘ workers, mÃ  lÃ :

1. **CPU limit quÃ¡ tháº¥p (4 cores)**
    
    - 30-50 CCU â†’ CPU 407-408% â†’ vÆ°á»£t limit â†’ treo
    - Cáº§n tÄƒng CPU limit lÃªn **6-8 cores**
2. **CPU idle cao (53.70%)**
    
    - Logging overhead
    - Background tasks
    - Cáº§n tá»‘i Æ°u xuá»‘ng <30%

---

## ğŸ¯ DECISION TREE THá»°C CHIáº¾N

```
Báº®T Äáº¦U: 1 WORKER (default)
   â†“
[1] Code cÃ³ 100% async/await?
   NO â†’ [2] CÃ³ thá»ƒ refactor?
          YES â†’ Refactor â†’ [3]
          NO â†’ DÃ™NG 2-4 WORKERS âš ï¸
   YES â†’ [3]

[3] Workload type?
   I/O-bound (â‰¥70% I/O) â†’ [4]
   CPU-bound (â‰¥70% CPU) â†’ DÃ™NG 2-4 WORKERS âš ï¸
   Mixed â†’ [5]

[4] Traffic level?
   Low (<5K reqs/s) â†’ GIá»® 1 WORKER âœ…
   Medium (5-10K) â†’ Load test â†’ [6]
   High (â‰¥10K) â†’ DÃ™NG 2-4 WORKERS âš ï¸

[5] CPU ratio?
   <30% CPU â†’ GIá»® 1 WORKER âœ…
   30-50% â†’ Load test â†’ [6]
   >50% â†’ DÃ™NG 2-4 WORKERS âš ï¸

[6] Load test results?
   CPU <80% & latency OK â†’ GIá»® 1 WORKER âœ…
   CPU >90% â†’ DÃ™NG 2 WORKERS âš ï¸
   CPU maxed + errors â†’ DÃ™NG 4 WORKERS âš ï¸
```

---

## ğŸ“‹ CHECKLIST THá»°C HÃ€NH

### TrÆ°á»›c khi scale workers:

- [ ] âœ… ÄÃ£ profile code (async/sync ratio >90%)
- [ ] âœ… ÄÃ£ fix N+1 queries
- [ ] âœ… ÄÃ£ migrate sync libraries â†’ async (requests â†’ httpx)
- [ ] âœ… ÄÃ£ cháº¡y load test vá»›i 1 worker
- [ ] âœ… CPU >90% under load OR latency p99 >1s
- [ ] âœ… Memory Ä‘á»§ (cÃ³ â‰¥2GB available)

### Khi scale workers:

- [ ] âœ… Load test cáº£i thiá»‡n â‰¥30%
- [ ] âœ… Monitor 1-2 tuáº§n: CPU, memory, latency
- [ ] âœ… So sÃ¡nh metrics before/after
- [ ] âœ… Rollback náº¿u khÃ´ng cáº£i thiá»‡n

---

## ğŸ”§ GIáº¢I PHÃP CHO mem0-server

### Ngáº¯n háº¡n (URGENT - TrÃ¡nh treo):

```yaml
# docker-compose-app.yml
deploy:
  resources:
    limits:
      cpus: '6.0'  # TÄƒng tá»« 4.0 â†’ 6.0 cores
      memory: 2G
command: uvicorn main:app --host 0.0.0.0 --port 8000 --workers 1 --loop uvloop
```

**Dá»± kiáº¿n:**

- 30 CCU: CPU ~65% (khÃ´ng vÆ°á»£t limit)
- 50 CCU: CPU ~85% (khÃ´ng vÆ°á»£t limit)
- 80 CCU: CPU ~100% (max capacity)

### Trung háº¡n (Tá»‘i Æ°u CPU idle):

```python
# main.py - Tá»‘i Æ°u logging
@app.middleware("http")
async def add_process_time_header(request, call_next):
    start = time.time()
    response = await call_next(request)
    process_time = time.time() - start
    
    # Chá»‰ log náº¿u cháº­m hoáº·c error
    if process_time > 0.5 or response.status_code >= 400:
        logging.warning(
            f"{request.method} {request.url.path} - {process_time:.4f}s"
        )
    
    return response
```

**Má»¥c tiÃªu:** CPU idle giáº£m tá»« 53.70% â†’ <30%

### DÃ i háº¡n (Scale):

```python
# Option 1: Auto-scaling CPU limit
if current_ccu > 50:
    cpus = min(8.0, current_ccu * 0.08)  # 8% CPU per CCU
else:
    cpus = 6.0

# Option 2: Scale ngang (nhiá»u containers)
replicas = ceil(current_ccu / 50)  # Má»—i container handle 50 CCU
```

---

## ğŸ“ CÃ”NG THá»¨C Tá»”NG QUÃT

### CÃ´ng thá»©c tÃ­nh workers tá»‘i Æ°u:

#### Cho I/O-bound (>70% I/O time):

```python
optimal_workers = 1  # Always!

# Trá»« khi:
if traffic > 10_000:  # reqs/s
    optimal_workers = 2
if traffic > 20_000:
    optimal_workers = 4
```

#### Cho CPU-bound (>70% CPU time):

```python
optimal_workers = min(
    CPU_cores,
    concurrent_requests / (cpu_time_per_req / target_response_time)
)

# VÃ­ dá»¥:
# - 4 CPU cores
# - 100 concurrent requests
# - 500ms CPU per request
# - Target: 200ms response time
optimal_workers = min(4, 100 / (500/200))
                = min(4, 40)
                = 4 workers
```

#### Cho Mixed workload:

```python
cpu_ratio = cpu_time / total_time

if cpu_ratio < 0.3:
    optimal_workers = 1
elif cpu_ratio < 0.5:
    optimal_workers = 2
else:
    optimal_workers = min(CPU_cores, 4)
```

---

## ğŸ’¡ Káº¾T LUáº¬N CUá»I CÃ™NG

### ğŸŸ¢ Quy táº¯c Ä‘Æ¡n giáº£n:

```
1. Báº®T Äáº¦U vá»›i 1 WORKER (async apps)

2. MONITOR 1-2 tuáº§n

3. CHá»ˆ SCALE khi:
   âœ… Load test chá»©ng minh cáº£i thiá»‡n â‰¥30%
   âœ… CPU â‰¥90% under production load
   âœ… CÃ³ CPU-bound khÃ´ng thá»ƒ offload
   âœ… Traffic â‰¥10K reqs/s

4. KHÃ”NG SCALE khi:
   âŒ Code 100% async + I/O-bound
   âŒ CPU idle >50% (overhead cao)
   âŒ ChÆ°a fix blocking code/N+1
   âŒ Memory háº¡n cháº¿
```

### ğŸ¯ Cho mem0-server:

```
âœ… GIáº¢I PHÃP: GIá»® 1 WORKER + TÄ‚NG CPU LIMIT

Config:
- Workers: 1 (async I/O-bound)
- CPU limit: 6.0 cores (tá»« 4.0)
- Memory: 2GB (giá»¯ nguyÃªn)

Expected:
- CPU idle: <30% (sau optimize logging)
- 30 CCU: ~65% CPU (khÃ´ng treo)
- 50 CCU: ~85% CPU (khÃ´ng treo)
- 80 CCU: ~100% CPU (max capacity)
```

---

**TL;DR:**

> **â€œVá»›i async I/O-bound apps: 1 worker + tÄƒng CPU limit > nhiá»u workersâ€**
> 
> TÄƒng workers chá»‰ khi: CPU-bound (â‰¥30%), high traffic (â‰¥10K reqs/s), hoáº·c load test chá»©ng minh cáº£i thiá»‡n â‰¥30%.



---
# CÃ³ pháº£i fast API Ä‘i theo sá»‘ core vá»›i sá»‘ unicorn worker ?
  

Äang kiá»ƒm tra cáº¥u hÃ¬nh hiá»‡n táº¡i vÃ  tÃ¬m tÃ i liá»‡u vá» best practices:

  
  

[3 tools called]

  
  

Äang kiá»ƒm tra script calculator Ä‘á»ƒ hiá»ƒu cÃ´ng thá»©c:

  
  

[1 tool called]

  
  

## Tráº£ lá»i: FastAPI/Uvicorn workers vÃ  CPU cores

  

KhÃ´ng pháº£i luÃ´n luÃ´n. Sá»‘ workers phá»¥ thuá»™c vÃ o loáº¡i workload.

  

---

  

## CÃ´ng thá»©c chung

  

### 1. CPU-bound workload (ML, computation)

  

```

Workers = CPU cores (1:1)

```

  

VÃ­ dá»¥:

- 4 cores â†’ 4 workers

- 8 cores â†’ 8 workers

  

LÃ½ do: Má»—i worker cáº§n 1 core Ä‘á»ƒ cháº¡y CPU-intensive code.

  

---

  

### 2. I/O-bound workload (API, database, HTTP calls)

  

```

Workers = (2 Ã— CPU cores) + 1

```

  

VÃ­ dá»¥:

- 2 cores â†’ 5 workers (2Ã—2+1)

- 4 cores â†’ 9 workers (2Ã—4+1)

  

LÃ½ do: Workers chá» I/O, cÃ³ thá»ƒ cháº¡y nhiá»u workers hÆ¡n sá»‘ cores.

  

---

  

### 3. Async I/O-bound (FastAPI vá»›i async/await)

  

```

Workers = 1 (default) â†’ Scale up náº¿u cáº§n

```

  

LÃ½ do: 1 worker + async event loop cÃ³ thá»ƒ xá»­ lÃ½ hÃ ng nghÃ¬n concurrent connections.

  

---

  

## Ãp dá»¥ng cho FastAPI

  

### TrÆ°á»ng há»£p 1: Pure async I/O-bound (khuyáº¿n nghá»‹)

  

```python

@app.get("/users")

async def get_users():

Â  Â  users = await db.query() Â  Â  Â # Async I/O

Â  Â  cache = await redis.get() Â  Â  Â # Async I/O

Â  Â  result = await api.call() Â  Â  Â # Async I/O

Â  Â  return users

```

  

CÃ´ng thá»©c:

```

Workers = 1 (báº¯t Ä‘áº§u)

â†’ TÄƒng náº¿u: CPU > 90% HOáº¶C throughput < target

```

  

VÃ­ dá»¥:

- 2 cores â†’ Báº¯t Ä‘áº§u vá»›i 1 worker

- Náº¿u CPU > 90% â†’ TÄƒng lÃªn 2 workers

- Náº¿u CPU < 50% nhÆ°ng throughput tháº¥p â†’ CÃ³ thá»ƒ tÄƒng lÃªn 4 workers

  

---

  

### TrÆ°á»ng há»£p 2: Mixed workload (CPU + I/O)

  

```python

@app.post("/search")

async def search(query):

Â  Â  embedding = await call_api(query) Â # I/O: 200ms

Â  Â  results = heavy_compute(embedding) Â  # CPU: 300ms

Â  Â  return results

```

  

CÃ´ng thá»©c:

```

Workers = CPU cores (1:1)

â†’ Hoáº·c: Workers = (2 Ã— CPU cores) + 1 náº¿u I/O > CPU

```

  

VÃ­ dá»¥:

- 2 cores â†’ 2-5 workers (tÃ¹y I/O ratio)

- 4 cores â†’ 4-9 workers

  

---

  

### TrÆ°á»ng há»£p 3: CPU-bound (ML inference)

  

```python

@app.post("/predict")

async def predict(data):

Â  Â  result = model.predict(data) Â # CPU-bound: 500ms

Â  Â  return result

```

  

CÃ´ng thá»©c:

```

Workers = CPU cores (1:1)

```

  

VÃ­ dá»¥:

- 4 cores â†’ 4 workers

  

---

  

## So sÃ¡nh cÃ¡c cÃ´ng thá»©c

  

| Workload Type | Formula | 2 Cores | 4 Cores | 8 Cores |

|---------------|---------|---------|---------|---------|

| **CPU-bound** | `cores` | 2 | 4 | 8 |

| **I/O-bound (sync)** | `(2Ã—cores)+1` | 5 | 9 | 17 |

| **Async I/O-bound** | `1 â†’ scale` | 1-4 | 1-8 | 1-16 |

  

---

  

## Ãp dá»¥ng cho mem0-server

  

### Hiá»‡n táº¡i:

- CPU limit: 2 cores

- Workers: 2

- Workload: Mixed (I/O + CPU)

  

### PhÃ¢n tÃ­ch:

  

| Metric | Value | ÄÃ¡nh giÃ¡ |

|--------|-------|----------|

| CPU @ 100 CCU | 110% (1 worker) â†’ 55% (2 workers) | âœ… OK |

| Workload type | Mixed (I/O + CPU) | âš ï¸ Cáº§n monitor |

| Formula | `cores` hoáº·c `(2Ã—cores)+1` | âš ï¸ TÃ¹y I/O ratio |

  

### Khuyáº¿n nghá»‹:

  

Option 1: Giá»¯ 2 workers (hiá»‡n táº¡i)

- CPU: ~55% â†’ OK

- Memory: ~500MB â†’ OK

- PhÃ¹ há»£p náº¿u I/O ratio ~50-70%

  

Option 2: TÄƒng lÃªn 4-5 workers (náº¿u cáº§n)

- Náº¿u CPU < 50% nhÆ°ng throughput tháº¥p

- Náº¿u latency cao

- Memory: ~1GB â†’ Cáº§n tÄƒng memory limit

  

---

  

## Quy táº¯c thá»±c hÃ nh

  

### BÆ°á»›c 1: XÃ¡c Ä‘á»‹nh workload type

  

```python

# Check CPU vs I/O ratio

# Náº¿u CPU time > 30% total â†’ CPU-bound

# Náº¿u I/O time > 70% total â†’ I/O-bound

```

  

### BÆ°á»›c 2: Chá»n cÃ´ng thá»©c

  

| Workload | Formula | VÃ­ dá»¥ (4 cores) |

|----------|---------|-----------------|

| Pure async I/O | `1 â†’ scale` | 1-4 workers |

| Mixed (I/O > CPU) | `(2Ã—cores)+1` | 9 workers |

| Mixed (CPU > I/O) | `cores` | 4 workers |

| CPU-bound | `cores` | 4 workers |

  

### BÆ°á»›c 3: Load test vÃ  Ä‘iá»u chá»‰nh

  

```bash

# Test vá»›i workers hiá»‡n táº¡i

# Náº¿u CPU > 90% â†’ TÄƒng workers

# Náº¿u CPU < 50% + throughput OK â†’ Giá»¯ nguyÃªn

# Náº¿u CPU < 50% + throughput tháº¥p â†’ TÄƒng workers

```

  

---

  

## TÃ³m táº¯t

  

CÃ¢u há»i: CÃ³ pháº£i FastAPI Ä‘i theo sá»‘ cores vá»›i sá»‘ uvicorn workers?

  

Tráº£ lá»i: KhÃ´ng pháº£i luÃ´n luÃ´n. Phá»¥ thuá»™c vÃ o workload:

  

1. CPU-bound: `workers = cores` (1:1)

2. I/O-bound sync: `workers = (2Ã—cores)+1`

3. Async I/O-bound: `workers = 1` (default) â†’ scale náº¿u cáº§n

  

Vá»›i mem0-server (mixed workload):

- 2 cores â†’ 2-5 workers (tÃ¹y I/O ratio)

- Hiá»‡n táº¡i: 2 workers â†’ OK

- CÃ³ thá»ƒ tÄƒng lÃªn 4-5 náº¿u cáº§n throughput cao hÆ¡n

  

Báº¡n muá»‘n tÃ´i táº¡o má»™t document chi tiáº¿t vá» cÃ¡ch tÃ­nh workers cho tá»«ng loáº¡i workload khÃ´ng?